<PlatformWrapper platform="windows">

### Custom audio capture

Refer to the following call sequence diagram to implement custom audio capture in your app:

<details>
<summary>Custom audio capture</summary>

![Custom audio capture](/images/rtc-sdk/custom-audio-capture.svg)
</details>

Follow these steps to implement custom audio capture in your project:

1. Enable and configure custom audio source:

   Before calling `joinChannel` to join the channel, call `setExternalAudioSource` to enable and configure custom audio capture.

   ```cpp
   // Specify the custom audio source
   m_rtcEngine->setExternalAudioSource(true, m_capAudioInfo.sampleRate, m_capAudioInfo.channels);

   // Local user joins the channel
   ChannelMediaOptions option;
   option.autoSubscribeAudio = true;
   option.autoSubscribeVideo = true;
   m_rtcEngine->joinChannel("Your token", szChannelId.c_str(), 0, option);
   ```

1. Implement audio capture and processing

    Use methods outside the SDK to implement audio capture and processing yourself.

1. Send audio frames to SDK

    Call `pushAudioFrame` to send the captured audio frames to the SDK for later use.

    ```cpp
    mediaEngine->pushAudioFrame(AUDIO_RECORDING_SOURCE, &m_audioFrame);
    ```

### Custom audio rendering

This section shows you how to implement custom audio rendering. Refer to the following call sequence diagram to implement custom audio rendering in your <Vpl k="CLIENT" />:

<details>
<summary>Custom audio rendering workflow</summary>

![Custom Audio Rendering Workflow](/images/rtc-sdk/custom-audio-render.svg)
</details>

To implement custom audio rendering, use the following methods:

1. Enable and configure custom audio sink

    Before calling `joinChannel` to join the channel, call `setExternalAudioSink` to enable and configure custom audio rendering.
    ```cpp
    // Enable custom audio rendering
    // Sample rate (Hz) can be set to 16000, 32000, 44100 or 48000
    // Number of channels can be set to 1 or 2
    nRet = m_rtcEngine->setExternalAudioSink(m_renderAudioInfo.sampleRate, m_renderAudioInfo.channels); 
    ```

1. Pull and render remote audio data

    * After joining the channel, call `pullAudioFrame` to get the audio data sent by the remote user.
    * Use your own audio renderer to process the audio data and then play the rendered data.

    ```cpp
    void CAgoraCaptureAduioDlg::PullAudioFrameThread(CAgoraCaptureAduioDlg * self)
    {
        int nRet = 0;
        agora::util::AutoPtr<agora::media::IMediaEngine> mediaEngine;
        mediaEngine.queryInterface(self->m_rtcEngine, AGORA_IID_MEDIA_ENGINE);
        IAudioFrameObserver::AudioFrame audioFrame;
        audioFrame.avsync_type = 0; // Reserved parameterÂ 
        audioFrame.bytesPerSample = TWO_BYTES_PER_SAMPLE;
        audioFrame.type = agora::media::IAudioFrameObserver::FRAME_TYPE_PCM16;
        audioFrame.channels = self->m_renderAudioInfo.channels;
        audioFrame.samplesPerChannel = self->m_renderAudioInfo.sampleRate / 100 * self->m_renderAudioInfo.channels;
        audioFrame.samplesPerSec = self->m_renderAudioInfo.sampleRate;
        audioFrame.buffer = new BYTE[audioFrame.samplesPerChannel * audioFrame.bytesPerSample];
        while (self->m_extenalRenderAudio )
        {
            // Pull remote audio data
            nRet = mediaEngine->pullAudioFrame(&audioFrame);
            if (nRet != 0)
            {
                Sleep(10);
                continue;
            }
            SIZE_T nSize = audioFrame.samplesPerChannel * audioFrame.bytesPerSample;
            self->m_audioRender.Render((BYTE*)audioFrame.buffer, nSize);
        }
        delete audioFrame.buffer;
    }
    ```

### Using raw audio data callback

This section explains how to implement custom audio rendering.

To retrieve audio data for playback, implement collection and processing of raw audio data. Refer to [Raw audio processing](./advanced-features/stream-raw-audio).

Follow these steps to call the raw audio data API in your project for custom audio rendering:

1. Retrieve audio data for playback using the `onRecordAudioFrame`, `onPlaybackAudioFrame`, `onMixedAudioFrame`, or `onPlaybackAudioFrameBeforeMixing` callback.

2. Independently render and play the audio data.

</PlatformWrapper>