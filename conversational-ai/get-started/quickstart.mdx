---
title: 'Agent quickstart'
sidebar_position: 1
type: docs
platform_selector: false
description: >
  Build a backend server to manage Conversational AI agents.
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';
import ProductOverview from '@site/src/components/ProductOverview';

This guide shows you how to build a backend server that manages <Vpd k="NAME" /> agents through RESTful APIs. You'll create a basic service that starts and stops AI agents, handles authentication, and integrates with your chosen AI models.

## Understand the tech

<Vg k="COMPANY" />'s <Vpd k="NAME" /> is a cloud-based orchestration that enables real-time voice, video, and avatar interactions between users and AI-driven agents within an <Vg k="COMPANY" /> channel. Building a conversational AI application requires two core components:

- **Client App (Front-end)**: The user-facing application where end-users interact with AI agents through voice, video, or text. This is where your AI Avatar would appear (if implemented).
- **Agent Manager (Backend Server)**: The backend server that handles invoking <Vg k="COMPANY" />'s orchestration to deploy an Agent into a given <Vg k="COMPANY" /> channel. This server will define the Agent workflow, either cascading (STT, LLM, TTS) or Multimodal-LLM (voice-to-voice).

![](/images/conversational-ai/ai-agent-tech.svg)

Within the <Vpd k="NAME" /> orchestration, you can define a custom LLM endpoint to connect existing models, add RAG, custom tools, or multi-agent flows. For more details view the [Custom LLM guide](conversational-ai/develop/custom-llm). 

<Admonition type="warning">
Always use a separate server for Agent management and custom LLM. Using a single server will cause the LLM to not respond.
</Admonition>

## Prerequisites

Before you begin, make sure you have:

- A development environment with Node.js (16+), Python (3.8+), or Go (1.19+) installed
- [Enabled <Vg k="COMPANY" /> conversational AI](../get-started/manage-agora-account#enable-conversational-ai) for your project
- The following information from <Vg k="CONSOLE" />:
    - [App ID](../get-started/manage-agora-account#get-the-app-id): The string identifier for your project
    - App Certificate: Required to generate RTC tokens for agent authentication (found in <Vg k="CONSOLE" /> alongside your App ID)
    - [Customer ID and Customer secret](/conversational-ai/rest-api/restful-authentication#generate-customer-id-and-customer-secret): Used for HTTP authentication when calling RESTful APIs
- API keys from your chosen AI service providers (see the AI models section below)

### Client applications

To interact with your AI agents, use one of these demo client applications:

<ProductOverview
    linkButtons={[
        {
            label: "Web Demo (TypeScript)",
            link: "https://github.com/AgoraIO-Community/Conversational-AI-Web-Demo",
            description: "React-based web application for interacting with AI agents",
            variant: "default",
            group: "demos"
        },
        {
            label: "Android Demo",
            link: "https://github.com/AgoraIO-Community/Conversational-AI-Android-Demo",
            description: "Native Android app for AI agent conversations",
            variant: "default",
            group: "demos"
        },
        {
            label: "iOS Demo",
            link: "https://github.com/AgoraIO-Community/Conversational-AI-iOS-Demo",
            description: "Native iOS app for AI agent conversations",
            variant: "default",
            group: "demos"
        }
    ]}
/>

<Admonition type="info">
For the best conversational experience, <Vg k="COMPANY" /> recommends using <Vpd k="NAME" /> with specific <Vg k="COMPANY" /> Video/Voice SDK versions. For details, [contact technical support](mailto:support@agora.io).
</Admonition>

## AI models

Conversational AI agents require AI models to understand speech, generate responses, and speak naturally. <Vpd k="NAME" /> supports two workflow types, each optimized for different use cases:

[IMAGE: Side-by-side comparison diagram showing STT-LLM-TTS pipeline workflow (left) with three separate components flowing linearly, and MLLM workflow (right) with a single multimodal model handling voice-to-voice directly]

<Tabs groupId="workflow">
<TabItem value="pipeline" label="STT-LLM-TTS Pipeline" default>

### STT-LLM-TTS Pipeline

The pipeline workflow chains three specialized AI services to create a conversational agent. Each component excels at its specific task:

- **STT (Speech-to-Text)**: Converts user's spoken words into text
- **LLM (Large Language Model)**: Processes the text, generates intelligent responses
- **TTS (Text-to-Speech)**: Converts the LLM's text responses into natural-sounding speech

[IMAGE: Flow diagram showing: User audio → STT (transcribe) → LLM (think) → TTS (speak) → Agent audio, with each step labeled with its function and example provider]

This approach gives you flexibility to mix and match providers based on your needs—whether you want to optimize for cost, speed, language support, or voice quality. For example, you might use <Vg k="COMPANY" />'s ARES for fast speech recognition, OpenAI's GPT-4 for smarter responses, and ElevenLabs for natural-sounding voices.

#### Recommended starter configuration

This configuration provides excellent quality with straightforward setup. No additional API keys are needed for the ASR component as it uses <Vg k="COMPANY" />'s built-in ARES engine:

| Component | Recommended Model | Alternative Options |
|-----------|------------------|---------------------|
| **ASR** | [ARES](/conversational-ai/models/asr/ares) (Built-in) | [Microsoft Azure](/conversational-ai/models/asr/microsoft), [Deepgram](/conversational-ai/models/asr/deepgram), [AssemblyAI](/conversational-ai/models/asr/assembly-ai) |
| **LLM** | [OpenAI GPT-4o mini](/conversational-ai/models/llm/openai) | [Azure OpenAI](/conversational-ai/models/llm/azure-openai), [Google Gemini](/conversational-ai/models/llm/gemini), [Claude](/conversational-ai/models/llm/claude) |
| **TTS** | [Microsoft Azure](/conversational-ai/models/tts/microsoft) | [ElevenLabs](/conversational-ai/models/tts/elevenlabs), [Cartesia](/conversational-ai/models/tts/cartesia), [OpenAI](/conversational-ai/models/tts/openai) |

#### When to use the pipeline

Choose the STT-LLM-TTS pipeline when you need:
- Full control over each AI component
- Ability to switch providers independently
- Cost optimization by mixing free/paid services
- Support for specific languages or voices
- Integration with custom LLM endpoints or RAG systems

See the [ASR overview](/conversational-ai/models/asr/overview), [LLM overview](/conversational-ai/models/llm/overview), and [TTS overview](/conversational-ai/models/tts/overview) for complete provider catalogs and configuration details.

</TabItem>
<TabItem value="mllm" label="MLLM (Voice-to-Voice)">

### MLLM (Multimodal Large Language Model)

The MLLM workflow uses a single, powerful AI model that processes voice input directly and generates voice output—no separate STT or TTS needed. This creates faster, more natural conversations with better context understanding.

[IMAGE: Flow diagram showing: User audio → MLLM (listen, think, speak) → Agent audio, with the MLLM shown as a single unified component]

MLLMs like OpenAI's Realtime API and Google's Gemini Live understand audio directly. They can pick up on tone, emotion, and speech patterns that get lost when converting to text first. This means faster responses that sound more natural.

#### Supported MLLM providers

<Vpd k="NAME" /> currently supports:

| Provider | Model | Key Advantages |
|----------|-------|----------------|
| **[OpenAI Realtime API](/conversational-ai/models/mllm/openai)** | GPT-4o Realtime | Excellent conversational abilities, low latency, multiple voices |
| **[Google Gemini Live](/conversational-ai/models/mllm/gemini)** | Gemini 2.5 Flash | Fast responses, strong multilingual support, cost-effective |

#### Important notes

When you enable MLLM mode (`enable_mllm: true`), the system automatically disables separate ASR, LLM, and TTS configurations since the MLLM handles everything.

Keep in mind:
- Intelligent interruption handling (`enable_aivad`) isn't available with MLLM
- Turn detection works differently (see [`turn_detection`](/conversational-ai/rest-api/agent/join#turn-detection))

#### When to use MLLM

Choose MLLM when you want:
- The fastest response times
- More natural-sounding conversations
- Simpler setup (one model instead of three)
- Better understanding of tone and emotion
- Access to the latest AI capabilities

See the [MLLM overview](/conversational-ai/models/mllm/overview) for detailed configuration instructions and capabilities.

</TabItem>
</Tabs>

<Admonition type="tip">
If you're just getting started, use the STT-LLM-TTS pipeline. It's easier to debug and gives you more control. You can always switch to MLLM later when you want faster response times.
</Admonition>

## Implementation

This section shows you how to build a complete backend server with endpoints to start and stop conversational AI agents. Pick your language—all three examples do the same thing.

### Project initialization

Create a new project directory and set it up for your language. This creates the basic structure you'll need.

<Tabs groupId="language">
<TabItem value="node" label="Node.js" default>

<CodeBlock language="bash">{`# Create project directory
mkdir agora-ai-backend
cd agora-ai-backend\n
# Initialize Node.js project
npm init -y\n
# Create source directory
mkdir src
touch src/server.js`}</CodeBlock>

Your project structure:

<CodeBlock language="text">{`agora-ai-backend/
├── package.json
├── .env
└── src/
    └── server.js`}</CodeBlock>

</TabItem>
<TabItem value="python" label="Python">

<CodeBlock language="bash">{`# Create project directory
mkdir agora-ai-backend
cd agora-ai-backend\n
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n
# Create source file
touch server.py`}</CodeBlock>

Your project structure:

<CodeBlock language="text">{`agora-ai-backend/
├── requirements.txt
├── .env
├── venv/
└── server.py`}</CodeBlock>

</TabItem>
<TabItem value="go" label="Go">

<CodeBlock language="bash">{`# Create project directory
mkdir agora-ai-backend
cd agora-ai-backend\n
# Initialize Go module
go mod init agora-ai-backend\n
# Create source file
touch server.go`}</CodeBlock>

Your project structure:

<CodeBlock language="text">{`agora-ai-backend/
├── go.mod
├── go.sum
├── .env
└── server.go`}</CodeBlock>

</TabItem>
</Tabs>

### Install packages

Install the packages you need to run an HTTP server, make API calls, and load environment variables.

<Tabs groupId="language">
<TabItem value="node" label="Node.js" default>

<CodeBlock language="bash">{`npm install express dotenv agora-token`}</CodeBlock>

What these packages do:
- **express**: Handles HTTP requests and API endpoints
- **dotenv**: Loads credentials from your .env file
- **agora-token**: Generates RTC tokens for agent authentication

Node.js 18+ includes fetch built-in, so you don't need an extra package for API calls.

</TabItem>
<TabItem value="python" label="Python">

Create a `requirements.txt` file:

<CodeBlock language="text">{`fastapi==0.104.1
uvicorn==0.24.0
requests==2.31.0
python-dotenv==1.0.0
agora-token-builder`}</CodeBlock>

Install dependencies:

<CodeBlock language="bash">{`pip install -r requirements.txt`}</CodeBlock>

What these packages do:
- **fastapi**: Fast HTTP server framework with automatic API docs
- **uvicorn**: Server that runs your FastAPI app
- **requests**: Makes HTTP calls to <Vg k="COMPANY" />'s APIs
- **python-dotenv**: Loads credentials from your .env file
- **agora-token-builder**: Generates RTC tokens for agent authentication

</TabItem>
<TabItem value="go" label="Go">

<CodeBlock language="bash">{`go get github.com/gin-gonic/gin
go get github.com/joho/godotenv
go get github.com/AgoraIO-Community/go-tokenbuilder/rtctokenbuilder2`}</CodeBlock>

What these packages do:
- **gin**: Fast HTTP server framework
- **godotenv**: Loads credentials from your .env file
- **go-tokenbuilder**: Generates RTC tokens for agent authentication

Go's standard library already includes HTTP client functionality (`net/http`), so you don't need an extra package for API calls.

</TabItem>
</Tabs>

### Environment configuration

Create a `.env` file to store your credentials. Never commit this file to version control—add it to `.gitignore` right away.

Create `.env` in your project root:

<CodeBlock language="bash">{`# Agora Credentials
AGORA_APP_ID=your_app_id_here
AGORA_APP_CERTIFICATE=your_app_certificate_here
AGORA_CUSTOMER_ID=your_customer_id_here
AGORA_CUSTOMER_SECRET=your_customer_secret_here\n
# AI Model API Keys
OPENAI_API_KEY=your_openai_api_key_here
MICROSOFT_TTS_KEY=your_microsoft_key_here
MICROSOFT_TTS_REGION=eastus\n
# Server Configuration
PORT=3000`}</CodeBlock>

**What each variable does:**

- `AGORA_APP_ID`: Identifies your Agora project
- `AGORA_APP_CERTIFICATE`: Used to generate RTC tokens for agent authentication (keep this secret—never expose it to clients)
- `AGORA_CUSTOMER_ID` & `AGORA_CUSTOMER_SECRET`: Authenticate your server with Agora's APIs (keep these secret—never expose them to clients)
- `OPENAI_API_KEY`: Lets you call OpenAI's API for LLM or MLLM
- `MICROSOFT_TTS_KEY` & `MICROSOFT_TTS_REGION`: Lets you call Microsoft's text-to-speech API (only needed for STT-LLM-TTS pipeline)
- `PORT`: The port your server runs on

<Admonition type="warning">
Keep your `.env` file secure. Add it to `.gitignore` immediately to prevent accidentally committing credentials to version control.
</Admonition>

### Generate authentication credentials

Your server needs to authenticate with <Vg k="COMPANY" />'s APIs using HTTP Basic Authentication. You'll also need to generate RTC tokens for agents to join channels. Here's how to do both:

<Tabs groupId="language">
<TabItem value="node" label="Node.js" default>

<CodeBlock language="javascript">{`const \{
  RtcTokenBuilder,
  RtcRole
\} = require('agora-token');\n
// Generate Base64 credentials for Agora API authentication
function generateBasicAuth(customerId, customerSecret) \{
  const credentials = \`\$\{customerId\}:\$\{customerSecret\}\`;
  return Buffer.from(credentials).toString('base64');
\}\n
// Generate RTC token for agent to join channel
function generateRtcToken(appId, appCertificate, channelName, uid, role, expireTime) \{
  return RtcTokenBuilder.buildTokenWithUid(
    appId,
    appCertificate,
    channelName,
    uid,
    role,
    expireTime
  );
\}`}</CodeBlock>

</TabItem>
<TabItem value="python" label="Python">

<CodeBlock language="python">{`from agora_token_builder import RtcTokenBuilder, RtcRole
import base64
from datetime import datetime, timedelta\n
# Generate Base64 credentials for Agora API authentication
def generate_basic_auth(customer_id: str, customer_secret: str) -> str:
    credentials = f"\{customer_id\}:\{customer_secret\}"
    return base64.b64encode(credentials.encode()).decode()\n
# Generate RTC token for agent to join channel
def generate_rtc_token(app_id: str, app_certificate: str, channel_name: str, uid: int, role: int, expire_time: int) -> str:
    return RtcTokenBuilder.buildTokenWithUid(
        app_id,
        app_certificate,
        channel_name,
        uid,
        role,
        expire_time
    )`}</CodeBlock>

</TabItem>
<TabItem value="go" label="Go">

<CodeBlock language="go">{`import (
    "encoding/base64"
    "time"
    "github.com/AgoraIO-Community/go-tokenbuilder/rtctokenbuilder2"
)\n
// Generate Base64 credentials for Agora API authentication
func generateBasicAuth(customerID, customerSecret string) string \{
    credentials := customerID + ":" + customerSecret
    return base64.StdEncoding.EncodeToString([]byte(credentials))
\}\n
// Generate RTC token for agent to join channel
func generateRtcToken(appID, appCertificate, channelName string, uid uint32, role rtctokenbuilder2.Role, expireTime uint32) (string, error) \{
    token := rtctokenbuilder2.BuildTokenWithUid(appID, appCertificate, channelName, uid, role, expireTime)
    return token, nil
\}`}</CodeBlock>

</TabItem>
</Tabs>

For more details on authentication, see [RESTful authentication](/conversational-ai/rest-api/restful-authentication).

### Complete server implementation

Here's the complete backend server with start and stop agent endpoints, to invoke agents using the <Vpd k="NAME" />.

<Tabs groupId="language">
<TabItem value="node" label="Node.js" default>

<CodeBlock language="javascript">{`require('dotenv').config();
const express = require('express');
const \{ RtcTokenBuilder, RtcRole \} = require('agora-token');\n
const app = express();
app.use(express.json());\n
// Load environment variables
const \{
  AGORA_APP_ID,
  AGORA_APP_CERTIFICATE,
  AGORA_CUSTOMER_ID,
  AGORA_CUSTOMER_SECRET,
  OPENAI_API_KEY,
  MICROSOFT_TTS_KEY,
  MICROSOFT_TTS_REGION,
  PORT = 3000
\} = process.env;\n
// Generate Base64 credentials for Agora API authentication
function generateBasicAuth(customerId, customerSecret) \{
  const credentials = \`\$\{customerId\}:\$\{customerSecret\}\`;
  return Buffer.from(credentials).toString('base64');
\}\n
// Generate RTC token for agent to join channel
function generateRtcToken(channelName, uid) \{
  const currentTimestamp = Math.floor(Date.now() / 1000);
  const expireTimestamp = currentTimestamp + 3600; // Token expires in 1 hour
  return RtcTokenBuilder.buildTokenWithUid(
    AGORA_APP_ID,
    AGORA_APP_CERTIFICATE,
    channelName,
    uid,
    RtcRole.PUBLISHER,
    expireTimestamp
  );
\}\n
const basicAuth = generateBasicAuth(AGORA_CUSTOMER_ID, AGORA_CUSTOMER_SECRET);\n
// Health check endpoint
app.get('/health', (req, res) => \{
  res.json(\{ status: 'ok', timestamp: new Date().toISOString() \});
\});\n
// Start agent endpoint
app.post('/agents/start', async (req, res) => \{
  try \{
    const \{ channelName, agentName, userUids \} = req.body;\n
    // Validate required fields
    if (!channelName || !agentName) \{
      return res.status(400).json(\{
        error: 'Missing required fields',
        required: ['channelName', 'agentName']
      \});
    \}\n
    // Parse userUids - split comma-separated string
    if (typeof userUids !== 'string') \{
      return res.status(400).json(\{
        error: 'userUids must be a comma-separated string'
      \});
    \}\n
    const remoteRtcUids = userUids.split(',').map(uid => uid.trim()).filter(uid => uid.length > 0);\n
    if (remoteRtcUids.length === 0) \{
      return res.status(400).json(\{
        error: 'userUids cannot be empty'
      \});
    \}\n
    const agentUid = 1001; // Define your agent UID to easily identify the agent streams on the client-side
    const token = generateRtcToken(channelName, agentUid);\n
    // Configure agent with STT-LLM-TTS pipeline
    const agentConfig = \{
      name: agentName,
      properties: \{
        channel: channelName,
        token: token,
        agent_rtc_uid: String(agentUid),
        remote_rtc_uids: remoteRtcUids.map(uid => String(uid)),
        enable_string_uid: false,
        idle_timeout: 120,
        llm: \{
          url: "https://api.openai.com/v1/chat/completions",
          api_key: OPENAI_API_KEY,
          system_messages: [
            \{
              role: "system",
              content: "You are a helpful AI assistant powered by Agora's Conversational AI Engine."
            \}
          ],
          greeting_message: "Hello! How can I help you today?",
          failure_message: "I'm having trouble processing that. Could you try again?",
          max_history: 10,
          params: \{
            model: "gpt-4o-mini"
          \}
        \},
        asr: \{
          language: "en-US"
        \},
        tts: \{
          vendor: "microsoft",
          params: \{
            key: MICROSOFT_TTS_KEY,
            region: MICROSOFT_TTS_REGION,
            voice_name: "en-US-AndrewMultilingualNeural"
          \}
        \}
      \}
    \};\n
    // Call Agora API to start the agent
    const response = await fetch(
      \`https://api.agora.io/api/conversational-ai-agent/v2/projects/\$\{AGORA_APP_ID\}/join\`,
      \{
        method: 'POST',
        headers: \{
          'Authorization': \`Basic \$\{basicAuth\}\`,
          'Content-Type': 'application/json'
        \},
        body: JSON.stringify(agentConfig)
      \}
    );\n
    const data = await response.json();\n
    if (!response.ok) \{
      return res.status(response.status).json(\{
        error: 'Failed to start agent',
        details: data
      \});
    \}\n
    // Return agent information to client
    res.json(\{
      success: true,
      agentId: data.agent_id,
      status: data.status,
      createTime: data.create_ts
    \});
  \} catch (error) \{
    console.error('Error starting agent:', error.message);
    res.status(500).json(\{
      error: 'Failed to start agent',
      details: error.message
    \});
  \}
\});\n
// Stop agent endpoint
app.post('/agents/:agentId/stop', async (req, res) => \{
  try \{
    const \{ agentId \} = req.params;\n
    // Call Agora API to stop the agent
    const response = await fetch(
      \`https://api.agora.io/api/conversational-ai-agent/v2/projects/\$\{AGORA_APP_ID\}/agents/\$\{agentId\}/leave\`,
      \{
        method: 'POST',
        headers: \{
          'Authorization': \`Basic \$\{basicAuth\}\`,
          'Content-Type': 'application/json'
        \}
      \}
    );\n
    if (!response.ok) \{
      const data = await response.json();
      return res.status(response.status).json(\{
        error: 'Failed to stop agent',
        details: data
      \});
    \}\n
    res.json(\{
      success: true,
      message: 'Agent stopped successfully'
    \});
  \} catch (error) \{
    console.error('Error stopping agent:', error.message);
    res.status(500).json(\{
      error: 'Failed to stop agent',
      details: error.message
    \});
  \}
\});\n
// Start server
app.listen(PORT, () => \{
  console.log(\`Agora AI backend server running on port \$\{PORT\}\`);
  console.log(\`Health check: http://localhost:\$\{PORT\}/health\`);
\});`}</CodeBlock>

Run your server:

<CodeBlock language="bash">{`node src/server.js`}</CodeBlock>

</TabItem>
<TabItem value="python" label="Python">

<CodeBlock language="python">{`import os
import base64
from datetime import datetime, timedelta
from typing import Optional
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import requests
from dotenv import load_dotenv
from agora_token_builder import RtcTokenBuilder, RtcRole
import uvicorn\n
# Load environment variables
load_dotenv()\n
app = FastAPI(title="Agora AI Backend")\n
# Configuration
AGORA_APP_ID = os.getenv("AGORA_APP_ID")
AGORA_APP_CERTIFICATE = os.getenv("AGORA_APP_CERTIFICATE")
AGORA_CUSTOMER_ID = os.getenv("AGORA_CUSTOMER_ID")
AGORA_CUSTOMER_SECRET = os.getenv("AGORA_CUSTOMER_SECRET")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MICROSOFT_TTS_KEY = os.getenv("MICROSOFT_TTS_KEY")
MICROSOFT_TTS_REGION = os.getenv("MICROSOFT_TTS_REGION")
PORT = int(os.getenv("PORT", 3000))\n
# Generate Base64 credentials for Agora API authentication
def generate_basic_auth(customer_id: str, customer_secret: str) -> str:
    credentials = f"\{customer_id\}:\{customer_secret\}"
    return base64.b64encode(credentials.encode()).decode()\n
# Generate RTC token for agent to join channel
def generate_rtc_token(channel_name: str, uid: int) -> str:
    current_timestamp = int(datetime.now().timestamp())
    expire_timestamp = current_timestamp + 3600  # Token expires in 1 hour
    return RtcTokenBuilder.buildTokenWithUid(
        AGORA_APP_ID,
        AGORA_APP_CERTIFICATE,
        channel_name,
        uid,
        RtcRole.Publisher,
        expire_timestamp
    )\n
basic_auth = generate_basic_auth(AGORA_CUSTOMER_ID, AGORA_CUSTOMER_SECRET)\n
# Request models
class StartAgentRequest(BaseModel):
    channelName: str
    agentName: str
    userUids: str  # Comma-separated string of UIDs\n
# Health check endpoint
@app.get("/health")
async def health_check():
    return \{"status": "ok", "timestamp": datetime.now().isoformat()\}\n
# Start agent endpoint
@app.post("/agents/start")
async def start_agent(request: StartAgentRequest):
    try:
        # Parse userUids - split comma-separated string
        remote_rtc_uids = [uid.strip() for uid in request.userUids.split(',') if uid.strip()]\n
        if len(remote_rtc_uids) == 0:
            raise HTTPException(
                status_code=400,
                detail="userUids cannot be empty"
            )\n
        agent_uid = 1001  # Define your agent UID to easily identify the agent streams on the client-side
        token = generate_rtc_token(request.channelName, agent_uid)\n
        # Configure agent with STT-LLM-TTS pipeline
        agent_config = \{
            "name": request.agentName,
            "properties": \{
                "channel": request.channelName,
                "token": token,  # Generated token for agent authentication
                "agent_rtc_uid": str(agent_uid),
                "remote_rtc_uids": [str(uid) for uid in remote_rtc_uids],
                "enable_string_uid": False,
                "idle_timeout": 120,
                "llm": \{
                    "url": "https://api.openai.com/v1/chat/completions",
                    "api_key": OPENAI_API_KEY,
                    "system_messages": [
                        \{
                            "role": "system",
                            "content": "You are a helpful AI assistant powered by Agora's Conversational AI Engine."
                        \}
                    ],
                    "greeting_message": "Hello! How can I help you today?",
                    "failure_message": "I'm having trouble processing that. Could you try again?",
                    "max_history": 10,
                    "params": \{
                        "model": "gpt-4o-mini"
                    \}
                \},
                "asr": \{
                    "language": "en-US"
                \},
                "tts": \{
                    "vendor": "microsoft",
                    "params": \{
                        "key": MICROSOFT_TTS_KEY,
                        "region": MICROSOFT_TTS_REGION,
                        "voice_name": "en-US-AndrewMultilingualNeural"
                    \}
                \}
            \}
        \}\n
        # Call Agora API to start the agent
        response = requests.post(
            f"https://api.agora.io/api/conversational-ai-agent/v2/projects/\{AGORA_APP_ID\}/join",
            json=agent_config,
            headers=\{
                "Authorization": f"Basic \{basic_auth\}",
                "Content-Type": "application/json"
            \}
        )\n
        if response.status_code != 200:
            raise HTTPException(
                status_code=response.status_code,
                detail=response.json()
            )\n
        data = response.json()
        return \{
            "success": True,
            "agentId": data["agent_id"],
            "status": data["status"],
            "createTime": data["create_ts"]
        \}
    except requests.exceptions.RequestException as e:
        raise HTTPException(status_code=500, detail=str(e))\n
# Stop agent endpoint
@app.post("/agents/\{agent_id\}/stop")
async def stop_agent(agent_id: str):
    try:
        # Call Agora API to stop the agent
        response = requests.post(
            f"https://api.agora.io/api/conversational-ai-agent/v2/projects/\{AGORA_APP_ID\}/agents/\{agent_id\}/leave",
            headers=\{
                "Authorization": f"Basic \{basic_auth\}",
                "Content-Type": "application/json"
            \}
        )\n
        if response.status_code != 200:
            raise HTTPException(
                status_code=response.status_code,
                detail=response.json()
            )\n
        return \{
            "success": True,
            "message": "Agent stopped successfully"
        \}
    except requests.exceptions.RequestException as e:
        raise HTTPException(status_code=500, detail=str(e))\n
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=PORT)`}</CodeBlock>

Run your server:

<CodeBlock language="bash">{`python server.py`}</CodeBlock>

</TabItem>
<TabItem value="go" label="Go">

<CodeBlock language="go">{`package main\n
import (
    "bytes"
    "encoding/base64"
    "encoding/json"
    "fmt"
    "io"
    "log"
    "net/http"
    "os"
    "time"\n
    "github.com/gin-gonic/gin"
    "github.com/joho/godotenv"
    "github.com/AgoraIO-Community/go-tokenbuilder/rtctokenbuilder2"
)\n
// Config holds environment variables
type Config struct \{
    AppID              string
    AppCertificate     string
    CustomerID         string
    CustomerSecret     string
    OpenAIKey          string
    MicrosoftTTSKey    string
    MicrosoftTTSRegion string
    Port               string
\}\n
// StartAgentRequest represents the request body for starting an agent
type StartAgentRequest struct \{
    ChannelName string \`json:"channelName"\`
    AgentName   string \`json:"agentName"\`
    UserUIDs    string \`json:"userUids"\` // Comma-separated string of UIDs
\}\n
// AgentResponse represents the response from Agora API
type AgentResponse struct \{
    AgentID   string \`json:"agent_id"\`
    CreateTS  int64  \`json:"create_ts"\`
    Status    string \`json:"status"\`
\}\n
var config Config
var basicAuth string\n
// Generate RTC token for agent to join channel
func generateRtcToken(channelName string, uid uint32) (string, error) \{
    currentTimestamp := uint32(time.Now().Unix())
    expireTimestamp := currentTimestamp + 3600 // Token expires in 1 hour
    token := rtctokenbuilder2.BuildTokenWithUid(
        config.AppID,
        config.AppCertificate,
        channelName,
        uid,
        rtctokenbuilder2.RolePublisher,
        expireTimestamp,
    )
    return token, nil
\}\n
func main() \{
    // Load environment variables
    if err := godotenv.Load(); err != nil \{
        log.Println("No .env file found")
    \}\n
    config = Config\{
        AppID:              os.Getenv("AGORA_APP_ID"),
        AppCertificate:     os.Getenv("AGORA_APP_CERTIFICATE"),
        CustomerID:         os.Getenv("AGORA_CUSTOMER_ID"),
        CustomerSecret:     os.Getenv("AGORA_CUSTOMER_SECRET"),
        OpenAIKey:          os.Getenv("OPENAI_API_KEY"),
        MicrosoftTTSKey:    os.Getenv("MICROSOFT_TTS_KEY"),
        MicrosoftTTSRegion: os.Getenv("MICROSOFT_TTS_REGION"),
        Port:               getEnv("PORT", "3000"),
    \}\n
    // Generate Base64 credentials for Agora API authentication
    basicAuth = generateBasicAuth(config.CustomerID, config.CustomerSecret)\n
    // Setup HTTP server
    gin.SetMode(gin.ReleaseMode)
    router := gin.Default()\n
    // Routes
    router.GET("/health", healthCheck)
    router.POST("/agents/start", startAgent)
    router.POST("/agents/:agentId/stop", stopAgent)\n
    // Start server
    log.Printf("Agora AI backend server running on port %s", config.Port)
    log.Printf("Health check: http://localhost:%s/health", config.Port)
    if err := router.Run(":" + config.Port); err != nil \{
        log.Fatal("Failed to start server:", err)
    \}
\}\n
// Helper function to generate Base64 authentication string
func generateBasicAuth(customerID, customerSecret string) string \{
    credentials := customerID + ":" + customerSecret
    return base64.StdEncoding.EncodeToString([]byte(credentials))
\}\n
// Helper function to get environment variable with default
func getEnv(key, defaultVal string) string \{
    if value := os.Getenv(key); value != "" \{
        return value
    \}
    return defaultVal
\}\n
// Health check endpoint
func healthCheck(c *gin.Context) \{
    c.JSON(http.StatusOK, gin.H\{
        "status":    "ok",
        "timestamp": time.Now().Format(time.RFC3339),
    \})
\}\n
// Start agent endpoint
func startAgent(c *gin.Context) \{
    var req StartAgentRequest
    if err := c.ShouldBindJSON(&req); err != nil \{
        c.JSON(http.StatusBadRequest, gin.H\{
            "error":    "Missing required fields",
            "required": []string\{"channelName", "agentName", "userUids"\},
        \})
        return
    \}\n
    // Parse userUids - split comma-separated string
    uids := strings.Split(req.UserUIDs, ",")
    remoteRtcUids := make([]string, 0, len(uids))
    for _, uid := range uids \{
        uid = strings.TrimSpace(uid)
        if uid != "" \{
            remoteRtcUids = append(remoteRtcUids, uid)
        \}
    \}\n
    if len(remoteRtcUids) == 0 \{
        c.JSON(http.StatusBadRequest, gin.H\{
            "error": "userUids cannot be empty",
        \})
        return
    \}\n
    agentUID := uint32(1001) // Define your agent UID to easily identify the agent streams on the client-side
    token, err := generateRtcToken(req.ChannelName, agentUID)
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to generate token"\})
        return
    \}\n
    // Configure agent with STT-LLM-TTS pipeline
    agentConfig := map[string]interface\{\}\{
        "name": req.AgentName,
        "properties": map[string]interface\{\}\{
            "channel":           req.ChannelName,
            "token":             token, // Generated token for agent authentication
            "agent_rtc_uid":     fmt.Sprintf("%d", agentUID),
            "remote_rtc_uids":   remoteRtcUids,
            "enable_string_uid": false,
            "idle_timeout":      120,
            "llm": map[string]interface\{\}\{
                "url":     "https://api.openai.com/v1/chat/completions",
                "api_key": config.OpenAIKey,
                "system_messages": []map[string]string\{
                    \{
                        "role":    "system",
                        "content": "You are a helpful AI assistant powered by Agora's Conversational AI Engine.",
                    \},
                \},
                "greeting_message": "Hello! How can I help you today?",
                "failure_message":  "I'm having trouble processing that. Could you try again?",
                "max_history":      10,
                "params": map[string]string\{
                    "model": "gpt-4o-mini",
                \},
            \},
            "asr": map[string]string\{
                "language": "en-US",
            \},
            "tts": map[string]interface\{\}\{
                "vendor": "microsoft",
                "params": map[string]string\{
                    "key":        config.MicrosoftTTSKey,
                    "region":     config.MicrosoftTTSRegion,
                    "voice_name": "en-US-AndrewMultilingualNeural",
                \},
            \},
        \},
    \}\n
    // Marshal config to JSON
    jsonData, err := json.Marshal(agentConfig)
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to create request"\})
        return
    \}\n
    // Call Agora API to start the agent
    url := fmt.Sprintf("https://api.agora.io/api/conversational-ai-agent/v2/projects/%s/join", config.AppID)
    httpReq, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to create request"\})
        return
    \}\n
    httpReq.Header.Set("Authorization", "Basic "+basicAuth)
    httpReq.Header.Set("Content-Type", "application/json")\n
    client := &http.Client\{Timeout: 10 * time.Second\}
    resp, err := client.Do(httpReq)
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to call Agora API"\})
        return
    \}
    defer resp.Body.Close()\n
    body, err := io.ReadAll(resp.Body)
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to read response"\})
        return
    \}\n
    if resp.StatusCode != http.StatusOK \{
        c.JSON(resp.StatusCode, gin.H\{
            "error":   "Failed to start agent",
            "details": string(body),
        \})
        return
    \}\n
    var agentResp AgentResponse
    if err := json.Unmarshal(body, &agentResp); err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to parse response"\})
        return
    \}\n
    c.JSON(http.StatusOK, gin.H\{
        "success":    true,
        "agentId":    agentResp.AgentID,
        "status":     agentResp.Status,
        "createTime": agentResp.CreateTS,
    \})
\}\n
// Stop agent endpoint
func stopAgent(c *gin.Context) \{
    agentID := c.Param("agentId")\n
    // Call Agora API to stop the agent
    url := fmt.Sprintf("https://api.agora.io/api/conversational-ai-agent/v2/projects/%s/agents/%s/leave",
        config.AppID, agentID)
    httpReq, err := http.NewRequest("POST", url, nil)
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to create request"\})
        return
    \}\n
    httpReq.Header.Set("Authorization", "Basic "+basicAuth)
    httpReq.Header.Set("Content-Type", "application/json")\n
    client := &http.Client\{Timeout: 10 * time.Second\}
    resp, err := client.Do(httpReq)
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to call Agora API"\})
        return
    \}
    defer resp.Body.Close()\n
    if resp.StatusCode != http.StatusOK \{
        body, _ := io.ReadAll(resp.Body)
        c.JSON(resp.StatusCode, gin.H\{
            "error":   "Failed to stop agent",
            "details": string(body),
        \})
        return
    \}\n
    c.JSON(http.StatusOK, gin.H\{
        "success": true,
        "message": "Agent stopped successfully",
    \})
\}`}</CodeBlock>

Run your server:

<CodeBlock language="bash">{`go run server.go`}</CodeBlock>

</TabItem>
</Tabs>

### Test your server

Test your endpoints to ensure everything works correctly:

**1. Health check:**

<CodeBlock language="bash">{`curl http://localhost:3000/health`}</CodeBlock>

Expected response:

<CodeBlock language="json">{`\{
  "status": "ok",
  "timestamp": "2025-01-15T10:30:00.000Z"
\}`}</CodeBlock>

**2. Start an agent:**

<CodeBlock language="bash">{`# Single user UID
curl -X POST http://localhost:3000/agents/start \\
  -H "Content-Type: application/json" \\
  -d '\{
    "channelName": "test-channel",
    "agentName": "test-agent-1",
    "userUids": "1002"
  \}'\n
# Multiple user UIDs (comma-separated)
curl -X POST http://localhost:3000/agents/start \\
  -H "Content-Type: application/json" \\
  -d '\{
    "channelName": "test-channel",
    "agentName": "test-agent-1",
    "userUids": "1002,1003"
  \}'`}</CodeBlock>

Expected response:

<CodeBlock language="json">{`\{
  "success": true,
  "agentId": "1NT29X10YHxxxxxWJOXLYHNYB",
  "status": "RUNNING",
  "createTime": 1737111452
\}`}</CodeBlock>

**3. Stop the agent:**

<CodeBlock language="bash">{`curl -X POST http://localhost:3000/agents/1NT29X10YHxxxxxWJOXLYHNYB/stop`}</CodeBlock>

Expected response:

<CodeBlock language="json">{`\{
  "success": true,
  "message": "Agent stopped successfully"
\}`}</CodeBlock>

<Admonition type="info">
Store the `agentId` returned from the start endpoint. You'll need it to stop, query, or update the agent. In production, save this to a database associated with the user's session.
</Admonition>

### Using MLLM instead of the pipeline

To use multimodal voice-to-voice models instead of the STT-LLM-TTS pipeline, modify the agent configuration in the start endpoint:

<Tabs groupId="language">
<TabItem value="node" label="Node.js" default>

<CodeBlock language="javascript">{`// Replace the agent_config in the /agents/start endpoint with:
// Note: userUids should already be normalized to an array from the request
const agentConfig = \{
  name: agentName,
  properties: \{
    channel: channelName,
    token: token,
    agent_rtc_uid: String(agentUid), // Use the defined agent UID
    remote_rtc_uids: remoteRtcUids, // Already normalized to array
    enable_string_uid: false,
    idle_timeout: 120,
    advanced_features: \{
      enable_mllm: true  // Enable MLLM mode
    \},
    mllm: \{
      url: "wss://api.openai.com/v1/realtime",
      api_key: OPENAI_API_KEY,
      params: \{
        model: "gpt-realtime",
        voice: "coral",
        instructions: "You are a helpful AI assistant powered by Agora's Conversational AI Engine."
      \},
      greeting_message: "Hello! How can I help you today?",
      output_modalities: ["text", "audio"],
      vendor: "openai",
      style: "openai"
    \}
  \}
\};`}</CodeBlock>

</TabItem>
<TabItem value="python" label="Python">

<CodeBlock language="python">{`# Replace the agent_config in the /agents/start endpoint with:
# Note: remote_rtc_uids should already be normalized to a list from the request
agent_config = \{
    "name": request.agentName,
    "properties": \{
        "channel": request.channelName,
        "token": token,  # Generated token
        "agent_rtc_uid": str(agent_uid),  # Use the defined agent UID
        "remote_rtc_uids": remote_rtc_uids,  # Already normalized to list
        "enable_string_uid": False,
        "idle_timeout": 120,
        "advanced_features": \{
            "enable_mllm": True  # Enable MLLM mode
        \},
        "mllm": \{
            "url": "wss://api.openai.com/v1/realtime",
            "api_key": OPENAI_API_KEY,
            "params": \{
                "model": "gpt-realtime",
                "voice": "coral",
                "instructions": "You are a helpful AI assistant powered by Agora's Conversational AI Engine."
            \},
            "greeting_message": "Hello! How can I help you today?",
            "output_modalities": ["text", "audio"],
            "vendor": "openai",
            "style": "openai"
        \}
    \}
\}`}</CodeBlock>

</TabItem>
<TabItem value="go" label="Go">

<CodeBlock language="go">{`// Replace the agentConfig in the startAgent function with:
agentConfig := map[string]interface\{\}\{
    "name": req.AgentName,
    "properties": map[string]interface\{\}\{
        "channel":           req.ChannelName,
        "token":             token,  // Generated token
        "agent_rtc_uid":     fmt.Sprintf("%d", agentUID),  // Use the defined agent UID
        "remote_rtc_uids":   remoteRtcUids,  // Already normalized to []string
        "enable_string_uid": false,
        "idle_timeout":      120,
        "advanced_features": map[string]bool\{
            "enable_mllm": true,  // Enable MLLM mode
        \},
        "mllm": map[string]interface\{\}\{
            "url":     "wss://api.openai.com/v1/realtime",
            "api_key": config.OpenAIKey,
            "params": map[string]string\{
                "model":        "gpt-realtime",
                "voice":        "coral",
                "instructions": "You are a helpful AI assistant powered by Agora's Conversational AI Engine.",
            \},
            "greeting_message":   "Hello! How can I help you today?",
            "output_modalities":  []string\{"text", "audio"\},
            "vendor":             "openai",
            "style":              "openai",
        \},
    \},
\}`}</CodeBlock>

</TabItem>
</Tabs>

<Admonition type="caution">
When `enable_mllm` is true, do NOT include `asr`, `llm`, or `tts` configurations. The MLLM handles all voice processing internally.
</Admonition>

### Next steps

You now have a working backend server that manages Conversational AI agents. Here's what to do next:

1. **Test with a demo app**: Use one of the demo client applications (Web, Android, or iOS) linked in the Prerequisites section. Configure them to call your backend's `/agents/start` endpoint. Save the returned `agentId` so you can stop the agent later.

2. **Customize your agent**: Edit the `system_messages` in the LLM config to give your agent specific knowledge, personality, or instructions.

3. **Add advanced features**: Check out [Custom LLM integration](conversational-ai/develop/custom-llm) to add RAG, custom tools, or multi-agent flows.

4. **Listen to agent events**: Set up [webhooks](/conversational-ai/develop/webhooks) to get real-time updates about agent status, errors, and performance.

5. **Deploy to production**: Move your server to a production environment with proper security, monitoring, and scaling.

<Admonition type="warning">
The number of Peak Concurrent Users (PCU) allowed to call the server API under a single App ID is limited to 20. If you need to increase this limit, [contact technical support](mailto:support@agora.io).
</Admonition>

## Why use a backend server

Your backend server is critical for security and scalability. Your Customer ID and Customer Secret must never be exposed to client applications—they grant full API access to your <Vg k="COMPANY" /> project. By centralizing agent management on your backend, you:

- Keep credentials secure on the server side
- Control who can start agents and when
- Implement business logic and access control
- Monitor agent usage and costs
- Handle errors and edge cases reliably

This architecture also lets you:
- Generate RTC tokens on-demand without exposing your App Certificate
- Add authentication and authorization for your users
- Log and audit all agent operations
- Implement rate limiting and cost controls
- Scale independently from your client applications

## Reference

Additional resources and API documentation.

### API reference

- [Start a conversational AI agent](/conversational-ai/rest-api/agent/join)
- [Stop a conversational AI agent](/conversational-ai/rest-api/agent/leave)
- [Update agent configuration](/conversational-ai/rest-api/agent/update)
- [Query agent status](/conversational-ai/rest-api/agent/query)
- [Retrieve a list of agents](/conversational-ai/rest-api/agent/list)

### Model documentation

- [ASR providers overview](/conversational-ai/models/asr/overview)
- [LLM providers overview](/conversational-ai/models/llm/overview)
- [TTS providers overview](/conversational-ai/models/tts/overview)
- [MLLM providers overview](/conversational-ai/models/mllm/overview)

### Additional guides

- [RESTful authentication](/conversational-ai/rest-api/restful-authentication)
- [Custom LLM integration](conversational-ai/develop/custom-llm)
- [Listen to agent events](/conversational-ai/develop/webhooks)
- [Send multimodal messages](/conversational-ai/develop/send-multimodal-messages)
