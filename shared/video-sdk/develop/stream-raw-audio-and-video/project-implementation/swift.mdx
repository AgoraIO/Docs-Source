import * as data from '@site/data/variables';
import CreateUI from '@docs/assets/code/video-sdk/raw-video-audio/swift/create-ui.mdx';
import ConfigureButtons from '@docs/assets/code/video-sdk/raw-video-audio/swift/configure-buttons.mdx';
import StartStopVideo from '@docs/assets/code/video-sdk/raw-video-audio/swift/start-stop-video-processing.mdx';
import RegisterFrameObservers from '@docs/assets/code/video-sdk/raw-video-audio/swift/register-frame-observers.mdx';
import UnRegisterFrameObservers from '@docs/assets/code/video-sdk/raw-video-audio/swift/unregister-frame-observers.mdx';

<ProductWrapper notAllowed="voice-calling">
### Implement the user interface

To enable or disable processing of captured raw video data, add a button to the user interface. In the `ViewController` class:

1.  **Add a button to zoom in and out on the video**

    Add the following declaration at the top of the class:

    <CreateUI />

2.  **Configure the `zoomBtn` button in your interface**

    Paste the following lines inside the `initViews` function:

    <ConfigureButtons />

### Handle the system logic

This section describes the steps required to use the relevant libraries, declare the necessary variables, and setup access to the UI elements.

1.  **Define a variable to manage video processing**

    Add the following declaration at the top of `ViewController`:

    ```swift
    var isZoomed: Bool = false
    ```
</ProductWrapper>

### Implement processing of raw data

To register and use frame observers in your <Vpl k="CLIENT" />, take the following steps:

1.  **Setup the audio frame observer**

    The `AgoraAudioFrameDelegate` gives you access to each audio frame after it is captured or before it is played back. To setup the `AgoraAudioFrameDelegate`, add the following `extension` to the `ViewController`:

    ```swift
    extension ViewController: AgoraAudioFrameDelegate {
        // Occurs when the recorded audio frame is received
        func onRecord(_ frame: AgoraAudioFrame, channelId: String) -> Bool {
            // true: The recorded audio frame is valid and is encoded and sent
            // false: The recorded audio frame is invalid and is not encoded or sent
            return false
        }

        // Occurs when the playback audio frame is received
        func onPlaybackAudioFrame(_ frame: AgoraAudioFrame, channelId: String) -> Bool {
            // true: The playback audio frame is valid and is encoded and sent
            // false: The playback audio frame is invalid and is not encoded or sent
            return false
        }

        // Occurs when the mixed audio data is received
        func onMixedAudioFrame(_ frame: AgoraAudioFrame, channelId: String) -> Bool {
            // true: The mixed audio data is valid and is encoded and sent
            // false: The mixed audio data is invalid and is not encoded or sent
            return false
        }

        // Occurs when the ear monitoring audio frame is received
        func onEarMonitoringAudioFrame(_ frame: AgoraAudioFrame) -> Bool {
            // true: The ear monitoring audio frame is valid and is encoded and sent
            // false: The ear monitoring audio frame is invalid and is not encoded or sent
            return false
        }

        // Occurs when the before-mixing playback audio frame is received
        func onPlaybackAudioFrame(beforeMixing frame: AgoraAudioFrame, channelId: String, uid: UInt) -> Bool {
            // true: The before-mixing playback audio frame is valid and is encoded and sent
            // false: The before-mixing playback audio frame is invalid and is not encoded or sent
            return false
        }
    }
    ```
<ProductWrapper notAllowed="voice-calling">
2.  **Setup the video frame observer**

    The `AgoraVideoFrameDelegate` gives you access to each local video frame after it is captured, and to each remote video frame before it is played back. To capture and process the video frames, implement the `onCaptureVideoFrame`, `onScreenCaptureVideoFrame`, and
    `onRenderVideoFrame` callbacks. To setup the `AgoraVideoFrameDelegate`, add the following `extension` to the `ViewController`:

    ```swift
    extension ViewController: AgoraVideoFrameDelegate {
        // Occurs each time the SDK receives a video frame captured by the local camera
        func onCapture(_ videoFrame: AgoraOutputVideoFrame) -> Bool {
            if isZoomed {
                // Add the captured video frame's modification code here
            }
            // Choose whether to ignore the current video frame if the pre-processing fails
            return true
        }

        // Occurs each time the SDK receives a video frame captured by the screen
        func onScreenCapture(_ videoFrame: AgoraOutputVideoFrame) -> Bool {
            // Choose whether to ignore the current video frame if the pre-processing fails
            return false
        }

        // Occurs each time the SDK receives a video frame sent by the remote user
        func onRenderVideoFrame(_ videoFrame: AgoraOutputVideoFrame, uid: UInt, channelId: String) -> Bool {
            // Choose whether to ignore the current video frame if the post-processing fails
            return false
        }

        // Indicate the video frame mode of the observer
        func getVideoFrameProcessMode() -> AgoraVideoFrameProcessMode {
            // The process mode of the video frame: readOnly, readWrite
            return AgoraVideoFrameProcessMode.readWrite
        }

        // Sets the video frame type preference
        func getVideoFormatPreference() -> AgoraVideoFormat {
            // Video frame format: I420, BGRA, NV21, RGBA, NV12, CVPixel, I422, Default
            return AgoraVideoFormat.I420
        }

        // Sets the frame position for the video observer
        func getObservedFramePosition() -> AgoraVideoFramePosition {
            // Frame position: postCapture, preRenderer, preEncoder
            return AgoraVideoFramePosition.postCapture
        }
    }
    ```

    Note that you must set the return value in `getVideoFrameProcessMode` to `readWrite` in order for your raw data changes to take effect.
</ProductWrapper>

3.  **Register the video and audio frame observers**

    To receive the callbacks that you declared, you must register your frame observers with the <Vg k="ENGINE" />, before joining a channel. To specify the format of the audio frames captured by each `AgoraAudioFrameDelegate` callback, use `setRecordingAudioFrameParametersWithSampleRate`, `setPlaybackAudioFrameParametersWithSampleRate`, and `setMixedAudioFrameParametersWithSampleRate`.

    To do this, add the following lines at the end of the `joinChannel` method:

    <RegisterFrameObservers />

4.  **Unregister the video and audio observers when you leave a channel**

    When you leave a channel, you unregister the frame observers by calling the register frame observer method again with a `nil` argument. To do this, add the following lines to the
    `leaveChannel()` function before `agoraEngine.leaveChannel(nil)`:

    <UnRegisterFrameObservers />

<ProductWrapper notAllowed="voice-calling">
5.  **Start and stop video processing**

    The first time a user presses `zoomBtn`, video processing is enabled. The next time, video processing is disabled. To enable this functionality, add the following method to `ViewController`:

    <StartStopVideo />

</ProductWrapper>