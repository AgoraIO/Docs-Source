import ImportLibrary from '@docs/assets/code/video-sdk/custom-video-and-audio/import-library.mdx';
import SetVariables from '@docs/assets/code/video-sdk/custom-video-and-audio/set-variables.mdx';
import EnableVideoPublishing from '@docs/assets/code/video-sdk/custom-video-and-audio/enable-video-publishing.mdx';
import RenderCustomVideo from '@docs/assets/code/video-sdk/custom-video-and-audio/render-custom-video.mdx';
import PushVideoFrames from '@docs/assets/code/video-sdk/custom-video-and-audio/push-video-frames.mdx';

import ImportAudioLibrary from '@docs/assets/code/video-sdk/custom-video-and-audio/import-library-audio.mdx';
import SetAudioVariables from '@docs/assets/code/video-sdk/custom-video-and-audio/set-variables-audio.mdx';
import EnableAudioPublishing from '@docs/assets/code/video-sdk/custom-video-and-audio/enable-audio-publishing.mdx';
import ReadAudioInput from '@docs/assets/code/video-sdk/custom-video-and-audio/read-audio-input.mdx';
import PushAudioFrames from '@docs/assets/code/video-sdk/custom-video-and-audio/push-audio-frames.mdx';
import CustomVideoTrack from '@docs/assets/code/video-sdk/custom-video-and-audio/create-custom-video-track.mdx';
import CustomAudioTrack from '@docs/assets/code/video-sdk/custom-video-and-audio/create-custom-audio-track.mdx';

<PlatformWrapper platform="ios, macos, android, react-js">
<ProductWrapper notAllowed="voice-calling">
### Implement a custom video source

In the following code example, you create the basic framework required to push video frames from a custom source. Depending on the type of your source, you add your own code to this framework that converts the source data to `VideoFrame` data. To create the basic framework, take the following steps:

1.  **Add the required imports**

    <ImportLibrary />

1.  **Add the required variables**

    <SetVariables />
<PlatformWrapper notAllowed="react-js">

3.  **Enable custom video track publishing**

    When a user presses **Join**, you configure the following to enable publishing of the captured video from a custom source:

    <PlatformWrapper platform="ios, macos">
    Add the following line to the `init()` method of `AgoraManager` to set the external video source to `true` before joining a channel:
    </PlatformWrapper>

    <EnableVideoPublishing />

1.  **Setup a video renderer for custom video**

    <RenderCustomVideo />

1.  **Push the video frames**

    A callback method of `AgoraManager` is called when a video frame is captured. You use the data in the callback to create a `VideoFrame`, and push the `VideoFrame` to the channel.

    <PushVideoFrames />
</PlatformWrapper>
<PlatformWrapper platform="react-js">
3. **Create a custom source video track**

    <CustomVideoTrack/>
4.  **Render and publish the custom video track**

    <RenderCustomVideo />
</PlatformWrapper>
</ProductWrapper>

### Implement a custom audio source

To push audio from a custom source to a channel, take the following steps:

<PlatformWrapper platform="ios, macos">

1.  **Enable publishing the custom audio**

    When a user presses **Join**, you configure the following to enable publishing of the captured audio from a custom source:

    <EnableAudioPublishing />

1.  **Setup an audio renderer for custom audio**

    For rendering audio frames captured in the push mode, implement a custom audio renderer using methods from outside the SDK because it's not supported by <Vg k="VSDK" />.

    [AVCaptureAudioDataOutput](https://developer.apple.com/documentation/avfoundation/avcaptureaudiodataoutput) can be used to receive the audio frames when they are captured. These frames can then be added as an audio output to an audio capturing session using [`AVCaptureSession`](https://developer.apple.com/documentation/avfoundation/avcapturesession).

    Have a look at [`AgoraAudioSourcePush`](https://github.com/AgoraIO/video-sdk-samples-ios/blob/main/custom-video-and-audio/AgoraAudioSourcePush.swift) for more details.

1.  **Push the audio frames**

    When an audio frame is captured, a callback method of `AgoraManager` is called. You push this data in the callback to the <Vg k="VSDK" /> to use as an external audio frame sample buffer:

    <PushAudioFrames />
</PlatformWrapper>

<PlatformWrapper platform="android, react-js">

1.  **Add the required imports**

    <ImportAudioLibrary />

1.  **Add the required variables**

    <SetAudioVariables />
<PlatformWrapper notAllowed="react-js">

3. **Enable custom audio track publishing**

    To enable custom audio track publishing, you set `ChannelMediaOptions` to disable the microphone audio track and enable the custom audio track. You also enable custom audio local playback and set the external audio source. 

    <EnableAudioPublishing />

1. **Read the input stream into a buffer**

    You read data from the input stream into a buffer.

    <ReadAudioInput />

1. **Push the audio frames**

    You push the data in the buffer as an audio frame using a separate process.

    <PushAudioFrames />
</PlatformWrapper>
<PlatformWrapper platform="react-js">
3. **Create a custom source audio track**

    <CustomAudioTrack/>
4.  **Play and publish the custom audio track**

    <EnableAudioPublishing />
</PlatformWrapper>

</PlatformWrapper>

</PlatformWrapper>

<PlatformWrapper platform="web">
1. **Add the required imports**

    <ImportLibrary />

1. **Enable custom video track publishing**

    When a user presses **Join with custom audio and video source**, you configure the following to enable publishing of the captured video from a custom source:

    <EnableVideoPublishing />

1. **Enable custom audio track publishing**

    When a user presses **Join with custom audio and video source**, you configure the following to enable publishing of the captured audio from a custom source:

    <EnableAudioPublishing />

</PlatformWrapper>
