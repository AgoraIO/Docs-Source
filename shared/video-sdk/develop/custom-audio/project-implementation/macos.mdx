<PlatformWrapper platform="macos">

This section shows you how to implement custom audio capture and render audio from a custom source.

### Customize the audio source

Refer to the following call sequence diagram to implement custom audio capture in your app:

![Custom audio capture](/images/video-sdk/custom-audio-capture.svg)

Follow these steps to implement custom audio capture in your project:

1. Before calling `joinChannelByToken` [2/4] to join a channel, call `setExternalAudioSource` to enable and configure custom audio capture.

   ```swift
   // Enable and configure custom audio capture
   agoraKit.setExternalAudioSource(true, sampleRate: Int(sampleRate), channels: Int(channel), sourceNumber: 1, localPlayback: true, publish: true)
   ```

2. Implement audio capture and processing using external SDK methods.

3. Call `pushExternalAudioFrameSampleBuffer` or `pushExternalAudioFrameRawData` to send audio frames to the SDK for backup.

    ```swift
    // Push audio frames to the SDK for backup
    extension CustomPcmAudioSourceMain: AgoraPcmSourcePushDelegate {
        func onAudioFrame(data: Data) {
            agoraKit.pushExternalAudioFrameRawData(data, sourceId: 0, timestamp: 0)
        }
    }
    ```

### Custom audio rendering

This section explains how to implement custom audio rendering.

To retrieve audio data for playback, implement collection and processing of raw audio data. Refer to [Raw audio processing](./advanced-features/stream-raw-audio).

Follow these steps to call the raw audio data API and implement custom audio rendering in your project:

1. Retrieve the audio data to be played from `onRecordAudioFrame`, `onPlaybackAudioFrame`, `onMixedAudioFrame`, or `onPlaybackAudioFrameBeforeMixing`.

2. Independently render and play the audio data.

</PlatformWrapper>
