---
title: 'Release notes'
sidebar_position: 3
type: docs
description: >
  Information about changes in each release of the Conversational AI agent.
---

export const toc = [{}];

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

This document tracks important changes and improvements to the <Vpd k="NAME" />. 

## Releases

### v2.4

Released on February 2, 2026.

#### New features

Included in this release:

* **MCP integration**

    Adds a [`llm.mcp_servers`](/conversational-ai/rest-api/agent/join#properties-llm-mcp-servers) field to the [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) API to connect the LLM to an MCP (Model Context Protocol) server. Set [`advanced_features.enable_tools`](/conversational-ai/rest-api/agent/join#properties-advanced-features-enable-tools) to `true`to enable tool calls. This allows the agent to call tools provided by external services to extend functionality.

* **Filler phrases**

    Adds a [`properties.filler_words`](/conversational-ai/rest-api/agent/join#properties-filler-words) field to insert pre-set or LLM-generated filler phrases during conversations to fill periods of silence while waiting for LLM output. This feature smooths dialogue flow, reduces user anxiety, and makes agent speech sound more natural.

#### Improvements

This release includes the following enhancements:

* **Turn detection configuration optimization**

    The `turn_detection` parameter structure has been updated to provide more flexible conversation turn detection. The new structure uses a `mode` + `config` pattern with separate Start of Speech (SoS) and End of Speech (EoS) detection configurations.

    **Basic configuration**
    - `mode`: Conversation turn detection mode (currently supports `default`)
    - `config.speech_threshold`: Voice activity detection sensitivity

    **Start of Speech (SoS) detection**

    Detects when the user begins speaking. When SoS is detected while the agent is speaking, an interruption occurs.

    The [`config.start_of_speech`](/conversational-ai/rest-api/agent/join#properties-turn-detection-config-start-of-speech) parameter supports three detection modes:
    - **VAD mode** (`vad`): Triggered by voice activity detection. Supports configuration of interruption threshold, prefix padding, and ignore word list.
    - **Keyword mode (Beta)** (`keywords`): Based on keyword triggering. The agent begins conversation after detecting a specified keyword.
    - **Disabled mode** (`disabled`): Disables interruption. Supports append or ignore strategies.

    **End of Speech (EoS) detection**

    Detects when the user finishes speaking. When EoS is detected, the agent generates a response.

    The [`config.end_of_speech`](/conversational-ai/rest-api/agent/join#properties-turn-detection-config-end-of-speech) parameter supports two detection modes:
    - **VAD mode** (`vad`): Determines conversation end based on silence duration.
    - **Semantic mode** (`semantic`): Determines conversation end based on semantic understanding. Supports configurable maximum wait time.    

#### API changes

This release introduces the following changes to the RESTful API.

- Changes to [**Start a conversational AI agent**](/conversational-ai/rest-api/agent/join)

    * **[`turn_detection`](/conversational-ai/rest-api/agent/join#properties-turn-detection) has a revamped structure**

        All previous fields under `turn_detection` have been deprecated and replaced with a new data structure. 

        - Deprecated

            -  `turn_detection.interrupt_mode`
            -  `turn_detection.interrupt_keywords`
            -  `turn_detection.interrupt_duration_ms`
            -  `turn_detection.prefix_padding_ms`
            -  `turn_detection.silence_duration_ms`
            -  `turn_detection.threshold`

    * **AIVAD activation**

        The `advanced_features.enable_aivad` field is now deprecated; To configure AIVAD activation use [`turn_detection.config.end_of_speech.mode= "sematic"`](/conversational-ai/rest-api/agent/join#properties-turn-detection-config-end-of-speech-mode).

    * **New parameters added**

        - [`advanced_features.enable_tools`](/conversational-ai/rest-api/agent/join#properties-advanced-features-enable-tools)
        - [`llm.mcp_servers`](/conversational-ai/rest-api/agent/join#properties-llm-mcp-servers)
        - [`properties.filler_words`](/conversational-ai/rest-api/agent/join#properties-filler-words)
        - [`turn_detection.mode`](/conversational-ai/rest-api/agent/join#properties-turn-detection-mode)
        - [`turn_detection.config`](/conversational-ai/rest-api/agent/join#properties-turn-detection-config)

### v2.3

Released on January 7, 2026.

#### New features

Included in this release:

* **Control LLM response interruption in custom LLM scenarios**

    Adds a `metadata.interruptable` field in the first chunk of the `chat.completion.custom_metadata` object to control whether user speech can interrupt the agent's TTS output when using custom LLMs with streaming response (SSE). Use this to prevent interruptions when delivering critical information such as regulations, policies, or pricing. For more information, see [Configure LLM response interruption](/conversational-ai/develop/custom-llm#configure-llm-response-interruption).

* **RTC media content encryption**

    Adds an `rtc` parameter to the [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) API for configuring RTC encryption.


* **New ASR provider**

    - [Sarvam (Beta)](/conversational-ai/models/asr/sarvam)

#### Improvements

This release includes the following enhancements:

* **ElevenLabs TTS compatibility Optimization**

    Supports SSML parsing and forwarding to ensure ElevenLabs TTS correctly renders intended speech effects such as pauses, emphasis, and pronunciation.

* **Latency optimization best practices**    

    Adds a guide to [Optimize conversation latency](/conversational-ai/best-practices/optimize-latency).

* **Cloud Recording best practices**    

    Adds a guide to [Record conversations with Cloud Recording](/conversational-ai/best-practices/cloud-recording).

#### API changes

This release introduces the following changes to the RESTful API.

- **Stop agent API is now asynchronous**

    The [Stop a conversational AI agent](/conversational-ai/rest-api/agent/leave) API now responds immediately after request parameters are validated. The request is processed asynchronously after the API returns.

- Changes to [**Start a conversational AI agent**](/conversational-ai/rest-api/agent/join)
    - **New parameters added**
        - `properties.rtc`

### v2.2

Released on December 15, 2025.

#### New features

Included in this release:

* **Geofencing**

    Use `geofence` configuration when you [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) to limit which Agora servers the Conversational AI Engine can access based on geographic regions. See [Restrict agent zones](../best-practices/regional-restrictions) for details.

* **Agent greeting mode**

    Adds a field `llm.greeting_configs.mode` to the [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) request to set the agent's greeting broadcast mode. The following modes are supported:

    - `single_every` (Default): The agent broadcasts a greeting every time a user joins a channel where there are no other users.
    - `single_first`: The agent broadcasts a greeting only when the first user joins a channel.

* **New TTS providers**

    - [Sarvam (Beta)](/conversational-ai/models/tts/sarvam)

#### Improvements

This release includes the following enhancements:

* **TTS parameter update**

    Adds `base_url` field to the TTS parameters for [OpenAI](/conversational-ai/models/tts/openai) and [ElevenLabs](/conversational-ai/models/tts/elevenlabs). This field specifies the endpoint URL for the TTS service.

#### API changes

This release introduces the following changes to the RESTful API.

- Changes to [**Start a conversational AI agent**](/conversational-ai/rest-api/agent/join)
    - **New parameters added**
        - `properties.geofence`
        - `llm.greeting_configs.mode`

### v2.1

Released on December 5, 2025.

#### New features

Included in this release:

* **Template variables**

    This version adds the `llm.template_variables` field to the [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) API, used to insert variables into the agent's `system_messages`, `greeting_message`, `failure_message`, and `parameters.silence_config.content` text. By configuring these variables, the Conversational AI engine automatically replaces them with the corresponding values defined in `llm.template_variables`. Template variables, combined with prompt customization and SIP outbound calling functionality, enable you to dynamically inject content to automate processes such as automatic hang-up, voicemail recognition, automatic message leaving, and call transfer.

* **Custom labels**

    This version adds a `labels` field to the [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) API, enabling agents to carry custom labels. These labels are bound to the agent and returned in the `payload` field of all message notification callbacks from the Conversational AI engine, allowing you to implement custom business logic, such as tagging activity IDs, customer groups, and business scenarios.

    In SIP outbound call scenarios, you can pass a custom label in the `properties.labels` field when calling the outbound call interface to mark the call.

#### API changes

This release introduces the following changes to the RESTful API.

- Changes to [**Start a conversational AI agent**](/conversational-ai/rest-api/agent/join)
    - **New parameters added**
        - `properties.labels`
        - `llm.template_variables`

### v2.0

Released on November 15, 2025.

#### New features

Included in this release:

* **Telephony (Beta)**

    This version adds an outbound calling feature that enables the <Vpd k="AGENT" /> to [initiate an outbound call](/conversational-ai/rest-api/telephony/start) to a specified number through a POST API. After the call is answered, the agent can engage in real-time dialogue with the callee. This feature supports a wide range of outbound AI call scenarios.

    A set of phone number management APIs is also added for handling numbers connected to <Vpd k="NAME" />. Refer to the API changes section for details.

    <Admonition type="info" title="Telephony pricing">
        The telephony feature is currently in **Beta** and is provided free of charge. Pricing terms may change upon official release. 
    </Admonition>

* **Selective attention locking (Beta)** 

    This version adds the selective attention lock feature. Register voiceprints to enable the agent to identify specific speakers and suppress background voices and environmental noise, ensuring clearer, more focused conversations.
    
* **Graceful exit**

    This version adds a new `farewell_config` field to [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) API to configure the graceful exit feature. When enabled, calling the [Stop a Conversational Agent](/conversational-ai/rest-api/agent/leave) API causes the agent to enter an `IDLE` state before leaving the channel.

* **Keyword interruption mode**

    This release adds a new option to the `turn_detection.interrupt_mode` field in the [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) API. Set this field to `"keyword"` to enable keyword interruption mode.

    When this mode is enabled, the agent stops its current behavior after detecting any of the keywords specified in the `turn_detection.interrupt_keywords` field.

* **Adaptive interruption mode**

    This release adds a new option to the `turn_detection.interrupt_mode` field in the [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) API. Set this field to `"adaptive"` to enable adaptive interruption mode.

    When this mode is enabled, the agent dynamically increases the voice continuity threshold while speaking to reduce accidental interruptions.

* **New ASR, LLM, MLLM, and TTS providers**

    * ASR
        - [OpenAI (Beta)](/conversational-ai/models/asr/openai)
        - [Speechmatics](/conversational-ai/models/asr/speechmatics)
        - [Google (Beta)](/conversational-ai/models/asr/google)
        - [Amazon Transcribe (Beta)](/conversational-ai/models/asr/amazon)
        - [AssemblyAI (Beta)](/conversational-ai/models/asr/assembly-ai)
    * LLM
        - [Groq](/conversational-ai/models/llm/groq)
        - [Amazon Bedrock](/conversational-ai/models/llm/amazon)
    * MLLM
        - [Google Gemini Live](/conversational-ai/models/mllm/gemini)
    * TTS
        - [Rime (Beta)](/conversational-ai/models/tts/rime)
        - [Fish Audio (Beta)](/conversational-ai/models/tts/fish-audio)
        - [Google (Beta)](/conversational-ai/models/tts/google)
        - [Amazon Polly (Beta)](/conversational-ai/models/tts/amazon)

* **New webhook notification events**

    This release adds three new webhook notification event types to support metrics reporting and call-state monitoring:

        - `111`: [agent metrics](/conversational-ai/develop/event-types#111-agent-metrics)
            
            Notifies real-time performance metrics for each dialogue turn, including ASR, LLM, and TTS latency measurements.

        - `201`: [inbound call state](/conversational-ai/develop/event-types#201-inbound-call-state)
            
            Reports state changes for incoming calls, such as when a call starts, is answered, transferred, or hung up.

        - `202`: [outbound call state](/conversational-ai/develop/event-types#202-outbound-call-state)
            
            Reports state changes for outbound calls initiated by the agent, including call start, dialing, ringing, answer, and hang-up events.

#### Improvements

This release includes the following enhancements:

* **Support for avatars with MLLMs**

    Added support for using avatars with MLLMs.

#### API changes

This release introduces the following changes to the RESTful API.

- Changes to [**Start a conversational AI agent**](/conversational-ai/rest-api/agent/join)
    - **New parameters added**
        - `properties.parameters.farewell_config`
        - `properties.advanced_features.enable_sal`
        - `properties.sal`
        - `properties.sal.sal_mode`
        - `properties.sal.sample_urls`
        - `properties.turn_detection.interrupt_mode` (supports `adaptive` and `keyword` values)
        - `properties.turn_detection.interrupt_keywords`
        - `properties.turn_detection.interrupt_duration_ms` (migrated from `vad.interrupt_duration_ms`)
        - `properties.turn_detection.prefix_padding_ms` (migrated from `vad.prefix_padding_ms`)
        - `properties.turn_detection.silence_duration_ms` (migrated from `vad.silence_duration_ms`)
        - `properties.turn_detection.threshold` (migrated from `vad.threshold`)

    - **Deprecated**
        - The `vad` interface is deprecated. All configuration items have been moved to the `turn_detection` field.

- **New APIs**
    - Telephony (Beta)
        - [Initiate an outbound call](/conversational-ai/rest-api/telephony/start)
        - [Retrieve call records](/conversational-ai/rest-api/telephony/history)
        - [Hang-up a call](/conversational-ai/rest-api/telephony/hang-up)
        - [Retrieve call status](/conversational-ai/rest-api/telephony/status)

    - Phone number management (Beta)
        - [Retrieve list of numbers](/conversational-ai/rest-api/phone-number-management/list)
        - [Import number](/conversational-ai/rest-api/phone-number-management/import)
        - [Retrieve number information](/conversational-ai/rest-api/phone-number-management/number-info)
        - [Update number configuration](/conversational-ai/rest-api/phone-number-management/update)
        - [Delete number](/conversational-ai/rest-api/phone-number-management/delete)

#### Toolkit API

This release renames all APIs and parameters containing the word `transcription` in the client-side subtitle API to use `transcript`, as shown below:

<Tabs>
    <TabItem value="android" label="Android" default>
    - `onTranscriptionUpdated` renamed to `onTranscriptUpdated`
    - `TranscriptionRenderMode` renamed to `TranscriptRenderMode`
    - `TranscriptionType` renamed to `TranscriptType`
    - `TranscriptionStatus` renamed to `TranscriptStatus`
    - `Transcription` renamed to `Transcript`
    </TabItem>
    <TabItem value="ios" label="iOS">
    - `onTranscriptionUpdated` renamed to `onTranscriptUpdated`
    - `TranscriptionRenderMode` renamed to `TranscriptRenderMode`
    - `TranscriptionType` renamed to `TranscriptType`
    - `TranscriptionStatus` renamed to `TranscriptStatus`
    - `Transcription` renamed to `Transcript`
    </TabItem>
    <TabItem value="web" label="Web">
    - `TRANSCRIPTION_UPDATED` renamed to `TRANSCRIPT_UPDATED`
    </TabItem>
</Tabs>

### v1.7

Released on July 31, 2025.

#### New features

* **AI avatars**

    Create visual avatar representations for your conversational agents using third-party avatar providers. AI avatars provide a visual presence during voice interactions, making conversations feel more natural and engaging. Enable AI avatars by setting `avatar.enable` to `true` and configuring the `avatar.vendor` and `avatar.params` fields when calling [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) to create your agent.

    <Admonition type="info">
    AI avatars require video streaming and incur additional charges. See [video calling pricing](/video-calling/overview/pricing) for details.
    </Admonition>

* **Selective attention locking** (Beta)

    This version introduces the selective attention locking feature, which uses voiceprint recognition technology to identify and filter out the speaker while suppressing background noise. This enhances the efficiency of conversational AI, particularly improving speech recognition accuracy. To experience this feature, contact [technical support](mailto:support@agora.io). 

* **Send picture messages** (Beta)

    The toolkit now includes an API for [sending picture messages](../develop/send-multimodal-messages). You can send image URLs to the main model, which automatically references the image in future interactions to generate more relevant responses. A new callback is available to receive image message receipt details after successful transmission.

    <Admonition type="info">
    - The picture messaging feature is currently in Beta and free for a limited time.
    - Image processing depends on the capabilities of the integrated LLM. Ensure the LLM you connect to the Conversational AI Engine supports image input.
    </Admonition>
    
#### API changes

This release introduces the following modifications to the RESTful API.

- [Start a conversational AI agent](/conversational-ai/rest-api/agent/join)
    - **New parameters added**
        - `avatar.enable`
        - `avatar.vendor`
        - `avatar.params`

##### Toolkit API

- Android:
    - `chat`
    - `ImageMessage`
    - `onMessageReceiptUpdated`
    - `MessageReceipt`
- iOS:
    - `chat`
    - `ChatMessage`
    - `ChatMessageType`
    - `ImageMessage`
    - `onMessageReceiptUpdated`
    - `MessageReceipt`
- Web:
    - `chat`
    - `TMessageReceipt`
    - `EChatMessagePriority`
    - `EChatMessageType`
    - `IChatMessageBase`
    - `IChatMessageImage`

### v1.6

Released on July 15, 2025.

#### New features

* **Support for OpenAI realtime API**

    Integrate Multimodal Large Language Models (MLLMs) with <Vpd k="NAME" /> to enable end-to-end real-time audio and text interactions. See [OpenAI Realtime API](/conversational-ai/models/mllm/openai) for integration details.

* **Support for more TTS vendors**

    <Vpd k="NAME" /> now supports the following additional TTS vendors:

    - [Cartesia](/conversational-ai/models/tts/cartesia)
    - [OpenAI](/conversational-ai/models/tts/openai)

* **Custom ASR provider support**

    To improve flexibility in configuring conversational agents, this release allows you to select a custom automatic speech recognition (ASR) provider. The [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) API now includes the following new parameters:

    - `asr.vendor`: Specify the ASR provider
    - `asr.params`: Configure ASR parameters

    The following ASR providers are supported:

    - **ARES** (default)  
    - **Microsoft Azure**  
    - **Deepgram**  

    **Billing update:**  
    In earlier versions, the service fee included the cost of the Ares ASR provider. Starting in v1.6, the pricing is restructured as follows:

    - If you use **ARES ASR**, the total price remains unchanged:  
        _**Total cost = Conversational AI Engine Audio Basic Task + ARES ASR Task**_
    - If you use **a different ASR provider**, you are charged **only** the new **Conversational AI Engine Audio Basic Task** fee.

    For further details, see [Pricing](pricing).

* **Multi-platform toolkit**

    Agora now offers a toolkit to help you quickly build conversational agent apps. The toolkit is available for [**iOS**](../reference/ios), [**Android**](../reference/android), and [**Web**](../reference/web), and includes APIs for common scenarios. Call these APIs to combine the capabilities of the Agora Voice SDK and Signaling SDK to achieve the following functions:

    - [**Display live transcript**](../develop/transcripts)
    Display real-time text output of user–agent conversations. The transcript component is now more robust, with better error handling, session management, and extensibility.

    - [**Interrupt the agent**](../develop/interrupt-agent)
    Stop the agent from speaking or thinking mid-conversation.

    - [**Receive event notifications**](../develop/event-notifications)
    Track changes in conversation state, performance metrics, and error events.

    - [**Optimize audio settings**](../best-practices/audio-setup)
    Quickly apply best-practice audio configurations to improve agent responsiveness and clarity.

#### API changes

##### REST API

This release introduces several important modifications to the RESTful API.

- [Start a conversational AI agent](/conversational-ai/rest-api/agent/join)
    - **New parameters added**
        - `asr.vendor`  
        - `asr.params`  
        - `advanced_features.enable_mllm`
        - `properties.mllm`
        - `turn_detection.type`
        - `turn_detection.interrupt_duration_ms`
        - `turn_detection.prefix_padding_ms`
        - `turn_detection.silence_duration_ms`
        - `turn_detection.threshold`
        - `turn_detection.create_response`
        - `turn_detection.interrupt_response`
        - `turn_detection.eagerness`
        - `parameters.enable_metrics`  
        - `parameters.data_channel`  
        - `parameters.enable_error_message`  

##### Toolkit APIs

- [Android SDK](../reference/android)
- [iOS SDK](../reference/ios)
- [Web SDK](../reference/web)

### v1.5

Released on Jun 9, 2025.

#### New features

* **Voice interruption mode**

    This release adds the `turn_detection.interrupt_mode` parameter to the [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) API, allowing you to control how the agent handles human voice interruptions. The following modes are supported:

    * **`interrupt`**: (Default) The human voice immediately interrupts the agent. The agent terminates the current interaction and processes the new human voice input.

    * **`append`**: The human voice does not interrupt the agent. The agent processes the newly received human voice request after the current interaction ends.

    * **`ignore`**: The agent ignores human voice requests received during speaking or thinking. These requests are discarded and not stored in the context.
    
* **TTS filtering**

    This release adds the `tts.skip_patterns` parameter to the [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) API. This parameter controls whether the TTS module skips bracketed content when reading LLM response text. This prevents the agent from vocalizing structural prompt information like tone indicators, action descriptions, and system prompts, creating a more natural and immersive listening experience.

#### API changes

This release introduces several important modifications to the RESTful API.

- [Start a conversational AI agent](/conversational-ai/rest-api/agent/join)
    - **New parameters added**
        - `turn_detection.interrupt_mode`
        - `parameters.silence_config`
        - `tts.skip_patterns`

### v1.4

Released on May 29, 2025.

#### New features

* **Metadata support for LLM requests**

    This release adds the `llm.vendor` parameter to the [Start a conversational AI agent](/conversational-ai/rest-api/agent/join) API. When set to `"custom"`, the agent includes additional metadata when calling the LLM, such as `turn_id` and `timestamp`.

* **Support for Anthropic**

    <Vpd k="NAME" /> now supports `anthropic` as a request style for chat completion. Refer to the `llm.style` parameter in [Start a conversational AI agent](/conversational-ai/rest-api/agent/join).

#### Improvements

This release includes the following enhancements:

* **Advanced LLM configuration**: The [Update agent configuration](/conversational-ai/rest-api/agent/update) API now supports:
    * `llm.system_messages` for updating system prompts
    * `llm.params` for modifying configuration parameters used when calling the large language model

#### API changes

This release introduces several important modifications to the RESTful API.

- [Start a conversational AI agent](/conversational-ai/rest-api/agent/join)
    - **New parameters added**
        - `llm.vendor`
    - **Removed parameters:**
        - `agent_rtm_uid`

- [Update agent configuration](/conversational-ai/rest-api/agent/update)
    - **New parameters added**
        - `llm.system_messages`
        - `llm.params`

### v1.3

Released on April 16, 2025.

#### New features

- **Agent conversation history**: This version adds two methods to retrieve an agent’s history. The history includes messages exchanged between the user and the agent and timestamps of agent creation and exit.

    - Call the RESTful API `history` endpoint to [Retrieve agent history](/conversational-ai/rest-api/agent/history).

    - Subscribe to the [agent history event](../develop/event-types#103-agent-history) through the [Agora message notification service](../develop/event-notifications). When the agent stops, Agora automatically sends the agent's history to your business server through a Webhook callback.

#### Improvements

- **Customize the priority of broadcast information**: This version upgrades the [Broadcast a message using TTS](/conversational-ai/rest-api/agent/speak) interface and adds two new configuration parameters related to broadcast interruption logic:

    - `priority`: Sets the priority of the message broadcast. Supports setting the following priorities: 
        - `INTERRUPT` High priority
        - `APPEND`: Medium priority
        - `IGNORE`: Low priority

    - `interruptable`: Configure whether to allow human voice to interrupt the agent's broadcast.

#### API changes

- Adds the [Retrieve agent history](/conversational-ai/rest-api/agent/history) method.
- Adds `priority` and `interruptable` parameters to the [Broadcast a message using TTS](/conversational-ai/rest-api/agent/speak) method.

### v1.2

Released on April 10, 2025.

#### New features

- **Broadcast a message using TTS**: A new message broadcast interface enables a specified agent to deliver a custom message. When interacting with an agent, calling this interface interrupts the agent’s speech and thinking process, allowing the TTS module to immediately broadcast the custom message.

- **Interrupt the agent**: The interrupt agent endpoint allows you to stop the specified agent’s speech and thinking process.

#### API changes

This version adds the following APIs:
- [Broadcast a message using TTS](/conversational-ai/rest-api/agent/speak)
- [Interrupt the agent](/conversational-ai/rest-api/agent/interrupt)

### v1.1

Released on March 27, 2025.

#### New features

The [Start a conversational agent](/conversational-ai/rest-api/agent/join) API adds the `enable_rtm`and `agent_rtm_uid` parameters to enable Signaling integration with <Vpd k="AGENT" />. When this feature is enabled, the agent can leverage the Signaling SDK to obtain a users's custom context information such as speaking status, selected text, signature, and score, and pass this data to the agent to generate more relevant content. For details, see [Transmit custom information](../develop/custom-information).

#### Improvements

To help you quickly integrate a custom large language model (LLM), this version adds documentation for [Custom LLMs](../develop/custom-llm). Refer to the sample code in the documentation to integrate your custom model into the <Vpd k="NAME" /> and enable advanced capabilities such as Retrieval-Augmented Generation (RAG), multi-modal processing, and tool invocation.

#### API changes

The `POST` method to [Start a <Vpd k="AGENT" />](/conversational-ai/rest-api/agent/join) now includes the `enable_rtm` and `agent_rtm_uid` parameters.

### v1.0 (Public Beta)

This version, released on March 4, 2025, adds pricing information for the Agora <Vpd k="NAME" />. For more information, see [Pricing](../overview/pricing).

#### Integration guide

To achieve the best conversation experience, use Agora <Vpd k="NAME" /> with the following Agora SDKs:

- Agora RTC Native SDK, v4.5.1 or later.
- Agora RTC Web SDK, version 4.23.2 or later.

#### New features

- **Live transcripts**: Supports real-time text output of conversations between users and the AI agent for transcript display in your app's UI. Agora provides an open-source transcript processing module. Simply integrate the module and call its API to implement live transcript. For details, see [Display live transcripts](../develop/transcripts).

- **Message Notification Service**: Introduces a new <Vpd k="NAME" /> message notification service. Configure it in the Agora console and subscribe to agent creation, stop, and error events. When a subscribed event occurs, Agora sends the details to your specified callback address. See [Receive event notifications](../develop/event-notifications).

- **Keywords**: Enhances recognition accuracy of <Vpd k="NAME" /> for proprietary words by adding keywords. This feature is currently in Beta stage. For details, [contact technical support](https://agoraio.zendesk.com/hc/en-us).

### v1.0 (Private Beta)

Released on February 18, 2025. The first beta release of the <Vpd k="NAME" /> brings natural, smooth, low-latency, and highly reliable real-time voice conversations with AI agents to Agora channels. It enables you to efficiently build intelligent and immersive interactive experiences. See [Product overview](../overview/product-overview) for details.

#### Core Features

- **Real-time voice conversation**

    Supports natural and smooth real-time voice conversations with AI. It delivers a low-latency, ultra-responsive interactive experience as if the user is communicating with a real person.

- **Intelligent noise suppression**

    Intelligently identifies and suppresses background noise, ensuring clear sound transmission even in noisy environments to provide users with a high-quality audio experience.

- **Background human voice suppression**

    Suppresses background voices and noise while accurately preserving the primary speaker's voice. This ensures a clear and focused interactive experience in multi-speaker environments.

- **Intelligent interruption handling**

    Allows users to interrupt AI at any time to ensure quick and natural responses. This feature enables smooth transitions and avoids mechanical interactions.

- **Intelligent transmission**

    An AI-optimized transmission algorithm ensures stable voice data delivery even in weak network conditions where packet loss reaches 80%. This guarantees conversation continuity and reliability across diverse network environments.

- **Flexible arrangement**

    Supports multiple Large Language Model (LLM) and Text-to-Speech (TTS) providers, enabling flexible orchestration to meet diverse business needs and deliver highly customizable AI dialogue solutions.

- **Multi-platform support**

    Compatible with iOS, Android, Web, and various embedded hardware platforms, providing a seamless and consistent cross-platform experience.

#### Integration guide

- For the best conversational experience, <Vg k="COMPANY" /> recommends using <Vpd k="NAME" /> with specific Agora Video/Voice SDK versions. For details, [contact technical support](mailto:support@agora.io).

- The number of Peak Concurrent Users (PCU) allowed to call the server API under a single App ID is limited to 20. If you need to increase this limit, please [contact technical support](mailto:support@agora.io).

