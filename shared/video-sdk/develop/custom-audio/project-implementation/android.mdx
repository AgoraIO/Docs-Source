<PlatformWrapper platform="android">
This section shows you how to implement custom audio capture and render audio from a custom source.

### Custom audio capture

Refer to the following call sequence diagram to implement custom audio capture in your app:

![Custom audio capture](/images/video-sdk/custom-audio-capture.svg)

Follow these steps to implement custom audio capture in your project:

1. Before calling `joinChannel`, use `setExternalAudioSource` to enable and configure your custom audio source.

    ```java
    // Specify the custom audio source
    engine.setExternalAudioSource(true, DEFAULT_SAMPLE_RATE, DEFAULT_CHANNEL_COUNT, 1, true, true);
    // Join the channel for the local user
    ChannelMediaOptions option = new ChannelMediaOptions();
    option.autoSubscribeAudio = true;
    option.autoSubscribeVideo = true;
    int res = engine.joinChannel(accessToken, channelId, 0, option);
    ```

2. Implement audio capture and processing using external SDK methods.

3. Call `pushExternalAudioFrame` to send audio frames to the SDK.

    ```java
    engine.pushExternalAudioFrame(ByteBuffer.wrap(buffer), 0, 0);
    ```

### Custom audio rendering

This section shows you how to implement custom audio rendering. Refer to the following call sequence diagram to implement custom audio rendering in your <Vpl k="CLIENT" />:

![Custom Audio Rendering Workflow](/images/video-sdk/custom-audio-render.svg)

To implement custom audio rendering, use the following methods:

1. Before calling `joinChannel`, use `setExternalAudioSink` to enable and configure custom audio rendering.

    ```java
    rtcEngine.setExternalAudioSink(
        true,      // Enable custom audio rendering
        44100,     // Sampling rate (Hz). Set this value to 16000, 32000, 441000, or 48000
        1          // Number of channels for the custom audio source. Set this value to 1 or 2
    );
    ```

2. After joining the channel, call `pullPlaybackAudioFrame` to get audio data sent by remote users. Use your own audio renderer to process the audio data and then play the rendered data.

    ```java
    private class FileThread implements Runnable {

        @Override
        public void run() {
            while (mPull) {
                int lengthInByte = 48000 / 1000 * 2 * 1 * 10;
                ByteBuffer frame = ByteBuffer.allocateDirect(lengthInByte);
                int ret = engine.pullPlaybackAudioFrame(frame, lengthInByte);
                byte[] data = new byte[frame.remaining()];
                frame.get(data, 0, data.length);
                // Write to a local file or render using a player
                FileIOUtils.writeFileFromBytesByChannel("/sdcard/agora/pull_48k.pcm", data, true, true);
                try {
                    Thread.sleep(10);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }
    ```

### Using raw audio data callback

This section explains how to implement custom audio rendering.

To retrieve audio data for playback, implement collection and processing of raw audio data. Refer to [Raw audio processing](./advanced-features/stream-raw-audio).

Follow these steps to call the raw audio data API in your project for custom audio rendering:

1. Retrieve audio data for playback using the `onRecordAudioFrame`, `onPlaybackAudioFrame`, `onMixedAudioFrame`, or `onPlaybackAudioFrameBeforeMixing` callback.

2. Independently render and play the audio data.

</PlatformWrapper>
