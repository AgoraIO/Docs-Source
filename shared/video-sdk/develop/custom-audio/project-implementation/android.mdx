<PlatformWrapper platform="android">

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

This section shows you how to implement custom audio capture and render audio from a custom source.

### Custom audio capture

Refer to the following call sequence diagram to implement custom audio capture in your app:

<details>
<summary>Custom audio capture process</summary>

![Custom audio capture](/images/rtc-sdk/custom-audio-capture-with-custom-track.svg)
</details>

Follow these steps to implement custom audio capture in your project:

1. After initializing `RtcEngine`, call `createCustomAudioTrack` to create a custom audio track and obtain the audio track ID.

    <Tabs groupId="language">
    <TabItem value="java" label="Java">
    <CodeBlock language="java" showLineNumbers>
    {`AudioTrackConfig config = new AudioTrackConfig();
   config.enableLocalPlayback = false;
   customAudioTrack = engine.createCustomAudioTrack(Constants.AudioTrackType.AUDIO_TRACK_MIXABLE, config);`}
    </CodeBlock>
    </TabItem>

    <TabItem value="kotlin" label="Kotlin" default>
    <CodeBlock language="kotlin" showLineNumbers>
    {`val config = AudioTrackConfig().apply {
        enableLocalPlayback = false
   }
   customAudioTrack = engine.createCustomAudioTrack(Constants.AudioTrackType.AUDIO_TRACK_MIXABLE, config)`}
    </CodeBlock>
    </TabItem>
    </Tabs>

2. Call `joinChannel` to join the channel. In `ChannelMediaOptions`, set `publishCustomAudioTrackId` to the audio track ID obtained in step 1, and set `publishCustomAudioTrack` to `true` to publish the custom audio track.

    <Admonition type="info" title="Information">
    To use `enableCustomAudioLocalPlayback` for local playback of an external audio source, or to adjust the volume of a custom audio track with `adjustCustomAudioPlayoutVolume`, set `enableAudioRecordingOrPlayout` to `true` in `ChannelMediaOptions`.
    </Admonition>

    <Tabs groupId="language">
    <TabItem value="java" label="Java">
    <CodeBlock language="java" showLineNumbers>
    {`ChannelMediaOptions option = new ChannelMediaOptions();
   option.clientRoleType = Constants.CLIENT_ROLE_BROADCASTER;
   option.autoSubscribeAudio = true;
   option.autoSubscribeVideo = true;
   // In the audio self-collection use-case, the audio collected by the microphone is not published
   option.publishMicrophoneTrack = false;
   // Publish the custom audio track
   publishCustomAudioTrack = true
   // Set the custom audio track ID
   publishCustomAudioTrackId = customAudioTrack

   // Join the channel
   val res = engine.joinChannel(accessToken, channelId, 0, option)`}
    </CodeBlock>
    </TabItem>
    <TabItem value="kotlin" label="Kotlin">
    <CodeBlock language="kotlin" showLineNumbers>
    {`val option = ChannelMediaOptions().apply {
        clientRoleType = Constants.CLIENT_ROLE_BROADCASTER
        autoSubscribeAudio = true
        autoSubscribeVideo = true
        // In the audio self-collection use-case, the audio collected by the microphone is not published
        publishMicrophoneTrack = false
        // Publish the custom audio track
        publishCustomAudioTrack = true
        // Set the custom audio track ID
        publishCustomAudioTrackId = customAudioTrack
    }

    // Join the channel
    val res = engine.joinChannel(accessToken, channelId, 0, option)`}
    </CodeBlock>
    </TabItem>
    </Tabs>

3. <Vg k="COMPANY"/> provides the [AudioFileReader.java](https://github.com/AgoraIO/API-Examples/blob/main/Android/APIExample/app/src/main/java/io/agora/api/example/utils/AudioFileReader.java) sample to demonstrate how to read and publish PCM-format audio data from a local file. In a production environment, you create a custom audio acquisition module based on your business needs.

4. Call `pushExternalAudioFrame` to send the captured audio frame to the SDK through the custom audio track. Ensure that the `trackId` matches the audio track ID you obtained by calling `createCustomAudioTrack`. Set `sampleRate`, `channels`, and `bytesPerSample` to define the sampling rate, number of channels, and bytes per sample of the external audio frame.

    <Admonition type="info" title="Information">
    For audio and video synchronization, <Vg k="COMPANY"/> recommends calling `getCurrentMonotonicTimeInMs` to get the systemâ€™s current monotonic time and setting the `timestamp` accordingly.
    </Admonition>

    <Tabs groupId="language">
    <TabItem value="java" label="Java">
    <CodeBlock language="java" showLineNumbers>
    {`audioPushingHelper = new AudioFileReader(requireContext(), (buffer, timestamp) -> {
        if (joined && engine != null && customAudioTrack != -1) {
            // Push external audio frames to SDK
            int ret = engine.pushExternalAudioFrame(buffer, timestamp,
                    AudioFileReader.SAMPLE_RATE,
                    AudioFileReader.SAMPLE_NUM_OF_CHANNEL,
                    Constants.BytesPerSample.TWO_BYTES_PER_SAMPLE,
                    customAudioTrack);
            Log.i(TAG, "pushExternalAudioFrame times:" + (++\pushTimes) + ", ret=" + ret);
        }
   });`}
    </CodeBlock>
    </TabItem>
    
    <TabItem value="kotlin" label="Kotlin" default>
    <CodeBlock language="kotlin" showLineNumbers>
    {`audioPushingHelper = AudioFileReader(requireContext()) { buffer, timestamp ->
        if (joined && engine != null && customAudioTrack != -1) {
            // Push external audio frames to SDK
            val ret = engine.pushExternalAudioFrame(
                buffer, timestamp,
                AudioFileReader.SAMPLE_RATE,
                AudioFileReader.SAMPLE_NUM_OF_CHANNEL,
                Constants.BytesPerSample.TWO_BYTES_PER_SAMPLE,
                customAudioTrack
            )
            Log.i(TAG, "pushExternalAudioFrame times: \$\{++pushTimes\}, ret=$ret")
        }
   }`}
    </CodeBlock>
    </TabItem>
    </Tabs>

5. To stop publishing custom audio, call `destroyCustomAudioTrack` to destroy the custom audio track.

    <Tabs groupId="language">
    <TabItem value="java" label="Java">
    <CodeBlock language="java" showLineNumbers>
    {`// Destroy the custom audio track
   engine.destroyCustomAudioTrack(customAudioTrack);`}
    </CodeBlock>
    </TabItem>
    
    <TabItem value="kotlin" label="Kotlin" default>
    <CodeBlock language="kotlin" showLineNumbers>
    {`// Destroy the custom audio track
   engine.destroyCustomAudioTrack(customAudioTrack)`}
    </CodeBlock>
    </TabItem>
    </Tabs>

### Custom audio rendering

This section shows you how to implement custom audio rendering. Refer to the following call sequence diagram to implement custom audio rendering in your <Vpl k="CLIENT" />:

<details>
<summary>Custom audio rendering workflow</summary>

![Custom Audio Rendering Workflow](/images/rtc-sdk/custom-audio-render.svg)
</details>

To implement custom audio rendering, use the following methods:

1. Before calling `joinChannel`, use `setExternalAudioSink` to enable and configure custom audio rendering.

    <Tabs groupId="language">
    <TabItem value="java" label="Java">
    <CodeBlock language="java" showLineNumbers>
    {`rtcEngine.setExternalAudioSink(
        true,      // Enable custom audio rendering
        44100,     // Sampling rate (Hz). Set this value to 16000, 32000, 441000, or 48000
        1          // Number of channels for the custom audio source. Set this value to 1 or 2
   );`}
    </CodeBlock>
    </TabItem>

    <TabItem value="kotlin" label="Kotlin" default>
    <CodeBlock language="kotlin" showLineNumbers>
    {`rtcEngine.setExternalAudioSink(
        true,      // Enable custom audio rendering
        44100,     // Sampling rate (Hz). Set this value to 16000, 32000, 441000, or 48000
        1          // Number of channels for the custom audio source. Set this value to 1 or 2
   )`}
    </CodeBlock>
    </TabItem>
    </Tabs>

2. After joining the channel, call `pullPlaybackAudioFrame` to get audio data sent by remote users. Use your own audio renderer to process the audio data and then play the rendered data.

    <Tabs groupId="language">
    <TabItem value="java" label="Java">
    <CodeBlock language="java" showLineNumbers>
    {`private class FileThread implements Runnable {

        @Override
        public void run() {
            while (mPull) {
                int lengthInByte = 48000 / 1000 * 2 * 1 * 10;
                ByteBuffer frame = ByteBuffer.allocateDirect(lengthInByte);
                int ret = engine.pullPlaybackAudioFrame(frame, lengthInByte);
                byte[] data = new byte[frame.remaining()];
                frame.get(data, 0, data.length);
                // Write to a local file or render using a player
                FileIOUtils.writeFileFromBytesByChannel("/sdcard/agora/pull_48k.pcm", data, true, true);
                try {
                    Thread.sleep(10);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
   }`}
    </CodeBlock>
    </TabItem>
    
    <TabItem value="kotlin" label="Kotlin" default>
    <CodeBlock language="kotlin" showLineNumbers>
    {`private class FileThread : Runnable {

        override fun run() {
            while (mPull) {
                val lengthInByte = 48000 / 1000 * 2 * 1 * 10
                val frame = ByteBuffer.allocateDirect(lengthInByte)
                val ret = engine.pullPlaybackAudioFrame(frame, lengthInByte)
                val data = ByteArray(frame.remaining())
                frame.get(data, 0, data.size)
                // Write to a local file or render using a player
                FileIOUtils.writeFileFromBytesByChannel("/sdcard/agora/pull_48k.pcm", data, true, true)
                try {
                    Thread.sleep(10)
                } catch (e: InterruptedException) {
                    e.printStackTrace()
                }
            }
        }
   }`}
    </CodeBlock>
    </TabItem>
    </Tabs>

### Using raw audio data callback

This section explains how to implement custom audio rendering.

To retrieve audio data for playback, implement collection and processing of raw audio data. Refer to [Raw audio processing](./advanced-features/stream-raw-audio).

Follow these steps to call the raw audio data API in your project for custom audio rendering:

1. Retrieve audio data for playback using the `onRecordAudioFrame`, `onPlaybackAudioFrame`, `onMixedAudioFrame`, or `onPlaybackAudioFrameBeforeMixing` callback.

2. Independently render and play the audio data.

</PlatformWrapper>
