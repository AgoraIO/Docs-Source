import CodeBlock from '@theme/CodeBlock';

The code provided on this page integrates Agora's real-time audio communication with OpenAI's API to create an interactive, voice-driven assistant. 

## Understand the tech

The integration of Agora's audio communication with OpenAI's LLMs enables real-time conversational AI. The `RealtimeKitAgent` class manages this integration by connecting to an Agora channel for real-time audio streaming and to OpenAI's API for processing audio input and generating AI-driven responses.

Audio frames captured from the Agora channel are streamed to OpenAI's API using the `send_audio_data` method, where the AI processes the input. The API responses, which include transcribed text and synthesized voice output, are then delivered back through the Agora channel.

The code introduces the concept of tools that can be executed locally via `LocalFunctionToolDeclaration` or passed through the API using `PassThroughFunctionToolDeclaration`. This allows the AI to perform specific tasks, such as retrieving data from external sources.

The agent processes various message types from OpenAI, such as audio responses, transcription updates, and error messages, and sends them to users through the Agora audio channel, facilitating continuous interaction.

## Implementation

The `RealtimeKitAgent` class integrates Agora's audio communication capabilities with OpenAI's AI services. This class manages audio streams, handles communication with the OpenAI API, and processes AI-generated responses, providing a seamless conversational AI experience. The agent operates within an audio channel and processes various message types, enabling users to interact with the AI through voice.

### Connect to Agora and OpenAI

The `setup_and_run_agent` method sets up the `RealtimeKitAgent` by connecting to an Agora channel and initializing a session with the OpenAI Realtime API client. It sends configuration messages to set up the session and conversation parameters before starting the agent's operations. The method ensures the connection is properly handled and cleaned up after use.

``` python
@classmethod
async def setup_and_run_agent(
    cls,
    *,
    engine: RtcEngine,
    inference_config: InferenceConfig,
    tools: ToolContext | None,
) -> None:
    channel = await engine.connect(channelId="realtimekit_agora", uid="123")

    try:
        async with RealtimeApiClient(
            base_uri=os.getenv("REALTIME_API_BASE_URI", "wss://api.openai.com"),
            api_key=os.getenv("OPENAI_API_KEY"),
            verbose=False,
        ) as client:
            await client.send_message(
                messages.UpdateSessionConfig(
                    session=messages.SessionResource(),
                    # turn_detection=inference_config.turn_detection,
                    # transcribe_input=False,
                    # input_audio_format=messages.AudioFormats.PCM16,
                    # vads=messages.VADConfig(),
                )
            )

            [start_session_message, _] = await asyncio.gather(
                *[
                    anext(client.listen()),
                    client.send_message(
                        messages.UpdateConversationConfig(
                            system_message=inference_config.system_message,
                            output_audio_format=messages.AudioFormats.PCM16,
                            voice=inference_config.voice,
                            tools=tools.model_description() if tools else None,
                            transcribe_input=False,
                        )
                    ),
                ]
            )
            assert isinstance(start_session_message, messages.StartSession)
            print(
                f"Session started: {start_session_message.session.id} model: {start_session_message.session.model}"
            )

            agent = cls(
                client=client,
                tools=tools,
                channel=channel,
            )
            await agent.run()

    finally:
        await engine.disconnect()
        await shutdown(asyncio.get_event_loop())
```

### Start the agent

The `entry_point` method is the primary entry point for launching the agent. It invokes `setup_and_run_agent` with the relevant parameters, initializing the agent and triggering its functionalities. 

```python
@classmethod
async def entry_point(
    cls,
    *,
    engine: RtcEngine,
    inference_config: InferenceConfig,
    tools: ToolContext | None = None,
) -> None:
    await cls.setup_and_run_agent(
        engine=engine, inference_config=inference_config, tools=tools
    )
```

### Initialize the RealtimeKitAgent

The `RealtimeKitAgent` class constructor accepts an OpenAI `RealtimeApiClient`, an optional `ToolContext` for function registration, and an Agora Channel for audio communication. This setup prepares the agent for processing audio streams and interacting with the AI model.

```python
def __init__(
    self,
    *,
    client: RealtimeApiClient,
    tools: ToolContext | None,
    channel: Channel,
) -> None:
    self.client = client
    self.tools = tools
    self._client_tool_futures = {}
    self.channel = channel
```

### Run the agent 

The asynchronous `run` method orchestrates the main operations of the `RealtimeKitAgent`. It handles audio streaming, manages tasks for processing audio input, output, and model messages, and sets up exception handling. 

```python
async def run(self) -> None:
    def log_exception(t: asyncio.Task[Any]) -> None:
        if not t.cancelled() and t.exception():
            logger.error(
                "unhandled exception",
                exc_info=t.exception(),
            )

    disconnected_future = asyncio.Future[None]()

    def _on_disconnected() -> None:
        if not disconnected_future.done():
            disconnected_future.set_result(None)

    # self.room.on("disconnected", _on_disconnected)

    asyncio.create_task(self._stream_input_audio_to_model()).add_done_callback(
        log_exception
    )
    asyncio.create_task(
        self._stream_audio_queue_to_audio_output()
    ).add_done_callback(log_exception)

    asyncio.create_task(self._process_model_messages()).add_done_callback(
        log_exception
    )

    await disconnected_future
    logger.info("Agent finished running")
```

### Stream input audio to the AI model

This asynchronous method `_stream_input_audio_to_model` captures audio frames from the Agora channel and sends them to the OpenAI API client for processing. It listens for incoming audio frames and forwards them for real-time audio analysis by the AI model.

```python
async def _stream_input_audio_to_model(self) -> None:
    audio_frames = self.channel.get_audio_frames()
    async for audio_frame in audio_frames:
        # send the frame to the model via the API client
        await self.client.send_audio_data(audio_frame.data)
```

### Stream audio from the model to the user

This asynchronous method `_stream_audio_queue_to_audio_output` manages the transmission of processed audio data from the AI model back to the end-user. It retrieves audio frames from a queue and sends them to the Agora channel, allowing users to hear the AI-generated responses in real-time.

```python
async def _stream_audio_queue_to_audio_output(self) -> None:
    while True:
        # audio queue contains audio data from the model, send it the end-user via our local audio source
        frame = await self.audio_queue.get()
        await self.channel.push_audio_frame(frame)
        await asyncio.sleep(0)  # allow other tasks to run  
```

This asynchronous method `_process_model_messages` listens for incoming messages from the OpenAI API client and processes them based on their type. It handles various message types, such as audio deltas, transcriptions, and errors, and ensures appropriate action for each message. This includes updating the user chat with transcribed text and managing audio playback.

```python
async def _process_model_messages(self) -> None:
    async for message in self.client.listen():
        match message:
            case messages.ResonseAudioDelta():
                # logger.info("Received audio message")
                await self.audio_queue.put(base64.b64decode(message.delta))

            case messages.ResonseAudioTranscriptionDelta():
                logger.info(f"Received text message {message=}")
                await self.channel.chat.send_message(ChatMessage(message=message.delta, msg_id=message.output_item_id))

            case messages.ResonseAudioTranscriptionDone():
                logger.info(f"Text message done: {message=}")
                await self.channel.chat.send_message(ChatMessage(message=message.value, msg_id=message.output_item_id, done=True))

            case messages.MessageAdded():
                pass
            case messages.ServerAddMessage():
                pass

            case messages.VADSpeechStarted():
                pass
            case messages.VADSpeechStopped():
                pass

            case messages.GenerationCanceled():
                logger.info(f"Server turn canceled: {message=}")

            case messages.GenerationFinished():
                # TODO this is where we mark no longer appending text
                logger.info(f"Server turn finished: {message=}")
                # await self.channel.generation_finished()

            case messages.AddContent(type=messages.AddContentType.TOOL_CALL):
                # TODO implement streaming tool calls
                logger.info(f"Received tool call buffer add {message=}")

            case messages.RealtimeError(error=error):
                # TODO do we have to stop the session here?
                logger.error(f"Received error message {error=}")

            case _:
                logger.warning(f"Unhandled message {message=}")
```


### Complete code

The `agent.py` script integrates the code components presented in this section into reusable Python classes that you can extend for your own applications.

<details>
<summary>Complete code for `agent.py`</summary>
<CodeBlock showLineNumbers language="python">
{`import abc
import asyncio
import base64
import json
import logging
import os
from builtins import anext
from typing import Any, Callable, assert_never

from attr import dataclass
from dotenv import load_dotenv
from pydantic import BaseModel

from realtimekit.realtimeapi import messages
from realtimekit.realtimeapi.client import RealtimeApiClient

from .agora.rtc import Channel, Chat, ChatMessage, RtcEngine

logger = logging.getLogger(__name__)


@dataclass(frozen=True, kw_only=True)
class InferenceConfig:
    system_message: str | None = None
    turn_detection: messages.TurnDetectionTypes | None = None
    voice: messages.Voices | None = None


@dataclass(frozen=True, kw_only=True)
class LocalFunctionToolDeclaration:
    """Declaration of a tool that can be called by the model, and runs a function locally on the tool context."""

    name: str
    description: str
    parameters: dict[str, Any]
    function: Callable[..., Any]

    def model_description(self) -> dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters,
            },
        }


@dataclass(frozen=True, kw_only=True)
class PassThroughFunctionToolDeclaration:
    """Declaration of a tool that can be called by the model, and is passed through the LiveKit client."""

    name: str
    description: str
    parameters: dict[str, Any]

    def model_description(self) -> dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters,
            },
        }


ToolDeclaration = LocalFunctionToolDeclaration | PassThroughFunctionToolDeclaration


@dataclass(frozen=True, kw_only=True)
class LocalToolCallExecuted:
    json_encoded_output: str


@dataclass(frozen=True, kw_only=True)
class ShouldPassThroughToolCall:
    decoded_function_args: dict[str, Any]


ExecuteToolCallResult = LocalToolCallExecuted | ShouldPassThroughToolCall


class ToolContext(abc.ABC):
    _tool_declarations: dict[str, ToolDeclaration]

    def __init__(self) -> None:
        # TODO should be an ordered dict
        self._tool_declarations = {}

    def register_function(
        self,
        *,
        name: str,
        description: str = "",
        parameters: dict[str, Any],
        fn: Callable[..., Any],
    ) -> None:
        self._tool_declarations[name] = LocalFunctionToolDeclaration(
            name=name, description=description, parameters=parameters, function=fn
        )

    def register_client_function(
        self,
        *,
        name: str,
        description: str = "",
        parameters: dict[str, Any],
    ) -> None:
        self._tool_declarations[name] = PassThroughFunctionToolDeclaration(
            name=name, description=description, parameters=parameters
        )

    async def execute_tool(
        self, tool_name: str, encoded_function_args: str
    ) -> ExecuteToolCallResult | None:
        tool = self._tool_declarations.get(tool_name)
        if not tool:
            return None

        args = json.loads(encoded_function_args)
        assert isinstance(args, dict)

        if isinstance(tool, LocalFunctionToolDeclaration):
            logger.info(f"Executing tool {tool_name} with args {args}")
            result = await tool.function(**args)
            logger.info(f"Tool {tool_name} executed with result {result}")
            return LocalToolCallExecuted(json_encoded_output=json.dumps(result))

        if isinstance(tool, PassThroughFunctionToolDeclaration):
            return ShouldPassThroughToolCall(decoded_function_args=args)

        assert_never(tool)

    def model_description(self) -> list[dict[str, Any]]:
        return [v.model_description() for v in self._tool_declarations.values()]


class ClientToolCallResponse(BaseModel):
    tool_call_id: str
    result: dict[str, Any] | str | float | int | bool | None = None


class RealtimeKitAgent:
    engine: RtcEngine
    channel: Channel
    client: RealtimeApiClient
    audio_queue: asyncio.Queue[bytes] = asyncio.Queue()
    message_queue: asyncio.Queue[messages.ResonseAudioTranscriptionDelta] = asyncio.Queue()
    message_done_queue: asyncio.Queue[messages.ResonseAudioTranscriptionDone] = asyncio.Queue()
    tools: ToolContext | None = None

    _client_tool_futures: dict[str, asyncio.Future[ClientToolCallResponse]]

    @classmethod
    async def setup_and_run_agent(
        cls,
        *,
        engine: RtcEngine,
        inference_config: InferenceConfig,
        tools: ToolContext | None,
    ) -> None:
        channel = await engine.connect(channelId="realtimekit_agora", uid="123")

        try:
            async with RealtimeApiClient(
                base_uri=os.getenv("REALTIME_API_BASE_URI", "wss://api.openai.com"),
                api_key=os.getenv("OPENAI_API_KEY"),
                verbose=False,
            ) as client:
                await client.send_message(
                    messages.UpdateSessionConfig(
                        session=messages.SessionResource(),
                        # turn_detection=inference_config.turn_detection,
                        # transcribe_input=False,
                        # input_audio_format=messages.AudioFormats.PCM16,
                        # vads=messages.VADConfig(),
                    )
                )

                [start_session_message, _] = await asyncio.gather(
                    *[
                        anext(client.listen()),
                        client.send_message(
                            messages.UpdateConversationConfig(
                                system_message=inference_config.system_message,
                                output_audio_format=messages.AudioFormats.PCM16,
                                voice=inference_config.voice,
                                tools=tools.model_description() if tools else None,
                                transcribe_input=False,
                            )
                        ),
                    ]
                )
                assert isinstance(start_session_message, messages.StartSession)
                print(
                    f"Session started: {start_session_message.session.id} model: {start_session_message.session.model}"
                )

                agent = cls(
                    client=client,
                    tools=tools,
                    channel=channel,
                )
                await agent.run()

        finally:
            await engine.disconnect()
            await shutdown(asyncio.get_event_loop())

    @classmethod
    async def entry_point(
        cls,
        *,
        engine: RtcEngine,
        inference_config: InferenceConfig,
        tools: ToolContext | None = None,
    ) -> None:
        await cls.setup_and_run_agent(
            engine=engine, inference_config=inference_config, tools=tools
        )

    def __init__(
        self,
        *,
        client: RealtimeApiClient,
        tools: ToolContext | None,
        channel: Channel,
    ) -> None:
        self.client = client
        self.tools = tools
        self._client_tool_futures = {}
        self.channel = channel

    async def run(self) -> None:
        def log_exception(t: asyncio.Task[Any]) -> None:
            if not t.cancelled() and t.exception():
                logger.error(
                    "unhandled exception",
                    exc_info=t.exception(),
                )

        disconnected_future = asyncio.Future[None]()

        def _on_disconnected() -> None:
            if not disconnected_future.done():
                disconnected_future.set_result(None)

        # self.room.on("disconnected", _on_disconnected)

        asyncio.create_task(self._stream_input_audio_to_model()).add_done_callback(
            log_exception
        )
        asyncio.create_task(
            self._stream_audio_queue_to_audio_output()
        ).add_done_callback(log_exception)

        asyncio.create_task(self._process_model_messages()).add_done_callback(
            log_exception
        )

        await disconnected_future
        logger.info("Agent finished running")

    async def _stream_input_audio_to_model(self) -> None:
        audio_frames = self.channel.get_audio_frames()
        async for audio_frame in audio_frames:
            # send the frame to the model via the API client
            await self.client.send_audio_data(audio_frame.data)

    async def _stream_audio_queue_to_audio_output(self) -> None:
        while True:
            # audio queue contains audio data from the model, send it the end-user via our local audio source
            frame = await self.audio_queue.get()
            await self.channel.push_audio_frame(frame)
            await asyncio.sleep(0)  # allow other tasks to run         
        

    async def _process_model_messages(self) -> None:
        async for message in self.client.listen():
            match message:
                case messages.ResonseAudioDelta():
                    # logger.info("Received audio message")
                    await self.audio_queue.put(base64.b64decode(message.delta))

                case messages.ResonseAudioTranscriptionDelta():
                    logger.info(f"Received text message {message=}")
                    await self.channel.chat.send_message(ChatMessage(message=message.delta, msg_id=message.output_item_id))

                case messages.ResonseAudioTranscriptionDone():
                    logger.info(f"Text message done: {message=}")
                    await self.channel.chat.send_message(ChatMessage(message=message.value, msg_id=message.output_item_id, done=True))

                case messages.MessageAdded():
                    pass
                case messages.ServerAddMessage():
                    pass

                case messages.VADSpeechStarted():
                    pass
                case messages.VADSpeechStopped():
                    pass

                case messages.GenerationCanceled():
                    logger.info(f"Server turn canceled: {message=}")

                case messages.GenerationFinished():
                    # TODO this is where we mark no longer appending text
                    logger.info(f"Server turn finished: {message=}")
                    # await self.channel.generation_finished()

                case messages.AddContent(type=messages.AddContentType.TOOL_CALL):
                    # TODO implement streaming tool calls
                    logger.info(f"Received tool call buffer add {message=}")

                case messages.RealtimeError(error=error):
                    # TODO do we have to stop the session here?
                    logger.error(f"Received error message {error=}")

                case _:
                    logger.warning(f"Unhandled message {message=}")

async def shutdown(loop, signal=None):
    """Gracefully shut down the application."""
    if signal:
        print(f"Received exit signal {signal.name}...")
    
    tasks = [t for t in asyncio.all_tasks() if t is not asyncio.current_task()]
    
    print(f"Cancelling {len(tasks)} outstanding tasks")
    for task in tasks:
        task.cancel()

    await asyncio.gather(*tasks, return_exceptions=True)
    loop.stop()

if __name__ == "__main__":
    load_dotenv()
    asyncio.run(
        RealtimeKitAgent.entry_point(
            engine=RtcEngine(appid="aab8b8f5a8cd4469a63042fcfafe7063"),
            inference_config=InferenceConfig(
                system_message="""\
You are a helpful assistant. If asked about the weather make sure to use the provided tool to get that information. \
If you are asked a question that requires a tool, say something like "working on that" and dont provide a concrete response \
until you have received the response to the tool call.\
""",
                voice=messages.Voices.Alloy,
                turn_detection=messages.TurnDetectionTypes.SERVER_VAD,
            ),
        )
    )`}
</CodeBlock>
</details>

## Test your code

1. Create an `.env` file containing the Agora and OpenAI connection parameters:

    ```python
    # .env file

    # API base URI for the Realtime API
    REALTIME_API_BASE_URI=wss://api.openai.com

    # OpenAI API key for authentication
    OPENAI_API_KEY=your_openai_api_key_here

    # Agora RTC app ID
    AGORA_APP_ID=your_agora_app_id
    ```

## Reference

This section contains content that completes the information on this page, or points you to documentation that explains other aspects to this product.

- [Voice calling quickstart (Python)](/voice-calling/get-started/get-started-sdk?platform=python)