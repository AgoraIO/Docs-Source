import ImportLibrary from '@docs/assets/code/video-sdk/custom-video-and-audio/import-library.mdx';
import SetVariables from '@docs/assets/code/video-sdk/custom-video-and-audio/set-variables.mdx';
import EnableVideoPublishing from '@docs/assets/code/video-sdk/custom-video-and-audio/enable-video-publishing.mdx';
import RenderCustomVideo from '@docs/assets/code/video-sdk/custom-video-and-audio/render-custom-video.mdx';
import PushVideoFrames from '@docs/assets/code/video-sdk/custom-video-and-audio/push-video-frames.mdx';

import ImportAudioLibrary from '@docs/assets/code/video-sdk/custom-video-and-audio/import-library-audio.mdx';
import SetAudioVariables from '@docs/assets/code/video-sdk/custom-video-and-audio/set-variables-audio.mdx';
import EnableAudioPublishing from '@docs/assets/code/video-sdk/custom-video-and-audio/enable-audio-publishing.mdx';
import ReadAudioInput from '@docs/assets/code/video-sdk/custom-video-and-audio/read-audio-input.mdx';
import PushAudioFrames from '@docs/assets/code/video-sdk/custom-video-and-audio/push-audio-frames.mdx';
import CustomVideoTrack from '@docs/assets/code/video-sdk/custom-video-and-audio/create-custom-video-track.mdx';
import CustomAudioTrack from '@docs/assets/code/video-sdk/custom-video-and-audio/create-custom-audio-track.mdx';
import DestroyCustomAudioTrack from '@docs/assets/code/video-sdk/custom-video-and-audio/destroy-custom-track-audio.mdx';
import ConfigureEngine from '@docs/assets/code/video-sdk/custom-video-and-audio/configure-engine.mdx';
import ConfigureEngineAudio from '@docs/assets/code/video-sdk/custom-video-and-audio/configure-engine-audio.mdx';


<PlatformWrapper platform="ios, macos, android, react-js, unity">
<ProductWrapper notAllowed="voice-calling">
## Implement a custom video source

In the following code example, you create the basic framework required to push video frames from a custom source. Depending on the type of your source, you add your own code to this framework that converts the source data to `VideoFrame` data. To create the basic framework, take the following steps:

### Add the required imports

    <ImportLibrary />

### Add the required variables

    <SetVariables />
<PlatformWrapper notAllowed="react-js, unity">

### Enable custom video track publishing

    You configure the following to enable publishing of the captured video from a custom source:

    <PlatformWrapper platform="ios, macos">
    Add the following line to the `init()` method of `AgoraManager` to set the external video source to `true` before joining a channel:
    </PlatformWrapper>

    <EnableVideoPublishing />

### Setup a video renderer for custom video

    <RenderCustomVideo />

### Push the video frames

    A callback method of `AgoraManager` is called when a video frame is captured. You use the data in the callback to create a `VideoFrame`, and push the `VideoFrame` to the channel.

    <PushVideoFrames />
</PlatformWrapper>
<PlatformWrapper platform="react-js">
### Create a custom source video track

    <CustomVideoTrack/>
### Render and publish the custom video track

    <RenderCustomVideo />
</PlatformWrapper>
<PlatformWrapper platform="unity">
### Configure the <Vg k="COMPANY"/> engine
   <ConfigureEngine/>
### Manage the custom video source

    <CustomVideoTrack/>
### Push the video frames

    To customize the video source, the `ShareScreen` coroutine captures a Unity texture frame, handles platform-specific texture data, configures an `ExternalVideoFrame` frame, and pushes it to the channel:
    <PushVideoFrames />
</PlatformWrapper>
</ProductWrapper>

## Implement a custom audio source

To push audio from a custom source to a channel, take the following steps:

<PlatformWrapper platform="ios, macos">

### Enable publishing the custom audio

    You configure the following to enable publishing of the captured audio from a custom source:

    <EnableAudioPublishing />

### Setup an audio renderer for custom audio

    For rendering audio frames captured in the push mode, implement a custom audio renderer using methods from outside the SDK because it's not supported by <Vg k="VSDK" />.

    [AVCaptureAudioDataOutput](https://developer.apple.com/documentation/avfoundation/avcaptureaudiodataoutput) can be used to receive the audio frames when they are captured. These frames can then be added as an audio output to an audio capturing session using [`AVCaptureSession`](https://developer.apple.com/documentation/avfoundation/avcapturesession).

    Have a look at [`AgoraAudioSourcePush`](https://github.com/AgoraIO/video-sdk-samples-ios/blob/main/custom-video-and-audio/AgoraAudioSourcePush.swift) for more details.

### Push the audio frames

    When an audio frame is captured, a callback method of `AgoraManager` is called. You push this data in the callback to the <Vg k="VSDK" /> to use as an external audio frame sample buffer:

    <PushAudioFrames />
</PlatformWrapper>

<PlatformWrapper platform="android, react-js, unity">

### Add the required imports

    <ImportAudioLibrary />

### Add the required variables

    <SetAudioVariables />
<PlatformWrapper notAllowed="react-js, unity">

### Enable custom audio track publishing

    To enable custom audio track publishing, you set `ChannelMediaOptions` to disable the microphone audio track and enable the custom audio track. You also enable custom audio local playback and set the external audio source. 

    <EnableAudioPublishing />

### Read the input stream into a buffer

    You read data from the input stream into a buffer.

    <ReadAudioInput />

### Push the audio frames

    You push the data in the buffer as an audio frame using a separate process.

    <PushAudioFrames />
</PlatformWrapper>
<PlatformWrapper platform="react-js">
### Create a custom source audio track

    <CustomAudioTrack/>
### Play and publish the custom audio track

    <EnableAudioPublishing />
</PlatformWrapper>
<PlatformWrapper platform="unity">

### Configure the <Vg k="COMPANY"/> engine
    <ConfigureEngineAudio/>
### Create a custom source audio track

    <CustomAudioTrack/>

### Manage the audio source

    <ReadAudioInput />

### Push the audio frames

    You push the data in the buffer as an audio frame using a separate process.

    <PushAudioFrames />
### Destroy the custom audio track
    <DestroyCustomAudioTrack/>
</PlatformWrapper>

</PlatformWrapper>

</PlatformWrapper>

<PlatformWrapper platform="web">
### Add the required imports

    <ImportLibrary />
<ProductWrapper notAllowed="voice-calling">
### Enable custom video track publishing

    You configure the following to enable publishing of the captured video from a custom source:

    <EnableVideoPublishing />
</ProductWrapper>

### Enable custom audio track publishing

    You configure the following to enable publishing of the captured audio from a custom source:

    <EnableAudioPublishing />

</PlatformWrapper>
