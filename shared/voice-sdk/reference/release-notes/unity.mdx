<PlatformWrapper platform="unity">
## v4.1.0

v4.1.0 was released on December 20, 2022.

#### New features

**1. In-ear monitoring**

This release adds support for in-ear monitoring. You can call `EnableInEarMonitoring` to enable the in-ear monitoring function.

After successfully enabling the in-ear monitoring function, you can call `RegisterAudioFrameObserver` to register the audio observer, and the SDK triggers the `OnEarMonitoringAudioFrame` callback to report the audio frame data. You can use your own audio effect processing module to preprocess the audio frame data of the in-ear monitoring to implement custom audio effects. Agora recommends that you choose one of the following two methods to set the audio data format of the in-ear monitoring:

- Call the `SetEarMonitoringAudioFrameParameters` method to set the audio data format of in-ear monitoring. The SDK calculates the sampling interval based on the parameters in this method and triggers the `OnEarMonitoringAudioFrame` callback based on the sampling interval.
- Set the audio data format in the return value of the `GetEarMonitoringAudioParams` callback. The SDK calculates the sampling interval based on the return value of the callback and triggers the `OnEarMonitoringAudioFrame` callback based on the sampling interval.

To adjust the in-ear monitoring volume, you can call `SetInEarMonitoringVolume`.

**2. Audio capture device test (Android)**

This release adds support for testing local audio capture devices before joining a channel. You can call `StartRecordingDeviceTest` to start the audio capture device test. After the test is complete, call the `StopPlaybackDeviceTest` method to stop the audio capture device test.

**3. Local network connection types**

To make it easier for users to know the connection type of the local network at any stage, this release adds the `GetNetworkType` method. You can use this method to get the type of network connection in use. The available values are `UNKNOWN`, `DISCONNECTED`, `LAN`, `WIFI`, `2G`, `3G`, `4G`, and `5G`. When the local network connection type changes, the SDK triggers the `OnNetworkTypeChanged` callback to report the current network connection type.

**4. Audio stream filter**

This release introduces filtering audio streams based on volume. Once this function is enabled, the Agora server ranks all audio streams by volume and transports the three audio streams with the highest volumes to the receivers by default. The number of audio streams to be transported can be adjusted; contact [support@agora.io](support@agora.io) to adjust this number according to your scenarios.

Agora also supports publishers in choosing whether the audio streams being published are to be filtered based on volume. Streams that are not filtered bypass this filter mechanism and are transported directly to the receivers. In scenarios with a number of publishers, enabling this function helps reduce the bandwidth and device system pressure for the receivers.

<div class="alert info">To enable this function, contact <a href="support@agora.io">support@agora.io</a>.</div>

**5. Loopback device (Windows)**

The SDK uses the playback device as the loopback device by default. As of 4.1.0, you can specify a loopback device separately and publish the captured audio to the remote end.

- `SetLoopbackDevice`: Specifies the loopback device. If you do not want the current playback device to be the loopback device, you can call this method to specify another device as the loopback device.
- `GetLoopbackDevice`: Gets the current loopback device.
- `FollowSystemLoopbackDevice`: Whether the loopback device follows the default playback device of the system.

**6. Spatial audio effect**

This release adds the following features applicable to spatial audio effect scenarios, which can effectively enhance the user's sense-of-presence experience in virtual interactive scenarios.

- Sound insulation area: You can set a sound insulation area and sound attenuation parameter by calling `SetZones`. When the sound source (which can be a user or the media player) and the listener belong to the inside and outside of the sound insulation area, the listener experiences an attenuation effect similar to that of the sound in the real environment when it encounters a building partition. You can also set the sound attenuation parameter for the media player and the user by calling `SetPlayerAttenuation` and `SetRemoteAudioAttenuation` respectively, and specify whether to use that setting to force an override of the sound attenuation parameter in `SetZones`.
- Doppler sound: You can enable Doppler sound by setting the `enable_doppler` parameter in `SpatialAudioParams`. The receiver experiences noticeable tonal changes in the event of a high-speed relative displacement between the source and receiver (such as in a racing game scenario).
- Headphone equalizer: You can use a preset headphone equalization effect by calling the `SetHeadphoneEQPreset` method to improve the audio experience for users with headphones.

**7. Headphone equalization effect**

This release adds the `SetHeadphoneEQParameters` method, which is used to adjust the low- and high-frequency parameters of the headphone EQ. This is mainly useful in spatial audio scenarios. If you cannot achieve the expected headphone EQ effect after calling `SetHeadphoneEQPreset`, you can call `setHeadphoneEQParameters` to adjust the EQ.

**8. MPUDP (MultiPath UDP) (Beta)**

As of this release, the SDK supports MPUDP protocol, which enables you to connect and use multiple paths to maximize the use of channel resources based on the UDP protocol. You can use different physical NICs on both mobile and desktop and aggregate them to effectively combat network jitter and improve transmission quality.

<div class="alert info">To enable this feature, contact <a href="sales-us@agora.io">sales-us@agora.io</a>.</div>

**9. Register extensions (Windows)**

This release adds the `RegisterExtension` method for registering extensions. When using a third-party extension, you need to call the extension-related APIs in the following order:

`loadExtensionProvider` -> `registerExtension` -> `setExtensionProviderProperty` -> `enableExtension`

**10. Device management (Windows, macOS)**

This release adds a series of callbacks to help you better understand the status of your audio devices:

- `OnAudioDeviceStateChanged`: Occurs when the status of the audio device changes.
- `OnAudioDeviceVolumeChanged`: Occurs when the volume of an audio device or app changes.

**11. Multi-channel management**

This release adds a series of multi-channel-related methods that you can call to manage audio streams in multi-channel scenarios.

- The `MuteLocalAudioStreamEx` method is used to cancel or resume publishing a local audio stream.
- The `MuteAllRemoteAudioStreamsEx`  is used to cancel or resume the subscription of all remote users to audio streams.
- The `StartRtmpStreamWithoutTranscodingEx`, `StartRtmpStreamWithTranscodingEx`, `UpdateRtmpTranscodingEx`, and `StopRtmpStreamEx` methods are used to implement Media Push in multi-channel scenarios.
- The `StartChannelMediaRelayEx`, `UpdateChannelMediaRelayEx`, `PauseAllChannelMediaRelayEx`, `ResumeAllChannelMediaRelayEx`, and `StopChannelMediaRelayEx` methods are used to relay media streams across channels in multi-channel scenarios.
- The `LeaveChannelEx` [2/2] method. Compared with the `LeaveChannelEx` [1/2] method, a new `options` parameter is added, which is used to choose whether to stop recording with the microphone when leaving a channel in a multi-channel scenario.

**12. Client role switching**

In order to enable users to know whether the switched user role is low-latency or ultra-low-latency, this release adds the `newRoleOptions` parameter to the `OnClientRoleChanged` callback. The value of this parameter is as follows:

- `AUDIENCE_LATENCY_LEVEL_LOW_LATENCY` (1): Low latency.
- `AUDIENCE_LATENCY_LEVEL_ULTRA_LOW_LATENCY` (2): Ultra-low latency.

#### Improvements

**1. Bluetooth permissions (Android)**

To simplify integration, as of this release, you can use the SDK to enable Android users to use Bluetooth normally without adding the `BLUETOOTH_CONNECT`permission.

**2. Relaying media streams across channels**

This release optimizes the `UpdateChannelMediaRelay` method as follows:

- Before v4.1.0: If the target channel update fails due to internal reasons in the server, the SDK returns the error code `RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_REFUSED`(8), and you need to call the `UpdateChannelMediaRelay` method again.
- v4.1.0 and later: If the target channel update fails due to internal server reasons, the SDK retries the update until the target channel update is successful.

**3. Reconstructed AIAEC algorithm**

This release reconstructs the AEC algorithm based on the AI method. Compared with the traditional AEC algorithm, the new algorithm can preserve the complete, clear, and smooth near-end vocals under poor echo-to-signal conditions, significantly improving the system's echo cancellation and dual-talk performance. This gives users a more comfortable call and live-broadcast experience. AIAEC is suitable for conference calls, chats, karaoke, and other scenarios.

**Other improvements**

This release includes the following additional improvements:

- Reduces the latency when pushing external audio sources.
- Improves the performance of echo cancellation when using the `AUDIO_SCENARIO_MEETING` scenario.
- Enhances the ability to identify different network protocol stacks and improves the SDK's access capabilities in multiple-operator network scenarios.

#### Issues fixed

This release fixed the following issues:

**All**

  - The call `GetExtensionProperty` failed and returned an empty string.
  - Audience members heard buzzing noises when the host switched between speakers and earphones during live streaming.
  - Crashes occurred if you call the `RegisterAudioEncodedFrameObserver` method after failing to initialize  `RtcEngine`.

**Android**

  - After calling `SetCloudProxy` to set the cloud proxy, calling `JoinChannelEx` to join multiple channels failed.
  - In online meeting scenarios, the local user and the remote user occasionally could not hear each other after the local user was interrupted by a call.

**iOS**

  - Calling `StartAudioMixing` to play music files in the `ipod-library://item` path failed.

**macOS**

  - After starting and stopping the audio capture device test, there was no sound when the audio playback device was subsequently started.

#### API changes

**Added**

- `EnableInEarMonitoring`
- `SetEarMonitoringAudioFrameParameters`
- `OnEarMonitoringAudioFrame`
- `SetInEarMonitoringVolume`
- `GetEarMonitoringAudioParams`
- `StartRecordingDeviceTest` (Android)
- `StopRecordingDeviceTest` (Android)
- `GetNetworkType`
- `SetRecordingDeviceVolume`  (Windows)
- `isAudioFilterable` in `ChannelMediaOptions`
- `SetLoopbackDevice`
- `GetLoopbackDevice`
- `FollowSystemLoopbackDevice`
- `SetZones`
- `SetPlayerAttenuation`
- `SetRemoteAudioAttenuation`
- `MuteRemoteAudioStream`
- `SpatialAudioParams`
- `SetHeadphoneEQPreset`
- `HEADPHONE_EQUALIZER_PRESET`
- `SetHeadphoneEQParameters`
- `LeaveChannelEx` [2/2]
- `MuteLocalAudioStreamEx`
- `MuteAllRemoteAudioStreamsEx`
- `StartRtmpStreamWithoutTranscodingEx`
- `StartRtmpStreamWithTranscodingEx`
- `UpdateRtmpTranscodingEx`
- `StopRtmpStreamEx`
- `StartChannelMediaRelayEx`
- `UpdateChannelMediaRelayEx`
- `PauseAllChannelMediaRelayEx`
- `ResumeAllChannelMediaRelayEx`
- `StopChannelMediaRelayEx`
- `newRoleOptions` in `OnClientRoleChanged`
- `AdjustUserPlaybackSignalVolumeEx`
- `EnableAudioVolumeIndicationEx`
- `OnAudioDeviceStateChanged ` (Windows,macOS)
- `OnAudioDeviceVolumeChanged ` (Windows,macOS)
- `SetParameters` in `IRtcEngine` (Windows)

**Deprecated**

- `StartEchoTest` [2/3]
- `OnApiCallExecuted`. Use the callbacks triggered by specific methods instead.

**Deleted**

- Removes `RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_REFUSED`(8) in `OnChannelMediaRelayEvent` callback.

## v<Vg k = "VSDK_LATEST_4_0_0"/>

v<Vg k = "VSDK_LATEST_4_0_0"/> was released on September 28, 2022.

#### Compatibility changes

This release has optimized the implementation of some features, resulting in incompatibility with v<Vg k = "VSDK_PREVIOUS_RELEASE"/>. The following are the main features with compatibility changes:
- Multiple channel
- Media stream publishing control
- Warning codes

After upgrading the SDK, you need to update the code in your app according to your business scenarios. For details, see [Migration guide](../develop/migration-guide).

#### New features

**1. Multiple media tracks**

This release supports one `IRtcEngine` instance to collect multiple audio and video sources at the same time and publish them to the remote users by setting `IRtcEngineEx` and `ChannelMediaOptions.`

- After calling `JoinChannel` to join the first channel, call `JoinChannelEx` multiple times to join multiple channels, and publish the specified stream to different channels through different user ID (`localUid`) and `ChannelMediaOptions` settings.
- You can simultaneously publish multiple sets of video streams captured by multiple cameras or screen sharing by setting `publishSecondaryCameraTrack` and `publishSecondaryScreenTrack` in `ChannelMediaOptions`. (Windows)

This release adds `CreateCustomVideoTrack` method to implement video custom capture. You can refer to the following steps to publish multiple custom captured video in the channel:

1. Create a custom video track: Call the `CreateCustomVideoTrack` method to create a video track, and get the video track ID.
2. Set the custom video track to be published in the channel: In each channel's `ChannelMediaOptions`, set the `customVideoTrackId` parameter to the ID of the video track you want to publish, and set `publishCustomVideoTrack` to `true`.
3. Pushing an external video source: Call `PushVideoFrame`, and specify `videoTrackId` as the ID of the custom video track in step 2 in order to publish the corresponding custom video source in multiple channels.

You can also experience the following features with the multi-channel capability:

- Publish multiple sets of audio and video streams to the remote users through different user IDs (`uid`).
- Mix multiple audio streams and publish to the remote users through a user ID (`uid`).
- Combine multiple video streams and publish them to the remote users through a user ID (`uid`).

**2. Ultra HD resolution (Beta)**

In order to improve the interactive video experience, the SDK optimizes the whole process of video capture, encoding, decoding and rendering, and now supports 4K resolution. The improved FEC (Forward Error Correction) algorithm enables adaptive switches according to the frame rate and number of video frame packets, which further reduces the video stuttering rate in 4K scenes.

Additionally, you can set the encoding resolution to 4K (3840 × 2160) and the frame rate to 60 fps when calling `SetVideoEncoderConfiguration`. The SDK supports automatic fallback to the appropriate resolution and frame rate if your device does not support 4K.

> **_NOTE:_** This feature has certain requirements with regards to device performance and network bandwidth, and the supported upstream and downstream frame rates vary on different platforms. To experience this feature, contact [support@agora.io](mailto:support@agora.io).

**3. Agora media player**

To make it easier for users to integrate the Agora SDK and reduce the SDK's package size, this release introduces the Agora media player.  You can then call the methods in the `IMediaPlayer` class to experience a series of functions:

- Plays local and online media files.
- Preloads media files.
- Changes the CDN route for playing media files according your network conditions.
- Shares the audio and video streams being played with remote users.
- Caches data when playing media files.

**3. Brand-new AI Noise Suppression**

The SDK supports a new version of AI noise reduction (in comparison to the basic AI noise reduction in v<Vg k = "VSDK_PREVIOUS_RELEASE"/>). The new AI noise reduction has better vocal fidelity, cleaner noise suppression, and adds a dereverberation option. To experience this feature, contact sales-us@agora.io.

**5. Ultra-high audio quality**

To make the audio clearer and restore more details, this release adds the `ULTRA_HIGH_QUALITY_VOICE` enumeration. In scenarios that mainly feature the human voice, such as chat or singing, you can call `SetVoiceBeautifierPreset` and use this enumeration to experience ultra-high audio quality.

**6. Spatial audio**

> **_NOTE:_** This feature is in experimental status. To enable this feature, contact sales-us@agora.io. Contact [Technical Support](mailto:support@agora.io) if needed.

You can set the spatial audio for the remote user as following:

- Local Cartesian Coordinate System Calculation Solution: This solution uses the `ILocalSpatialAudioEngine` class to implement spatial audio by calculating the spatial coordinates of the remote user. You need to call `UpdateSelfPosition` and `UpdateRemotePosition` to update the spatial coordinates of the local and remote users respectively, so that the local user can hear the spatial audio of the remote user.
![Spatial effect](/images/video-sdk/video-call-spatial.png)

- Local Cartesian Coordinate System Calculation Solution: This solution uses the `ILocalSpatialAudioEngine` class to implement spatial audio. You need to call `UpdateSelfPosition` and `UpdatePlayerPositionInfo` to update the spatial coordinates of the local user and media player, respectively, so that the local user can hear the spatial audio effect of media player.
![Spatial effect](/images/video-sdk/spatial-audio-effect.png)

**7.** **Real-time chorus**

This release gives real-time chorus the following abilities:

- Two or more choruses are supported.
- Each singer is independent of each other. If one singer fails or quits the chorus, the other singers can continue to sing.
- Very low latency experience. Each singer can hear each other in real time, and the audience can also hear each singer in real time.

This release adds the `AUDIO_SCENARIO_CHORUS` enumeration in `AUDIO_SCENARIO_TYPE`. With this enumeration, users can experience ultra-low latency in real-time chorus when the network conditions are good.

**8. Enhanced channel management**

To meet the channel management requirements of various business scenarios, this release adds the following functions to the `ChannelMediaOptions` structure:

- Sets or switches the publishing of multiple audio and video sources.
- Sets or switches channel profile and user role.
- Sets or switches the stream type of the subscribed video.
- Controls audio publishing delay.

Set `ChannelMediaOptions` when calling `JoinChannel` or `JoinChannelEx` to specify the publishing and subscription behavior of a media stream, for example, whether to publish video streams captured by cameras or screen sharing, and whether to subscribe to the audio and video streams of remote users. After joining the channel, call `UpdateChannelMediaOptions` to update the settings in `ChannelMediaOptions` at any time, for example, to switch the published audio and video sources.

**9. Screen sharing**

This release optimizes the screen sharing function. You can enable this function through the following ways.

On Windows and macOS:

- Call the `StartScreenCaptureByDisplayId` method before joining a channel, and then call `JoinChannel[2/2]`  to join a channel and set `publishScreenTrack`or `publishSecondaryScreenTrack` as `true`.
- Call the `StartScreenCaptureByDisplayId` method after joining a channel, and then call `UpdateChannelMediaOptions` to set `publishScreenTrack` or `publishSecondaryScreenTrack` as `true`.

On Android and iOS:

- Call the `StartScreenCapture` method before joining a channel, and then call `JoinChannel[2/2]`  to join a channel and set `publishScreenCaptureVideo` as `true`.
- Call the `StartScreenCapture` method after joining a channel, and then call `UpdateChannelMediaOptions` to set `publishScreenCaptureVideo` as `true`.

**10. Subscription allowlists and blocklists**

This release introduces subscription allowlists and blocklists for remote audio and video streams. You can add the user ID that you want to subscribe to in your allowlist, or in your blocklist if you do not want to subscribe to. You can experience this feature through the following APIs, and in scenarios that involve multiple channels, you can call the following methods in the `IRtcEngineEx` interface.

- `SetSubscribeAudioBlacklist`：Set the audio subscription blocklist.
- `SetSubscribeAudioWhitelist`：Set the audio subscription allowlist.
- `SetSubscribeVideoBlacklist`：Set the video subscription blocklist.
- `SetSubscribeVideoWhitelist`：Set the video subscription allowlist.

If a user is added in a blocklist and allowlist at the same time, only the blocklist takes effect.

**11. Set audio scenarios**

To make it easier to change audio scenarios, this release adds the `SetAudioScenario` method. For example, if you want to change the audio scenario from `AUDIO_SCENARIO_DEFAULT` to `AUDIO_SCENARIO_GAME_STREAMING` when you are in a channel, you can call this method.

**12. Replace video feeds with images**

This release supports replacing video feeds with images when publishing video streams. You can call the `EnableVideoImageSource` method to enable this function and choose your own images through the `options` parameter. If you disable this function, the remote users see the video feeds that you publish.

**13. Local video transcoder**

This release introduces local video transcoder with which you can locally merge multiple video streams into one. Common scenarios are as follows:

When streaming or using media push, you can merge the frames of multiple anchors into one locally. 

To do this, you should merge multi-channel video streams collected locally (such as video captured by camera, screen sharing stream, video files and pictures) into one video stream. Then, release the merged stream in the channel. 

You can call the `StartLocalVideoTranscoder` method to enable the local video transcoder and call the `StopLocalVideoTranscoder` method to stop the local video transcoder; After the local video transcoder is enabled, you can call `UpdateLocalTranscoderConfiguration` to update the configuration of the local video transcoder. 

**14. Video device management**

A video capture device may support a variety of video formats, each of which supports a different combination of video frame width, video frame height, and frame rate.

This release introduces the `NumberOfCapabilities` and `GetCapability` method to obtain the number of video formats supported by video capture devices and the details of video frames under specified video formats. When you call the `StartPrimaryCameraCapture` or `StartSecondaryCameraCapture` method to capture video using camera, you can obtain the video with the specified video format. 
The SDK will automatically select the video format for video capture equipment according to your settings in `VideoEncoderConfiguration`. In general, you don't need to use this set of new methods. 

#### Improvements

**1. Fast channel switching**

This release can achieve the same switching speed as `SwitchChannel` in v<Vg k = "VSDK_PREVIOUS_RELEASE"/> through the`LeaveChannel` and `JoinChannel `methods so that you don't need to take the time to call the `SwitchChannel `method.

**2. Push external video frames**

This releases supports pushing video frames in I422 format. You can call the `PushVideoFrame` method to push such video frames to the SDK.

**3. Monitor the width and height of videos**

This adds the `OnTextureSizeModify` callback that can be used to monitor any change in the width and height of videos.

**4. Voice pitch of the local user**
This release adds `voicePitch` in `AudioVolumeInfo` of `OnAudioVolumeIndication`. You can use `voicePitch` to get the local user's voice pitch and perform business functions such as rating for singing.

**5. Video preview**

This release improves the implementation logic of `StartPreview`. You can call the `StartPreview ` method to enable video preview at any time.

 **6. Video types of subscription**

You can call the `SetRemoteDefaultVideoStreamType ` method to choose the video stream type when subscribing streams.
</PlatformWrapper>