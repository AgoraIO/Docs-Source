---
title: Pass custom information
sidebar_position: 3
platform_selector: false
description: >
   Pass custom information to the Conversational AI agent to guide it in generating responses customized for the user.
---

When interacting with a <Vpd k="AGENT" />, you may need to obtain custom context information from the client side, such as the user's speaking status, selected text, personal signature, or score. This information can then be passed to the agent to guide it in generating responses customized to the user's needs.

This document explains how to use the capabilities of the Signaling SDK to include custom information in interactions with the <Vpd k="AGENT" />.

## Understand the tech
Agora Signaling SDK allows users in a channel to set custom temporary status information and notifies other online users in the channel through event notifications.

If your app integrates both Agora Real-Time Engagement (RTC) and Real-Time Messaging (RTM) services, you can enable the RTM feature when creating a conversational agent. This allows the agent to retrieve temporary status information from the RTM channel before invoking the large model, passing it as context to guide the agent in generating responses that better align with user needs.

## Prerequisites

Before you begin, ensure that you have:

- Implemented the basic logic for interacting with a <Vg k="AGENT" /> by following the [REST Quickstart](../get-started/quickstart).
- Integrated the Signaling SDK into your app and implemented basic messaging functionality by following the [SDK Quickstart](/signaling/get-started/sdk-quickstart).

## Implementation

### Enable Signaling

To enable Signaling, set `advanced_features.enable_rtm` to `true` when calling the POST request to create a <Vpd k="AGENT" />. Refer to the following sample request:

```bash
curl --request post \
  --url https://api.agora.io/cn/api/conversational-ai-agent/v2/projects/<your_app_id>/join \
  --header 'Authorization: Basic <credentials>' \
  --data '
{
  "name": "unique_name",
  "properties": {
    "channel": "channel_name",
    "token": "token",
    "agent_rtc_uid": "friday",
    // highlight-start
    "agent_rtm_uid": "friday",
    "advanced_features": {
      "enable_rtm": true
    },
    // highlight-end
    "remote_rtc_uids": [
      "*"
    ],
    "enable_string_uid": true,
    "llm": {
      "url": "https://api.xxxx/v1/xxxx",
      "api_key": "xxx",
      "params": {
        "model": "xxxx"
      }
    },
    "tts": {
      "vendor": "vendor_name",
      "params": {
        "key": "xxxx",
        "voice_id": "xxxx"
      }
    }
  }
}'
```

### Set Custom Information
Refer to [User status management](/signaling/core-functionality/presence#user-status-management) to set status information for users in the channel.

### Transmit Custom Information
Before invoking the LLM, the agent automatically retrieves the active user's temporary status information and passes it as context to the model. This temporary status information is stored in the `context.presence` field.

The following example illustrates a scenario where UserA selects the text "Pythagorean theorem" in the app and asks the agent, "What does this mean?". The JSON example shows how the agent retrieves a temporary status field named `selection` from Signaling before calling the LLM. The request structure is as follows:

```json
{
  "messages": [
    {
      "role": "user",
      "content": "What does this mean?"
    }
  ],
  "context": {
    "presence": {
      "userA": {
        "selection": "Pythagorean Theorem"
      }
    }
  },
  "model": "deepseek-r1"
}
```

### Large Model Adaptation

Adapt the LLM to process the temporary status information in the `context.presence` field and generate content that better meets user needs. For implementation details, refer to the Custom Large Model documentation.