<PlatformWrapper platform="windows">

### Implement the user interface

To enable or disable processing of captured raw video data, add a button to the user interface:

    1. Go to menu **View** > **Other Windows** > **Resource View**.
    
        If the **Resource View** window isn't the top-most window, select the **Resource View** tab to bring it to the top.
    
    1. In **Resource View**, go to **AgoraImplementation.rc** > **Dialog** and double-click `IDD_AGORAIMPLEMENTATION_DIALOG`.
        
        The resource opens inside the **Dialog Editor**. 

    1. Click **View** > **ToolBox**. The **Toolbox** opens.

    1. From **ToolBox**, drag **Button** to the surface of the **Dialog Editor**.

    1. In **Properties**, update the **Caption** field to `Zoom In`.

### Handle the system logic

This sections describes the steps required to use the relevant libraries and declare the necessary variables, and set up access to the UI elements.

1.  **Define a variable to manage video processing**

        In **Solution Explorer**, open `AgoraImplementationDlg.cpp` and add the following as a global variable after the list of header includes:
        
        ```cpp
        bool isZoomed = false;
        ```
2.    **Start and stop video processing**
    
        When the user presses **Zoom In/Zoom Out** on screen, it update the state of `isZoomed` variable. This variable controls the behavior of the `onCaptureVideoFrame` callback to enable or disable frame cropping. To implement this workflow:

            1. In **Dialog Editor**, double-click **Zoom In**; this creates an event listener.

            1. Add the following code to the event listener:
   
                ```cpp
                // Toggle the zoom state
                isZoomed = !isZoomed;

                // Get a handle to the parent control of the button
                // We implemented the Agora Windows Get Started guide, using the button with ID 'IDC_BUTTON3' 
                // for zoom in and zoom out functionality. However, please note that the button ID may differ 
                // in your specific scenario.
                CWnd* pParent = GetDlgItem(IDC_BUTTON3);  

                // Cast the control to a CButton object
                CButton* pButtonCtrl = static_cast<CButton*>(pParent);

                // Set the button text based on the zoom state
                if (isZoomed)
                {
                    pButtonCtrl->SetWindowText(_T("Zoom Out"));
                }
                else
                {
                    pButtonCtrl->SetWindowText(_T("Zoom In"));
                }
                ```
### Implement processing of raw video and audio data

To register and use video and audio frame observers in your <Vpl k="CLIENT" />, <Vg k = "COMPANY"/> provides the `IVideoFrameObserver` and `IAudioFrameObserver` interfaces for real-time video and audio processing. These interfaces enable developers to capture and process raw video and audio data before it is sent over the network. To implement these interfaces:

1.  **Set up the video and audio frame observer**
    1. Implement the `IVideoFrameObserver` and `IAudioFrameObserver` video and audio frame observer interfaces.

        Put the following code in `AgoraImplementationDlg.h` before the `AgoraEventHandler` class declaration:

        ```cpp
        class CustomVideoFrameObserver : public IVideoFrameObserver {
        public:
            CustomVideoFrameObserver() : originalYBuffer(nullptr), originalUBuffer(nullptr), originalVBuffer(nullptr) {}
            ~CustomVideoFrameObserver() {
                delete[] originalYBuffer;
                delete[] originalUBuffer;
                delete[] originalVBuffer;
            }
            virtual bool CustomVideoFrameObserver::onCaptureVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onSecondaryCameraCaptureVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onSecondaryPreEncodeCameraVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onScreenCaptureVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onPreEncodeScreenVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onSecondaryScreenCaptureVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onSecondaryPreEncodeScreenVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onRenderVideoFrame(const char* channelId, rtc::uid_t remoteUid, VideoFrame& videoFrame)override;
            virtual bool onPreEncodeVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onMediaPlayerVideoFrame(VideoFrame& videoFrame, int mediaPlayerId)override;
            virtual bool onTranscodedVideoFrame(VideoFrame& videoFrame)override;
            virtual VIDEO_FRAME_PROCESS_MODE CustomVideoFrameObserver::getVideoFrameProcessMode()override;
        private:
            uint8_t* originalYBuffer;
            uint8_t* originalUBuffer;
            uint8_t* originalVBuffer;
        };

        class CustomAudioFrameObserver: public IAudioFrameObserver {
            virtual bool onPlaybackAudioFrameBeforeMixing(const char* channelId, rtc::uid_t uid, AudioFrame& audioFrame)override;
            virtual bool onRecordAudioFrame(const char* channelId, AudioFrame& audioFrame)override;
            virtual bool onPlaybackAudioFrame(const char* channelId, AudioFrame& audioFrame)override;
            virtual bool onMixedAudioFrame(const char* channelId, AudioFrame& audioFrame)override;
            virtual bool onEarMonitoringAudioFrame(AudioFrame& audioFrame)override;
            virtual int getObservedAudioFramePosition()override;
            virtual AudioParams getPlaybackAudioParams()override;
            virtual AudioParams getRecordAudioParams()override;
            virtual AudioParams getMixedAudioParams()override;
            virtual AudioParams getEarMonitoringAudioParams()override;
        };
        ```

    1. Add the video and audio frame observers:

        In `AgoraImplementationDlg.h`, add the following code after `AgoraEventHandler agoraEventHandler;`

        ```cpp
        // Video and audio frame observers objects
        CustomVideoFrameObserver* video_frame_observer = new CustomVideoFrameObserver();
        CustomAudioFrameObserver* audio_frame_observer = new CustomAudioFrameObserver();
        ```
    1. Provide the member functions definitions you declared in `CustomVideoFrameObserver` and `CustomAudioFrameObserver`.

        1. Implement video frame observer callbacks:
        
            `IVideoFrameObserver` gives you access to each local video frame after it is captured and access to each remote video frame before it is played back. In this sample, the `onCaptureVideoFrame` callback is used to modify the captured video frame buffer for cropping and scaling, resulting in a modified version of the frame that is played back. To implement `IVideoFrameObserver` callbacks add the following to `AgoraImplementationDlg.cpp`,:

            ```cpp
            // IVideoFrameObserver Implementation
            // "onCaptureVideoFrame()" is actually responsible for catching each frame on registering the video frame observer. 
            bool CustomVideoFrameObserver::onCaptureVideoFrame(VideoFrame& videoFrame)
            {
                if (isZoomed) {

                    int originalWidth = videoFrame.width;
                    int originalHeight = videoFrame.height;

                    int newWidth = originalWidth / 2;
                    int newYStride = newWidth;
                    int newHeight = originalHeight / 2;

                    // Create temporary buffers for the cropped frame data
                    uint8_t* newYBuffer = new uint8_t[newWidth * newHeight];
                    uint8_t* newUBuffer = new uint8_t[newWidth * newHeight / 4];
                    uint8_t* newVBuffer = new uint8_t[newWidth * newHeight / 4];

                    for (int y = 0; y < newHeight; ++y) {
                        for (int x = 0; x < newWidth; ++x) {
                            // Copy Y plane
                            newYBuffer[y * newYStride + x] = videoFrame.yBuffer[y * videoFrame.yStride + x];

                            // Copy U and V planes for every 2x2 block of pixels
                            if (y % 2 == 0 && x % 2 == 0) {
                                int newIndexUV = (y / 2) * (newWidth / 2) + (x / 2);
                                int originalIndexUV = (y / 2) * (videoFrame.uStride) + (x / 2);

                                newUBuffer[newIndexUV] = videoFrame.uBuffer[originalIndexUV];
                                newVBuffer[newIndexUV] = videoFrame.vBuffer[originalIndexUV];
                            }
                        }
                    }

                    // Update videoFrame with the new width, height, and strides
                    videoFrame.width = newWidth;
                    videoFrame.height = newHeight;
                    videoFrame.yStride = newYStride;
                    videoFrame.uStride = newWidth / 2;
                    videoFrame.vStride = newWidth / 2;

                    // Check if the original buffers have already been stored
                    if (!originalYBuffer) {
                        originalYBuffer = videoFrame.yBuffer;
                        originalUBuffer = videoFrame.uBuffer;
                        originalVBuffer = videoFrame.vBuffer;
                    }

                    // Update videoFrame to reference the new buffers
                    videoFrame.yBuffer = newYBuffer;
                    videoFrame.uBuffer = newUBuffer;
                    videoFrame.vBuffer = newVBuffer;

                }
                
                // Return true to indicate that pre-processing is successful and the frame should not be ignored
                return true;
            }

            IVideoFrameObserver::VIDEO_FRAME_PROCESS_MODE CustomVideoFrameObserver::getVideoFrameProcessMode() {
                return VIDEO_FRAME_PROCESS_MODE::PROCESS_MODE_READ_WRITE;
            }

            // Rest the below functions are dummy "do-nothing" implentaion just to sake for overriding of interface pure virtual functions.
            bool CustomVideoFrameObserver::onSecondaryCameraCaptureVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver :: onSecondaryPreEncodeCameraVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onScreenCaptureVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onPreEncodeScreenVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onSecondaryScreenCaptureVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::CustomVideoFrameObserver::onSecondaryPreEncodeScreenVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onRenderVideoFrame(const char* channelId, rtc::uid_t remoteUid, VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onPreEncodeVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onMediaPlayerVideoFrame(VideoFrame& videoFrame, int mediaPlayerId)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onTranscodedVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }
            ```
            **Note** that `getVideoFrameProcessMode()` must override `PROCESS_MODE_READ_WRITE` in order for your raw data changes to take effect.

        2. Implement audio frame observer callbacks:
            
            `IAudioFrameObserver` provides access to each captured or played back audio frame, allowing you to process the audio frames according to your needs.To implement `IAudioFrameObserver` callbacks add the following to `AgoraImplementationDlg.cpp`:

            ```cpp
            // IAudioFrameObserver Implementation
            // User can provide implementation for "onRecordAudioFrame()", "onPlaybackAudioFrame()" and "onMixedAudioFrame()" as per scenario. 
            bool CustomAudioFrameObserver::onRecordAudioFrame(const char* channelId, AudioFrame& audioFrame)
            {
                // Gets the captured audio frame.
                // Add code here to process the recorded audio.
                return true;
            }

            bool CustomAudioFrameObserver::onPlaybackAudioFrame(const char* channelId, AudioFrame& audioFrame)
            {
                // Gets the audio frame for playback.
                // Add code here to process the playback audio.
                return true;
            }

            bool CustomAudioFrameObserver::onMixedAudioFrame(const char* channelId, AudioFrame& audioFrame)
            {
                // Retrieves the mixed captured and playback audio frame.
                // Add code here to process the mixed captured playback audio
                return true;
            }

            // Rest the below functions are dummy "do-nothing" implentaion just to sake for overriding of interface pure virtual functions.
            bool CustomAudioFrameObserver::onPlaybackAudioFrameBeforeMixing(const char* channelId, rtc::uid_t uid, AudioFrame& audioFrame)
            {
                return false;
            }

            bool CustomAudioFrameObserver::onEarMonitoringAudioFrame(AudioFrame& audioFrame)
            {
                return false;
            }

            int CustomAudioFrameObserver::getObservedAudioFramePosition()
            {
                return 0;
            }

            IAudioFrameObserver::AudioParams CustomAudioFrameObserver::getPlaybackAudioParams()
            {
                return AudioParams();
            }

            IAudioFrameObserver::AudioParams CustomAudioFrameObserver::getRecordAudioParams()
            {
                return AudioParams();
            }

            IAudioFrameObserver::AudioParams CustomAudioFrameObserver::CustomAudioFrameObserver::getMixedAudioParams()
            {
                return AudioParams();
            }

            IAudioFrameObserver::AudioParams CustomAudioFrameObserver::getEarMonitoringAudioParams()
            {
                return AudioParams();
            }       
            ```
2.  **Register the video and audio frame observers**

    To receive the callbacks declared in `IVideoFrameObserver` and `IAudioFrameObserver`, you register the video and audio frame observers with the <Vg k="ENGINE" /> before joining a channel. To specify the format of audio frames captured by each `IAudioFrameObserver` callback, use the `setRecordingAudioFrameParameters`, `setPlaybackAudioFrameParameters` and `setMixedAudioFrameParameters` methods.

    To register the observers, do the following:

    1. Setup a function to register and unregister observers for audio and video frames. In `AgoraImplementationDlg.h`, add the following code after `void setupVideoSDKEngine();`:
      
        ```cpp
        bool EnableAudioVideoCapture(bool bEnable);
        ```
    
    1. Define `EnableAudioVideoCapture()`. Add the following in `AgoraImplementationDlg.cpp`, before `CAboutDlg()`:

        ```cpp
        bool CAgoraImplementationDlg::EnableAudioVideoCapture(bool bEnable)
        {
            agora::util::AutoPtr<agora::media::IMediaEngine> mediaEngine;
            //query interface agora::AGORA_IID_MEDIA_ENGINE in the engine.
            mediaEngine.queryInterface(agoraEngine, agora::rtc::AGORA_IID_MEDIA_ENGINE);
            int nRet = 0;
            agora::base::AParameter apm(agoraEngine);
            if (mediaEngine.get() == NULL)
                return FALSE;
            if (bEnable) 
            {
                // Register video & audio frame observer
                nRet = mediaEngine->registerVideoFrameObserver(video_frame_observer);
                nRet = mediaEngine->registerAudioFrameObserver(audio_frame_observer);

                // Set the format of the captured raw audio data.
                int SAMPLE_RATE = 16000, SAMPLE_NUM_OF_CHANNEL = 1, SAMPLES_PER_CALL = 1024;

                agoraEngine->setRecordingAudioFrameParameters(SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL,
                    RAW_AUDIO_FRAME_OP_MODE_READ_WRITE, SAMPLES_PER_CALL);

                agoraEngine->setPlaybackAudioFrameParameters(SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL,
                    RAW_AUDIO_FRAME_OP_MODE_READ_WRITE, SAMPLES_PER_CALL);

                agoraEngine->setMixedAudioFrameParameters(SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL, SAMPLES_PER_CALL);
            }
            else 
            {
                nRet = mediaEngine->registerVideoFrameObserver(NULL);
                nRet = mediaEngine->registerAudioFrameObserver(NULL);
            }
            return nRet == 0 ? TRUE : FALSE;
        }
        ```

    1. To execute this method before joining the channel, add the following to the `Join` button event listener,`OnBnClickedButton2()`, before `agoraEngine->enableAudio()`:

        ```cpp
        // Enable audio & video frame capture by registering the frames.
        EnableAudioVideoCapture(TRUE);
        ```
3. **Unregister the video and audio frame observers when you leave a channel**
    
    When you leave a channel, you unregister the frame observers by setting `EnableAudioVideoCapture()` to `false`.To do this, add the following to the`Leave` button event listener, `OnBnClickedButton1()` after `agoraEngine->disableAudio();`:

        ```cpp
        // Unregister audio & video frame.
		EnableAudioVideoCapture(FALSE);
        ```
</PlatformWrapper>