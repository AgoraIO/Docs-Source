---
title: Overview
sidebar_position: 1
platform_selector: false
description: >
  Integrate custom text-to-speech into Agora's Conversational AI Engine.
---


Text-to-Speech (TTS) engines convert your AI agent's text responses into natural-sounding speech. They enable real-time voice interactions by synthesizing audio from the language model's output. Agora supports multiple TTS providers, allowing you to choose the best voice quality and characteristics for your specific requirements.

## Integration steps

To integrate the TTS provider of your choice, follow these steps:

1. Choose your TTS provider from the [Supported TTS providers](#supported-tts-providers) table
1. Obtain an API key from the provider's console
1. Copy the sample configuration for your chosen provider
1. Replace the API key placeholder with your actual API key
1. Select an appropriate voice and configure audio parameters
1. Specify the configuration in the request body as `properties` > `tts` when [Starting a conversational AI agent](/conversational-ai/rest-api/agent/join)


## Supported TTS providers

<Vpd k="NAME" /> currently supports the following TTS providers:

- [Microsoft Azure](microsoft)
- [ElevenLabs](elevenlabs)
- [MiniMax](minimax)
- [Cartesia (Beta)](cartesia)
- [OpenAI (Beta)](openai)
- [Hume AI (Beta)](humeai)
- [Rime (Beta)](rime)
- [Fish Audio (Beta)](fish-audio)
- [Google (Beta)](google)
- [Amazon Polly (Beta)](amazon)
- [Sarvam (Beta)](sarvam)

<Admonition type="info">
Providers marked **Beta** support only *text* mode and do not support *word* mode for [transcript rendering](/conversational-ai/reference/android#transcriptrendermode).
</Admonition>