import * as data from '@site/data/variables';

import ProjectSetup from '@docs/shared/video-sdk/develop/video-compositor/project-setup/index.mdx';
import ProjectImplement from '@docs/shared/video-sdk/develop/video-compositor/project-implementation/index.mdx';
import ProjectTest from '@docs/shared/video-sdk/develop/video-compositor/project-test/index.mdx';
import Reference from '@docs/shared/video-sdk/develop/video-compositor/reference/index.mdx';

<PlatformWrapper platform="web">
The video compositor extension can be used in conjunction with the <Vg k="VSDK" /> (v4.17.0 or above). It can combine multiple video streams and pictures of the local users into one video stream, allowing multiple video screens to be displayed on the same screen at the same time. For scenarios such as online education, remote conferences, and live broadcasts, the video compositor extension can allow app users to view and manage multiple videos more conveniently, and realize portrait-in-picture and other functions.

## Prerequisites

- The browser support of the video compositor extension is as follows:
    - Chrome 91+, Edge 91+, and Firefox latest versions are supported. For the best experience, Chrome or Edge 94+ is recommended.
    - Only iOS Safari 15.4 and above and macOS Safari 13 and above are supported.
- Under the premise of ensuring the effect, the video compositor extension can synthesize up to 2 video streams (from the camera or local video files), 1 screen sharing stream, and 2 pictures. Compositing more video streams and pictures impacts performance and experience.
- If you need to use multiple media processing extensions at the same time, <Vg k="COMPANY" /> recommends that you use an Intel Core i5 4-core or higher processor. After multiple extensions are enabled at the same time, if other running programs occupy high system resources, your app may experience audio and video freezes.

## Understand the tech

![Video Compositor](/images/video-calling/video-compositor.png)

The specific process of local map integration is as follows:

- Create a video input layer `IBaseProcessor()` for each video track participating in the local composite track, and create an image input layer `HTMLImageElement()` for each image.
- Connect the pipeline between each video track and the corresponding video input layer, and inject the video stream into the corresponding input layer.
- The Compositor combines all input layers.
- Connect the pipeline between the compositor and the local video track, and output the combined video to the <Vg k="VSDK" />.

## Project setup

<ProjectSetup />

## Implement video compositor extension

This section shows how to use the <Vpd k="SDK" /> to implement video compositor extension in your <Vpl k="CLIENT" />, step-by-step.

<ProjectImplement/>

## Test your <Vg k="CP"/> implementation

To ensure that you have implemented video compositor extension in your <Vpl k="CLIENT" />:

1.  [Generate a temporary token](../reference/manage-agora-account#generate-a-temporary-token) in <Vg k="CONSOLE" /> .

2. In your browser, navigate to the <Link target="_blank" to="{{Global.DEMO_BASIC_VIDEO_CALL_URL}}"><Vg k="COMPANY" /> web demo</Link> and update _App ID_, _Channel_, and _Token_ with the values for your temporary token, then click **Join**.

<ProjectTest/>

## Reference

This section contains information that completes the information in this page, or points you to documentation that explains other aspects to this
product.

<Reference/>
</PlatformWrapper>
