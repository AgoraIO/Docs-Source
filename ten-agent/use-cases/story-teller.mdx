---
title: 'Storyteller'
sidebar_position: 2
type: docs
description: >
  Configure properties in the TEN agent playground.
---

The storyteller use case demonstrates how to build an AI agent that creates engaging stories with accompanying images. The storyteller agent:

1. Listens to your story prompts or ideas
2. Generates creative narratives based on your input
3. Automatically creates images at key story moments
4. Narrates the story with synchronized visuals

This guide shows you how to configure both traditional and real-time voice-based storytellers.

## Prerequisites

Before starting, ensure you have:
- <Vpd k="NAME" /> playground running. Refer to the [Agent quickstart](../get-started/quickstart.mdx).
- Agora RTC credentials from [Agora Console](https://console.agora.io/v2)
- API keys for your chosen services
    1. For traditional pipeline:
        1. STT service like [Deepgram](https://deepgram.com/)
        1. LLM like [OpenAI](https://openai.com)
        1. TTS service like [Fish.Audio](https://fish.audio/)
    1. For real-time V2V:
        1. Realtime API key from your V2V provider

## Traditional storyteller 

This configuration uses separate services for speech recognition, language processing, and speech synthesis (STT + LLM + TTS).

### Configuration steps

Set up your storyteller with these steps:

1. Open the playground at `http://localhost:3000`
2. Select the `story_teller` graph type
3. Configure modules:
    1. Click **Module Picker**
    1. Select your preferred STT and TTS modules
    1. Keep the pre-configured OpenAI ChatGPT for LLM
    1. Click **Save Changes**
4. Configure properties:
    1. Click the settings button next to the graph selector
    1. Enter your OpenAI API key and other module credentials
    1. Click **Save Changes**
5. Start storytelling:
    1. Click **Connect** to initialize the agent
    1. Wait a few seconds for startup
    1. Begin speaking to create your story

### Azure STT integration

For Azure speech recognition:

1. Select the `story_teller_integrated_stt` graph type
2. Configure Azure credentials in the RTC module
3. Follow the remaining configuration steps

### Pre-configured tools

The `story_teller` use-case is preconfigured to use `openai_image_generate_tool`. No additional tool configuration is necessary.

## Real-time storyteller (V2V)

Create stories with lower latency using voice-to-voice models.

### Configuration steps

Set up your real-time storyteller:

1. Open the playground at `http://localhost:3000`
2. Select the `story_teller_realtime` graph type
3. Configure the V2V module:
    1. Click **Module Picker**
    1. Use the pre-configured OpenAI Realtime or select another provider
    1. Click **Save Changes**
4. Configure API credentials:
    1. Click the settings button
    1. Enter your Realtime API key
    1. If using a different V2V provider, copy the prompt from OpenAI Realtime
    1. Click **Save Changes**
5. Start creating:
    1. Click **Connect** to start
    1. Speak naturally to generate stories
