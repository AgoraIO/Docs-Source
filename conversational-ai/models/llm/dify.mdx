---
title: Dify
sidebar_position: 6
platform_selector: false
description: >
  Integrate Conversational AI Engine with Dify
---

Dify is an open-source LLM application development platform that provides a unified API for multiple LLM providers with workflow orchestration and advanced features.

### Setup and Configuration

To integrate Dify with Agora Conversational AI, install the plugin, configure your Agora project, and create an endpoint:

1. **Install the Dify plugin**
   1. Log in to the [Dify Console](https://console.dify.ai).
   2. Click on **Plugins** in the top navigation bar to open the Marketplace.
   3. Search for the **Agora Conversational AI** plugin.
   4. Click **Install** to install the plugin.
   5. After installation, confirm that the plugin status is **Active** in the Installed Plugins list.

2. **Configure the Agora Console**
   1. Log in to the [Agora Console](https://console.agora.io).
   2. Create a new project or select an existing one.
   3. Enable the **Conversational AI** feature within the selected project.
   4. Record the following information for later use:
      - **App ID** (unique project identifier)
      - **Certificate** (optional, if enabled for enhanced security)
   5. Navigate to the **RESTful API** page and generate an **API Key** and **API Secret** (required for HTTP Basic Authentication).

3. **Create an Endpoint in Dify**
   1. In the Dify console's left-hand navigation panel, click on the **Agora Conversational AI** plugin you just installed.
   2. Click **Create a new API endpoint** to open the configuration page.
   3. Fill in the following details:
      - **App ID** (copied from the Agora Console)
      - **API Key and Secret** (copied from the Agora Console)
      - **TTS** (Text-to-Speech) configuration (e.g., Azure or ElevenLabs)

4. **Save and note the endpoint details**
   1. Save the endpoint configuration. Dify generates an **Endpoint URL**.
   2. Note down this **Endpoint URL** and **API Key** for use in the `llm` configuration.

    ![](/images/conversational-ai/dify-endpoint.png)
    
### Sample configuration

The following example shows a starting `llm` parameter configuration you can use when you [Start a conversational AI agent](../../rest-api/join).

```json
"llm": {
   "url": "https://qv90***.ai-plugin.io/convoai-start",
   "api_key": "<same_api_key_as_in_endpoint_setup>",
   "system_messages": [
       {
           "role": "system",
           "content": "You are a helpful voice assistant."
       }
   ],
   "max_history": 32,
   "greeting_message": "Hello, how can I assist you today?",
   "failure_message": "Hold on a moment.",
   "params": {
       "model": "default"
   },
   "style": "dify"
}
```

### Key parameters

- `api_key`: Use the same API key configured in your Dify endpoint setup.
- `url`: Use the custom endpoint URL from your Dify marketplace integration.
- `model`: Set to `"default"` to use the model configured in your Dify application.
- `style`: Set to `"dify"` to use Dify's message format and workflow processing.

For advanced configuration options, workflow setup, and detailed parameter descriptions, see the [Agora Conversational AI - Dify Marketplace](https://marketplace.dify.ai/plugins/plutoless/convoai) documentation.
