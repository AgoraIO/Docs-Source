---
title: Interrupt agent
sidebar_position: 4.7
platform_selector: false
description: >
  Interrupt the agent to start a new round of conversation.
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

When interacting with an agent, you may need to interrupt the agent to begin a new round of conversation. The Agora <Vpd k="NAME" /> supports agent interruption in the following ways:

- **Voice interruption**: The engine detects user voice input and automatically stops the agent’s response.
- **Manual interruption**: Your app can explicitly stop the agent by calling a REST API or client SDK method—typically triggered by a button tap or custom command.

This page describes how to implement agent interruption in your app.

## Voice interruption

<Vpd k="NAME" /> supports a graceful interruption feature that allows a user’s voice input to automatically interrupt the speaking agent. This enables quicker response times and more natural, fluid interactions.

<Admonition type="info">
Graceful interruption is a value-added service. A separate fees is charged after the service is enabled. For details, see [Pricing](../overview/pricing).
</Admonition>

By default, this feature is disabled. To enable it, set `advanced_features.enable_aivad` to `true` when calling [Start a conversational AI agent](../rest-api/join). The following example shows how to do this:


```bash
curl --request post \
--url https://api.agora.io/api/conversational-ai-agent/v2/projects/:appid/join \
--header 'Authorization: Basic <your_base64_encoded_credentials>' \
--data '
{
    "name": "unique_name",
    "properties": {
        "channel": "channel_name",
        "token": "token",
        "agent_rtc_uid": "1001",
        "remote_rtc_uids": [
            "1002"
        ],
        "idle_timeout": 120,
        "advanced_features": {
            "enable_aivad": true
        },
        "llm": {
            "url": "https://api.openai.com/v1/chat/completions",
            "api_key": "<your_llm_key>",
            "system_messages": [
                {
                    "role": "system",
                    "content": "You are a helpful chatbot."
                }
            ],
            "max_history": 32,
            "greeting_message": "Hello, how can I assist you today?",
            "failure_message": "Please hold on a second.",
            "params": {
                "model": "gpt-4o-mini"
            }
        },
        "tts": {
            "vendor": "microsoft",
            "params": {
                "key": "<your_tts_api_key>",
                "region": "eastus",
                "voice_name": "en-US-AndrewMultilingualNeural"
            }
        },
        "asr": {
            "language": "en-US"
        }
    }
}'
```

If the request succeeds, the API returns a `200` status code and a response body like the following:

```json
{
  "agent_id": "1NT29X10YHxxxxxWJOXLYHNYB",
  "create_ts": 1737111452,
  "status": "RUNNING"
}
```

## Manual interruption

<Vpd k="NAME" /> supports actively triggering an interruption by calling RESTful APIs or client component APIs. This allows users to interrupt the agent through a button click or a specific command.

### Call the RESTful API

Use the [Interrupt agent](../rest-api/interrupt) API to manually initiate an interruption request.

```bash
curl --request post \
--url https://api.agora.io/cn/api/conversational-ai-agent/v2/projects/:appid/agents/:agentId/interrupt \
--header 'Authorization: Basic <credentials>' \
--data '{}'
```

If the request is successful, the API returns a 200 status code and the following response body:

```json
{
  "agent_id": "1NT29XxxxxxxxxELWEHC8OS",
  "channel": "test_channel",
  "start_ts": 1744877089
}
```

### Call the client toolkit API

Agora provides a set of flexible, scalable and standardized client components for its conversational AI engine. These components support iOS, Android, and Web platforms and encapsulate scenario-based APIs. You can use them to integrate Agora Real-Time Communication (RTC) and Real-Time Messaging <Vg k="SIG" /> capabilities, enabling the following features:

- Interrupt the agent
- Display real-time subtitles
- Receive event notifications
- Optimize audio (Android and iOS only)

Before you begin, make sure you:

- Integrate <Vg k="VSDK" /> v4.5.1 or later and follow the [Quickstart](/video-calling/get-started/get-started-sdk) guide to implement basic real-time audio and video features.
- Enable the <Vg k="SIG" /> service for your project in the <Vg k="CONSOLE" /> and follow the [<Vg k="SIG" /> Quickstart](/signaling/get-started/sdk-quickstart) to implement real-time messaging.
- Implement the basic logic to communicate with a <Vpd k="AGENT"/>.
- Ensure that the RTC engine instance is initialized and <Vg k="SIG" /> is logged in. The toolkit does not handle initialization, lifecycle management, authentication, or login for <Vg k="VSDK" /> or <Vg k="SIG" />.

#### Integrate the toolkit

<Tabs groupId="platform">
<TabItem value="android" label="Android" default>
Copy the [`convoaiApi`](https://github.com/AgoraIO-Community/Conversational-AI-Demo/tree/main/Android/scenes/convoai/src/main/java/io/agora/scene/convoai/convoaiApi) folder to your project and import it before calling API methods. Refer to the [component structure](#component-structure) to understand the role of each file.

</TabItem>

<TabItem value="ios" label="iOS">
Copy the [`ConversationalAIAPI`](https://github.com/AgoraIO-Community/Conversational-AI-Demo/tree/main/iOS/Scenes/ConvoAI/ConvoAI/ConvoAI/Classes/ConversationalAIAPI) folder to your project and import it before calling API methods. Refer to the [component structure](#component-structure) to understand the role of each file.

</TabItem>

<TabItem value="web" label="Web">
Copy the [`conversational-ai-api`](https://github.com/AgoraIO-Community/Conversational-AI-Demo/tree/main/Web/Scenes/VoiceAgent/src/conversational-ai-api) file to your project and import it before calling API methods.. Refer to the [component structure](#component-structure) to understand the role of each file.     
</TabItem>
</Tabs>

#### Initialize the component

Create a configuration object for the RTC engine and <Vg k="SIG" /> client instances, then use it to initialize the component instance.

<Tabs groupId="platform">
<TabItem value="android" label="Android" default>
<CodeBlock language="kotlin">
{`// Create a configuration object for the RTC and RTM instances
val config = ConversationalAIAPIConfig(
    rtcEngine = rtcEngineInstance,
    rtmClient = rtmClientInstance,
    enableLog = true
)

// Create the component instance
val api = ConversationalAIAPIImpl(config)`}
</CodeBlock>
</TabItem>

<TabItem value="ios" label="iOS">
<CodeBlock language="swift">
{`// Create a configuration object for the RTC and RTM instances
let config = ConversationalAIAPIConfig(
    rtcEngine: rtcEngine, 
    rtmEngine: rtmEngine,
    enableLog: true
)

// Create the component instance
convoAIAPI = ConversationalAIAPIImpl(config: config)`}
</CodeBlock>
</TabItem>

<TabItem value="web" label="Web">
<CodeBlock language="typescript">
{`// Create a configuration object for the RTC and RTM instances
ConversationalAIAPI.init({
    rtcEngine,
    rtmEngine,
})

// Get the API instance (singleton)
const conversationalAIAPI = ConversationalAIAPI.getInstance()
`}
</CodeBlock>
</TabItem>
</Tabs>

#### Configure the conversational AI agent

Call [Start a conversational AI agent](../rest-api/join) using the following parameter settings:

- `advanced_features.enable_rtm: true`: Start the <Vg k="SIG" /> service (Required)
- `parameters.data_channel: "rtm"`: Enable the RTM data transmission channel (Required)
- `parameters.enable_metrics: true`: Receive agent performance data (Enabled on demand)
- `parameters.enable_error_message: true`: Receive agent error events (Enable on demand)

After the call is successful, the agent joins the specified RTC channel and the user can start interacting with the agent.

#### Interrupt the agent

Call the `interrupt` method to interrupt the agent.

<Tabs groupId="platform">
<TabItem value="android" label="Android" default>
<CodeBlock language="kotlin">
{`api.interrupt("agentId") { error -> /* ... */ }`}
</CodeBlock>
</TabItem>

<TabItem value="ios" label="iOS">
<CodeBlock language="swift">
{`convoAIAPI.interrupt(agentUserId: "\(agentUid)") { error in
    if let error = error {
        print("Interruption failed: \(error.message)")
    } else {
        print("Interruption succeeded")
    }
}`}
</CodeBlock>
</TabItem>

<TabItem value="web" label="Web">
<CodeBlock language="typescript">
{`await conversationalAIAPI.interrupt(\`\${agent_rtc_uid}\`)`}
</CodeBlock>
</TabItem>
</Tabs>

#### Destroy the component

When the agent interaction ends, destroy the component instance to release all resources.

<Tabs groupId="platform">
<TabItem value="android" label="Android" default>
<CodeBlock language="kotlin">
{`api.destroy()`}
</CodeBlock>
</TabItem>

<TabItem value="ios" label="iOS">
<CodeBlock language="swift">
{`convoAIAPI.destroy()`}
</CodeBlock>
</TabItem>

<TabItem value="web" label="Web">
<CodeBlock language="typescript">
{`conversationalAIAPI.destroy()`}
</CodeBlock>
</TabItem>
</Tabs>

## Reference

### Sample project

<Vg k="COMPANY" /> provides a [sample project](https://github.com/AgoraIO-Community/Conversational-AI-Demo/) for your reference. Download or view the source code for a complete example.

### Component structure

The structure of the client component folder and the functions of each file are as follows:

<Admonition type="info">
Copy only the following files and folders to integrate the client component. You do not need to copy other files.
</Admonition>

<Tabs groupId="platform">
<TabItem value="android" label="Android" default>
- `IConversationalAIAPI.kt`: API interface and related data structures and enumerations
- `ConversationalAIAPIImpl.kt`: ConversationalAI API main implementation logic
- `ConversationalAIUtils.kt`: Tool functions and event callback management
subRender/
    - `v3/`: Subtitle module
        - `TranscriptionController.kt`: Subtitle controller
        - `MessageParser.kt`: Message parser
</TabItem>

<TabItem value="ios" label="iOS">
- `ConversationalAIAPI.swift`: API interface and related data structures and enumerations
- `ConversationalAIAPIImpl.swift`: ConversationalAI API main implementation logic
- Transcription/
    - `TranscriptionController.swift`: Subtitle controller
</TabItem>

<TabItem value="web" label="Web">
- `index.ts`: API Class
- `type.ts`: API interface and related data structures and enumerations
- `utils/index.ts`: API utility functions
- `utils/events.ts`: Event management class, which can be extended to easily implement event monitoring and broadcasting
- `utils/sub-render.ts`: Subtitle module
</TabItem>
</Tabs>

### API reference

#### RESTful API

- [Start a conversational AI Agent](../rest-api/join)
- [Interrupt the Agent](../rest-api/interrupt)

#### Toolkit

<Tabs groupId="platform">
<TabItem value="android" label="Android" default>
- [`interrupt`](../reference/android#interrupt)
- [`destroy`](../reference/android#destroy)
</TabItem>

<TabItem value="ios" label="iOS">
- [`interrupt`](../reference/ios#interrupt)
- [`destroy`](../reference/ios#destroy)
</TabItem>

<TabItem value="web" label="Web">
- [`interrupt`](../reference/web#interrupt)
- [`destroy`](../reference/web#destroy)
</TabItem>
</Tabs>

