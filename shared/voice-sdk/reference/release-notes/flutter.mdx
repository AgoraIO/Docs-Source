<PlatformWrapper platform="flutter">
import KnownIssues from '@docs/shared/voice-sdk/reference/known-issues/flutter.mdx';

### Known issues

<KnownIssues />

### v6.5.0

v6.5.0 was released on December 10, 2024.

#### Compatibility changes

This version includes optimizations to some features, including changes to SDK behavior and API renaming and deletion. To ensure normal operation of the project, update the code in the app after upgrading to this release.

1. **Changes in strong video noise suppression implementation**

   This version adjusts the implementation of strong video noise suppression. `videoDenoiserLevelStrength` is removed from `VideoDenoiserLevel`. Instead, after enabling video noise suppression by calling `setVideoDenoiserOptions`, you can call the `setBeautyEffectOptions` method to enable the beauty skin smoothing feature. Using both together will help achieve better video noise suppression effects. For strong noise suppression, it is recommended to set the skin smoothing parameters as detailed in `setVideoDenoiserOptions`.

   Additionally, due to this adjustment, to achieve the best low-light enhancement effect with a focus on image quality, enable video noise suppression first and use specific settings as detailed in `setLowlightEnhanceOptions`.

1. **Changes in camera plug and unplug status (macOS, Windows)**

   In previous versions, when the camera was unplugged and replugged, the `onVideoDeviceStateChanged` callback would report the device status as `mediaDeviceStateActive` (1) (device in use). Starting from this version, after the camera is replugged, the device status will change to `mediaDeviceStateIdle`(0) (device ready).

1. **Changes in video encoding preferences**

   To enhance the userâ€™s video interaction experience, this version optimizes the default preferences for video encoding:

   - In the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_compressionpreference.html">`CompressionPreference`</Link> enumeration class, a new `preferCompressionAuto` (-1) enumeration is added, replacing the original `preferQuality` (1) as the default value. In this mode, the SDK will automatically choose between `preferLowLatency` and `preferQuality` based on your video scene settings to achieve the best user experience.
   - In the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_degradationpreference.html">`DegradationPreference`</Link> enumeration class, a new `maintainAuto` (-1) enumeration is added, replacing the original `maintainQuality` (1) as the default value. In this mode, the SDK will automatically choose between `maintainFramerate`, `maintainBalanced`, and `maintainResolution` based on your video scene settings to achieve the optimal overall quality of experience (QoE).

1. **16 KB memory page size**

    Starting from Android 15, the system adds support for 16 KB memory page size, as detailed in [Support 16 KB page sizes](https://developer.android.com/guide/practices/page-sizes). To ensure the stability and performance of the app, starting from this version, the SDK supports 16 KB memory page size, ensuring seamless operation on devices with both 4 KB and 16 KB memory page sizes, enhancing compatibility and preventing crashes.

1. To distinguish context information in different extension callbacks, this version removes the original extension callbacks and adds corresponding callbacks that contain context information (see the table below). You can identify the extension name, the user ID, and the service provider name through `ExtensionContext` in each callback.

   | Original callback    | Current callback                |
   | -------------------- | ------------------------------- |
   | `onExtensionEvent`   | `onExtensionEventWithContext`   |
   | `onExtensionStarted` | `onExtensionStartedWithContext` |
   | `onExtensionStopped` | `onExtensionStoppedWithContext` |
   | `onExtensionError`   | `onExtensionErrorWithContext`   |

#### New features

1. **Live show scenario**

   This version adds the `applicationScenarioLiveshow`(3) (Live Show) enumeration to <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_videoapplicationscenariotype.html">`VideoApplicationScenarioType`</Link>. You can call `setVideoScenario` to set the video business scenario to show room. To meet the high requirements for first frame rendering time and image quality in this scenario, the SDK has optimized strategies to significantly improve the first frame rendering experience and image quality, while enhancing the image quality in weak network environments and on low-end devices.

1. **Maximum frame rate for video rendering**

   This version adds the `setLocalRenderTargetFps` and `setRemoteRenderTargetFps` methods, which support setting the maximum frame rate for video rendering locally and remotely. The actual frame rate for video rendering by the SDK will be as close to this value as possible.

   In use-cases where the frame rate requirement for video rendering is not high (e.g., screen sharing, online education) or when the remote end uses mid-to-low-end devices, you can use this set of methods to limit the video rendering frame rate, thereby reducing CPU consumption and improving system performance.

1. **Filter effects**

   This version introduces the `setFilterEffectOptions` method. You can pass a cube map file (.cube) in the `config` parameter to achieve custom filter effects such as whitening, vivid, cool, black and white, etc. Additionally, the SDK provides a built-in `built_in_whiten_filter.cube` file for quickly achieving a whitening filter effect.

1. **Local audio mixing**

   This version introduces the local audio mixing feature. You can call the `startLocalAudioMixer` method to mix the audio streams from the local microphone, media player, sound card, and remote audio streams into a single audio stream, which can then be published to the channel. When you no longer need audio mixing, you can call the `stopLocalAudioMixer` method to stop local audio mixing. During the mixing process, you can call the `updateLocalAudioMixerConfiguration` method to update the configuration of the audio streams being mixed.

   Example use cases for this feature include:

   - By utilizing the local video mixing feature, the associated audio streams of the mixed video streams can be simultaneously captured and published.
   - In live streaming use-cases, users can receive audio streams within the channel, mix multiple audio streams locally, and then forward the mixed audio stream to other channels.
   - In educational use-cases, teachers can mix the audio from interactions with students locally and then forward the mixed audio stream to other channels.

1. **External MediaProjection (Android)**

   This version introduces the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setexternalmediaprojection">`setExternalMediaProjection`</Link> method, which allows you to set an external `MediaProjection` and replace the `MediaProjection` applied by the SDK.

   If you have the capability to apply for `MediaProjection` on your own, you can use this feature to achieve more flexible screen capture.

1. **EGL context (Android)**

   This version introduces the `setExternalRemoteEglContext` method, which is used to set the EGL context for rendering remote video streams. When using Texture format video data for remote video self-rendering, you can use this method to replace the SDK's default remote EGL context, achieving unified EGL context management.

1. **Color space settings**

   This version adds the **colorSpace** parameter to `VideoFrame` and `ExternalVideoFrame`. You can use this parameter to set the color space properties of the video frame. By default, the color space uses Full Range and BT.709 standard configuration. You can flexibly adjust according to your own capture or rendering needs, further enhancing the customization capabilities of video processing.

1. **Voice AI tuner**

   This version introduces the voice AI tuner feature, which can enhance the sound quality and tone, similar to a physical sound card. You can enable the voice AI tuner feature by calling the `enableVoiceAITuner` method and passing in the sound effect types supported in the `VoiceAiTunerType` enum to achieve effects like deep voice, cute voice, husky singing voice, etc.

1. **1v1 video call scenario**

   This version adds `applicationScenario1v1` (1v1 video call) in <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_videoapplicationscenariotype.html">`VideoApplicationScenarioType`</Link>. You can call `setVideoScenario` to set the video application scenario to 1v1 video call, the SDK optimizes performance to achieve low latency and high video quality, enhancing image quality, first frame rendering, latency on mid-to-low-end devices, and smoothness under poor network conditions.

1. **Other features**

    - <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengineeventhandler.html#callback_irtcengineeventhandler_onlocalvideostatechanged">`onLocalVideoStateChanged`</Link> callback adds the `localVideoStreamReasonDeviceDisconnected` enumeration, indicating that the currently used video capture device has been disconnected (for example, unplugged). (Windows)
    - <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_mediadevicestatetype.html">`MediaDeviceStateType`</Link> adds the `mediaDeviceStatePluggedIn` enumeration, indicating that the device has been plugged in. (Windows)

#### Improvements

1. **Virtual background algorithm optimization**

   This version upgrades the virtual background algorithm, making the segmentation between the portrait and the background more accurate. There is no background exposure, the body contour of the portrait is complete, and the detail recognition of fingers is significantly improved. Additionally, the edges between the portrait and the background are more stable, reducing edge jumping and flickering in continuous video frames.

1. **Snapshot at specified video observation points**

   This version introduces the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_takesnapshot2">`takeSnapshotWithConfig`</Link> and <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengineex_takesnapshotex2">`takeSnapshotWithConfigEx`</Link> methods. You can use the `config` parameter when calling these methods to take snapshots at specified video observation points, such as before encoding, after encoding, or before rendering, to achieve more flexible snapshot effects.

1. **Custom audio capture improvements**

   This version adds the `enableAudioProcessing` member parameter to <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_audiotrackconfig.html">`AudioTrackConfig`</Link>, which is used to control whether to enable 3A audio processing for custom audio capture tracks of the `AUDIO_TRACK_DIRECT` type. The default value of this parameter is `false`, meaning that audio processing is not enabled. Users can enable it as needed, enhancing the flexibility of custom audio processing.

1. **Adaptive hardware decoding support (Android, Windows)**

   This release introduces adaptive hardware decoding support, enhancing rendering smoothness on low-end devices and effectively reducing system load.

1. **Rendering performance enhancement (Windows)**

   DirectX 11 renderer is now enabled by default on Windows devices, providing high-performance and high-quality graphics rendering capabilities.

1. **Facial region beautification**

   To avoid losing details in non-facial areas during heavy skin smoothing, this version improves the skin smoothing algorithm. The SDK now recognizes various parts of the face, applying smoothing to facial skin areas excluding the mouth, eyes, and eyebrows. In addition, the SDK supports smoothing up to two faces simultaneously.

1. **Other improvements**

   - In use-cases where Alpha transparency effects are achieved by stitching video frames and Alpha data, the rendering performance on the receiving end has been improved, effectively reducing stuttering and latency. (Android, iOS)
   - Optimizes the logic for calling `queryDeviceScore` to obtain device score levels, improving the accuracy of the score results.
   - Supports using virtual cameras in YV12 format as video capture devices. (Windows)
   - When calling `switchSrc` to switch between live streams or on-demand streams of different resolutions, smooth and seamless switching can be achieved. An automatic retry mechanism has been added in case of switching failures. The SDK will automatically retry 3 times after a failure. If it still fails, the `onPlayerEvent` callback will report the `playerEventSwitchError` event, indicating an error occurred during media resource switching.
   - When calling `setPlaybackSpeed` to set the playback speed of an audio file, the minimum supported speed is 0.3x.
   - Optimizes transmission strategy: calling `enableInstantMediaRendering` no longer impacts the security of the transmission link.
   - The `localVideoStreamReasonScreenCaptureDisplayDisconnected` enumerator is added in `onLocalVideoStateChanged` callback, indicating that the display used for screen capture has been disconnected. (Windows, macOS)
   - Optimizes the video link for window sharing, reducing CPU usage. (macOS)
   - Improves echo cancellation for screen sharing use-cases. (Windows)
   - Adds the `channelId` parameter to `Metadata`, which is used to get the channel name from which the metadata is sent.
   - Deprecates redundant enumeration values `clientRoleChangeFailedRequestTimeOut` and `clientRoleChangeFailedConnectionFailed` in `ClientRoleChangeFailedReason`.

#### Issues fixed

This version fixes the following issues:

- When calling `startScreenCaptureByWindowId` to share the screen, the window capture area specified by **regionRect** was inaccurate, resulting in incorrect width and height of the screen sharing window seen by the receiving end. (Windows)
- When the video source type of the sender is in JPEG format, the frame rate on the receiving end occasionally falls below expectations. (Android, iOS)
- During audio and video interaction, after being interrupted by a system call, the user volume reported by the `onAudioVolumeIndication` callback was incorrect. (Android)
- When the receiving end subscribes to the low-quality video stream by default and does not automatically subscribe to any video stream when joining the channel, calling `muteRemoteVideoStream(uid, false)` after joining the channel to resume receiving the video stream results in receiving the high-quality video stream, which is not as expected. (Android)
- Occasional errors of not finding system files during audio and video interaction on Windows 7 systems. (Windows)
- When calling `followSystemRecordingDevice` or `followSystemPlaybackDevice` to set the audio capture or playback device used by the SDK to not follow the system default audio playback device, the local audio state callback `onLocalAudioStateChanged` is not triggered when the audio device is removed, which is not as expected. (Windows)
- Occasional instances where the receiving end cannot hear the sender during audio and video interaction. (iOS)
- During audio and video interaction, if the sender's device system version is iOS 17, the receiving end occasionally cannot hear the sender. (iOS)
- In live streaming use-cases, the time taken to reconnect to the live room after the audience end disconnects due to network switching is longer than expected. (iOS)
- No sound when playing online media resources using the media player after the app starts. (iOS)
- Occasional instances of no sound in audio capture after resuming from being interrupted by other system apps during audio and video interaction. (iOS)
- Calling `startAudioMixing`and then immediately calling `pauseAudioMixing` to pause the music file playback does not take effect.
- Occasional crashes during audio and video interaction. (Android)
- Occasional app crashes occurred when multiple remote users joined the channel simultaneously during real-time interaction. (iOS)
- Remote video occasionally froze or displayed corrupted images when the app returned to the foreground after being in the background for a while. (iOS)
- After the sender called `startDirectCdnStreaming` to start direct CDN streaming, frequent switching or toggling of the network occasionally resulted in a black screen on the receiver's end without a streaming failure callback on the sender's end. (iOS)
- Audio playback failed when pushing external audio data using `pushAudioFrame` and the sample rate was not set as a recommended value, such as 22050 Hz and 11025 Hz. (Android, iOS)


{/*
### v6.4.0

v6.4.0 was released on August 29, 2024.

#### Compatibility changes

This version includes optimizations to some features, including changes to SDK behavior and API renaming and deletion.
To ensure normal operation of the project, update the code in the app after upgrading to this release.

1. To distinguish context information in different extension callbacks, this version removes the original extension callbacks and adds corresponding callbacks that contain context information (see the table below). You can identify the extension name, the user ID, and the service provider name through `ExtensionContext` in each callback.

   | Original callback  | New callback                |
   | ------------------ | ------------------------------- |
   | `onExtensionEvent`   | `onExtensionEventWithContext`   |
   | `onExtensionStarted` | `onExtensionStartedWithContext` |
   | `onExtensionStopped` | `onExtensionStoppedWithContext` |
   | `onExtensionError`   | `onExtensionErrorWithContext`   |

#### New features

1. **Voice AI tuner**

   This version introduces the voice AI tuner feature, which can enhance the sound quality and tone, similar to a
   physical sound card. You can enable the voice AI tuner feature by calling the `enableVoiceAITuner` method and passing
    in the sound effect types supported in the `VoiceAiTunerType` enum to achieve effects like deep voice, cute voice,
    husky singing voice, and so on.

#### Improvements

1. **Adaptive hardware decoding support (Android, Windows)**

   This release introduces adaptive hardware decoding support, enhancing rendering smoothness on low-end devices and effectively reducing system load.

1. **Rendering performance enhancement (Windows)**

   DirectX 11 renderer is now enabled by default on Windows devices, providing high-performance and high-quality graphics rendering capabilities.

1. **Other improvements**

   This version also includes the following improvements:

   - Optimizes the transmission strategy: Calling `enableInstantMediaRendering` no longer impacts the security of the
   transmission link.
   - Adds the `channelId` parameter to `Metadata`, which is used to get the channel name from which the metadata is sent.
   - Deprecates redundant enumeration values `clientRoleChangeFailedRequestTimeOut` and `clientRoleChangeFailedConnectionFailed` in `ClientRoleChangeFailedReason`.

#### Issues fixed

This release fixed the following issues:

- Occasional app crashes occurred when multiple remote users joined the channel simultaneously during real-time
interaction (iOS).
- After the sender called `startDirectCdnStreaming` to start direct CDN streaming, frequent switching or toggling of the
 network occasionally resulted in a black screen on the receiver's end without a streaming failure callback on the sender's end (iOS).
- Audio playback failed when pushing external audio data using `pushAudioFrame` and the sample rate was not set as a
recommended value, such as 22050 Hz and 11025 Hz (Android, iOS).
*/}

### v6.3.2

v6.3.2 was released on June 6, 2024.

#### Improvements

This release enhances the usability of the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setremotesubscribefallbackoption">setRemoteSubscribeFallbackOption</Link> method by removing the timing requirements for invocation. It can now be called both before and after joining the channel to dynamically switch audio and video stream fallback options in weak network conditions.

#### Issues fixed

This version fixed the following issues:

- Local audio capture failed after joining a channel while answering a system phone call and hanging up, preventing remote users from hearing any sound (Android).
- During the interaction process on certain devices (for example, Redmi Note8), after answering and hanging up a system call, local media files were played without sound and no sound was heard from the remote end (Android).
- The app occasionally crashed when remote users left the channel.
- When playing an audio file finished, the SDK sometimes failed to trigger the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengineeventhandler.html#callback_irtcengineeventhandler_onaudiomixingstatechanged">onAudioMixingStateChanged</Link> (`audioMixingStateStopped`, `audioMixingReasonAllLoopsCompleted`) callback that reports that the playing is completed (iOS).
- When calling the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_playeffect3">playEffect</Link> method to play sound effect files shorter than 1 second with `loopCount` set to `0`, there was no sound (iOS).

### v6.3.1

v4.3.1 was released on May 9, 2024.

#### New features

1. **Privacy manifest file (iOS)**

   To meet Apple's safety compliance requirements for app publication, the SDK now includes a privacy manifest file, `PrivacyInfo.xcprivacy`, detailing the SDK's API calls that access or use user data, along with a description of the types of data collected.

   <Admonition type="info" title="Note"> If you need to publish an app with SDK versions prior to v4.3.1 to the Apple App Store, manually add the `PrivacyInfo.xcprivacy` file to your Xcode project. </Admonition>

1. **Data stream encryption**

   This version adds `datastreamEncryptionEnabled` to <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_encryptionconfig.html">EncryptionConfig</Link> for enabling data stream encryption. You can set this when you activate encryption with <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_enableencryption">enableEncryption</Link>. If there are issues causing failures in data stream encryption or decryption, these can be identified by the newly added `encryptionErrorDatastreamDecryptionFailure` and `encryptionErrorDatastreamEncryptionFailure` enumerations.

1. **Other features**

   - A new method <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengineex_enableencryptionex">enableEncryptionEx</Link> is added for enabling media stream or data stream encryption in multi-channel use-cases.
   - A new method <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setaudiomixingplaybackspeed">setAudioMixingPlaybackSpeed</Link> is introduced for setting the playback speed of audio files.
   - A new method <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengineex_getcallidex">getCallIdEx</Link> is introduced for retrieving call IDs in multi-channel use-cases.

#### Improvements

1. **Audio device type detection (macOS)**

   This version adds the `deviceTypeName` in <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_audiodeviceinfo.html">AudioDeviceInfo</Link>, used to identify the type of audio devices, such as built-in, USB, HDMI, and so on.

1. **CPU consumption reduction of in-ear monitoring**

   This release adds an enumerator `earMonitoringFilterReusePostProcessingFilter` in `EarMonitoringFilterType`. For complex audio processing use-cases, you can specify this option to reuse the audio filter post sender-side processing in in-ear monitoring, thereby reducing CPU consumption. Note that this option may increase the latency of in-ear monitoring, which is suitable for latency-tolerant use-cases requiring low CPU consumption.

1. **Other improvements**

   This version also includes the following improvements:

   - Enhanced performance and stability of the local compositing feature, reducing its CPU usage (Android).
   - In <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_audioeffectpreset.html">AudioEffectPreset</Link>, a new enumeration `roomAcousticsChorus` (chorus effect) is added, enhancing the spatial presence of vocals in chorus use-cases.
   - In <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_remoteaudiostats.html">RemoteAudioStats</Link>, a new `e2eDelay` field is added to report the delay from when the audio is captured on the sending side to when the audio is played on the receiving side.

#### Issues fixed

This version fixed the following issues:

- Hosts using certain models of devices in the speaker mode experienced occasional local audio capture failure when switching the app process to the background and then back to the foreground, preventing remote users from hearing the host's audio (Android).
- When the network conditions of the sender deteriorated (for example, in poor network environments), the receiver occasionally experienced a decrease in video smoothness and an increase in lag.

#### API changes

**Added**

- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_enablecameracenterstage">enableCameraCenterStage</Link> (iOS, macOS)
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_iscameracenterstagesupported">isCameraCenterStageSupported</Link> (iOS, macOS)
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setcamerastabilizationmode">setCameraStabilizationMode</Link> (iOS)
- [CameraStabilizationMode](API/enum_camerastabilizationmode.html) <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_camerastabilizationmode.html">CameraStabilizationMode</Link> (iOS)
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_imediaengine.html#api_imediaengine_registerfaceinfoobserver">registerFaceInfoObserver</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_imediaengine.html#api_imediaengine_unregisterfaceinfoobserver">unregisterFaceInfoObserver</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_ifaceinfoobserver.html#class_ifaceinfoobserver">FaceInfoObserver</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_ifaceinfoobserver.html#callback_ifaceinfoobserver_onfaceinfo">onFaceInfo</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_mediasourcetype.html">MediaSourceType</Link> adds `speechDrivenVideoSource`
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_videosourcetype.html">VideoSourceType</Link> adds `videoSourceSpeechDriven`
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_encryptionconfig.html">EncryptionConfig</Link> adds `datastreamEncryptionEnabled`
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_encryptionerrortype.html">EncryptionErrorType</Link> adds the following enumerations:
  - `encryptionErrorDatastreamDecryptionFailure`
  - `encryptionErrorDatastreamEncryptionFailure`
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_audiodeviceinfo.html">AudioDeviceInfo</Link> adds `deviceTypeName` (macOS)
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_remoteaudiostats.html">RemoteAudioStats</Link> adds `e2eDelay`
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_errorcodetype.html">ErrorCodeType</Link> adds `errDatastreamDecryptionFailed`
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_audioeffectpreset.html">AudioEffectPreset</Link> adds `roomAcousticsChorus`, enhancing the spatial presence of vocals in chorus use-cases.
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengineex_getcallidex">getCallIdEx</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengineex_enableencryptionex">enableEncryptionEx</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setaudiomixingplaybackspeed">setAudioMixingPlaybackSpeed</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_querycamerafocallengthcapability">queryCameraFocalLengthCapability</Link> (Android, iOS)
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_focallengthinfo.html">FocalLengthInfo</Link> (Android, iOS)
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_camerafocallengthtype.html">CameraFocalLengthType</Link> (Android, iOS)
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_cameracapturerconfiguration.html">CameraCapturerConfiguration</Link> adds a new member `cameraFocalLengthType` (Android, iOS)
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_cameracapturerconfiguration.html">CameraCapturerConfiguration</Link> adds a new member `cameraId` (Android)
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_earmonitoringfiltertype.html">EarMonitoringFilterType</Link> adds a new enumeration `earMonitoringFilterBuiltInAudioFilters`


### v6.3.0

v6.3.0 was released on February 28, 2024.

#### Compatibility changes

This release has optimized the implementation of some functions, involving renaming or deletion of some APIs. To ensure the normal operation of the project, you need to update the code in the app after upgrading to this release.

1. **Renaming parameters in callbacks**

   In order to make the parameters in some callbacks and the naming of enumerations in enumeration classes easier to understand, the following modifications have been made in this release. Please modify the parameter settings in the callbacks after upgrading to this release.

   | Callback                                                     | Original parameter name | New parameter name |
   | ------------------------------------------------------------ | ----------------------- | ----------------------- |
   | `onLocalAudioStateChanged`                                   | `error`                 | `reason`                |
   | `onLocalVideoStateChanged`                                   | `error`                 | `reason`                |
   | `onDirectCdnStreamingStateChanged`                           | `error`                 | `reason`                |
   | `onRtmpStreamingStateChanged`                                | `errCode`               | `reason`                |

   | Original enumeration class | New enumeration class  |
   | -------------------------- | -------------------------- |
   | `LocalAudioStreamError`   | `localAudioStreamReason`      |
   | `LocalVideoStreamError`   | `LocalVideoStreamReason`      |
   | `DirectCdnStreamingError` | `DirectCdnStreamingReason`    |
   | `MediaPlayerError`        | `MediaPlayerReason`           |
   | `RtmpStreamPublishErrorType`  | `RtmpStreamPublishReason`     |

   **Note:** For specific renaming of enumerations, please refer to [API changes](#api-changes).

1. **Channel media relay**

   To improve interface usability, this release removes some methods and callbacks for channel media relay. Use the alternative options listed in the table below:

   | Deleted methods and callbacks                         | Alternative methods and callbacks  |
   | ----------------------------------------------------- | ---------------------------------- |
   | <ul><li>`startChannelMediaRelay`</li><li>`updateChannelMediaRelay`</li></ul>     | `startOrUpdateChannelMediaRelay`   |
   | <ul><li>`startChannelMediaRelayEx`</li><li>`updateChannelMediaRelayEx`</li></ul> | `startOrUpdateChannelMediaRelayEx` |
   | `onChannelMediaRelayEvent`                            | `onChannelMediaRelayStateChanged`  |

1. **Audio route**

   Starting with this release, `routeBluetooth` in <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_audioroute.html">AudioRoute</Link> is renamed to `routeHeadsetbluetooth`, representing a Bluetooth device using the HFP protocol. `routeBluetoothSpeaker`(10) is added to represent a Bluetooth device using the A2DP protocol.

1. **Log encryption behavior changes**

   For security and performance reasons, as of this release, the SDK encrypts logs and no longer supports printing plaintext logs via the console.

   Refer to the following solutions for different needs:

   - If you need to know the API call status, please check the API logs and print the SDK callback logs yourself.
   - For any other special requirements, please contact [technical support](mailto:support@agora.io) and provide the corresponding encrypted logs.

1. **Audio loopback capturing (Windows, macOS)**

   - Before v6.3.0, if you call the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_disableaudio">disableAudio</Link> method to disable the audio module, audio loopback capturing will not be disabled.
   - As of v6.3.0, if you call the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_disableaudio">disableAudio</Link> method to disable the audio module, audio loopback capturing will be disabled as well. If you need to enable audio loopback capturing, you need to enable the audio module by calling the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_enableaudio">enableAudio</Link> method and then call <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_enableloopbackrecording">enableLoopbackRecording</Link>.

#### New features

1. **Local preview with multiple views**

   This release supports local preview with simultaneous display of multiple frames, where the videos shown in the frames are positioned at different observation positions along the video link. Examples of usage are as follows:

   1. Call <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setuplocalvideo">setupLocalVideo</Link> to set the first view: Set the `position` parameter to `positionPostCapturerOrigin` (introduced in this release) in `VideoCanvas`. This corresponds to the position after local video capture and before preprocessing. The video observed here does not have preprocessing effects.
   1. Call <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setuplocalvideo">setupLocalVideo</Link> to set the second view: Set the `position` parameter to `positionPostCapturer` in `VideoCanvas`, the video observed here has the effect of video preprocessing.
   1. Observe the local preview effect: The first view is the original video of a real person; the second view is the virtual portrait after video preprocessing (including image enhancement, virtual background, and local preview of watermarks) effects.

1. **Query device score**

   This release adds the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_querydevicescore">queryDeviceScore</Link> method to query the device's score level to ensure that the user-set parameters do not exceed the device's capabilities. For example, in HD or UHD video use-cases, you can first call this method to query the device's score. If the returned score is low (for example, below 60), you need to lower the video resolution to avoid affecting the video experience. The minimum device score required for different business use-cases is varied. For specific score recommendations, please contact [technical support](mailto:support@agora.io).

1. **Select different audio tracks for local playback and streaming**

   This release introduces the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_Imediaplayer_selectmultiaudiotrack">selectMultiAudioTrack</Link> method that allows you to select different audio tracks for local playback and streaming to remote users. For example, in use-cases like online karaoke, the host can choose to play the original sound locally and publish the accompaniment in the channel. Before using this function, you need to open the media file through the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_imediaplayer.html#api_imediaplayer_openwithmediasource">openWithMediaSource</Link> method and enable this function by setting the `enableMultiAudioTrack` parameter in <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_mediasource.html">MediaSource</Link>.

1. **Others**

   This release has passed the test verification of the following APIs and can be applied to the entire series of RTC 4.x SDK.

   - <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengineeventhandler.html#callback_irtcengineeventhandler_onremotesubscribefallbacktoaudioonly">onRemoteSubscribeFallbackToAudioOnly</Link>: Occurs when the subscribed video stream falls back to audio-only stream due to weak network conditions or switches back to the video stream after the network conditions improve.
   - <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_iaudiodevicemanager.html#api_iaudiodevicemanager_setplaybackdevicevolume">setPlaybackDeviceVolume</Link> (Windows): Sets the volume of the audio playback device.
   - <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_iaudiodevicemanager.html#api_iaudiodevicemanager_getrecordingdevicevolume">setPlaybackDeviceVolume</Link>: Sets the volume of the audio capturing device.
   - <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_imediaplayer.html#api_imediaplayer_setplayeroption">setPlayerOptionInInt</Link> and <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_imediaplayer.html#api_imediaplayer_setplayeroption2">setPlayerOptionInString</Link>: Sets media player options for providing technical previews or special customization features.
   - <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengine_enablecustomaudiolocalplayback">enableCustomAudioLocalPlayback</Link>: Sets whether to enable the local playback of external audio source.

#### Improvements

1. **SDK task processing scheduling optimization**

   This release optimizes the scheduling mechanism for internal tasks within the SDK, with improvements in the following aspects:

   - The speed of video rendering and audio playback for both remote and local first frames improves by 10% to 20%.
   - The API call duration and response time are reduced by 5% to 50%.
   - The SDK's parallel processing capability significantly improves, delivering higher video quality (720P, 24 fps) even on lower-end devices. Additionally, image processing remains more stable in use-cases involving high resolutions and frame rates.
   - The stability of the SDK is further enhanced, leading to a noticeable decrease in the crash rate across various specific use-cases.

1. **In-ear monitoring volume boost**

   This release provides users with more flexible in-ear monitoring audio adjustment options, supporting the ability to set the in-ear monitoring volume to four times the original volume by calling <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setinearmonitoringvolume">setInEarMonitoringVolume</Link>.

1. **Spatial audio effects usability improvement**

   - This release optimizes the design of the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_ibasespatialaudioengine.html#api_ibasespatialaudioengine_setzones">setZones</Link> method, supporting the ability to set the `zones` parameter to `NULL`, indicating the clearing of all echo cancellation zones.
   - As of this release, it is no longer necessary to unsubscribe from the audio streams of all remote users within the channel before calling the <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_ilocalspatialaudioengine.html#class_ilocalspatialaudioengine">LocalSpatialAudioEngine</Link> method.

1. **Other Improvements**

   This release also includes the following improvements:

   - The <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_imediaplayersourceobserver.html#callback_imediaplayersourceobserver_onplayercachestats">onPlayerCacheStats</Link> callback is added to reports the statistics of the media file being cached. This callback is triggered once per second after file caching is started.
   - The <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_imediaplayersourceobserver.html#callback_imediaplayersourceobserver_onplayerplaybackstats">onPlayerPlaybackStats</Link> callback is added to reports the statistics of the media file being played. This callback is triggered once per second after the media file starts playing. You can obtain information like the audio and video bitrate of the media file through <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_playerplaybackstats.html">PlayerPlaybackStats</Link>.
   - This release optimizes the SDK's domain name resolution strategy, improving the stability of calling `setLocalAccessPoint` to resolve domain names in complex network environments.
   - This release adds the `earMonitorDelay` and `aecEstimatedDelay` members in <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_localaudiostats.html">LocalAudioStats</Link> to report ear monitor delay and acoustic echo cancellation (AEC) delay, respectively.

#### Issues fixed

This release fixed the following issue:

- The SDK failed to detect any changes in the audio routing after plugging in and out 3.5mm earphones (Windows).

#### API changes

**Added**

- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengineeventhandler.html#callback_irtcengineeventhandler_ontranscodedstreamlayoutinfo">onTranscodedStreamLayoutInfo</Link> (Android, iOS)
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_videolayout.html">VideoLayout</Link> (Android, iOS)
- The `subviewUid` member in <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_videocanvas.html">VideoCanvas</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengine_enablecustomaudiolocalplayback">enableCustomAudioLocalPlayback</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_Imediaplayer_selectmultiaudiotrack">selectMultiAudioTrack</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_imediaplayersourceobserver.html#callback_imediaplayersourceobserver_onplayercachestats">onPlayerCacheStats</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_imediaplayersourceobserver.html#callback_imediaplayersourceobserver_onplayerplaybackstats">onPlayerPlaybackStats</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_playerplaybackstats.html">PlayerPlaybackStats</Link>
- The `earMonitorDelay` and `aecEstimatedDelay` members in <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_localaudiostats.html">LocalAudioStats</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_querydevicescore">queryDeviceScore</Link>
- <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_mediasourcetype.html">MediaSourceType</Link>
- The `routeBluetoothSpeaker` enumeration in <Link to="{{Global.API_REF_FLUTTER_ROOT_VOICE_SDK}}/enum_audioroute.html">AudioRoute</Link>

**Modified**

- `routeBluetooth` is renamed as `routeHeadsetbluetooth`
- All `Error` fields in the following enumerations are changed to `Reason`:
  - `localAudioStreamErrorOk`
  - `localAudioStreamErrorFailure`
  - `localAudioStreamErrorDeviceNoPermission`
  - `localAudioStreamErrorDeviceBusy`
  - `localAudioStreamErrorRecordFailure`
  - `localAudioStreamErrorEncodeFailure`
  - `localAudioStreamErrorRecordInvalidId` (Windows)
  - `localAudioStreamErrorPlayoutInvalidId` (Windows)
  - `localVideoStreamErrorOk`
  - `localVideoStreamErrorFailure`
  - `localVideoStreamErrorDeviceNoPermission`
  - `localVideoStreamErrorDeviceBusy`
  - `localVideoStreamErrorCaptureFailure`
  - `localVideoStreamErrorCodecNotSupport`
  - `localVideoStreamErrorCaptureInbackground` (iOS)
  - `localVideoStreamErrorCaptureMultipleForegroundApps` (iOS)
  - `localVideoStreamErrorDeviceNotFound`
  - `localVideoStreamErrorDeviceDisconnected`
  - `localVideoStreamErrorDeviceInvalidId`
  - `localVideoStreamErrorScreenCaptureWindowMinimized`
  - `localVideoStreamErrorScreenCaptureWindowClosed`
  - `localVideoStreamErrorScreenCaptureWindowOccluded`
  - `localVideoStreamErrorScreenCaptureNoPermission` (Windows)
  - `localVideoStreamErrorScreenCapturePaused` (Windows)
  - `localVideoStreamErrorScreenCaptureResumed` (Windows)
  - `localVideoStreamErrorScreenCaptureWindowHidden` (Windows)
  - `localVideoStreamErrorScreenCaptureWindowRecoverFromHidden` (Windows)
  - `localVideoStreamErrorScreenCaptureWindowRecoverFromMinimized` (Windows)
  - `localVideoStreamErrorScreenCaptureFailure` (Windows)
  - `localVideoStreamErrorDeviceSystemPressure` (Windows)
  - `directCdnStreamingErrorOk`
  - `directCdnStreamingErrorFailed`
  - `directCdnStreamingErrorAudioPublication`
  - `directCdnStreamingErrorVideoPublication`
  - `directCdnStreamingErrorNetConnect`
  - `directCdnStreamingErrorBadName`
  - `playerErrorNone`
  - `playerErrorInvalidArguments`
  - `playerErrorInternal`
  - `playerErrorNoResource`
  - `playerErrorInvalidMediaSource`
  - `playerErrorUnknownStreamType`
  - `playerErrorObjNotInitialized`
  - `playerErrorCodecNotSupported`
  - `playerErrorVideoRenderFailed`
  - `playerErrorInvalidState`
  - `playerErrorUrlNotFound`
  - `playerErrorInvalidConnectionState`
  - `playerErrorSrcBufferUnderflow`
  - `playerErrorInterrupted`
  - `playerErrorNotSupported`
  - `playerErrorTokenExpired`
  - `playerErrorUnknown`
  - `rtmpStreamPublishErrorOk`
  - `rtmpStreamPublishErrorInvalidArgument`
  - `rtmpStreamPublishErrorEncryptedStreamNotAllowed`
  - `rtmpStreamPublishErrorConnectionTimeout`
  - `rtmpStreamPublishErrorInternalServerError`
  - `rtmpStreamPublishErrorRtmpServerError`
  - `rtmpStreamPublishErrorTooOften`
  - `rtmpStreamPublishErrorReachLimit`
  - `rtmpStreamPublishErrorNotAuthorized`
  - `rtmpStreamPublishErrorStreamNotFound`
  - `rtmpStreamPublishErrorFormatNotSupported`
  - `rtmpStreamPublishErrorNotBroadcaster`
  - `rtmpStreamPublishErrorTranscodingNoMixStream`
  - `rtmpStreamPublishErrorNetDown`
  - `rtmpStreamPublishErrorInvalidPrivilege`
  - `rtmpStreamUnpublishErrorOk`

**Deleted**

- `startChannelMediaRelay`
- `updateChannelMediaRelay`
- `startChannelMediaRelayEx`
- `updateChannelMediaRelayEx`
- `onChannelMediaRelayEvent`
- `ChannelMediaRelayEvent`

### v6.2.6

v6.2.6 was released on November 24, 2023.

#### Issues fixed

This release fixed the following issue:

- When using an iOS 16 or later device with Bluetooth headphones connected before joining the channel, the audio routing after joining the channel was not as expected: Audio was played from the speaker, not the Bluetooth headphones (iOS).

### v6.2.4

v6.2.4 was released on October 25, 2023.

#### Issues fixed

This release fixes the following issue:

The `AgoraRtcWrapper` version number in `CFBundleShortVersionString` on iOS and macOS is wrong, which interferes with submitting the App to the App Store.

### v6.2.3

v6.2.3 was released on October 20, 2023.

#### Improvements

This release optimizes the logic of Token parsing, in order to prevent an app from crashing when an invalid token is passed in.

#### Issues fixed

This release fixed the following issues:

- Occasional crashes when joining a channel on macOS.
- Occasional failure of joining a channel when the local system time was not set correctly.
- When calling the `playEffect` method to play two audio files using the same `soundId`, the first audio file was sometimes played repeatedly.
- When the host called the `startAudioMixing` method to play music, sometimes the host couldn't hear the music while the remote users could hear it on Android.
- Occasional crashes occurred on certain Android devices.
- In channels joined by calling `joinChannelEx` exclusively, calling `setEnableSpeakerphone` did not result in switching audio route from the speaker to the headphone on Android.

#### API changes

**Added**

- The following enumerations in `onLocalVideoStateChanged` on Windows and macOS:
  - `localVideoStreamErrorScreenCapturePaused`
  - `localVideoStreamErrorScreenCaptureResumed`
  - `localVideoStreamErrorScreenCaptureWindowHidden`
  - `localVideoStreamErrorScreenCaptureWindowRecoverFromHidden`
  - `localVideoStreamErrorScreenCaptureWindowRecoverFromMinimized`
- `textureSliceIndex` members in `ExternalVideoFrame` on Windows
- `videoTextureId3d11texture2d` in `VideoPixelFormat` on Windows
- `enableContentInspectEx`
- `contentInspectImageModeration` in `ContentInspectType`.
- `serverConfig` in `ContentInspectConfig`
- `isFeatureAvailableOnDevice`
- `FeatureType`

### v6.2.2

v6.2.2 was released on August 1, 2023.

#### New features

1. **Wildcard token**

   This release introduces wildcard tokens. Agora supports setting the channel name used for generating a token as a wildcard character. The token generated can be used to join any channel if you use the same user id. In use-cases involving multiple channels, such as switching between different channels, using a wildcard token can avoid repeated application of tokens every time users joining a new channel, which reduces the pressure on your token server. See [Secure authentication with tokens](/en/video-calling/get-started/authentication-workflow).

   <Admonition type="info">All 4.x SDKs support using wildcard tokens.</Admonition>

2. **Preloading channels**

   This release adds `preloadChannel` and `preloadChannelWithUserAccount` methods, which allows a user whose role is set as audience to preload channels before joining one. Calling the method can help shortening the time of joining a channel, thus reducing the time it takes for audience members to hear the host.

   When preloading more than one channels, Agora recommends that you use a wildcard token for preloading to avoid repeated application of tokens every time you joining a new channel, thus saving the time for switching between channels. See [Secure authentication with tokens](/en/video-calling/get-started/authentication-workflow).

#### Improvements

1. **Channel media relay**

   The number of target channels for media relay has been increased to 6. When calling `startOrUpdateChannelMediaRelay` and `startOrUpdateChannelMediaRelayEx`, you can specify up to 6 target channels.

This release includes the following additional improvements:

1. To improve the switching experience between multiple audio routes, this release adds the `setRouteInCommunicationMode` method. This method can switch the audio route from a Bluetooth headphone to the earpiece, wired headphone or speaker in communication volume mode ([`MODE_IN_COMMUNICATION`](https://developer.android.google.cn/reference/kotlin/android/media/AudioManager?hl=en#mode_in_communication)). (Android)

#### Issues fixed

This release fixed the following issues:

- Occasionally, noise occurred when the local user listened to their own and remote audio after joining the channel. (macOS)
- Slow channel reconnection after the connection was interrupted due to network reasons.
- In multi-device audio recording use-cases, after repeatedly plugging and unplugging or enabling/disabling the audio recording device, no sound could be heard occasionally when calling the `startRecordingDeviceTest` to start an audio capturing device test. (Windows)

#### API changes

**Added**

- `preloadChannel`
- `preloadChannelWithUserAccount`
- `updatePreloadChannelToken`
- `setRouteInCommunicationMode` (Android)


### v6.2.1

This version was released on June 21, 2023.

#### Improvements

This version improves the network transmission strategy, enhancing the smoothness of audio interactions.

#### Issues fixed

This version fixed the following issues:
- Inability to join channels caused by SDK's incompatibility with some older versions of AccessToken.
- After the sending end called `setAINSMode` to activate AI noise reduction, occasional echo was observed by the receiving end.
- Brief noise occurred while playing media files using the media player.
- Occasional crash after calling the `destroyMediaPlayer` method. (iOS)


### v6.2.0

v6.2.0 was released on May 29, 2023.

#### Compatibility changes

If you use the features mentioned in this section, ensure that you modify the implementation of the relevant features after upgrading the SDK.

**1. Channel media options**

- `publishCustomAudioTrackEnableAec` in `ChannelMediaOptions` is deleted. Use `publishCustomAudioTrack` instead.
- `publishCustomAudioSourceId` in `ChannelMediaOptions` is renamed to `publishCustomAudioTrackId`.

**2. Miscellaneous**

- `onApiCallExecuted` is deleted. Agora recommends getting the results of the API implementation through relevant channels and media callbacks.
- The `IAudioFrameObserver` class is renamed to `IAudioPcmFrameSink`, thus the prototypes of the following methods are updated accordingly:
    - `onFrame`
    - `registerAudioFrameObserver` and `unregisterAudioFrameObserver` in `MediaPlayer`
- `startChannelMediaRelay`, `updateChannelMediaRelay`, `startChannelMediaRelayEx`, and `updateChannelMediaRelayEx` are deprecated. Use `startOrUpdateChannelMediaRelay` and `startOrUpdateChannelMediaRelayEx` instead.


#### New features

**1. AI Noise Suppression**

This release introduces public APIs for the AI Noise Suppression function. Once enabled, the SDK automatically detects and reduces background noises. Whether in bustling public venues or real-time competitive arenas that demand lightning-fast responsiveness, this function guarantees optimal audio clarity, providing users with an elevated audio experience. You can enable this function through the newly-introduced `setAINSMode` method and set the noise reduction mode as balance, aggressive, or low latency according to your use-case.

<Admonition type="info">Agora charges separately for this function. See [AI Noise Suppression unit pricing](pricing#ai-noise-suppression-pricing).</Admonition>

**2. Cross-device synchronization**

In real-time collaborative singing use-cases, network issues can cause inconsistencies in the downlinks of different client devices. To address this, this release introduces `getNtpWallTimeInMs` for obtaining the current Network Time Protocol (NTP) time. By using this method to synchronize lyrics and music across multiple client devices, users can achieve synchronized singing and lyrics progression, resulting in a better collaborative experience.

**3. Instant frame rendering**

This release adds the `enableInstantMediaRendering` method to enable instant rendering mode for audio frames, which can speed up the first audio frame rendering after the user joins the channel.


#### Improvements

**1. Voice changer**

This release introduces the `setLocalVoiceFormant` method that allows you to adjust the formant ratio to change the timbre of the voice. This method can be used together with the `setLocalVoicePitch` method to adjust the pitch and timbre of voice at the same time, enabling a wider range of voice transformation effects.

**2. Improved compatibility with audio file types (Android)**

As of this release, you can use the following methods to open files with a URI starting with `content://`:
- `startAudioMixing`
- `playEffect`
- `openWithMediaSource`

**3. Channel media relay**

This release introduces `startOrUpdateChannelMediaRelay` and `startOrUpdateChannelMediaRelayEx`, allowing for a simpler and smoother way to start and update media relay across channels. With these methods, developers can easily start the media relay across channels and update the target channels for media relay with a single method. Additionally, the internal interaction frequency has been optimized, effectively reducing latency in function calls.

**4. Custom audio tracks**

To better meet the needs of custom audio capture use-cases, this release adds `createCustomAudioTrack` and `destroyCustomAudioTrack` for creating and destroying custom audio tracks. Two types of audio tracks are also provided for users to choose from, further improving the flexibility of capturing external audio source:

- Mixable audio track: Supports mixing multiple external audio sources and publishing them to the same channel, suitable for multi-channel audio capture use-cases.
- Direct audio track: Only supports publishing one external audio source to a single channel, suitable for low-latency audio capture use-cases.

#### Issues fixed

This release fixed the following issues:

- Occasional crashes occurred on Android devices when users joining or leaving a channel (Android).
- When the host frequently switched the user role between broadcaster and audience in a short period of time, the audience members could not hear the audio of the host.
- Occasional failure when enabling in-ear monitoring (Android).
- Occasional echo (Android).
- Abnormal client status caused by an exception in the `onRemoteAudioStateChanged` callback (Android, iOS).
- Playing audio files with a sample rate of 48 kHz failed.
- In real-time chorus use-cases, remote users heard noises and echoes when an OPPO R11 device joined the channel in the loudspeaker mode  (Android).
- When the playback of the local music finished, the `onAudioMixingFinished` callback was not properly triggered (Android).
- At the moment when a user left a channel, a request for leaving was not sent to the server and the leaving behavior was incorrectly determined by the server as timed out.

#### API changes

**Added**

- `startOrUpdateChannelMediaRelay`
- `startOrUpdateChannelMediaRelayEx`
- `getNtpWallTimeInMs`
- `setAINSMode`
- `createAudioCustomTrack`
- `destroyAudioCustomTrack`
- `AudioTrackConfig`
- `AudioAinsMode`
- `AudioTrackType`
- The `domainLimit` and `autoRegisterAgoraExtensions` members in `RtcEngineContext`
- `enableInstantMediaRendering`

**Deprecated**

- `startChannelMediaRelay`
- `startChannelMediaRelayEx`
- `updateChannelMediaRelay`
- `updateChannelMediaRelayEx`
- `onChannelMediaRelayEvent`
- `ChannelMediaRelayEvent`

**Deleted**

- `onApiCallExecuted`
- `publishCustomAudioTrackEnableAec` in `ChannelMediaOptions` in `ChannelMediaOptions`

### v6.1.0

v6.1.0 was released on December 20, 2022.

#### New features

**1. In-ear monitoring**

This release adds support for in-ear monitoring. You can call `enableInEarMonitoring` to enable the in-ear monitoring function.

After successfully enabling the in-ear monitoring function, you can call `registerAudioFrameObserver` to register the audio observer, and the SDK triggers the `onEarMonitoringAudioFrame` callback to report the audio frame data. You can use your own audio effect processing module to preprocess the audio frame data of the in-ear monitoring to implement custom audio effects. Agora recommends that you call the `setEarMonitoringAudioFrameParameters` method to set the audio data format of in-ear monitoring. The SDK calculates the sampling interval based on the parameters in this method and triggers the `onEarMonitoringAudioFrame` callback based on the sampling interval.

To adjust the in-ear monitoring volume, you can call `setInEarMonitoringVolume`.


**2. Audio capture device test (Android)**

This release adds support for testing local audio capture devices before joining a channel. You can call `startRecordingDeviceTest` to start the audio capture device test. After the test is complete, call the `stopPlaybackDeviceTest` method to stop the audio capture device test.


**3. Local network connection types**

To make it easier for users to know the connection type of the local network at any stage, this release adds the
`getNetworkType` method. You can use this method to get the type of network connection in use.
The available values are `UNKNOWN`, `DISCONNECTED`, `LAN`, `WIFI`, `2G`, `3G`, `4G`, and `5G`.
When the local network connection type changes, the SDK triggers the `onNetworkTypeChanged` callback to report
the current network connection type.

**4. Audio stream filter**

This release introduces filtering audio streams based on volume. Once this function is enabled, the Agora server ranks all audio streams by volume and transports the three audio streams with the highest volumes to the receivers by default. The number of audio streams to be transported can be adjusted; contact [support@agora.io](mailto:support@agora.io) to adjust this number according to your use-case.

Agora also supports publishers in choosing whether the audio streams being published are to be filtered based on volume. Streams that are not filtered bypass this filter mechanism and are transported directly to the receivers. In use-cases with a number of publishers, enabling this function helps reduce the bandwidth and device system pressure for the receivers.

<div class="alert info">To enable this function, contact <a href="mailto:support@agora.io/">support@agora.io</a>.</div>

**5. Loopback device (Windows)**

The SDK uses the playback device as the loopback device by default. As of 6.1.0, you can specify a loopback device separately and publish the captured audio to the remote end.

- `setLoopbackDevice`: Specifies the loopback device. If you do not want the current playback device to be the loopback device, you can call this method to specify another device as the loopback device.
- `getLoopbackDevice`: Gets the current loopback device.
- `followSystemLoopbackDevice`: Whether the loopback device follows the default playback device of the system.


**6. Spatial audio effect**

This release adds the following features applicable to spatial audio effect use-cases, which can effectively enhance the user's sense-of-presence experience in virtual interactive use-cases.

- Sound insulation area: You can set a sound insulation area and sound attenuation parameter by calling `setZones`. When the sound source (which can be a user or the media player) and the listener belong to the inside and outside of the sound insulation area, the listener experiences an attenuation effect similar to that of the sound in the real environment when it encounters a building partition. You can also set the sound attenuation parameter for the media player and the user by calling `setPlayerAttenuation` and `setRemoteAudioAttenuation` respectively, and specify whether to use that setting to force an override of the sound attenuation parameter in `setZones`.
- Doppler sound: You can enable Doppler sound by setting the `enableDoppler` parameter in `SpatialAudioParams`. The receiver experiences noticeable tonal changes in the event of a high-speed relative displacement between the source and receiver (such as in a racing game use-case).
- Headphone equalizer: You can use a preset headphone equalization effect by calling the `setHeadphoneEQPreset` method to improve the audio experience for users with headphones.


**7. Headphone equalization effect**

This release adds the `setHeadphoneEQParameters` method, which is used to adjust the low- and high-frequency parameters of the headphone EQ. This is mainly useful in spatial audio use-cases. If you cannot achieve the expected headphone EQ effect after calling `setHeadphoneEQPreset`, you can call `setHeadphoneEQParameters` to adjust the EQ.



**8. MPUDP (MultiPath UDP) (Beta)**

As of this release, the SDK supports MPUDP protocol, which enables you to connect and use multiple paths to maximize the use of channel resources based on the UDP protocol. You can use different physical NICs on both mobile and desktop and aggregate them to effectively combat network jitter and improve transmission quality.

<div class="alert info">To enable this feature, contact <a href="mailto:support@agora.io">support@agora.io</a>.</div>


**9. Register extensions (Windows)**

This release adds the `registerExtension` method for registering extensions. When using a third-party extension, you need to call the extension-related APIs in the following order:

`loadExtensionProvider` -> `registerExtension` -> `setExtensionProviderProperty` -> `enableExtension`


**10. Device management (Windows, macOS)**

This release adds a series of callbacks to help you better understand the status of your audio devices:

- `onAudioDeviceStateChanged`: Occurs when the status of the audio device changes.
- `onAudioDeviceVolumeChanged`: Occurs when the volume of an audio device or app changes.


**11. Multi-channel management**

This release adds a series of multi-channel-related methods that you can call to manage audio streams in multi-channel use-cases.

- The `muteLocalAudioStreamEx` method is used to cancel or resume publishing a local audio stream.
- The `muteAllRemoteAudioStreamsEx` method is used to cancel or resume the subscription of all remote users to audio streams.
- The `startRtmpStreamWithoutTranscodingEx`, `startRtmpStreamWithTranscodingEx`, `updateRtmpTranscodingEx`, and `stopRtmpStreamEx` methods are used to implement Media Push in multi-channel use-cases.
- The `startChannelMediaRelayEx`, `updateChannelMediaRelayEx`, `pauseAllChannelMediaRelayEx`, `resumeAllChannelMediaRelayEx`, and `stopChannelMediaRelayEx` methods are used to relay media streams across channels in multi-channel use-cases.
- The `options` parameter in the `leaveChannelEx` method is used to choose whether to stop recording with the microphone when leaving a channel in a multi-channel use-case.


**12. Client role switching**

In order to enable users to know whether the switched user role is low-latency or ultra-low-latency, this release adds the `newRoleOptions` parameter to the `onClientRoleChanged` callback. The value of this parameter is as follows:

- `audienceLatencyLevelLowLatency (1)`: Low latency.
- `audienceLatencyLevelUltraLowLatency (2)`: Ultra-low latency.



#### Improvements


**1. Bluetooth permissions (Android)**

To simplify integration, as of this release, you can use the SDK to enable Android users to use Bluetooth normally without adding the `BLUETOOTH_CONNECT` permission.


**2. Relaying media streams across channels**

This release optimizes the `updateChannelMediaRelay` method as follows:

- Before v6.1.0: If the target channel update fails due to internal reasons in the server, the SDK returns the error code `relayEventPacketUpdateDestChannelRefused (8)`, and you need to call the `updateChannelMediaRelay` method again.
- v6.1.0 and later: If the target channel update fails due to internal server reasons, the SDK retries the update until the target channel update is successful.


**3. Reconstructed AIAEC algorithm**

This release reconstructs the AEC algorithm based on the AI method. Compared with the traditional AEC algorithm, the new algorithm can preserve the complete, clear, and smooth near-end vocals under poor echo-to-signal conditions, significantly improving the system's echo cancellation and dual-talk performance. This gives users a more comfortable call and live-broadcast experience. AIAEC is suitable for conference calls, chats, karaoke, and other scenarios.


**Other improvements**

This release includes the following additional improvements:

- Reduces the latency when pushing external audio sources.
- Improves the performance of echo cancellation when using the `audioScenarioMeeting` scenario.
- Enhances the ability to identify different network protocol stacks and improves the SDK's access capabilities in multiple-operator network use-cases.



#### Issues fixed

This release fixes the following issues:

**All**
- When entering a live streaming room that has been played for a long time as an audience, the time for the first frame to be rendered was shortened.
- The call `getExtensionProperty` failed and returned an empty string.
- Audience members heard buzzing noises when the host switched between speakers and earphones during live streaming.


**Android**
- In online meeting use-cases, the local user and the remote user occasionally could not hear each other after the local user was interrupted by a call.
- After calling `setCloudProxy` to set the cloud proxy, calling `joinChannelEx` to join multiple channels failed.


**iOS**
- Calling `startAudioMixing` to play music files in the `ipod-library://item` path failed.


**Windows**
- When the host started screen sharing during live streaming, the audience members sometimes heard echoes.
- In screen sharing use-cases, the system volume of the local user occasionally decreased.
- The uplink network quality reported by the `onNetworkQuality` callback was inaccurate for the user who was sharing a screen.


**macOS**
- In screen sharing use-cases, the system volume of the local user occasionally decreased.
- The uplink network quality reported by the `onNetworkQuality` callback was inaccurate for the user who was sharing a screen.
- After starting and stopping the audio capture device test, there was no sound when the audio playback device was subsequently started.



#### API changes

**Added**

- `getNativeHandle`
- `getPlaybackDefaultDevice`
- `getRecordingDefaultDevice`
- `SimulcastStreamMode`
- `getNetworkType`
- `setLoopbackDevice` (Windows)
- `getLoopbackDevice` (Windows)
- `followSystemLoopbackDevice` (Windows)
- `setZones`
- `setPlayerAttenuation`
- `setRemoteAudioAttenuation`
- `setHeadphoneEQPreset`
- `setHeadphoneEQParameters`
- `HeadphoneEqualizerPreset`
- `AdvanceOptions`
- `EncodingPreference`
- `CompressionPreference`
- `adjustUserPlaybackSignalVolumeEx`
- `onRhythmPlayerStateChanged` (Android, iOS)
- `RhythmPlayerStateType`
- `RhythmPlayerErrorType`
- `enableAudioVolumeIndicationEx`
- `onAudioDeviceStateChanged` (Windows, macOS)
- `onAudioDeviceVolumeChanged` (Windows, macOS)
- `registerExtension` (Windows)
- `muteLocalAudioStreamEx`
- `muteAllRemoteAudioStreamsEx`
- `startRtmpStreamWithoutTranscodingEx`
- `startRtmpStreamWithTranscodingEx`
- `updateRtmpTranscodingEx`
- `stopRtmpStreamEx`
- `startChannelMediaRelayEx`
- `updateChannelMediaRelayEx`
- `pauseAllChannelMediaRelayEx`
- `resumeAllChannelMediaRelayEx`
- `stopChannelMediaRelayEx`


**Modified**

- Adds `isAudioFilterable` in `ChannelMediaOptions`
- Adds `enableDoppler` in `SpatialAudioParams`
- Adds `options` in `leaveChannelEx`
- Adds `newRoleOptions` in `onClientRoleChanged`
- `enableInEarMonitoring`: Supports Windows and macOS
- `setEarMonitoringAudioFrameParameters`: Supports Windows and macOS
- `setInEarMonitoringVolume`: Supports Windows and macOS
- `onEarMonitoringAudioFrame`: Supports Windows and macOS


**Deprecated**

- `onApiCallExecuted`: Use the callbacks triggered by specific methods instead.
- `relayEventPacketUpdateDestChannelRefused (8)` in `ChannelMediaRelayEvent`


### v<Vg k = "VSDK_FLUTTER_LATEST_RELEASE"/>

v<Vg k = "VSDK_FLUTTER_LATEST_RELEASE"/> was released on September 29, 2022.

#### Compatibility changes

This release changed SDK package name from `agora_rtc_ng` to `agora_rtc_engine`, and optimized the implementation of some features, resulting in incompatibility with v<Vg k = "VSDK_FLUTTER_PREVIOUS_RELEASE"/> The following are the main features with compatibility changes:

- Multiple channel
- Media stream publishing control
- Error codes and warning codes

After upgrading the SDK, you need to update the code in your app according to the business use-cases. See [Migration guide](../overview/migration-guide) for details.

#### New features

**1. Multiple media tracks**

This release supports one `RtcEngine` instance to collect multiple audio sources at the same time and publish them to the remote users by setting `RtcEngineEx` and `ChannelMediaOptions`.

- After calling `joinChannel` to join the first channel, call `joinChannelEx` multiple times to join multiple channels, and publish the specified stream to different channels through different user ID (`localUid`) and `ChannelMediaOptions` settings.

You can also experience the following features with the multi-channel capability:

- Publish multiple sets of audio streams to the remote users through different user IDs (`uid`).
- Mix multiple audio streams and publish to the remote users through a user ID (`uid`).


**2. Agora media player**

To make it easier for users to integrate the Agora SDK and reduce the SDK's package size, this release introduces the Agora media player. After calling the `createMediaPlayer` method to create a media player object, you can then call the methods in the `MediaPlayer` class to experience a series of functions, such as playing local and online media files, preloading a media file, changing the CDN route for playing according to your network conditions, or sharing the audio streams being played with remote users.

- Plays local and online media files.
- Preloads media files.
- Changes the CDN route for playing media files according your network conditions.
- Shares the audio streams being played with remote users.
- Caches data when playing media files.


3. **Brand-new AI Noise Suppression**

    The SDK supports a new version of Noise Suppression (versus the basic AI Noise Suppression in agora_rtc_engine: ^5.x). Compared to the previous Noise Suppression, the new AI Noise Suppression has better vocal fidelity, cleaner noise suppression, and add the Dereverberation capability. To enable this feature, contact [support@agora.io](mailto:support@agora.io).


**4. Ultra-high audio quality**

To make audios sound clearer and stay true to the original sound of audio files, this release adds the `ultraHighQualityVoice` enumeration. In use-cases that involve human voices, such as chatting or singing, you can call `setVoiceBeautifierPreset` and use this enumeration to experience ultra-high audio quality.


**5. Spatial audio**

> **_NOTE:_** This feature is in experimental status. To enable this feature, contact <a href= "mailto:support@agora.io">support@agora.io</a>. Contact Technical Support if needed.

You can set the spatial audio for the remote user as following:

- Local Cartesian Coordinate System Calculation Solution: This solution uses the `LocalSpatialAudioEngine` class to implement spatial audio by calculating the spatial coordinates of the remote user. You need to call `updateSelfPosition` and `updateRemotePosition` to update the spatial coordinates of the local and remote users respectively, so that the local user can hear the spatial audio of the remote user.
![Spatial effect](/images/video-sdk/video-call-spatial.png)

- Local Cartesian Coordinate System Calculation Solution: This solution uses the `LocalSpatialAudioEngine` class to implement spatial audio. You need to call `updateSelfPosition` and `updatePlayerPositionInfo` to update the spatial coordinates of the local user and media player, respectively, so that the local user can hear the spatial audio effect of media player.
![Spatial effect](/images/video-sdk/spatial-audio-effect.png)


**6. Real-time chorus**

This release gives real-time chorus the following abilities:

- Two or more choruses are supported.
- Each singer is independent of each other. If one singer fails or quits the chorus, the other singers can continue to sing.
- Very low latency experience. Each singer can hear each other in real time, and the audience can also hear each singer in real time.

This release adds the `audioScenarioChorus` enumeration in `AudioScenarioType`. With this enumeration, users can experience ultra-low latency in real-time chorus when the network conditions are good.


**7. Enhanced channel management**

To meet the channel management requirements of various business use-cases, this release adds the following functions to the `ChannelMediaOptions` structure:

- Sets or switches the publishing of multiple audio sources.
- Sets or switches channel profile and user role.
- Controls audio publishing delay.

Set `ChannelMediaOptions` when calling `joinChannel` or `joinChannelEx` to specify the publishing and subscription behavior of a media stream, for example, whether to subscribe to the audio of remote users. After joining the channel, call `updateChannelMediaOptions` to update the settings in `ChannelMediaOptions` at any time, for example, to switch the published audio sources.


**8. Subscription allowlists and blocklists**

This release introduces subscription allowlists and blocklists for remote audio streams. You can add the user ID that you want to subscribe to in your allowlist, or in your blocklist if you do not want to subscribe to. You can experience this feature through the following APIs, and in use-cases that involve multiple channels, you can call the following methods in the `RtcEngineEx` interface.

- `setSubscribeAudioBlacklist`: Set the audio subscription blocklist.
- `setSubscribeAudioWhitelist`: Set the audio subscription allowlist.

If a user is added in a blocklist and allowlist at the same time, only the blocklist takes effect.


**9. Set audio scenarios**

To make it easier to change audio scenarios, this release adds the `setAudioScenario` method. For example, if you want to change the audio scenario from `AudioScenarioDefault` to `AudioScenarioGameStreaming` when you are in a channel, you can call this method.


#### Improvements

**1. Fast channel switching**

This release can achieve the same switching speed as `switchChannel` in agora_rtc_engine: ^5.x through the `leaveChannel` and `joinChannel` methods so that you don't need to take the time to call the `switchChannel` method.

**2. Voice pitch of the local user**

This release adds `voicePitch` in `AudioVolumeInfo` of `onAudioVolumeIndication`. You can use `voicePitch` to get the local user's voice pitch and perform business functions such as rating for singing.
</PlatformWrapper>