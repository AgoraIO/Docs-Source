<PlatformWrapper platform="android">
    ```kotlin
    private val iAudioFrameObserver: IAudioFrameObserver = object : IAudioFrameObserver {
        override fun onRecordAudioFrame(
            channelId: String?,
            type: Int,
            samplesPerChannel: Int,
            bytesPerSample: Int,
            channels: Int,
            samplesPerSec: Int,
            buffer: ByteBuffer?,
            renderTimeMs: Long,
            avsync_type: Int
        ): Boolean {
            // Gets the captured audio frame.
            // Add code here to process the recorded audio.
            return false
        }

        override fun onPlaybackAudioFrame(
            channelId: String?,
            type: Int,
            samplesPerChannel: Int,
            bytesPerSample: Int,
            channels: Int,
            samplesPerSec: Int,
            buffer: ByteBuffer?,
            renderTimeMs: Long,
            avsync_type: Int
        ): Boolean {
            // Gets the audio frame for playback.
            // Add code here to process the playback audio.
            // return true to indicate that Data has been processed
            return false
        }

        override fun onMixedAudioFrame(
            channelId: String?,
            type: Int,
            samplesPerChannel: Int,
            bytesPerSample: Int,
            channels: Int,
            samplesPerSec: Int,
            buffer: ByteBuffer?,
            renderTimeMs: Long,
            avsync_type: Int
        ): Boolean {
            // Retrieves the mixed captured and playback audio frame.
            return false
        }

        override fun onEarMonitoringAudioFrame(
            type: Int,
            samplesPerChannel: Int,
            bytesPerSample: Int,
            channels: Int,
            samplesPerSec: Int,
            buffer: ByteBuffer?,
            renderTimeMs: Long,
            avsync_type: Int
        ): Boolean {
            return false
        }

        override fun onPlaybackAudioFrameBeforeMixing(
            channelId: String?,
            userId: Int,
            type: Int,
            samplesPerChannel: Int,
            bytesPerSample: Int,
            channels: Int,
            samplesPerSec: Int,
            buffer: ByteBuffer?,
            renderTimeMs: Long,
            avsync_type: Int
        ): Boolean {
            // Retrieves the audio frame of a specified user before mixing.
            return false
        }

        override fun getObservedAudioFramePosition(): Int {
            return 0
        }

        override fun getRecordAudioParams(): AudioParams {
            return AudioParams(sampleRate,numberOfChannels, 0 ,samplesPerCall)
        }

        override fun getPlaybackAudioParams(): AudioParams {
            return AudioParams(sampleRate,numberOfChannels, 0 ,samplesPerCall)
        }

        override fun getMixedAudioParams(): AudioParams {
            return AudioParams(sampleRate,numberOfChannels, 0 ,samplesPerCall)
        }

        override fun getEarMonitoringAudioParams(): AudioParams {
            return AudioParams(sampleRate,numberOfChannels, 0 ,samplesPerCall)
        }
    }
    ```
    - <Link to = "{{global.API_REF_ANDROID_ROOT}}/class_iaudioframeobserver.html">IAudioFrameObserver</Link>
</PlatformWrapper>
<PlatformWrapper platform={["ios","macos"]}>

    ```swift
    extension ModifyAudioFrameDelegate: AgoraAudioFrameDelegate {
        public func onRecordAudioFrame(_ frame: AgoraAudioFrame, channelId: String) -> Bool {
            // Change the audio frame immediately after recording it
            true
        }
        public func onPlaybackAudioFrame(_ frame: AgoraAudioFrame, channelId: String) -> Bool {
            // Change the audio frame just before playback
            true
        }
    }
    ```

    <PlatformWrapper platform="ios">
    - <Link target="_blank" to="{{Global.API_REF_IOS_ROOT_RTC_KIT}}/agoraaudioframedelegate">AgoraAudioFrameDelegate</Link>
    </PlatformWrapper>
    <PlatformWrapper platform="macos">
    - <Link target="_blank" to="{{Global.API_REF_MACOS_ROOT_RTC_KIT}}/agoraaudioframedelegate">AgoraAudioFrameDelegate</Link>
    </PlatformWrapper>
</PlatformWrapper>
<PlatformWrapper platform="unity">
    ```csharp
    // Internal class for handling audio events
    internal class RawAudioEventHandler : IAudioFrameObserver
    {
        private RawAudioVideoManager _agoraAudioRawData;
        
        internal RawAudioEventHandler(RawAudioVideoManager agoraAudioRawData)
        {
            _agoraAudioRawData = agoraAudioRawData;
        }
        
        public override bool OnRecordAudioFrame(string channelId, AudioFrame audioFrame)
        {
            var floatArray = RawAudioVideoManager.ConvertByteToFloat16(audioFrame.RawBuffer);
            
            lock (_agoraAudioRawData._audioBuffer)
            {
                _agoraAudioRawData._audioBuffer.Put(floatArray);
                _agoraAudioRawData._writeCount += floatArray.Length;
                _agoraAudioRawData._count++;
            }
            return true;
        }
        public override bool OnPlaybackAudioFrame(string channelId, AudioFrame audioFrame)
        {
            return true;
        }
        public override bool OnPlaybackAudioFrameBeforeMixing(string channel_id, uint uid, AudioFrame audio_frame)
        {
            return false;
        }
        
        public override bool OnPlaybackAudioFrameBeforeMixing(string channel_id,
        string uid,
        AudioFrame audio_frame)
        {
            return false;
        }
    }
    ```
    - <Link to="{{Global.API_REF_UNITY_ROOT}}/class_iaudioframeobserver.html#class_iaudioframeobserver">IAudioFrameObserver</Link>
</PlatformWrapper>
