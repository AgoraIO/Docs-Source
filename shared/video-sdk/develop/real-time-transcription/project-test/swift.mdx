
3. In the `ViewController`, update `appID`, `channelName`, and `token` with the values from <Vg k="CONSOLE" />. Make sure that the `uid` is set to a non-zero integer.

4. In <Vg k="CONSOLE" />, click the account name in the top right corner, and select **RESTful API** from the drop-down list. If you have not added a secret already, do so now and download it. Update `apiKey` and `aipSecret` in `ViewController` with these values.

5. Run your <Vpl k="CLIENT" />.

    If this is the first time you run the project, grant microphone and camera access to your <Vpl k="CLIENT" />.
    <PlatformWrapper platform="ios">
        If you use an iOS simulator, you see the remote video only. You cannot see the local video stream because of <Link target="_blank" to="https://help.apple.com/simulator/mac/current/#/devb0244142d">Apple simulator hardware restrictions</Link>.
    </PlatformWrapper>
<ProductWrapper notAllowed="video-calling">
6. Select **Broadcaster** mode and press **Join** to connect to the same channel as your web demo.
</ProductWrapper>

<ProductWrapper product="video-calling">
6. Press **Join** to connect to the same channel as your web demo.
</ProductWrapper>

7. Press **Start real-time transcription to text**. You see notifications confirming receipt of a builder token and starting of a real-time transcription task.

8. Speak into the microphone. You see spoken words displayed in your <Vpl k="CLIENT" /> as text.

9. Press **Query real-time transcription to text**. You see a message informing you of the current status of the task.

10. Press **Stop real-time transcription to text**. The real-time transcription task stops and a confirmation message is displayed.

11. Check the storage location you specified in the starting configuration. You see a `WebVTT` file containing real-time transcription data.