---
title: OpenAI
sidebar_position: 1
platform_selector: false
description: >
  Integrate an OpenAI LLM into Conversational AI Engine.
---

import IntegrationSteps from '@docs/shared/conversational-ai/develop/llm-integration.mdx'

OpenAI provides state-of-the-art language models optimized for different use cases.

### Sample configuration

The following example shows a starting `llm` parameter configuration you can use when you [Start a conversational AI agent](/conversational-ai/rest-api/join). 

```json
"llm": {
    "url": "https://api.openai.com/v1/chat/completions",
    "api_key": "<your_llm_key>",
    "system_messages": [
      {
        "role": "system",
        "content": "You are a helpful chatbot."
      }
    ],
    "max_history": 32,
    "greeting_message": "Hello, how can I assist you",
    "failure_message": "Please hold on a second.",
    "params": {
      "model": "gpt-4o-mini"
    },
  }
```

### Key parameters

-  `api_key`: Create or manage your API key from [OpenAI organization settings](https://platform.openai.com/settings/organization/api-keys).
- `url`: Use the completions endpoint.
- `model`: Refer to [OpenAI models](https://platform.openai.com/docs/models) for available models.

For advanced configuration options, model capabilities, and detailed parameter descriptions, see the [OpenAI API documentation](https://platform.openai.com/docs/api-reference/responses/create).
