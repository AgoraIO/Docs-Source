---
title: Class 及 Enum
---

## Class


<h3 className="anchor index-class-agoraserviceconfig" id="agoraserviceconfig">AgoraServiceConfig</h3>

```python
@dataclass(kw_only=True)
class AgoraServiceConfig:
    log_path: str = ""
    log_size: int = 0
    enable_audio_processor: int = 1
    enable_audio_device: int = 0
    enable_video: int = 0
    context: object = None
    appid: str = ""
    area_code: int = AreaCode.AREA_CODE_GLOB.value
    channel_profile: ChannelProfileType = ChannelProfileType.CHANNEL_PROFILE_LIVE_BROADCASTING
    audio_scenario: AudioScenarioType = AudioScenarioType.AUDIO_SCENARIO_CHORUS
    use_string_uid: int = 0
```

<span className="index-desc-agoraserviceconfig">Global configuration of the `AgoraServiceConfig` class. Set when calling the [`initialize`](#initialize) method.</span>

export const TableHeader921ji2tzyj = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeader921ji2tzyj}>
  <Tr>
    <Td>`log_path`</Td>
    <Td>The full path to the log file. If this parameter is set to `None`, the log is located in the current application's pwd directory.</Td>
  </Tr>
  <Tr>
    <Td>`log_size`</Td>
    <Td>The size of a single log file in KB. The default value is 1024 KB. If you set this parameter to 1024 KB, the SDK outputs a maximum of 5 MB of log files. If you set this parameter to less than 1024 KB, the setting does not take effect, and the maximum size of a single log file is still 1024 KB.</Td>
  </Tr>
  <Tr>
    <Td>`enable_audio_processor`</Td>
    <Td>
    Whether to enable the audio processing module.
    - `0`: Disable the audio processing module. You will not be able to create an audio track.
    - `1`: (Default) Enable the audio processing module.
    </Td>
  </Tr>
  <Tr>
    <Td>`enable_audio_device`</Td>
    <Td>
    Whether to enable the Audio Device Module (ADM). ADM is used to manage audio devices such as recording and playing audio.
    - `0`: Disable the audio device module. You cannot record or play audio.
    - `1`: (Default) Enable the audio device module. You can record and play audio.

    Note: If you set `enable_audio_device` to `0` and `enable_audio_processor` to `1`, you will not be able to use audio devices, but you can push PCM audio data.
    </Td>
  </Tr>
  <Tr>
    <Td>`enable_video`</Td>
    <Td>
    Whether to enable video.
    - `0`: (Default) Disable video.
    - `1`: Enable video.
    </Td>
  </Tr>
  <Tr>
    <Td>`context`</Td>
    <Td>Context.</Td>
  </Tr>
  <Tr>
    <Td>`appid`</Td>
    <Td>Your Agora project's App ID. If your Agora project has enabled Token authentication, you can also assign this parameter to an RTC Token. See <a href={`/doc/rtc-server-sdk/${props.ag_platform}/get-started/enable-service#get-app-id`}>Get App ID</a> for details.</Td>
  </Tr>
  <Tr>
    <Td>`area_code`</Td>
    <Td>The access region of the server. This feature is an advanced setting suitable for scenarios with access security restrictions. The area code supports bitwise operations. After specifying the access region, the SDK connects to Agora servers within the specified region. See [`AreaCode`](#areacode) for details.</Td>
  </Tr>
  <Tr>
    <Td>`channel_profile`</Td>
    <Td>Channel profile. See [`ChannelProfileType`](#channelprofiletype) for details.</Td>
  </Tr>
  <Tr>
    <Td>`audio_scenario`</Td>
    <Td>Audio encoding properties. See [`AudioScenarioType`](#audioscenariotype) for details.</Td>
  </Tr>
  <Tr>
    <Td>`use_string_uid`</Td>
    <Td>
    Whether to use String user IDs.
    - `0`: Do not use.
    - `1`: Use.
    </Td>
  </Tr>
</Table>


<h3 className="anchor index-class-audioencoderconfiguration" id="audioencoderconfiguration">AudioEncoderConfiguration</h3>

```python
@dataclass(kw_only=True)
class AudioEncoderConfiguration:
    audioProfile: AudioProfileType = AudioProfileType.AUDIO_PROFILE_DEFAULT
```

<span className="index-desc-audioencoderconfiguration">Audio encoder configuration.</span>

export const TableHeaderrvbnrxhz8o = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeaderrvbnrxhz8o}>
  <Tr>
    <Td>`audioProfile`</Td>
    <Td>Audio profile. For details, see [`AudioProfileType`](#audioprofiletype).</Td>
  </Tr>
</Table>

<h3 className="anchor index-class-audioframe" id="audioframe">AudioFrame</h3>

```python
@dataclass(frozen=True, kw_only=True)
class AudioFrame:
    type: int
    samples_per_channel: int
    bytes_per_sample: int
    channels: int
    samples_per_sec: int
    buffer: bytearray
    render_time_ms: int
    avsync_type: int
```

<span className="index-desc-audioframe">`AudioFrame` 定义。</span>

<span className="index-desc-audioframe">Definition of `AudioFrame`.</span>

| Parameter | Description |
| --- | --- |
| `type` | Type of audio frame. Only `0` is supported, indicating 16-bit PCM data. |
| `samples_per_channel` | Number of samples per channel. |
| `bytes_per_sample` | Number of bytes per sample. For PCM, typically 16 bits, which is two bytes. |
| `channels` | Number of channels (if stereo, data is interleaved). |
| `samples_per_sec` | Number of samples per second per channel. |
| `buffer` | Audio data buffer (if stereo, data is interleaved). The buffer size is calculated as `buffer = samples × channels × bytes_per_sample`. |
| `render_time_ms` | Render timestamp of the external audio frame. You can use this timestamp to restore the order of audio frames; in scenarios with video (including those using external video sources), this parameter can be used to achieve audio-video synchronization. |
| `avsync_type` | Reserved parameter. |


<h3 className="anchor index-class-audiosubscriptionoptions" id="audiosubscriptionoptions">AudioSubscriptionOptions</h3>

```python
@dataclass(kw_only=True)
class AudioSubscriptionOptions:
    packet_only: int = 0
    pcm_data_only: int = 0
    bytes_per_sample: int = 0
    number_of_channels: int = 0
    sample_rate_hz: int = 0
```

<span className="index-desc-audiosubscriptionoptions">Audio Subscription Options.</span>

export const TableHeader1um02ulamp = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeader1um02ulamp}>
  <Tr>
    <Td>`packet_only`</Td>
    <Td>
    Whether to subscribe to audio packets only:
    - `0`: (Default) The SDK automatically decodes the audio.
    - `1`: Subscribe to audio packets only. The SDK will not decode the audio.

    Note: If this parameter is set to `1`, other parameters in the structure are invalid.
    </Td>
  </Tr>
  <Tr>
    <Td>`pcm_data_only`</Td>
    <Td>
    Whether to subscribe to PCM data only:
    - `0`: (Default) The SDK automatically encodes the remote audio stream.
    - `1`: Subscribe to PCM data only.
    </Td>
  </Tr>
  <Tr>
    <Td>`bytes_per_sample`</Td>
    <Td>Number of bytes per audio sample.</Td>
  </Tr>
  <Tr>
    <Td>`number_of_channels`</Td>
    <Td>Number of audio channels.</Td>
  </Tr>
  <Tr>
    <Td>`sample_rate_hz`</Td>
    <Td>Audio sampling rate (Hz).</Td>
  </Tr>
</Table>


<h3 className="anchor index-class-encodedaudioframe" id="encodedaudioframe">EncodedAudioFrame</h3>

```python
@dataclass(kw_only=True)
class EncodedAudioFrameInfo:
    capture_timems: int = 0
    codec: AudioCodecType = AudioCodecType.AUDIO_CODEC_AACLC
    number_of_channels: int = 1
    sample_rate: int = 16000
    samples_per_channel: int = 1024
    send_even_if_empty: int = 1
    speech: int = 1
```

<span className="index-desc-encodedaudioframe">Encoded Audio Data.</span>

export const TableHeaderiuf2u3h985 = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeaderiuf2u3h985}>
  <Tr>
    <Td>`capture_timems`</Td>
    <Td>Unix timestamp of the audio frame (milliseconds).</Td>
  </Tr>
  <Tr>
    <Td>`codec`</Td>
    <Td>Audio codec type. See [`AudioCodecType`](#audiocodectype) for details.</Td>
  </Tr>
  <Tr>
    <Td>`number_of_channels`</Td>
    <Td>Number of channels in the audio frame.</Td>
  </Tr>
  <Tr>
    <Td>`sample_rate`</Td>
    <Td>Sampling rate of the audio frame (Hz).</Td>
  </Tr>
  <Tr>
    <Td>`samples_per_channel`</Td>
    <Td>Number of samples per channel. Defaults to 1024 for AAC codec format and 960 for Opus codec format.</Td>
  </Tr>
  <Tr>
    <Td>`send_even_if_empty`</Td>
    <Td>
    Whether to send empty audio frames:
    - `0`: Do not send empty audio frames.
    - `1`: (Default) Send empty audio frames.
    </Td>
  </Tr>
  <Tr>
    <Td>`speech`</Td>
    <Td>
    Whether the audio source is speech:
    - `0`: The audio source is not speech.
    - `1`: (Default) The audio source is speech.
    </Td>
  </Tr>
</Table>


<h3 className="anchor index-class-encodedvideoframeinfo" id="encodedvideoframeinfo">EncodedVideoFrameInfo</h3>

```python
@dataclass(kw_only=True)
class EncodedVideoFrameInfo:
    codec_type: VideoCodecType = VideoCodecType.VIDEO_CODEC_NONE
    width: int = 0
    height: int = 0
    frames_per_second: int = 0
    frame_type: int = 0
    rotation: int = 0
    track_id: int = 0
    capture_time_ms: int = 0
    decode_time_ms: int = 0
    uid: int = 0
    stream_type: int = 0
```

<span className="index-desc-encodedvideoframeinfo">Encoded Video Data.</span>

export const TableHeaderas5dfh00m6 = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeaderas5dfh00m6}>
  <Tr>
    <Td>`codec_type`</Td>
    <Td>Video codec type. See [`VideoCodecType`](#videocodectype) for details.</Td>
  </Tr>
  <Tr>
    <Td>`width`</Td>
    <Td>Width of the video frame (pixels).</Td>
  </Tr>
  <Tr>
    <Td>`height`</Td>
    <Td>Height of the video frame (pixels).</Td>
  </Tr>
  <Tr>
    <Td>`frames_per_second`</Td>
    <Td>Number of video frames per second. Used to calculate the timestamp of the encoded video frame. If set to 0, the SDK uses the real timestamp.</Td>
  </Tr>
  <Tr>
    <Td>`frame_type`</Td>
    <Td>
    Type of the encoded video frame:
    - `0`: Blank frame
    - `3`: Keyframe. For H.264 codec format, the SDK classifies I-frames with SPS and PPS information as keyframes.
    - `4`: Delta frame. For H.264 codec format, the SDK classifies P-frames and I-frames without SPS and PPS information as delta frames.
    - `5`: B-frame
    - `6`: Dropped frame
    - `7`: Unknown
    </Td>
  </Tr>
  <Tr>
    <Td>`rotation`</Td>
    <Td>
    Rotation information of the encoded video frame:
    - `0`: 0 degrees clockwise.
    - `90`: 90 degrees clockwise.
    - `180`: 180 degrees clockwise.
    - `270`: 270 degrees clockwise.
    </Td>
  </Tr>
  <Tr>
    <Td>`track_id`</Td>
    <Td>Track ID of the video frame.</Td>
  </Tr>
  <Tr>
    <Td>`capture_time_ms`</Td>
    <Td>Unix timestamp for capturing the external encoded video frame (milliseconds).</Td>
  </Tr>
  <Tr>
    <Td>`decode_time_ms`</Td>
    <Td>Timestamp for decoding the external encoded video frame (milliseconds).</Td>
  </Tr>
  <Tr>
    <Td>`uid`</Td>
    <Td>User ID.</Td>
  </Tr>
  <Tr>
    <Td>`stream_type`</Td>
    <Td>
    Stream type of the video frame:
    - `0`: High stream. Higher resolution and bitrate.
    - `1`: Low stream. Lower resolution and bitrate.
    </Td>
  </Tr>
</Table>


<h3 className="anchor index-class-externalvideoframe" id="externalvideoframe">ExternalVideoFrame</h3>

```python
@dataclass(kw_only=True)
class ExternalVideoFrame:
    type: int = 1
    format: int = 0
    buffer: bytearray = None
    stride: int = 0
    height: int = 0
    crop_left: int = 0
    crop_top: int = 0
    crop_right: int = 0
    crop_bottom: int = 0
    rotation: int = 0
    timestamp: int = 0
    egl_context: bytearray = None
    egl_type: int = 0
    texture_id: int = 0
    matrix: list = field(default_factory=list)
    metadata: str = ""
    alpha_buffer: bytearray = None
```

<span className="index-desc-externalvideoframe">YUV Format Video Data.</span>

export const TableHeaderoqlbsiebi5 = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeaderoqlbsiebi5}>
  <Tr>
    <Td>`type`</Td>
    <Td>
    Video data type:
    - `1`: Type is raw data.
    - `2`: Type is raw data.
    - `3`: Type is Texture.
    </Td>
  </Tr>
  <Tr>
    <Td>`format`</Td>
    <Td>
    Pixel format:
    - `0`: Raw video pixel format.
    - `1`: I420 format.
    - `4`: RGBA format.
    - `16`: I422 format.
    - `17`: ID3D11TEXTURE2D format. Currently supported types are DXGI_FORMAT_B8G8R8A8_UNORM, DXGI_FORMAT_B8G8R8A8_TYPELESS, and DXGI_FORMAT_NV12.

    Note: The SDK currently does not support the Alpha channel. The incoming Alpha value will be discarded.
    </Td>
  </Tr>
  <Tr>
    <Td>`buffer`</Td>
    <Td>Video buffer.</Td>
  </Tr>
  <Tr>
    <Td>`stride`</Td>
    <Td>The stride of the incoming video frame, in pixels rather than bytes. For Texture, this value refers to the width of the Texture.</Td>
  </Tr>
  <Tr>
    <Td>`height`</Td>
    <Td>Height of the incoming video frame.</Td>
  </Tr>
  <Tr>
    <Td>`crop_left`</Td>
    <Td>Field related to raw data. Specifies the number of pixels cropped from the left. Default is 0. This parameter is only applicable to raw video data.</Td>
  </Tr>
  <Tr>
    <Td>`crop_top`</Td>
    <Td>Field related to raw data. Specifies the number of pixels cropped from the top. Default is 0. This parameter is only applicable to raw video data.</Td>
  </Tr>
  <Tr>
    <Td>`crop_right`</Td>
    <Td>Field related to raw data. Specifies the number of pixels cropped from the right. Default is 0. This parameter is only applicable to raw video data.</Td>
  </Tr>
  <Tr>
    <Td>`crop_bottom`</Td>
    <Td>Field related to raw data. Specifies the number of pixels cropped from the bottom. Default is 0. This parameter is only applicable to raw video data.</Td>
  </Tr>
  <Tr>
    <Td>`rotation`</Td>
    <Td>Field related to raw data. Specifies whether the incoming video frame should be rotated clockwise. Possible values are 0, 90, 180, 270. Default is 0.</Td>
  </Tr>
  <Tr>
    <Td>`timestamp`</Td>
    <Td>Timestamp of the incoming video frame, in milliseconds. Incorrect timestamps can cause frame drops or audio-video desynchronization.</Td>
  </Tr>
  <Tr>
    <Td>`egl_context`</Td>
    <Td>
    This parameter is only applicable to Texture format video data.
    - When using the OpenGL interface defined by Khronos (javax.microedition.khronos.egl.*), set the eglContext to this field.
    - When using the OpenGL interface defined by Android (android.opengl.*), set the eglContext to this field.
    </Td>
  </Tr>
  <Tr>
    <Td>`egl_type`</Td>
    <Td>This parameter is only applicable to Texture format video data. Refers to the Texture ID of the video frame.</Td>
  </Tr>
  <Tr>
    <Td>`texture_id`</Td>
    <Td>This parameter is only applicable to Texture format video data. Refers to an input 4x4 transformation matrix, typically an identity matrix.</Td>
  </Tr>
  <Tr>
    <Td>`matrix`</Td>
    <Td>This parameter is only applicable to Texture format video data. Refers to the data buffer of MetaData, with a default value of `None`.</Td>
  </Tr>
  <Tr>
    <Td>`metadata`</Td>
    <Td>This parameter is only applicable to Texture format video data. Refers to the size of MetaData, with a default value of `0`.</Td>
  </Tr>
  <Tr>
    <Td>`alpha_buffer`</Td>
    <Td>Alpha channel data output by the portrait segmentation algorithm. This data matches the size of the video frame, with each pixel value ranging from [0,255], where 0 represents the background and 255 represents the foreground (portrait). You can set this parameter to render the video background with various effects, such as transparency, solid color, images, or videos.</Td>
  </Tr>
</Table>


<h3 className="anchor index-class-pcmaudioframe" id="pcmaudioframe">PcmAudioFrame</h3>

```python
@dataclass(kw_only=True)
class PcmAudioFrame:
    data: bytearray
    samples_per_channel: int
    bytes_per_sample: int
    number_of_channels: int
    sample_rate: int
    timestamp: int = 0
```

<span className="index-desc-pcmaudioframe">PCM Audio Data.</span>

| Parameter | Description |
|-----------|-------------|
| `data` | PCM audio data to be sent. |
| `timestamp` | Timestamp of the audio data collection (milliseconds). |
| `samples_per_channel` | Number of audio samples collected per channel in 10 milliseconds. |
| `bytes_per_sample` | Number of bytes per sample. |
| `number_of_channels` | Number of channels per sample. |
| `sample_rate` | Sampling rate (Hz). The minimum value is 8000. |


<h3 className="anchor index-class-rtcconnconfig" id="rtcconnconfig">RTCConnConfig</h3>

```python
@dataclass(kw_only=True)
class RTCConnConfig:
    auto_subscribe_audio: int = 0
    auto_subscribe_video: int = 0
    enable_audio_recording_or_playout: int = 0
    max_send_bitrate: int = 0
    min_port: int = 0
    max_port: int = 0
    audio_subs_options: 'AudioSubscriptionOptions' = AudioSubscriptionOptions()
    client_role_type: ClientRoleType = ClientRoleType.CLIENT_ROLE_BROADCASTER
    channel_profile: ChannelProfileType = ChannelProfileType.CHANNEL_PROFILE_LIVE_BROADCASTING
    audio_recv_media_packet: int = 0
    audio_recv_encoded_frame: int = 0
    video_recv_media_packet: int = 0
```

<span className="index-desc-rtcconnconfig">RTC Connection Configuration.</span>

export const TableHeader3aln69x78b = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeader3aln69x78b}>
  <Tr>
    <Td>`auto_subscribe_audio`</Td>
    <Td>
    Whether to automatically subscribe to all audio tracks.
    - `0`: Do not automatically subscribe to all audio tracks.
    - `1`: (Default) Automatically subscribe to all audio tracks.
    </Td>
  </Tr>
  <Tr>
    <Td>`auto_subscribe_video`</Td>
    <Td>
    Whether to automatically subscribe to all video tracks.
    - `0`: Do not automatically subscribe to all video tracks.
    - `1`: (Default) Automatically subscribe to all video tracks.
    </Td>
  </Tr>
  <Tr>
    <Td>`enable_audio_recording_or_playout`</Td>
    <Td>
    Whether to enable audio recording or playout.
    - `0`: Disable audio recording or playout.
    - `1`: Enable audio recording or playout.
    </Td>
  </Tr>
  <Tr>
    <Td>`max_send_bitrate`</Td>
    <Td>Maximum send bitrate.</Td>
  </Tr>
  <Tr>
    <Td>`min_port`</Td>
    <Td>Minimum port.</Td>
  </Tr>
  <Tr>
    <Td>`max_port`</Td>
    <Td>Maximum port.</Td>
  </Tr>
  <Tr>
    <Td>`audio_subs_options`</Td>
    <Td>Audio subscription options. See [`AudioSubscriptionOptions`](#audiosubscriptionoptions) for details.</Td>
  </Tr>
  <Tr>
    <Td>`client_role_type`</Td>
    <Td>User role. See [`ClientRoleType`](#clientroletype) for details.</Td>
  </Tr>
  <Tr>
    <Td>`channel_profile`</Td>
    <Td>Channel profile. See [`ChannelProfileType`](#channelprofiletype) for details.</Td>
  </Tr>
  <Tr>
    <Td>`audio_recv_media_packet`</Td>
    <Td>
    Whether to receive audio media packets.
    - `0`: Do not receive.
    - `1`: Receive.
    </Td>
  </Tr>
  <Tr>
    <Td>`video_recv_media_packet`</Td>
    <Td>
    Whether to receive video media packets.
    - `0`: Do not receive.
    - `1`: Receive.
    </Td>
  </Tr>
</Table>


<h3 className="anchor index-class-rtcconninfo" id="rtcconninfo">RTCConnInfo</h3>

```python
@dataclass(frozen=True, kw_only=True)
class RTCConnInfo():
    id: int
    channel_id: str
    state: int
    local_user_id: str
```

<span className="index-desc-rtcconninfo">RTC Connection Information.</span>

export const TableHeaderfj4a2lhgd0 = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeaderfj4a2lhgd0}>
  <Tr>
    <Td>`id`</Td>
    <Td>ID of the RTC connection.</Td>
  </Tr>
  <Tr>
    <Td>`channel_id`</Td>
    <Td>RTC channel ID. If you have not called the [`connect`](#connect) method, this parameter returns `None`.</Td>
  </Tr>
  <Tr>
    <Td>`state`</Td>
    <Td>
    Connection state:
    - `1`: Network connection disconnected.
    - `2`: Establishing network connection.
    - `3`: Network connected.
    - `4`: Re-establishing network connection.
    - `5`: Network connection failed.
    </Td>
  </Tr>
  <Tr>
    <Td>`local_user_id`</Td>
    <Td>Local user ID.</Td>
  </Tr>
</Table>



<h3 className="anchor index-class-senderoptions" id="senderoptions">SenderOptions</h3>

```python
@dataclass(kw_only=True)
class SenderOptions:
    target_bitrate: int
    cc_mode: TCcMode = TCcMode.CC_ENABLED
    codec_type: VideoCodecType = VideoCodecType.VIDEO_CODEC_NONE
```

<span className="index-desc-senderoptions">Configuration of the local video track object that includes the video source for sending encoded video data.</span>

export const TableHeaderojvg3y99d3 = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeaderojvg3y99d3}>
  <Tr>
    <Td>`target_bitrate`</Td>
    <Td>The target encoding bitrate (Kbps) of the current encoder, which is an estimated value by the SDK based on the current network conditions.</Td>
  </Tr>
  <Tr>
    <Td>`cc_mode`</Td>
    <Td>Congestion control mode. See [`TCcMode`](#tccmode) for details.</Td>
  </Tr>
  <Tr>
    <Td>`codec_type`</Td>
    <Td>Video codec type. See [`VideoCodecType`](#videocodectype) for details.</Td>
  </Tr>
</Table>


<h3 className="anchor index-class-videodimensions" id="videodimensions">VideoDimensions</h3>

```python
@dataclass(kw_only=True)
class VideoDimensions:
    width: int
    height: int
```

<span className="index-desc-videodimensions">Resolution of the video encoding.</span>

export const TableHeaderojvg3y99d4 = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeaderojvg3y99d4}>
  <Tr>
    <Td>`width`</Td>
    <Td>Width of the video frame (pixels).</Td>
  </Tr>
  <Tr>
    <Td>`height`</Td>
    <Td>Height of the video frame (pixels).</Td>
  </Tr>
</Table>


<h3 className="anchor index-class-videoencoderconfig" id="videoencoderconfig">VideoEncoderConfiguration</h3>

```python
@dataclass(kw_only=True)
class VideoEncoderConfiguration:
    dimensions: VideoDimensions
    codec_type: VideoCodecType = VideoCodecType.VIDEO_CODEC_NONE
    frame_rate: int = 15
    bitrate: int = 0
    min_bitrate: int = 0
    orientation_mode: int = 0
    degradation_preference: int = 0
    mirror_mode: int = 0
```

<span className="index-desc-videoencoderconfiguration">Video encoding properties.</span>

export const TableHeaderx51harpo7p = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeaderx51harpo7p}>
  <Tr>
    <Td>`codec_type`</Td>
    <Td>Video codec type. See [`VideoCodecType`](#videocodectype) for details.</Td>
  </Tr>
  <Tr>
    <Td>`dimensions`</Td>
    <Td>Resolution of the video encoding (px). This parameter measures the encoding quality, represented as width × height. The default value is 640 × 360. Users can set the resolution as needed. See [`VideoDimensions`](#videodimensions) for details.</Td>
  </Tr>
  <Tr>
    <Td>`frame_rate`</Td>
    <Td>Frame rate of the video encoding (fps), default is 15.</Td>
  </Tr>
  <Tr>
    <Td>`bitrate`</Td>
    <Td>
    Video encoding bitrate, in Kbps.
    - `0`: (Recommended) Standard bitrate mode. In this mode, the video bitrate is twice the base bitrate.
    - `-1`: Adapted bitrate mode. In this mode, the video bitrate is the same as the base bitrate. When this mode is selected for live streaming, the video frame rate may be lower than the set value.
    </Td>
  </Tr>
  <Tr>
    <Td>`min_bitrate`</Td>
    <Td>
    Minimum encoding bitrate, in Kbps. The SDK will automatically adjust the video encoding bitrate based on network conditions. Setting this parameter higher than the default value can force the video encoder to output higher quality images, but may cause packet loss and affect video playback fluency under poor network conditions, leading to stuttering. Therefore, unless there are special requirements for image quality, it is recommended not to modify this parameter.

    Note: This parameter is only applicable in live streaming scenarios.
    </Td>
  </Tr>
  <Tr>
    <Td>`orientation_mode`</Td>
    <Td>
    Orientation mode of the video encoding:
    - `0`: (Default) In this mode, the SDK outputs the video orientation consistent with the captured video. The receiver will rotate the video based on the received video rotation information. This mode is suitable for scenarios where the receiver can adjust the video orientation. If the captured video is in landscape mode, the output video will also be in landscape mode. If the captured video is in portrait mode, the output video will also be in portrait mode.
    - `1`: In this mode, the SDK outputs the video in landscape mode. If the captured video is in portrait mode, the video encoder will crop it. This mode is suitable for scenarios where the receiver cannot adjust the video orientation, such as direct push to CDN.
    - `2`: In this mode, the SDK outputs the video in portrait mode. If the captured video is in landscape mode, the video encoder will crop it. This mode is suitable for scenarios where the receiver cannot adjust the video orientation, such as direct push to CDN.
    </Td>
  </Tr>
  <Tr>
    <Td>`degradation_preference`</Td>
    <Td>
    Video encoding degradation preference when bandwidth is limited:
    - `0`: (Default) When bandwidth is limited, the video encoding prioritizes reducing the frame rate while maintaining video quality. This degradation preference is suitable for scenarios where image quality is prioritized.
    - `1`: When bandwidth is limited, the video encoding prioritizes reducing video quality while maintaining the frame rate. This degradation preference is suitable for scenarios where smoothness is prioritized and quality reduction is acceptable.
    - `2`: When bandwidth is limited, the video encoding reduces both frame rate and video quality. The reduction in `2` is less than in `0` and `1`, suitable for scenarios with limited smoothness and quality.
    - `3`: When bandwidth is limited, the video encoding prioritizes reducing the frame rate.
    </Td>
  </Tr>
  <Tr>
    <Td>`mirror_mode`</Td>
    <Td>
    Whether to enable mirror mode when sending encoded video, only affecting the video seen by the remote user.
    - `0`: (Default) The mirror mode is determined by the SDK.
    - `1`: Enable mirror mode.
    - `2`: Disable mirror mode.
    </Td>
  </Tr>
</Table>


<h3 className="anchor index-class-videoframe" id="videoframe">VideoFrame</h3>

```python
@dataclass(kw_only=True)
class VideoFrame():
    type: int = 0
    width: int = 0
    height: int = 0
    y_stride: int = 0
    u_stride: int = 0
    v_stride: int = 0
    y_buffer: bytearray = None
    u_buffer: bytearray = None
    v_buffer: bytearray = None
    rotation: int = 0
    render_time_ms: int = 0
    avsync_type: int = 0
```

<span className="index-desc-videoframe">Properties of the video frame. The video data format is YUV420. The buffer is given as a pointer to a pointer. This interface cannot modify the pointer of the buffer, only the content of the buffer.</span>

export const TableHeaderynqkth9hqh = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeaderynqkth9hqh}>
  <Tr>
    <Td>`type`</Td>
    <Td>
    Type of video data:
    - `1`: Raw data.
    - `2`: Raw data.
    - `3`: Texture.
    </Td>
  </Tr>
  <Tr>
    <Td>`width`</Td>
    <Td>Width of the video frame (pixels).</Td>
  </Tr>
  <Tr>
    <Td>`height`</Td>
    <Td>Height of the video frame (pixels).</Td>
  </Tr>
  <Tr>
    <Td>`y_stride`</Td>
    <Td>Stride of the Y buffer in the YUV data.</Td>
  </Tr>
  <Tr>
    <Td>`u_stride`</Td>
    <Td>Stride of the U buffer in the YUV data.</Td>
  </Tr>
  <Tr>
    <Td>`v_stride`</Td>
    <Td>Stride of the V buffer in the YUV data.</Td>
  </Tr>
  <Tr>
    <Td>`y_buffer`</Td>
    <Td>Pointer to the pointer of the Y buffer in the YUV data.</Td>
  </Tr>
  <Tr>
    <Td>`u_buffer`</Td>
    <Td>Pointer to the pointer of the U buffer in the YUV data.</Td>
  </Tr>
  <Tr>
    <Td>`v_buffer`</Td>
    <Td>Pointer to the pointer of the V buffer in the YUV data.</Td>
  </Tr>
  <Tr>
    <Td>`rotation`</Td>
    <Td>Clockwise rotation angle of the frame before rendering the video. Currently supports 0 degrees, 90 degrees, 180 degrees, and 270 degrees.</Td>
  </Tr>
  <Tr>
    <Td>`render_time_ms`</Td>
    <Td>Timestamp of the external audio frame. This parameter is mandatory. You can use this timestamp to restore the order of audio frames; in scenarios with video (including those using external video sources), this parameter can help achieve audio-video synchronization.</Td>
  </Tr>
  <Tr>
    <Td>`avsync_type`</Td>
    <Td>Reserved parameter.</Td>
  </Tr>
</Table>


<h3 className="anchor index-class-videosubscriptionoptions" id="videosubscriptionoptions">VideoSubscriptionOptions</h3>

```python
@dataclass(kw_only=True)
class VideoSubscriptionOptions:
    type: VideoStreamType = VideoStreamType.VIDEO_STREAM_HIGH
    encodedFrameOnly: bool = False
```

<span className="index-desc-videosubscriptionoptions">Video subscription options.</span>

export const TableHeaderpxfa2c828w = [
  {
    label: 'Parameter'
  },
  {
    label: 'Description'
  }
];

<Table header={TableHeaderpxfa2c828w}>
  <Tr>
    <Td>`type`</Td>
    <Td>Type of video to subscribe to. See [`VideoStreamType`](#videostreamtype) for details.</Td>
  </Tr>
  <Tr>
    <Td>`encodedFrameOnly`</Td>
    <Td>
    Whether to subscribe only to encoded video data:
    - `0`: (Default) Subscribe only to decoded video data.
    - `1`: Subscribe only to encoded video data.
    </Td>
  </Tr>
</Table>


## Enum

<h3 className="anchor index-enum-areacode" id="areacode">AreaCode</h3>

<span className="index-desc-areacode">Server access regions. This feature is an advanced setting and is used in scenarios with access security restrictions. The region code supports bitwise operations. After specifying the access region, the SDK will connect to the Agora servers within the specified region.</span>

| Enumeration | Description |
|-------------|-------------|
| `AREA_CODE_CN` | `0x00000001`: Mainland China. |
| `AREA_CODE_NA` | `0x00000002`: North America. |
| `AREA_CODE_EU` | `0x00000004`: Europe. |
| `AREA_CODE_AS` | `0x00000008`: Asia (excluding Mainland China). |
| `AREA_CODE_JP` | `0x00000010`: Japan. |
| `AREA_CODE_IN` | `0x00000020`: India. |
| `AREA_CODE_GLOB` | `0xFFFFFFFF`: (Default) Global. |

<h3 className="anchor index-enum-audiocodectype" id="audiocodectype">AudioCodecType</h3>

<span className="index-desc-audiocodectype">Audio codec types.</span>

| Enumeration | Description |
|-------------|-------------|
| `AUDIO_CODEC_OPUS` | `1`: OPUS |
| `AUDIO_CODEC_PCMA` | `3`: PCMA |
| `AUDIO_CODEC_PCMU` | `4`: PCMU |
| `AUDIO_CODEC_G722` | `5`: G722 |
| `AUDIO_CODEC_AACLC` | `8`: AAC LC |
| `AUDIO_CODEC_HEAAC` | `9`: HE AAC |
| `AUDIO_CODEC_HEAAC2` | `11`: HEAAC2 |

<h3 className="anchor index-enum-audioprofiletype" id="audioprofiletype">AudioProfileType</h3>

<span className="index-desc-audioprofiletype">Audio profiles.</span>

| Enumeration | Description |
|-------------|-------------|
| `AUDIO_PROFILE_DEFAULT` | `0`: Default audio profile.<ul><li>In communication scenarios: 16 kHz sampling rate, voice codec, mono, maximum encoding bitrate of 16 Kbps.</li><li>In live broadcast scenarios: 48 kHz sampling rate, music codec, mono, maximum encoding bitrate of 64 Kbps.</li></ul> |
| `AUDIO_PROFILE_SPEECH_STANDARD` | `1`: Specifies a 32 kHz sampling rate, voice codec, mono, maximum encoding bitrate of 18 Kbps. |
| `AUDIO_PROFILE_MUSIC_STANDARD` | `2`: Specifies a 48 kHz sampling rate, music codec, mono, maximum encoding bitrate of 64 Kbps. |
| `AUDIO_PROFILE_MUSIC_STANDARD_STEREO` | `3`: Specifies a 48 kHz sampling rate, music codec, stereo, maximum encoding bitrate of 80 Kbps. |
| `AUDIO_PROFILE_MUSIC_HIGH_QUALITY` | `4`: Specifies a 48 kHz sampling rate, music codec, mono, maximum encoding bitrate of 96 Kbps. |
| `AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO` | `5`: Specifies a 48 kHz sampling rate, music codec, stereo, maximum encoding bitrate of 128 Kbps. |
| `AUDIO_PROFILE_IOT` | `6`: Specifies a 16 kHz sampling rate, voice codec, mono, with echo cancellation algorithm AES. |
| `AUDIO_PROFILE_NUM` | `7`: Enumeration boundary. |

<h3 className="anchor index-enum-audioscenariotype" id="audioscenariotype">AudioScenarioType</h3>

<span className="index-desc-audioscenariotype">Audio scenario types.</span>

| Enumeration | Description |
|-------------|-------------|
| `AUDIO_SCENARIO_DEFAULT` | `0`: (Default) Automatic scenario, automatically matches the appropriate audio quality based on user role and audio routing. |
| `AUDIO_SCENARIO_GAME_STREAMING` | `3`: High-quality scenario, suitable for music-centric scenarios. |
| `AUDIO_SCENARIO_CHATROOM` | `5`: Chatroom scenario, suitable for scenarios where users frequently switch between speaking and listening. In this scenario, audience members will receive a prompt to request microphone permission. |
| `AUDIO_SCENARIO_CHORUS` | `7`: Chorus scenario, suitable for real-time chorus with extremely low latency under good network conditions. |
| `AUDIO_SCENARIO_MEETING` | `8`: Meeting scenario, suitable for multi-person meetings focused on voice. |
| `AUDIO_SCENARIO_NUM` | `9`: Enumeration boundary. |

<h3 className="anchor index-enum-channelprofiletype" id="channelprofiletype">ChannelProfileType</h3>

<span className="index-desc-channelprofiletype">Channel usage scenarios.</span>

| Enumeration | Description |
|-------------|-------------|
| `CHANNEL_PROFILE_COMMUNICATION` | `0`: (Default) Communication scenario. Recommended for channels with only two users. |
| `CHANNEL_PROFILE_LIVE_BROADCASTING` | `1`: Live broadcasting scenario. This scenario has two user roles: host and audience. Hosts can publish and receive audio and video streams, while the audience can only receive streams. Suitable for voice chat rooms, video live broadcasts, interactive large classes, etc. |

<h3 className="anchor index-enum-clientroletype" id="clientroletype">ClientRoleType</h3>

<span className="index-desc-clientroletype">User roles.</span>

| Enumeration | Description |
|-------------|-------------|
| `CLIENT_ROLE_BROADCASTER` | `1`: Broadcaster. Broadcasters can both send and receive media streams. |
| `CLIENT_ROLE_AUDIENCE` | `2`: Audience. Audience can only receive media streams. |

<h3 className="anchor index-enum-tccmode" id="tccmode">TCcMode</h3>

<span className="index-desc-tccmode">Congestion control modes.</span>

| Enumeration | Description |
|-------------|-------------|
| `CC_ENABLED` | `0`: Enable congestion control mode. |
| `CC_DISABLED` | `1`: Disable congestion control mode. |

<h3 className="anchor index-enum-videocodectype" id="videocodectype">VideoCodecType</h3>

<span className="index-desc-videocodectype">Video codec types.</span>

| Enumeration | Description |
|-------------|-------------|
| `VIDEO_CODEC_NONE` | `0`: None |
| `VIDEO_CODEC_VP8` | `1`: VP8 |
| `VIDEO_CODEC_H264` | `2`: H.264 |
| `VIDEO_CODEC_H265` | `3`: H.265 |
| `VIDEO_CODEC_GENERIC` | `6`: Generic |
| `VIDEO_CODEC_GENERIC_H264` | `7`: Generic H264 |
| `VIDEO_CODEC_AV1` | `12`: AV1 |
| `VIDEO_CODEC_VP9` | `13`: VP9 |
| `VIDEO_CODEC_GENERIC_JPEG` | `20`: JPEG |

<h3 className="anchor index-enum-videostreamtype" id="videostreamtype">VideoStreamType</h3>

<span className="index-desc-videostreamtype">Video stream types.</span>

| Enumeration | Description |
|-------------|-------------|
| `VIDEO_STREAM_HIGH` | `0`: (Default) High stream. Higher resolution and bitrate. |
| `VIDEO_STREAM_LOW` | `1`: Low stream. Lower resolution and bitrate. |
