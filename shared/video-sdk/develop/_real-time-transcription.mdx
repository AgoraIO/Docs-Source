import * as data from '@site/data/variables';
import Prerequites from '@docs/shared/common/prerequities.mdx';
import ProjectSetup from '@docs/shared/video-sdk/develop/real-time-transcription/project-setup/index.mdx';
import ProjectImplement from '@docs/shared/video-sdk/develop/real-time-transcription/project-implementation/index.mdx';
import ProjectTest from '@docs/shared/video-sdk/develop/real-time-transcription/project-test/index.mdx';
import Reference from '@docs/shared/video-sdk/develop/real-time-transcription/reference/index.mdx';

<Vg k="RTT" /> takes the audio content of a host's media stream and transcribes it into written words in real time.
This page shows you how to start and stop <Vg k="RTT" /> in your <Vpl k="CLIENT" />, through a business server, then
display the text in your <Vpl k="CLIENT" />.

## Understand the tech

To start transcribing the audio in a channel in real time, you send an `HTTP` request to the <Vg k="AGORA_BACKEND" />
through your business server. <Vg k="RTT" /> provides the following modes:

* Transcribe speech in real-time, then stream this data to the channel.
* Transcribe speech in real-time, store the text in the `WebVTT` format, and upload the file to third-party cloud
storage.

<Vg k="RTT" /> transcribes at most three speakers in a channel. When there are more than three speakers, the top three are selected based on volume, and their audio is transcribed.

The following figure shows the workflow to start, query, and stop a <Vg k="RTT" /> task:

![Real-Time Transcription business server](/images/video-sdk/real-time-transcription-server.svg)

In order to use the RESTful API to transcribe speech, make the following calls:

1. `acquire`: Request a `builderToken` that authenticates the user and gives permission to start <Vg k="RTT" /> . You must call
`start` using this `builderToken` within five minutes.
1. `start`: Begin the transcription task. Once you start a task, `builderToken` remains valid for the entire
session. Use the same `builderToken` to query and stop the task.
1. `query`: Check the task status.
1. `stop`: Stop the transcription task.

## Prerequisites

In order to set up <Vg k="RTT" /> in your <Vpl k="CLIENT" />, you must have:

* Enabled <Vg k="RTT" /> for your project:

    Contact sales@agora.io.
* Activated a [supported cloud storage service](#supported-third-party-cloud-storage-services) to record and store <Vg k="RTT" /> videos and texts
* Installed the [Protobuf package](https://protobuf.dev/downloads) to generate code classes for displaying transcription text.
* To run the post-processing script, install:
  * Python 3.0
  * [`ffmpeg`](https://ffmpeg.org/download.html) and `ffplay`

## Implement a business server

You create a business server as a bridge between your <Vpl k="CLIENT" /> and <Vg k="COMPANY"/> <Vg k="RTT" />.
Implementing a business server to manage <Vg k="RTT" /> provides the following benefits:

* Improved security as your `apiKey`, `apiSecret`, `builderToken`, and `taskId`, are not exposed to the client.
* Token processing is securely handled on the business server.
* Avoid splicing complex request body strings on the client side to reduce the probability of errors.
* Implement additional functionality on the business server. For example, billing for  <Vg k="RTT" /> use, checking
user privileges and payment status of a user.
* If the REST API is updated, you do not need to update the client.

Agora <Vg k="RTT" /> supports only integer `uid`s.

- When you join a channel in your app, use an integer value for your UID. For example, `7`.
- When you [start a <Vg k="RTT" /> session](https://documenter.getpostman.com/view/6319646/SVSLr9AM#92041cab-1f45-4ff3-83a5-601fa06a0427) set `uid` to the same integer UID enclosed in quotation marks. For example, `"7"`.

To obtain sample code for your business server, see the:

* [Real-Time Transcription business server demo](https://github.com/AgoraIO/agora-rtt-server) - an example business
server that follows the workflow described in this document
* [Postman Collection](https://documenter.getpostman.com/view/6319646/SVSLr9AM#69bd200a-7543-4104-8ccc-415741abbeb7) - API reference and code examples for the language
you want to program in.


## Use Google Protobuf Generator to parse text data

Google Protocol buffers are an extensible and language-neutral mechanism for serializing transcription data.
Protobuf enables you to generate source code in multiple languages, based on a specified structure. For more information about Google protocol buffers, see [protobuf.dev](https://protobuf.dev/).

<Vg k="COMPANY"/> provides the following Protobuf template for parsing <Vg k="RTT" /> data:

```
syntax = "proto3";

package agora.audio2text;
option java_package = "io.agora.rtc.audio2text";
option java_outer_classname = "Audio2TextProtobuffer";

message Text {
  int32 vendor = 1;
  int32 version = 2;
  int32 seqnum = 3;
  int32 uid = 4;
  int32 flag = 5;
  int64 time = 6;
  int32 lang = 7;
  int32 starttime = 8;
  int32 offtime = 9;
  repeated Word words = 10;
}
message Word {
  string text = 1;
  int32 start_ms = 2;
  int32 duration_ms = 3;
  bool is_final = 4;
  double confidence = 5;
}
```

To read and display the <Vg k="RTT" /> text in your client:

1. Copy the Protobuf template to a local `.proto` file.

1. In your file, edit the following properties to match your project:

    *	`package` : The source code package namespace.
    *	`option` : The desired language [options](https://protobuf.dev/programming-guides/proto3/#options). 

1. Generate a Protobuf class.

    You run the `protoc` protocol compiler on your `.proto` file to [generate the code]((https://protobuf.dev/programming-guides/proto3/#generating)) that you need to work with the defined message types. The `protoc` compiler is invoked as follows:

    ```
    protoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR --java_out=DST_DIR --python_out=DST_DIR --go_out=DST_DIR --ruby_out=DST_DIR --objc_out=DST_DIR --csharp_out=DST_DIR path/to/file.proto
    ```

    <Vg k="COMPANY"/> also provides Protobuf sample code to parse and display transcription text. To obtain the sample code, contact sales@agora.io

1. Use the Protobuf class to read transcription text.

    When transcription text is available, your <Vpl k="CLIENT" /> receives the `onStreamMessage` callback. You use the generated Protobuf class in you <Vpl k="CLIENT" /> to read the byte data returned by the callback. Refer to the [API reference](#api-reference) for callback details.

## Synchronize transcription files with the cloud recording

The `m3u8+vtt` file generated by <Vg k="RTT" />, and the `m3u8+ts` file generated by [Cloud Recording](../../../cloud-recording/overview/product-overview.mdx) are two independent files. The time stamp references in these media
files are different, and not synchronized. The cloud recording time stamp starts at `0`, while the `m3u8+vtt` uses the system time stamp. If either process starts abnormally, the media files generated by the two services may be out of sync during playback.

Post-processing ensures synchronization of subtitles and recorded audio. It enables you to associate the `m3u8+ts` file generated by cloud recording with the `m3u8+vtt` file generated by <Vg k="RTT" />.

<Vg k="COMPANY" /> provides a post-processing script that enables you to synchronize the two files.

#### Run the post-processing script

To synchronize files generated by <Vg k="RTT" />, take the following steps:

1. Unzip the [post-processing script](https://github.com/AgoraIO/Docs-Source/files/10931258/add_webvtt.zip) to a local folder.

1. Run the script on your <Vg k="RTT" /> files:

    ```shell
     python3 insert_subtitle.py --av audio_dir/audio_ts.m3u8 --subtitle subtitle_dir/subtitle.m3u8 --output output_dir/ --overwrite
     ```

     If `ffmpeg/ffprob` are not in your `PATH`, use`â€“ffmpeg_path` to specify the path.

1. Play the synchronized files:

    1. Start the HTTP server by running the following command:

       ```shell
       python3 -m http.server --bind 127.0.0.1 -doutput_dir
       ```

    1. In your browser, enter the following URL:

       ```
       http://127.0.0.1:8000/player_demo.html
       ```

## Reference

This section contains information that completes the information in this page, or points you to documentation that explains other aspects to this product.

### REST API

Refer to the <Vg k="RTT" /> [REST API documentation](/en/api-reference?platform=rest) for parameter details.

### SDK API

<Reference />

### List of supported languages

Use the following language codes in the `recognizeConfig.language` parameter of the start request. The current version supports at most two languages, separated by commas. 

| Language                         | Code  | 
| -------------------------------- | ----- |
| Chinese (Cantonese, Traditional) | zh-HK |
| Chinese (Mandarin, Simplified)   | zh-CN |
| Chinese (Taiwanese Putonghua)    | zh-TW |
| English (India)                  | en-IN |
| English (US)                     | en-US |
| French (French)                  | fr-FR |
| German (Germany)                 | de-DE |
| Hindi (India)                    | hi-IN |
| Indonesian (Indonesia)           | id-ID |
| Italian (Italy)                  | it-IT |
| Japanese (Japan)                 | ja-JP |
| Korean (South Korea)             | ko-KR |
| Portuguese (Portugal)            | pt-PT |
| Spanish (Spain)                  | es-ES |

### Supported third-party cloud storage services

The following third-party cloud storage service providers are supported:

* [Alibaba Cloud](https://www.alibabacloud.com/product/oss)
* [Amazon S3](https://aws.amazon.com/s3/?nc1=h_ls)
* [Baidu AI Cloud](https://intl.cloud.baidu.com/product/bos.html)
* [Google Cloud](https://cloud.google.com/storage)
* [Huawei Cloud](https://www.huaweicloud.com/intl/en-us/product/obs.html)
* [Kingsoft Cloud](https://en.ksyun.com/nv/product/KS3.html)
* [Microsoft Azure](https://azure.microsoft.com/en-us/services/storage/blobs/)
* [Qiniu Cloud](https://www.qiniu.com/en/products/kodo)
* [Tencent Cloud](https://intl.cloud.tencent.com/product/cos)
