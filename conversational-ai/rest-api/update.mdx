---
title: 'Update agent configuration'
sidebar_position: 3
type: docs
platform_selector: false
description: >
  Adjust agent parameters at runtime.
---

import CodeBlock from '@theme/CodeBlock';
import MultiCodeBlock, { CodeGroup, CodeItem } from '@app/mdx-components/MultiCodeBlock';

Use this endpoint to adjust <Vpd k="NAME" /> instance parameters at runtime.

### API Endpoint

- Method: `POST`
- Endpoint: `https://api.agora.io/api/conversational-ai-agent/v1/projects/{appid}/agents/{agentId}/update`

### Path parameters

| Parameter   | Type | Required | Description   |
|:--------|:---------|:----|:--------------|
| `appid` | string | Yes | The App ID of the project|
| `agentId` | string | Yes | The agent instance ID you obtained after successfully calling `join` to start the conversational agent. |

### Request body parameters
The request body must be a JSON object containing the following parameters:

| Parameter | Type    | Required | Description   |
|:----------------------|:-------------|:--------------|:--------|
| `token`   | string| Yes   | The authentication token for the channel.   |
| `tts` | object | Optional | Text-to-speech (TTS) module configuration. |
| ⇒`voice_id` | integer | Optional | Voice ID, see the [supported tones list]((../rest-api/reference#voice-id)) for details. Default value `en-US-AndrewMultilingualNeural`| 
| `custom_llm` | object  | Optional| Custom large language model configuration.    |
| ⇒`url` | string | Yes | Custom LLM callback address..   |
| ⇒`token` | string | Optional | Custom LLM verification token. It is empty by default. Best practice is to enable the token in a production environment.  |
| ⇒`prompt` | string | Optional   | A prompt that the custom LLM supports; will be passed in as a system message. |
| ⇒`model` | string | Optional    | Model ID that may be required by a custom LLM. |
| ⇒`max_tokens` | integer | Optional | The maximum number of completion tokens that a custom LLM may require. Default value `1024` |
| ⇒`max_history` | integer | Optional | The number of short-term memory entries cached in the custom LLM. `0` means no short-term memory is cached. User and assistant log entries separately. Default value `10`  |
| ⇒`greeting` | string | Optional | Agent greeting. If provided, the first RTC user in the channel is automatically greeted when joining.  |
| ⇒`failure_message` | string | Optional | Prompt for agent activation failure. If provided, it is returned through TTS when the custom LLM call fails. |
| ⇒`extra_metadata` | object | Optional | The context information carried by the agent. If provided, it is passed to the server through  `metadata` parameters every time a custom LLM is requested. <Admonition type="info">Third-party large model services do not support this parameter and it is only applicable to self-built scenarios.</Admonition>  |
| ⇒`metadata_enabled` | boolean | Optional | Whether to carry context: <li>`true`: Carry</li> <li>`false`: (Default) Do not carry</li>  |
|⇒`vad` | object   | Optional | Voice activity detection (VAD) configuration. |
| ⇒`interrupt_threshold` | number  | Optional | Interrupt sensitivity, the value range is (0.0 - 1.0]. The larger the value, the higher the sensitivity. Default value `0.8` |
| ⇒`prefix_padding_ms` | integer | Optional | Padding duration (ms) at the beginning of audio recognition. Default value `300` |
| ⇒`silence_duration_ms` | integer | Optional | Audio silence duration (ms). Default value `500` |
| ⇒`threshold` | number  | Optional | VAD recognition sensitivity. Default value `0.5` |

### Request examples

Use one of the following request examples as a starting point:

<MultiCodeBlock caption="Sample request:">
<CodeGroup label="Select">
<CodeItem language="bash" name="curl">{`curl --request post \\
  --url https://api.agora.io/api/conversational-ai-agent/v1/projects/:appid/agents/:agentId/update`}</CodeItem>

  <CodeItem language="python" name="Python">{`import requests\n
url = "https://api.agora.io/api/conversational-ai-agent/v1/projects/:appid/agents/:agentId/update"\n
response = requests.request("post", url)\n
print(response.text)`}</CodeItem>

  <CodeItem language="js" name="Node.js">{`const url = 'const url = 'https://api.agora.io/api/conversational-ai-agent/v1/projects/:appid/agents/:agentId/update';
const options = {method: 'post'};\n
fetch(url, options)
  .then(res => res.json())
  .then(json => console.log(json))
  .catch(err => console.error(err));`}</CodeItem>

</CodeGroup>
</MultiCodeBlock>

### Response

- If the returned status code is `200`, the request was successful. The response body contains the result of the request.

- If the returned status code is not `200`, the request failed. The response body includes the error code and description. Refer to [status codes](../rest-api/reference#response-status-codes) to understand the possible reasons for failure.