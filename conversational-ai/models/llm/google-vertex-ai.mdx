---
title: Google Vertex AI
sidebar_position: 4
platform_selector: false
description: >
  Integrate Google Vertex AI into Conversational AI 
---

Google Vertex AI provides enterprise-grade access to Google's generative AI models with enhanced security, scaling capabilities, and integration with Google Cloud services.

### Sample configuration

The following example shows a starting `llm` parameter configuration you can use when you [Start a conversational AI agent](../../rest-api/join).

```json
"llm": {
   "url": "https://{region}-aiplatform.googleapis.com/v1/projects/{project}/locations/{region}/publishers/google/models/{model}:{resource}",
   "api_key": "$(gcloud auth print-access-token)",
   "system_messages": [
       {
           "role": "user",
           "parts": [ {"text": "You are a helpful chatbot."} ]
       }
   ],
   "max_history": 32,
   "greeting_message": "Good to see you!",
   "failure_message": "Hold on a second.",
   "params": {
       "model": "gemini-2.0-flash-001"
   },
   "style": "gemini"
}
```

### Key parameters

- `api_key`: Refer to Google Cloud [REST authentication](https://cloud.google.com/docs/authentication/rest) to get your GCP credentials.
- `url`: Use the Vertex AI endpoint with your Google Cloud project ID and region in the URL path. Refer to [Google Vertex AI API documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations) for details.
- `model`: Refer to [Vertex AI models](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models) for available models.
- `system_messages`: Use `parts` array with `text` objects instead of simple `content` string.
- `style`: Set to `"gemini"` to use Gemini's message format.

For advanced configuration options, model capabilities, and detailed parameter descriptions, see the [Google Vertex AI API documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instructions).