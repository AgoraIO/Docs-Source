---
title: Azure OpenAI
sidebar_position: 3
platform_selector: false
description: >
  Integrate an Azure OpenAI LLM into Conversational AI Engine.
---

Azure OpenAI service provides REST API access to OpenAI's powerful language models through Microsoft Azure's secure infrastructure.

### Sample configuration

The following example shows a starting `llm` parameter configuration you can use when you [Start a conversational AI agent](/conversational-ai/rest-api/agent/join).

```json
"llm": {
    "url": "https://YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/chat/completions?api-version=AZURE_API_VERSION",
    "api_key": "<api_key>",
    "system_messages": [
        {
            "role": "system",
            "content": "You are a helpful chatbot."
        }
    ],
    "max_history": 32,
    "greeting_message": "Hello, how can I assist you today?",
    "failure_message": "Please hold on a second.",
    "style": "openai",
    "params": {
        "model": "gpt-4o-mini"
    }
}
```

### Key parameters

<ParameterList title="llm" required={true}>
  <Parameter name="api_key" type="string" required={true}>  
  Find your API key in the Azure portal under your OpenAI resource.
  </Parameter>
  <Parameter name="url" type="string" required={true}>  
  Replace `YOUR_RESOURCE_NAME` with your Azure resource name and `YOUR_DEPLOYMENT_NAME` with your model deployment name.
  </Parameter>
  <Parameter name="params" type="object" required={true}>  
    <Parameter name="model" type="string" required={true}>  
    Use the deployment name you created in Azure, not the base model name.
    </Parameter>
  </Parameter>
</ParameterList>

For advanced configuration options, deployment setup, and detailed parameter descriptions, see the [Azure OpenAI API documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference).