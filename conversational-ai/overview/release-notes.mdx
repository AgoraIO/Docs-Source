---
title: 'Release notes'
sidebar_position: 4
type: docs
description: >
  Information about changes in each release of the Conversational AI agent.
---

export const toc = [{}];

This document tracks important changes and improvements to the <Vpd k="NAME" />. 

## Releases

### v1.6

Released on Jul 15, 2025.

#### New features

* **Support for OpenAI realtime API**

    Integrate Multimodal Large Language Models (MLLMs) with <Vpd k="NAME" /> to enable end-to-end real-time audio and text interactions. See [OpenAI Realtime API](/conversational-ai/models/mllm/openai) for integration details.

* **Support for more TTS vendors**

    <Vpd k="NAME" /> now supports the following additional TTS vendors:

    - [Cartesia](/conversational-ai/models/tts/cartesia)
    - [OpenAI](/conversational-ai/models/tts/openai)

* **Custom ASR provider support**

    To improve flexibility in configuring conversational agents, this release allows you to select a custom automatic speech recognition (ASR) provider. The [Start a conversational AI agent](../rest-api/join) API now includes the following new parameters:

    - `asr.vendor`: Specify the ASR provider
    - `asr.params`: Configure ASR parameters

    The following ASR providers are supported:

    - **Ares** (default)  
    - **Microsoft Azure**  
    - **Deepgram**  

    **Billing update:**  
    In earlier versions, the service fee included the cost of the Ares ASR provider. Starting in v1.6, the pricing is restructured as follows:

    - If you use **Ares ASR**, the total price remains unchanged:  
        _**Total cost = Conversational AI Engine Audio Basic Task + Ares ASR Task**_
    - If you use **a different ASR provider**, you are charged **only** the new **Conversational AI Engine Audio Basic Task** fee.

    For further details, see [Pricing](pricing).

* **Multi-platform toolkit**

    Agora now offers a toolkit to help you quickly build conversational agent apps. The toolkit is available for [**iOS**](../reference/ios), [**Android**](../reference/android), and [**Web**](../reference/web), and includes APIs for common scenarios. Call these APIs to combine the capabilities of the Agora Voice SDK and Signaling SDK to achieve the following functions:

    - [**Display live subtitles**](../develop/subtitles)
    Display real-time text output of user–agent conversations. The subtitle component is now more robust, with better error handling, session management, and extensibility.

    - [**Interrupt the agent**](../develop/interrupt-agent)
    Stop the agent from speaking or thinking mid-conversation.

    - [**Receive event notifications**](../develop/event-notifications)
    Track changes in conversation state, performance metrics, and error events.

    - [**Optimize audio settings**](../best-practices/audio-setup)
    Quickly apply best-practice audio configurations to improve agent responsiveness and clarity.

#### API changes

##### REST API

This release introduces several important modifications to the RESTful API.

- [Start a conversational AI agent](../rest-api/join)
    - **New parameters added:**
        - `asr.vendor`  
        - `asr.params`  
        - `advanced_features.enable_mllm`
        - `properties.mllm`
        - `turn_detection.type`
        - `turn_detection.interrupt_duration_ms`
        - `turn_detection.prefix_padding_ms`
        - `turn_detection.silence_duration_ms`
        - `turn_detection.threshold`
        - `turn_detection.create_response`
        - `turn_detection.interrupt_response`
        - `turn_detection.eagerness`
        - `parameters.enable_metrics`  
        - `parameters.data_channel`  
        - `parameters.enable_error_message`  

##### Toolkit APIs

- [Android SDK](../reference/android)
- [iOS SDK](../reference/ios)
- [Web SDK](../reference/web)

### v1.5

Released on Jun 9, 2025.

#### New features

* **Voice interruption mode**

    This release adds the `turn_detection.interrupt_mode` parameter to the [Start a conversational AI agent](../rest-api/join) API, allowing you to control how the agent handles human voice interruptions. The following modes are supported:

    * **`interrupt`**: (Default) The human voice immediately interrupts the agent. The agent terminates the current interaction and processes the new human voice input.

    * **`append`**: The human voice does not interrupt the agent. The agent processes the newly received human voice request after the current interaction ends.

    * **`ignore`**: The agent ignores human voice requests received during speaking or thinking. These requests are discarded and not stored in the context.
    
* **TTS filtering**

    This release adds the `tts.skip_patterns` parameter to the [Start a conversational AI agent](../rest-api/join) API. This parameter controls whether the TTS module skips bracketed content when reading LLM response text. This prevents the agent from vocalizing structural prompt information like tone indicators, action descriptions, and system prompts, creating a more natural and immersive listening experience.

#### API changes

This release introduces several important modifications to the RESTful API.

- [Start a conversational AI agent](../rest-api/join)
    - **New parameters added:**
        - `turn_detection.interrupt_mode`
        - `parameters.silence_config`
        - `tts.skipPatterns`

### v1.4

Released on May 29, 2025.

#### New features

* **Metadata support for LLM requests**

    This release adds the `llm.vendor` parameter to the [Start a conversational AI agent](../rest-api/join) API. When set to `"custom"`, the agent includes additional metadata when calling the LLM, such as `turn_id` and `timestamp`.

* **Support for Anthropic**

    The conversational AI engine now supports `anthropic` as a request style for chat completion. Refer to the `llm.style` parameter in [Start a conversational AI agent](../rest-api/join).

#### Improvements

This release includes the following enhancements:

* **Advanced LLM configuration**: The [Update agent configuration](../rest-api/update) API now supports:
    * `llm.system_messages` for updating system prompts
    * `llm.params` for modifying configuration parameters used when calling the large language model

#### API changes

This release introduces several important modifications to the RESTful API.

- [Start a conversational AI agent](../rest-api/join)
    - **New parameters added:**
        - `llm.vendor`
    - **Removed parameters:**
        - `agent_rtm_uid`

- [Update agent configuration](../rest-api/update)
    - **New parameters added:**
        - `llm.system_messages`
        - `llm.params`

### v1.3

Released on April 16, 2025.

#### New features

- **Agent conversation history**: This version adds two methods to retrieve an agent’s history. The history includes messages exchanged between the user and the agent and timestamps of agent creation and exit.

    - Call the RESTful API `history` endpoint to [Retrieve agent history](../rest-api/history).

    - Subscribe to the [agent history event](../develop/event-types#103-agent-history) through the [Agora message notification service](../develop/event-notifications). When the agent stops, Agora automatically sends the agent's history to your business server through a Webhook callback.

#### Improvements

- **Customize the priority of broadcast information**: This version upgrades the [Broadcast a message using TTS](../rest-api/speak) interface and adds two new configuration parameters related to broadcast interruption logic:

    - `priority`: Sets the priority of the message broadcast. Supports setting the following priorities: 
        - `INTERRUPT` High priority
        - `APPEND`: Medium priority
        - `IGNORE`: Low priority

    - `interruptable`: Configure whether to allow human voice to interrupt the agent's broadcast.

#### API changes

- Adds the [Retrieve agent history](../rest-api/history) method.
- Adds `priority` and `interruptable` parameters to the [Broadcast a message using TTS](../rest-api/speak) method.

### v1.2

Released on April 10, 2025.

#### New features

- **Broadcast a message using TTS**: A new message broadcast interface enables a specified agent to deliver a custom message. When interacting with an agent, calling this interface interrupts the agent’s speech and thinking process, allowing the TTS module to immediately broadcast the custom message.

- **Interrupt the agent**: The interrupt agent endpoint allows you to stop the specified agent’s speech and thinking process.

#### API changes

This version adds the following APIs:
- [Broadcast a message using TTS](../rest-api/speak)
- [Interrupt the agent](../rest-api/interrupt)

### v1.1

Released on March 27, 2025.

#### New features

The [Start a conversational agent](../rest-api/join) API adds the `enable_rtm`and `agent_rtm_uid` parameters to enable Signaling integration with <Vpd k="AGENT" />. When this feature is enabled, the agent can leverage the Signaling SDK to obtain a users's custom context information such as speaking status, selected text, signature, and score, and pass this data to the agent to generate more relevant content. For details, see [Transmit custom information](../develop/custom-information).

#### Improvements

To help you quickly integrate a custom large language model (LLM), this version adds documentation for [Custom LLMs](../develop/custom-llm). Refer to the sample code in the documentation to integrate your custom model into the conversational AI engine and enable advanced capabilities such as Retrieval-Augmented Generation (RAG), multi-modal processing, and tool invocation.

#### API changes

The `POST` method to [Start a <Vpd k="AGENT" />](../rest-api/join) now includes the `enable_rtm` and `agent_rtm_uid` parameters.

### v1.0 (Public Beta)

This version, released on March 4, 2025, adds pricing information for the Agora <Vpd k="NAME" />. For more information, see [Pricing](../overview/pricing).

#### Integration guide

To achieve the best conversation experience, use Agora <Vpd k="NAME" /> with the following Agora SDKs:

- Agora RTC Native SDK, v4.5.1 or later.
- Agora RTC Web SDK, version 4.23.2 or later.

#### New features

- **Live subtitles**: Supports real-time text output of conversations between users and the AI agent for subtitle display in your app's UI. Agora provides an open-source subtitle processing module. Simply integrate the module and call its API to implement live subtitles. For details, see [Display live subtitles](../develop/subtitles).

- **Message Notification Service**: Introduces a new <Vpd k="NAME" /> message notification service. Configure it in the Agora console and subscribe to agent creation, stop, and error events. When a subscribed event occurs, Agora sends the details to your specified callback address. See [Receive event notifications](../develop/event-notifications).

- **Keywords**: Enhances recognition accuracy of <Vpd k="NAME" /> for proprietary words by adding keywords. This feature is currently in Beta stage. For details, [contact technical support](https://agoraio.zendesk.com/hc/en-us).

### v1.0 (Private Beta)

Released on February 18, 2025. The first beta release of the <Vpd k="NAME" /> brings natural, smooth, low-latency, and highly reliable real-time voice conversations with AI agents to Agora channels. It enables you to efficiently build intelligent and immersive interactive experiences. See [Product overview](../overview/product-overview) for details.

#### Core Features

- **Real-time voice conversation**

    Supports natural and smooth real-time voice conversations with AI. It delivers a low-latency, ultra-responsive interactive experience as if the user is communicating with a real person.

- **Intelligent noise suppression**

    Intelligently identifies and suppresses background noise, ensuring clear sound transmission even in noisy environments to provide users with a high-quality audio experience.

- **Background human voice suppression**

    Suppresses background voices and noise while accurately preserving the primary speaker's voice. This ensures a clear and focused interactive experience in multi-speaker environments.

- **Intelligent interruption handling**

    Allows users to interrupt AI at any time to ensure quick and natural responses. This feature enables smooth transitions and avoids mechanical interactions.

- **Intelligent transmission**

    An AI-optimized transmission algorithm ensures stable voice data delivery even in weak network conditions where packet loss reaches 80%. This guarantees conversation continuity and reliability across diverse network environments.

- **Flexible arrangement**

    Supports multiple Large Language Model (LLM) and Text-to-Speech (TTS) providers, enabling flexible orchestration to meet diverse business needs and deliver highly customizable AI dialogue solutions.

- **Multi-platform support**

    Compatible with iOS, Android, Web, and various embedded hardware platforms, providing a seamless and consistent cross-platform experience.

#### Integration guide

- For the best conversational experience, <Vg k="COMPANY" /> recommends using <Vpd k="NAME" /> with specific Agora Video/Voice SDK versions. For details, [contact technical support](mailto:support@agora.io).

- The number of Peak Concurrent Users (PCU) allowed to call the server API under a single App ID is limited to 20. If you need to increase this limit, please [contact technical support](mailto:support@agora.io).

