<PlatformWrapper platform="android">
    ```kotlin
    private val onFrameAvailableListener = OnFrameAvailableListener {
        // Callback to notify that a new stream video frame is available.
        if (isJoined) {
            // Configure the external video frames and send them to the SDK
            val videoFrame: VideoFrame? = null

            // Add code here to convert the surfaceTexture data to a VideoFrame object

            // Send VideoFrame to the SDK
            agoraEngine!!.pushExternalVideoFrame(videoFrame)
        }
    }
    ```
    - <Link to="{{Global.API_REF_ANDROID_ROOT}}/class_irtcengine.html#api_imediaengine_pushvideoframe">pushExternalVideoFrame</Link>
</PlatformWrapper>
<PlatformWrapper platform={["ios","macos"]}>
    ```swift
    func myVideoCapture(_ pixelBuffer: CVPixelBuffer, rotation: Int, timeStamp: CMTime) {
        let videoFrame = AgoraVideoFrame()
        videoFrame.format = 12
        videoFrame.textureBuf = pixelBuffer
        videoFrame.time = timeStamp
        videoFrame.rotation = Int32(rotation)

        // Push the video frame to the Agora SDK
        let framePushed = self.agoraEngine.pushExternalVideoFrame(videoFrame)
        if !framePushed {
            print("Frame could not be pushed.")
        }
    }
    ```
    <PlatformWrapper platform="ios">
    - <Link to="{{Global.API_REF_IOS_ROOT_RTC_KIT}}/agoravideoframe">AgoraVideoFrame</Link>
    - <Link to="{{Global.API_REF_IOS_ROOT_RTC_ENGINE_KIT}}/pushexternalvideoframe(_:)">pushExternalVideoFrame(_:)</Link>
    </PlatformWrapper>
    <PlatformWrapper platform="macos">
    - <Link to="{{Global.API_REF_MACOS_ROOT_RTC_KIT}}/agoravideoframe">AgoraVideoFrame</Link>
    - <Link to="{{Global.API_REF_MACOS_ROOT_RTC_ENGINE_KIT}}/pushexternalvideoframe(_:)">pushExternalVideoFrame(_:)</Link>
    </PlatformWrapper>
</PlatformWrapper>
<PlatformWrapper platform="unity">
    ```csharp
    // Coroutine for sharing screen
    public IEnumerator ShareScreen()
    {
        PushAudioFrameCoroutine();
        yield return new WaitForEndOfFrame();
        if (agoraEngine != null)
        {
            texture.ReadPixels(rect, 0, 0);
            texture.Apply();

            // Check Unity version for texture data access
#if UNITY_2018_1_OR_NEWER
            NativeArray<byte> nativeByteArray = texture.GetRawTextureData<byte>();
            if (shareData?.Length != nativeByteArray.Length)
            {
                shareData = new byte[nativeByteArray.Length];
            }
            nativeByteArray.CopyTo(shareData);
#else
            shareData = texture.GetRawTextureData();
#endif

            ExternalVideoFrame externalVideoFrame = new ExternalVideoFrame();
            externalVideoFrame.type = VIDEO_BUFFER_TYPE.VIDEO_BUFFER_RAW_DATA;
            externalVideoFrame.format = VIDEO_PIXEL_FORMAT.VIDEO_PIXEL_RGBA;
            externalVideoFrame.buffer = shareData;
            externalVideoFrame.stride = (int)rect.width;
            externalVideoFrame.height = (int)rect.height;
            externalVideoFrame.rotation = 180;
            externalVideoFrame.timestamp = DateTime.Now.Ticks / 1000;
            var ret = agoraEngine.PushVideoFrame(externalVideoFrame);
            Debug.Log("PushVideoFrame ret = " + ret + "time: " + DateTime.Now.Millisecond);
        }
    }
    // Get timestamp millisecond
    private double GetTimestamp()
    {
        TimeSpan ts = DateTime.UtcNow - new DateTime(1970, 1, 1, 0, 0, 0, 0);
        return ts.TotalMilliseconds;
    }
    ```
    - <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_imediaengine_pushvideoframe">PushVideoFrame</Link>

</PlatformWrapper>