---
title: "Start a conversational AI agent"
sidebar_position: 1
type: docs
platform_selector: false
description: >
  Create and start a Conversational AI agent instance.
---
import RestAPILayout from '@site/src/components/rest-api/RestAPILayout';
import LeftColumn from '@site/src/components/rest-api/LeftColumn';
import RightColumn, { Section } from '@site/src/components/rest-api/RightColumn';
import ParameterList, { Parameter } from '@site/src/components/rest-api/ParameterList';
import PathParameter from '@site/src/components/rest-api/PathParameter';
import { Tabs, TabItem } from '@site/src/components/rest-api/Tabs';

<RestAPILayout>
  <LeftColumn
    title={frontMatter.title}
    method="POST"
    endpoint="https://api.agora.io/api/conversational-ai-agent/v2/projects/{appid}/join"
  >

Use this endpoint to create and start a <Vpd k="AGENT" /> instance.

## Request

### Path parameters

<PathParameter name="appid" type="string" required={true}>
  The App ID of the project.
</PathParameter>

### Request body

<div class="api-mime-type">APPLICATION/JSON</div>

<ParameterList title="BODY" required={true}>
  <Parameter name="name" type="string" required={true}>
    The unique identifier of the agent. The same identifier cannot be used repeatedly.
  </Parameter>

  <Parameter name="properties" type="object" required={true}>
    Configuration details of the agent.

    <Parameter name="channel" type="string" required={true}>
      The name of the channel to join.
    </Parameter>

    <Parameter name="token" type="string" required={true}>
      The authentication token used by the agent to join the channel.
    </Parameter>

    <Parameter name="agent_rtc_uid" type="string" required={true}>
      The user ID of the agent in the channel. A value of <code>0</code> means that a random UID is generated and assigned. Set the <code>token</code> accordingly.
    </Parameter>

    <Parameter name="remote_rtc_uids" type="array[string]" required={true}>
      The list of user IDs that the agent subscribes to in the channel. Only subscribed users can interact with the agent. <code>"*"</code> means that the agent subscribes to all users in the channel.
    </Parameter>

    <Parameter name="enable_string_uid" type="boolean" defaultValue="false" required={false}>
      Whether to enable String uid:
      <ul>
        <li>`true`: Both agent and subscriber user IDs use strings.</li>
        <li>`false`: Both agent and subscriber user IDs must be integers.</li>
      </ul>
    </Parameter>

    <Parameter name="idle_timeout" type="integer" defaultValue="30" required={false}>
      Sets the timeout after all the users specified in <code>remote_rtc_uids</code> are detected to have left the channel. When the timeout value is exceeded, the agent automatically stops and exits the channel. A value of <code>0</code> means that the agent does not exit until it is stopped manually.
    </Parameter>

    <Parameter name="silence_timeout" type="integer" defaultValue="0" required={false} possibleValues="0 to 60">
      Maximum agent silence time (in seconds). After the agent is successfully created and the user joins the channel, the duration during which the agent is not in a listening, thinking, or speaking state is considered the agentâ€™s silence time. When the silence time reaches the configured value, the agent broadcasts the silence reminder message specified in `llm.silence_message`, and then resets the silence timer.

      Set this value to `0` to disable the feature (default).

      You must also configure `llm.silence_message` for the reminder to work. Otherwise, this setting has no effect.
    </Parameter>
    
    <Parameter name="agent_rtm_uid" type="string" required={false}>
      The agent's user ID in the Signaling channel. Only valid when `advanced_features.enable_rtm` is set to `true`.
    </Parameter>

    <Parameter name="advanced_features" type="object" required={false}>
      Advanced features configuration.

      <Parameter name="enable_aivad" type="boolean" defaultValue="false" required={false}>
        Whether to enable the intelligent interruption handling function (AIVAD). This feature is currently available only for English.
      </Parameter>

      <Parameter name="enable_rtm" type="boolean" defaultValue="false" required={false}>
        Whether to enable the Signaling service. When enabled, the agent can combine the capabilities provided by Signaling to implement advanced functions, such as delivering [custom information](../develop/custom-information).
      </Parameter>
    </Parameter>

    <Parameter name="asr" type="object" required={false}>
      Automatic Speech Recognition (ASR) configuration.

      <Parameter name="language" type="string" defaultValue="en-US" possibleValues="en-US,es-ES,ja-JP,ko-KR,ar-AE,hi-IN" required={false}>
        The language used by users to interact with the agent. The following languages are in Beta: <ul><li>`es-ES`: Spanish - Spain</li><li> `ja-JP`: Japanese</li><li> `ko-KR`: Korean</li><li> `ar-AE`: Arabic - UAE</li><li> `hi-IN`: Hindi - India</li></ul>
      </Parameter>
    </Parameter>
  </Parameter>

  <Parameter name="tts" type="object" required={true}>
    Text-to-speech (TTS) module configuration.

    <Parameter name="vendor" type="string" required={true} possibleValues="microsoft,elevenlabs">
      TTS provider. <ul><li>`microsoft`: Microsoft Azure</li><li> `elevenlabs`: ElevenLabs</li></ul>
    </Parameter>

    <Parameter name="params" type="object" required={true}>
      The configuration parameters for the TTS vendor. See [TTS vendor configuration](#tts-vendor-configuration) for details.
    </Parameter>
  </Parameter>

  <Parameter name="llm" type="object" required={true}>
    Large language model (LLM) configuration.

    <Parameter name="url" type="string" required={true}>
      The LLM callback address.
    </Parameter>

    <Parameter name="api_key" type="string" defaultValue="" required={false}>
      The LLM verification API key. The default value is an empty string. Ensure that you enable the API key in a production environment.
    </Parameter>

    <Parameter name="system_messages" type="array[object]" required={false}>
      A set of predefined information used as input to the LLM, including prompt words and examples.
    </Parameter>

    <Parameter name="params" type="object" required={false}>
      Additional LLM information transmitted in the message body, such as the <code>model</code> used, and the maximum token limit.
    </Parameter>

    <Parameter name="max_history" type="integer" defaultValue="10" required={false}>
      The number of short-term memory entries cached in the custom LLM. <code>0</code> means no short-term memory is cached. Users and agents log entries separately.
    </Parameter>

    <Parameter name="input_modalities" type="array[string]" defaultValue='["text"]' required={false}>
      LLM input modalities. Supports `["text"]`, `["text", "image"]`.
    </Parameter>

    <Parameter name="output_modalities" type="array[string]" defaultValue='["text"]' required={false}>
      LLM output modalities. Supports <code>["audio"]</code>, <code>["text"]</code>, <code>["text", "audio"]</code>.
    </Parameter>

    <Parameter name="greeting_message" type="string" required={false}>
      Agent greeting. If provided, the first user in the channel is automatically greeted with the message upon joining.
    </Parameter>

    <Parameter name="failure_message" type="string" required={false}>
      Prompt for agent activation failure. If provided, it is returned through TTS when the custom LLM call fails.
    </Parameter>

    <Parameter name="silence_message" type="string" required={false} defaultValue="''">
      When the silence time reaches the value set in `silence_timeout`, the agent broadcasts this reminder message. If `silence_timeout` is set to 0, this parameter is ignored.
    </Parameter>

    <Parameter name="style" type="string" defaultValue="openai" possibleValues="openai,gemini" required={false}>
      The request style for chat completion. <br/> <code>openai</code> includes OpenAI compatible APIs.
    </Parameter>
  </Parameter>

  <Parameter name="vad" type="object" required={false}>
    Voice Activity Detection (VAD) configuration.

    <Parameter name="interrupt_duration_ms" type="number" defaultValue="160" required={false}>
      The amount of time in milliseconds that the user's voice must exceed the VAD threshold before an interruption is triggered.
    </Parameter>

    <Parameter name="prefix_padding_ms" type="integer" defaultValue="300" required={false}>
      The extra forward padding time in milliseconds before the processing system starts to process the speech input. This padding helps capture the beginning of the speech.
    </Parameter>

    <Parameter name="silence_duration_ms" type="integer" defaultValue="640" required={false}>
      The duration of audio silence in milliseconds. If no voice activity is detected during this period, the agent assumes that the user has stopped speaking.
    </Parameter>

    <Parameter name="threshold" type="number" defaultValue="0.5" required={false}>
      Identification sensitivity determines the level of sound in the audio signal that is considered voice activity. The value range is <code>(0.0, 1.0)</code>. Lower values make it easier for the agent to detect speech, and higher values ignore weak sounds.
    </Parameter>
  </Parameter>
</ParameterList>

## Response

- If the returned status code is `200`, the request was successful. The response body contains the result of the request.

  <ParameterList title="OK">
    <Parameter name="agent_id" type="string">
      Unique id of the agent instance
    </Parameter>
    
    <Parameter name="create_ts" type="integer">
      Timestamp of when the agent was created
    </Parameter>
    
    <Parameter 
      name="status" 
      type="string" 
      possibleValues="IDLE, STARTING, RUNNING, STOPPING, STOPPED, RECOVERING, FAILED"
    >
      Current status.
      <ul>
        <li>`IDLE` (0): Agent is idle.</li>
        <li>`STARTING` (1): The agent is being started.</li>
        <li>`RUNNING` (2): The agent is running.</li>
        <li>`STOPPING` (3): The agent is stopping.</li>
        <li>`STOPPED` (4): The agent has exited.</li>
        <li>`RECOVERING` (5): The agent is recovering.</li>
        <li>`FAILED` (6): The agent failed to execute.</li>
      </ul>
    </Parameter>
  </ParameterList>

- If the returned status code is not `200`, the request failed. The response body includes the `detail` and `reason` for failure. Refer to [status codes](../rest-api/reference#response-status-codes) to understand the possible reasons for failure.

## Reference

### TTS vendor configuration

<Vpd k="NAME" /> supports the following TTS vendors:

#### Microsoft

<ParameterList title="params" required={true}>
  <Parameter name="key" type="string" required={true}>  
  The API key used for authentication.
  </Parameter>
  <Parameter name="region" type="string" required={true}>
  The Azure region where the speech service is hosted.
  </Parameter>
  <Parameter name="voice_name" type="string">  
  The identifier for the selected voice for speech synthesis.
  </Parameter>
  <Parameter name="rate" type="number">
  Indicates the speaking rate of the text. The rate can be applied at the word or sentence level and should be between 0.5 and 2.0 times the original audio speed.
  </Parameter>
  <Parameter name="volume" type="number" defaultValue="100">  
   Specifies the audio volume as a number between 0.0 and 100.0, where 0.0 is the quietest and 100.0 is the loudest. For example, a value of 75 sets the volume to 75% of the maximum.
  </Parameter>
  <Parameter name="sample_rate" type="integer" defaultValue="24000">
  Specifies the audio sampling rate in Hz.
  </Parameter>
</ParameterList>

For further details, refer to [Microsoft TTS](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/text-to-speech).

**Sample configuration**

```json
{
    "vendor": "microsoft",
    "params": {
        "key": "<your_microsoft_key>",
        "region": "eastus",
        "voice_name": "en-US-AndrewMultilingualNeural",
        "rate": 1.0,
        "volume": 70
    }
}
```

#### Elevenlabs

<ParameterList title="params" required={true}>
  <Parameter name="key" type="string" required={true}>  
  The API key used for authentication.
  </Parameter>
  <Parameter name="model_id" type="string" required={true}>
  Identifier of the model to be used,
  </Parameter>
  <Parameter name="voice_id" type="string" required={true}>  
  The identifier for the selected voice for speech synthesis.
  </Parameter>
  <Parameter name="sample_rate" type="integer" defaultValue="24000">
  Specifies the audio sampling rate in Hz.
  </Parameter>  
  <Parameter name="stability" type="number">
  The stability for voice settings.
  </Parameter>
  <Parameter name="similarity_boost" type="number">  
  </Parameter>
  <Parameter name="style" type="number">
  </Parameter>
  <Parameter name="use_speaker_boost" type="boolean">  
  </Parameter>
</ParameterList>

For further details, refer to [Elevenlabs TTS](https://elevenlabs.io/docs/capabilities/text-to-speech).

**Sample configuration**

```json
{
  "vendor": "elevenlabs",
  "params": {
    "key": "<your_elevenlabs_key>",
    "model_id": "eleven_flash_v2_5",
    "voice_id": "pNInz6obpgDQGcFmaJgB"
  }
}
```
      
</LeftColumn>

<RightColumn>

<Section title="Authorization">
This endpoint requires [Basic Auth](../rest-api/restful-authentication).
</Section>

<Section title="Request example">

  <Tabs groupId="code-examples">
    <TabItem value="curl" label="curl" default>
      ```bash
      curl --request post \
      --url https://api.agora.io/api/conversational-ai-agent/v2/projects/:appid/join \
      --header 'Authorization: Basic <your_base64_encoded_credentials>' \
      --data '
      {
          "name": "unique_name",
          "properties": {
              "channel": "channel_name",
              "token": "token",
              "agent_rtc_uid": "friday",
              "remote_rtc_uids": [
                  "*"
              ],
              "enable_string_uid": true,
              "idle_timeout": 120,
              "advanced_features": {
                  "enable_aivad": true
              },
              "llm": {
                  "url": "https://api.openai.com/v1/chat/completions",
                  "api_key": "<your_llm_key>",
                  "system_messages": [
                      {
                          "role": "system",
                          "content": "You are a helpful chatbot."
                      }
                  ],
                  "max_history": 10,
                  "greeting_message": "Hello, how can I assist you today?",
                  "failure_message": "Please hold on a second.",
                  "params": {
                      "model": "gpt-4o-mini"
                  }
              },
              "tts": {
                  "vendor": "microsoft",
                  "params": {
                      "key": "<your_tts_api_key>",
                      "region": "eastus",
                      "voice_name": "en-US-AndrewMultilingualNeural"
                  }
              },
              "asr": {
                  "language": "en-US"
              }
          }
      }'
      ```
    </TabItem>
    <TabItem value="python" label="Python">

    ```python
    import requests
    import json

    url = "https://api.agora.io/api/conversational-ai-agent/v2/projects/:appid/join"

    headers = {"Authorization": "Basic <your_base64_encoded_credentials>"}

    data = {
        "name": "unique_name",
        "properties": {
            "channel": "channel_name",
            "token": "token",
            "agent_rtc_uid": "friday",
            "remote_rtc_uids": ["*"],
            "enable_string_uid": True,
            "idle_timeout": 120,
            "advanced_features": {
                "enable_aivad": True
            },
            "llm": {
                "url": "https://api.openai.com/v1/chat/completions",
                "api_key": "<your_llm_key>",
                "system_messages": [
                    {
                        "role": "system",
                        "content": "You are a helpful chatbot."
                    }
                ],
                "max_history": 10,
                "greeting_message": "Hello, how can I assist you today?",
                "failure_message": "Please hold on a second.",
                "params": {
                    "model": "gpt-4o-mini"
                }
            },
            "tts": {
                "vendor": "microsoft",
                "params": {
                    "key": "<your_tts_api_key>",
                    "region": "eastus",
                    "voice_name": "en-US-AndrewMultilingualNeural"
                }
            },
            "asr": {
                "language": "en-US"
            }
        }
    }

    response = requests.post(url, headers=headers, data=json.dumps(data))

    print(response.status_code)
    print(response.json())
    ```
    </TabItem>

    <TabItem value="node" label="Node.js">

    ```js
    const axios = require("axios");

    const url = "https://api.agora.io/api/conversational-ai-agent/v2/projects/:appid/join";

    const headers = {
      "Authorization": "Basic <your_base64_encoded_credentials>"
    };

    const data = {
      name: "unique_name",
      properties: {
        channel: "channel_name",
        token: "token",
        agent_rtc_uid: "friday",
        remote_rtc_uids: ["*"],
        enable_string_uid: true,
        idle_timeout: 120,
        advanced_features: {
          enable_aivad: true
        },
        llm: {
          url: "https://api.openai.com/v1/chat/completions",
          api_key: "<your_llm_key>",
          system_messages: [
            {
              role: "system",
              content: "You are a helpful chatbot."
            }
          ],
          max_history: 10,
          greeting_message: "Hello, how can I assist you today?",
          failure_message: "Please hold on a second.",
          params: {
            model: "gpt-4o-mini"
          }
        },
        tts: {
          vendor: "microsoft",
          params: {
            key: "<your_tts_api_key>",
            region: "eastus",
            voice_name: "en-US-AndrewMultilingualNeural"
          }
        },
        asr: {
          language: "en-US"
        }
      }
    };

    axios
      .post(url, data, { headers })
      .then(response => {
        console.log("Status:", response.status);
        console.log("Response:", response.data);
      })
      .catch(error => {
        console.error("Error:", error.response ? error.response.data : error.message);
      });
    ```
    </TabItem>
  </Tabs>

</Section>
<Section title="Response example">

  ```json
  {
    "agent_id": "1NT29X10YHxxxxxWJOXLYHNYB",
    "create_ts": 1737111452,
    "status": "RUNNING"
  }
  ```

</Section>
  </RightColumn>
</RestAPILayout>