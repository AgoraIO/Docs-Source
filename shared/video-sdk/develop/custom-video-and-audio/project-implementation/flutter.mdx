<PlatformWrapper platform="flutter">

### Implement a custom video source

In the following code example, you push an image to the video track using the custom video framework. To create the basic framework, take the following steps:

1. **Update the user interface**

    To enable a user to start pushing video frames, add a button to the user interface.

    Open `/lib/main.dart` and add the following lines after `ListView(...children: [` in the `build` method:

    ```dart
    ElevatedButton(
        onPressed:_isJoined ? () => {_pushVideoFrame()} : null,
        child: const Text("Push Video Frame"),
    ),
    ```

1. **Import the required dart libraries**

    To convert an image to a video frame, import the necessary dart libraries. Add the following statements after the last `import` statement in `/lib/main.dart`:

    ```dart
    import 'dart:typed_data';
    import 'dart:ui';
    import 'package:flutter/services.dart';
    ```

1. **Define variables to load and push image data**

    In `/lib/main.dart`, add the following declarations to the `_MyAppState` class:

    ```dart
    Uint8List? _imageByteData;
    int? _imageWidth;
    int? _imageHeight;
    ```

1. **Enable publishing the custom video track**

    To allow publishing of video from a custom source, you call the `setExternalVideoSource` method of the `MediaEngine`. To do this, in `setupVideoSDKEngine`, add the following lines after the call to `agoraEngine.initialize`:

    ```dart
    await agoraEngine
        .getMediaEngine()
        .setExternalVideoSource(enabled: true, useTexture: false);
    ```

1. **Load image data to push as a video frame**

    Your <Vpl k="CLIENT" /> loads an image file and pushes it as a video frame. Take the following steps to read an image file from the assets folder and convert it to byte data:

    1. To add an image file to your project, create a folder named `assets` in the root folder of your project. Copy an image file to this folder. In `pubspec.yaml` add the following lines:
        
        ```yaml
        assets:
        - assets/<file-name>.png
        ```

    1. To read the image file, add the following method to the `_MyAppState` class:

        ```dart
        Future<void> _loadImageByteData() async {
            ByteData data = await rootBundle.load("assets/<filename>.png");
            Uint8List bytes =
                data.buffer.asUint8List(data.offsetInBytes, 
                data.lengthInBytes);

            final image = await decodeImageFromList(bytes);

            final byteData =
                await image.toByteData(
                    format: ImageByteFormat.rawStraightRgba);
            _imageByteData = byteData!.buffer.asUint8List();
            _imageWidth = image.width;
            _imageHeight = image.height;
            image.dispose();
        }
        ```

    1. To load the image at startup, add the following line to `setupVideoSDKEngine()` before `agoraEngine.registerEventHandler(`:
    
        ```dart
        _loadImageByteData();
        ```

1. **Create and push a video frame**

    When a user presses the **Push Video Frame** button, you call `_pushVideoFrame` to create an `ExternalVideoFrame` from the loaded image data. You publish this frame using the `pushVideoFrame` method of the `MediaEngine`. To do this, add the following method to the `_MyAppState` class:

    ```dart
    Future<void> _pushVideoFrame() async {

        ExternalVideoFrame agoraFrame = ExternalVideoFrame(
            type: VideoBufferType.videoBufferRawData,
            format: VideoPixelFormat.videoPixelRgba,
            buffer: _imageByteData,
            stride: _imageWidth,
            height: _imageHeight,
            timestamp: DateTime.now().millisecondsSinceEpoch);

        await agoraEngine.getMediaEngine().pushVideoFrame(
            frame: agoraFrame);
    }
    ```

### Implement a custom audio source

In the following code example, you create the basic framework required to push audio frames from a custom source. Depending on the type of your source, you add your own code to this framework that converts the source data to an `AudioFrame`. To create the basic framework, take the following steps:

1. **Update the user interface**

    To enable a user to start pushing audio frames, add a button to the user interface.

    Open `/lib/main.dart` and add the following lines after `ListView(...children: [` in the `build` method:

    ```dart
    ElevatedButton(
        onPressed:_isJoined ? () => {_pushAudioFrame()} : null,
        child: const Text("Push Audio Frame"),
    ),
    ```

1. **Enable publishing the custom audio track**

     To allow publishing of audio from a custom source, you call the `setExternalAudioSource` method of the `MediaEngine`. To do this, in `setupVideoSDKEngine`, add the following lines after the call to `agoraEngine.initialize`:

    ```dart
    await agoraEngine
        .getMediaEngine()
        .setExternalAudioSource(enabled: true, channels: 2, sampleRate: 44100);
    ```

1. **Load the buffer and push an audio frame**

    In `_MyAppState` class, add the following method:

    ```dart
    Future<void> _pushAudioFrame() async {
        var buffer;
        // Add code here to read the audio input stream into a buffer

        // Create an audio frame from the buffer
        AudioFrame audioFrame = const AudioFrame(
            type: AudioFrameType.frameTypePcm16,
            buffer: buffer, // data buffer of the audio frame.
            samplesPerChannel: 5, // number of samples per channel
            channels: 2, // use 1 for mono, 2 for stereo
            bytesPerSample: 2,
            samplesPerSec: 44100,
            renderTimeMs: 5000
        );

        await agoraEngine.getMediaEngine().pushAudioFrame(
            frame: audioFrame, type:
            MediaSourceType.audioPlayoutSource
        );
    }
    ```



</PlatformWrapper>
