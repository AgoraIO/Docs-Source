---
title: Groq
sidebar_position: 4
platform_selector: false
description: >
  Integrate Groq LLM into Conversational AI Engine.
---

Groq provides state-of-the-art language models optimized for different use cases.

### Sample configuration

The following example shows a starting `llm` parameter configuration you can use when you [Start a conversational AI agent](/conversational-ai/rest-api/join). 

```json
"llm": {
    "url": "https://api.groq.com/openai/v1/chat/completions",
    "api_key": "<your_llm_key>",
    "system_messages": [
      {
        "role": "system",
        "content": "You are a helpful chatbot."
      }
    ],
    "max_history": 32,
    "greeting_message": "Hello, how can I assist you?",
    "failure_message": "Please hold on a second.",
    "params": {
      "model": "llama-3.3-70b-versatile"
    },
  }
```

### Key parameters

-  `api_key`: Create and manage your API key from [Groq console](https://console.groq.com/keys).
- `url`: Use the completions endpoint.
- `model`: Refer to [Groq models](https://console.groq.com/docs/models) for available models.

For advanced configuration options, model capabilities, and detailed parameter descriptions, see the [Groq API Documentation](https://console.groq.com/docs/api-reference).
