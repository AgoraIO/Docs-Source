---
title: Groq
sidebar_position: 4
platform_selector: false
description: >
  Integrate Groq LLM into Conversational AI Engine.
---

Groq provides state-of-the-art language models optimized for different use cases.

### Sample configuration

The following example shows a starting `llm` parameter configuration you can use when you [Start a conversational AI agent](/conversational-ai/rest-api/agent/join). 

```json
"llm": {
    "url": "https://api.groq.com/openai/v1/chat/completions",
    "api_key": "<your_llm_key>",
    "system_messages": [
      {
        "role": "system",
        "content": "You are a helpful chatbot."
      }
    ],
    "max_history": 32,
    "greeting_message": "Hello, how can I assist you?",
    "failure_message": "Please hold on a second.",
    "params": {
      "model": "llama-3.3-70b-versatile"
    },
  }
```

### Key parameters

<ParameterList title="llm" required={true}>
  <Parameter name="api_key" type="string" required={true}>  
  Create and manage your API key from [Groq console](https://console.groq.com/keys).
  </Parameter>
  <Parameter name="url" type="string" required={true}>  
  Use the completions endpoint.
  </Parameter>
  <Parameter name="params" type="object" required={true}>  
    <Parameter name="model" type="string" required={true}>  
    Refer to [Groq models](https://console.groq.com/docs/models) for available models.
    </Parameter>
  </Parameter>
</ParameterList>

For advanced configuration options, model capabilities, and detailed parameter descriptions, see the [Groq API Documentation](https://console.groq.com/docs/api-reference).
