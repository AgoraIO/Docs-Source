---
title: 'Start a conversational AI agent'
sidebar_position: 1
type: docs
platform_selector: false
description: >
  Create and start a Conversational AI agent instance.
---
import RestAPILayout from '@site/src/components/rest-api/RestAPILayout';
import LeftColumn from '@site/src/components/rest-api/LeftColumn';
import RightColumn from '@site/src/components/rest-api/RightColumn';
import Parameter from '@site/src/components/rest-api/Parameter';

<RestAPILayout>
  <LeftColumn
    title="Start a conversational AI agent"
    method="POST"
    endpoint="https://api.agora.io/api/conversational-ai-agent/v2/projects/{appid}/join"
    authorization="Basic Auth"
  >

    ### Authorization 

    This endpoint requires [Basic Authentication](https://en.wikipedia.org/wiki/Basic_access_authentication).

    ### Path parameters

    <Parameter name="appid" type="string" description="The App ID of the project" required />

    ### Request parameters

    <Parameter
    name="name"
    type="string"
    required={true}
    description="The unique identifier of the agent. The same identifier cannot be used repeatedly."
    />
    
    <Parameter
    name="properties"
    type="object"
    required={true}
    description="Configuration details of the agent"
    >
        <Parameter
            name="channel"
            type="string"
            required={true}
            description="The name of the channel to join."
        />
        
        <Parameter
            name="token"
            type="string"
            required={true}
            description="The authentication token used by the agent to join the channel."
        />
        
        <Parameter
            name="agent_rtc_uid"
            type="string"
            required={true}
            description="The user ID of the agent in the channel. A value of '0' means that a random uid is generated and assigned. Set the 'token' accordingly."
        />
    
        <Parameter
            name="remote_rtc_uids"
            type="array[string]"
            required={true}
            description="The list of user IDs that the agent subscribes to in the channel. Only subscribed users can interact with the agent. '*' means that the agent subscribes to all users in the channel."
        />
        
        <Parameter
            name="enable_string_uid"
            type="boolean"
            description="Whether to enable String uid:"
        >
            <ul>
            <li><code>true</code>: Both agent and subscriber user IDs use strings.</li>
            <li><code>false</code>: (Default) Both agent and subscriber user IDs must be integers.</li>
            </ul>
        </Parameter>
    
    <Parameter
        name="idle_timeout"
        type="integer"
        required={false}
        description="Sets the timeout after all the users specified in 'remote_rtc_uids' are detected to have left the channel. When the timeout value is exceeded, the agent automatically stops and exits the channel. A value of '0' means that the agent does not not exit until it is stopped manually. Default value '30'"
    />
    
    <Parameter
        name="advanced_features"
        type="object"
        description="Advanced features configuration."
    >
        <Parameter
        name="enable_aivad"
        type="boolean"
        description="Whether to enable the intelligent interruption handling function (AIVAD). Default value 'false'."
        >
        <div className="admonition">This feature is currently available only for English.</div>
        </Parameter>
        
        <Parameter
        name="enable_bhvs"
        type="boolean"
        description="Whether to enable background noise reduction. Default value 'true'."
        />
    </Parameter>
    
    <Parameter
        name="asr"
        type="object"
        description="Automatic Speech Recognition (ASR) configuration"
    >
        <Parameter
        name="language"
        type="string"
        description="The language used by users to interact with the agent. The following languages are supported:"
        >
        <ul>
            <li><code>en-US</code> English - US (Default)</li>
        </ul>
        In Beta:
        <ul>
            <li><code>es-ES</code> Spanish - Spain</li>
            <li><code>ja-JP</code> Japanese</li>
            <li><code>ko-KR</code> Korean</li>
            <li><code>ar-AE</code> Arabic - UAE</li>
            <li><code>hi-IN</code> Hindi - India</li>
        </ul>
        </Parameter>
    </Parameter>
    
    <Parameter
        name="tts"
        type="object"
        required={true}
        description="Text-to-speech (TTS) module configuration"
    >
        <Parameter
        name="vendor"
        type="string"
        required={true}
        description="TTS provider. Supports the following values:"
        >
        <ul>
            <li><code>microsoft</code>: Microsoft Azure</li>
            <li><code>elevenlabs</code>: ElevenLabs</li>
        </ul>
        </Parameter>
        
        <Parameter
        name="params"
        type="object"
        required={true}
        description="The configuration parameters for the TTS vendor."
        > 
        See [TTS](./something) vendor configuration for details."
        </Parameter>
    </Parameter>
    
    <Parameter
        name="llm"
        type="object"
        required={true}
        description="Large language model (LLM) configuration."
    >
        <Parameter
        name="url"
        type="string"
        required={true}
        description="The LLM callback address."
        />
        
        <Parameter
        name="api_key"
        type="string"
        description="The LLM verification API key. The default value is an empty string. Ensure that you enable the API key in a production environment."
        />
        
        <Parameter
        name="system_messages"
        type="array[object]"
        description="A set of predefined information used as input to the LLM, including prompt words and examples."
        />
        
        <Parameter
        name="params"
        type="object"
        description="Additional LLM information transmitted in the message body, such as the 'model' used, and the maximum token limit."
        />
        
        <Parameter
        name="max_history"
        type="integer"
        description="The number of short-term memory entries cached in the custom LLM. '0' means no short-term memory is cached. Users and agents log entries separately. Default value '10'"
        />
        
        <Parameter
        name="input_modalities"
        type="array[string]"
        description='LLM input modalities. Supports [\"text\"], [\"text\", \"image\"]. Default [\"text\"]'
        />
        
        <Parameter
        name="output_modalities"
        type="array[string]"
        description='LLM output modalities. Support [\"audio\"],[\"text\"], [\"text\", \"audio\"]. Default [\"text\"]'
        />
        
        <Parameter
        name="greeting_message"
        type="string"
        description="Agent greeting. If provided, the first user in the channel is automatically greeted with the message upon joining."
        />
        
        <Parameter
        name="failure_message"
        type="string"
        description="Prompt for agent activation failure. If provided, it is returned through TTS when the custom LLM call fails"
        />
        
        <Parameter
        name="style"
        type="string"
        description="The request style for chat completion. Supports:"
        >
        <ul>
            <li><code>openai</code> (Default, including OpenAI compatible APIs)</li>
            <li><code>gemini</code></li>
        </ul>
        </Parameter>
    </Parameter>
    
    <Parameter
        name="vad"
        type="object"
        description="Voice Activity Detection (VAD) configuration"
    >
        <Parameter
        name="interrupt_duration_ms"
        type="number"
        description="The amount of time in milliseconds that the agent waits after detecting that the voice input has been interrupted. This parameter ensures that the agent does not immediately process the input until the user stops speaking. Default value '160'"
        />
        
        <Parameter
        name="prefix_padding_ms"
        type="integer"
        description="The extra forward padding time in milliseconds before the processing system starts to process the speech input. This padding helps capture the beginning of the speech. Default value '300'"
        />
        
        <Parameter
        name="silence_duration_ms"
        type="integer"
        description="The duration of audio silence in milliseconds. If no voice activity is detected during this period, the agent assumes that the user has stopped speaking. Default value '500'"
        />
        
        <Parameter
        name="threshold"
        type="number"
        description="Identification sensitivity determines the level of sound in the audio signal that is considered voice activity. The value range is (0.0, 1.0). Lower values ​​make it easier for the agent to detect speech, and higher values ignore weak sounds. Default value '0.5'"
        />
    </Parameter>
    </Parameter>
 
  </LeftColumn>

  <RightColumn>

    ### Request example

    ```json
    {
      "model": "gpt-4",
      "settings": {
        "temperature": 0.7,
        "max_tokens": 1000
      },
      "prompt": "You are a helpful assistant.",
      "stream": false
    }
    ```

    ### Response example

    ```json
    {
      "agent_id": "agt_928ac7d35fb94e2a",
      "session": {
        "session_id": "sess_7fb23a910cd7",
        "expires_at": "2023-08-15T14:30:00Z"
      },
      "model": "gpt-4",
      "status": "ready"
    }
    ```
  </RightColumn>
</RestAPILayout>