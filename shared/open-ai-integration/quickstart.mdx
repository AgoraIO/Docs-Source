import CodeBlock from '@theme/CodeBlock';
import CodeRtcPy from '@docs/assets/code/open-ai-integration/rtc-py.mdx';
import Prerequisites from '@docs/shared/common/prerequisites/python.mdx';

Integrating Agora's real-time audio communication capabilities with OpenAI's language models enables dynamic, conversational AI experiences. This guide shows you how to set up a Python project that combines Agora's server-side Voice SDK with OpenAI's API to create an interactive, voice-driven assistant.

## Understand the tech

The `RealtimeKitAgent` class manages the integration by connecting to an Agora channel for real-time audio streaming and to OpenAI's API for processing audio input and generating AI-driven responses. Audio frames captured from the Agora channel are streamed to OpenAI's API, where the AI processes the input. The API responses, which include transcribed text and synthesized voice output, are then delivered back to the Agora channel.

The code sets up tools that can be executed locally or passed through the API. This allows the AI to perform specific tasks, such as retrieving data from external sources. The agent processes various message types from OpenAI, such as audio responses, transcription updates, and error messages, and sends them to users through the Agora audio channel, facilitating continuous interaction.

The following figure illustrates the integration topology:

![](/images/voice-sdk/open-ai-Integration-topology.png)

## Prerequisites

<Prerequisites />

## Set up the project

This guide walks you through the core elements of the [Agora Conversational AI Demo](https://github.com/AgoraIO/agora-openai-converse) integrating Agora's Python SDK with OpenAI's Realtime API:

1. Create a new folder for the project:

    ```
    mkdir realtime-agent
    cd realtime-agent/
    ```

1. Create the following structure for your project:

    ```
    /realtime_agent
        ├── __init__.py
        ├── .env
        ├── agent.py
        ├── requirements.txt        
        └── realtimeapi
            ├── __init__.py
            ├── client.py
            ├── messages.py
            └── util.py
    ```

    <Admonition type="info" title="Note">
    This project uses the OpenAI [`realtimeapi-examples`](https://openai.com/api/) package. Download the project and unzip it into your `realtime-agent` folder.
    </Admonition>

    Overview of key files:

    - `agent.py`: The primary script responsible for executing the `RealtimeKitAgent`. It integrates Agora's functionality from the `rtc.py` module and OpenAI's capabilities from the `realtimeapi` package.
    - `rtc.py`: Contains an implementation of the server-side Agora Python Voice SDK.
    - `realtimeapi/`: Contains the classes and methods that interact with OpenAI's Realtime API.

    The [complete code](#complete-integration-code) for `agent.py` is provided at the bottom of this page.

1. Add the following dependencies to the `requirements.txt` file:

    ```
    aiohttp[speedups]
    annotated-types==0.7.0
    anyio==4.4.0
    attrs==23.2.0
    black==24.4.2
    certifi==2024.7.4
    click==8.1.7
    distro==1.9.0
    frozenlist==1.4.1
    h11==0.14.0
    httpcore==1.0.5
    httpx==0.27.0
    idna==3.7
    iniconfig==2.0.0
    multidict==6.0.5
    mypy==1.10.1
    mypy-extensions==1.0.0
    numpy>=1.21.0
    openai==1.37.1
    packaging==24.1
    pathspec==0.12.1
    platformdirs==4.2.2
    pluggy==1.5.0
    protobuf==5.27.2
    psutil==5.9.8
    pydantic==2.8.2
    pydantic_core==2.20.1
    pyaudio>=0.2.11
    pydub==0.25.1
    pyee==12.0.0
    PyJWT==2.8.0
    pytest==8.2.2
    python-dotenv==1.0.1
    ruff==0.5.2
    sniffio==1.3.1
    sounddevice>=0.4.6
    tqdm==4.66.4
    types-protobuf==4.25.0.20240417
    typing_extensions==4.12.2
    watchfiles==0.22.0
    yarl==1.9.4
    agora-python-server-sdk>=2.0.0
    agora-realtime-ai-api==1.0.2
    ```

1. Create the `.env` file and fill in the values for the environment variables:

   ```python
   # Agora RTC app ID and app certificate
   AGORA_APP_ID=
   AGORA_APP_CERT=

   # OpenAI API key for authentication
   OPENAI_API_KEY=
   ```

1. Create a virtual environment and activate it:
   ```bash
   python3 -m venv venv && source venv/bin/activate
   ```

1. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

1. Install Agora realtime API:

    ```bash
    pip3 install agora-realtime-ai-api
    ```


## Implementation

The `RealtimeKitAgent` class integrates Agora's audio communication capabilities with OpenAI's AI services. This class manages audio streams, handles communication with the OpenAI API, and processes AI-generated responses, providing a seamless conversational AI experience.

### Connect to Agora and OpenAI

The `setup_and_run_agent` method sets up the `RealtimeKitAgent` by connecting to an Agora channel using the provided `RtcEngine` and initializing a session with the OpenAI Realtime API client. It sends configuration messages to set up the session and define conversation parameters, such as the system message and output audio format, before starting the agent's operations. The method uses asynchronous execution to handle both listening for the session start and sending conversation configuration updates concurrently. It ensures that the connection is properly managed and cleaned up after use, even in cases of exceptions, early exits, or shutdowns.

<Admonition type="info" title="Note">
  UIDs in the Python SDK are set using a string value. Agora recommends using only numerical values for UID strings to ensure compatibility
  with all Agora products and extensions.
</Admonition>

```python
@classmethod
async def setup_and_run_agent(
    cls,
    *,
    engine: RtcEngine,
    options: RtcOptions,
    inference_config: InferenceConfig,
    tools: ToolContext | None,
) -> None:
    # Create and connect to an Agora channel
    channel = engine.create_channel(options)
    await channel.connect()

    try:
        # Initialize the OpenAI Realtime API client
        async with RealtimeApiClient(
            base_uri="wss://api.openai.com",
            api_key=os.getenv("OPENAI_API_KEY"),
            verbose=False,
        ) as client:
            # Update the session configuration
            await client.send_message(
                messages.SessionUpdate(
                    session=messages.SessionUpdateParams(
                        turn_detection=inference_config.turn_detection,
                        tools=tools.model_description() if tools else None,
                        tool_choice="auto",
                        instructions=inference_config.system_message,
                    )
                )
            )

            # Concurrently wait for the session to start and update the conversation config
            [start_session_message, _] = await asyncio.gather(
                *[
                    anext(client.listen()),
                    client.send_message(
                        messages.UpdateConversationConfig(
                            system_message=inference_config.system_message,
                            output_audio_format=messages.AudioFormats.PCM16,
                            voice=inference_config.voice,
                            tools=tools.model_description() if tools else None,
                            transcribe_input=False,
                        )
                    ),
                ]
            )
            logger.info(
                f"Session started: {start_session_message.session.id} model: {start_session_message.session.model}"
            )

            # Create and run the RealtimeKitAgent
            agent = cls(
                client=client,
                tools=tools,
                channel=channel,
            )
            await agent.run()

    finally:
        # Ensure the Agora engine is destroyed, even if an exception occurs
        engine.destroy()
```

### Initialize the RealtimeKitAgent

The `RealtimeKitAgent` class constructor accepts an OpenAI `RealtimeApiClient`, an optional `ToolContext` for function registration, and an Agora channel for managing audio communication. This setup initializes the agent to process audio streams, registers tools (if provided), and interacts with the AI model.

```python
def __init__(
    self,
    *,
    client: RealtimeApiClient,
    tools: ToolContext | None,
    channel: Channel,
) -> None:
    self.client = client  # OpenAI Realtime API client
    self.tools = tools  # Optional tool context for function registration
    self._client_tool_futures = {}  # For managing asynchronous tool calls
    self.channel = channel  # Agora channel for audio communication
    self.subscribe_user = None  # Will store the user ID we're subscribing to
```

### Launch the Agent

The `run` method orchestrates the main operations of the `RealtimeKitAgent`. It manages audio streaming, processes tasks related to audio input, output, and model messages, and ensures exception handling is in place.

```python
async def run(self) -> None:
    try:
        # Helper function to log unhandled exceptions in tasks
        def log_exception(t: asyncio.Task[Any]) -> None:
            if not t.cancelled() and t.exception():
                logger.error(
                    "unhandled exception",
                    exc_info=t.exception(),
                )
        
        logger.info("Waiting for remote user to join")
        # Wait for a remote user to join the channel
        self.subscribe_user = await wait_for_remote_user(self.channel)
        logger.info(f"Subscribing to user {self.subscribe_user}")
        # Subscribe to the audio of the joined user
        await self.channel.subscribe_audio(self.subscribe_user)

        # Handle user leaving the channel
        async def on_user_left(agora_rtc_conn: RTCConnection, user_id: int, reason: int):
            logger.info(f"User left: {user_id}")
            if self.subscribe_user == user_id:
                self.subscribe_user = None
                logger.info("Subscribed user left, disconnecting")
                await self.channel.disconnect()
                
        self.channel.on("user_left", on_user_left)

        # Set up a future to track when the agent should disconnect
        disconnected_future = asyncio.Future[None]()

        # Handle connection state changes
        def callback(agora_rtc_conn: RTCConnection, conn_info: RTCConnInfo, reason):
            logger.info(f"Connection state changed: {conn_info.state}")
            if conn_info.state == 1:  # Disconnected state
                if not disconnected_future.done():
                    disconnected_future.set_result(None)

        self.channel.on("connection_state_changed", callback)

        # Start tasks for streaming audio and processing messages
        asyncio.create_task(self._stream_input_audio_to_model()).add_done_callback(
            log_exception
        )
        asyncio.create_task(
            self._stream_audio_queue_to_audio_output()
        ).add_done_callback(log_exception)
        asyncio.create_task(self._process_model_messages()).add_done_callback(
            log_exception
        )

        # Wait until the agent is disconnected
        await disconnected_future
        logger.info("Agent finished running")
    except asyncio.CancelledError:
        logger.info("Agent cancelled")
```

### Stream input audio to the AI model

The `_stream_input_audio_to_model` method captures audio frames from the Agora channel and sends them to the OpenAI API client for real-time processing by the AI model.

```python
async def _stream_input_audio_to_model(self) -> None:
    # Wait until we have a subscribed user
    while self.subscribe_user is None:
        await asyncio.sleep(0.1)
    # Get the audio frame stream for the subscribed user
    audio_frames = self.channel.get_audio_frames(self.subscribe_user)
    async for audio_frame in audio_frames:
        try:
            # Send the audio frame to the OpenAI model via the API client
            await self.client.send_audio_data(audio_frame.data)
        except Exception as e:
            logger.error(f"Error sending audio data to model: {e}")
```

### Stream audio from the AI model to the user

The `_stream_audio_queue_to_audio_output` method handles the playback of processed audio data from the AI model. It retrieves audio frames from a queue and sends them to the Agora channel, allowing users to hear AI-generated responses in real-time.

```python
async def _stream_audio_queue_to_audio_output(self) -> None:
    while True:
        # Get the next audio frame from the queue (contains audio data from the model)
        frame = await self.audio_queue.get()
        # Send the frame to the Agora channel for playback to the user
        await self.channel.push_audio_frame(frame)
        await asyncio.sleep(0)  # Allow other tasks to run
```

### Process model messages

The `_process_model_messages` method listens for messages from the OpenAI API client and processes them based on their type. It handles a variety of message types, including audio deltas, transcriptions, and errors.

```python
async def _process_model_messages(self) -> None:
    # Listen for incoming messages from the OpenAI API client
    async for message in self.client.listen():
        # Process each type of message received from the client
        match message:
            case messages.ResponseAudioDelta():
                # Process incoming audio data from the model
                await self.audio_queue.put(base64.b64decode(message.delta))

            case messages.ResponseAudioTranscriptDelta():
                # Handle incoming transcription updates
                logger.info(f"Received text message {message=}")
                await self.channel.chat.send_message(ChatMessage(message=message.model_dump_json(), msg_id=message.item_id))

            case messages.ResponseAudioTranscriptDone():
                # Handle completed transcriptions
                logger.info(f"Text message done: {message=}")
                await self.channel.chat.send_message(ChatMessage(message=message.model_dump_json(), msg_id=message.item_id))

            case messages.InputAudioBufferSpeechStarted():
                # Handle the start of speech in the input audio
                pass
            case messages.InputAudioBufferSpeechStopped():
                # Handle the end of speech in the input audio
                pass
            case messages.InputAudioBufferCommitted():
                # Handle when an input audio buffer is committed
                pass
            case messages.ItemCreated():
                # Handle when a new item is created in the conversation
                pass
            case messages.ResponseCreated():
                # Handle when a new response is created
                pass
            case messages.ResponseOutputItemAdded():
                # Handle when a new output item is added to the response
                pass
            case messages.ResponseContenPartAdded():
                # Handle when a new content part is added to the response
                pass
            case messages.ResponseAudioDone():
                # Handle when the audio response is complete
                pass
            case messages.ResponseContentPartDone():
                # Handle when a content part of the response is complete
                pass
            case messages.ResponseOutputItemDone():
                # Handle when an output item in the response is complete
                pass

            case _:
                # Log any unhandled or unknown message types
                logger.warning(f"Unhandled message {message=}")
```

### Main entry point

The main entry point of the application sets up the Agora RTC engine, configures the options, and launches the RealtimeKitAgent.

```python
if __name__ == "__main__":
    # Load environment variables from .env file
    load_dotenv()
    
    # Parse command line arguments
    options = parse_args_realtimekit()
    logger.info(f"app_id: channel_id: {options['channel_name']}, uid: {options['uid']}")
    
    # Ensure the Agora App ID is set
    if not os.environ.get("AGORA_APP_ID"):
        raise ValueError("Need to set environment variable AGORA_APP_ID")
    
    # Run the RealtimeKitAgent
    asyncio.run(
        RealtimeKitAgent.entry_point(
            # Initialize the RtcEngine with Agora credentials
            engine=RtcEngine(appid=os.environ.get("AGORA_APP_ID"), appcert=os.environ.get("AGORA_APP_CERT")),
            # Configure RTC options
            options=RtcOptions(
                channel_name=options['channel_name'],
                uid=options['uid'],
                sample_rate=SAMPLE_RATE,
                channels=CHANNELS
            ),
            # Configure inference settings
            inference_config=InferenceConfig(
                # Set up the AI assistant's behavior
                system_message="""\
You are a helpful assistant. If asked about the weather make sure to use the provided tool to get that information. \
If you are asked a question that requires a tool, say something like "working on that" and dont provide a concrete response \
until you have received the response to the tool call.\
""",
                voice=messages.Voices.Alloy,
                # Configure voice activity detection
                turn_detection=messages.ServerVAD(
                    threshold=0.5,
                    prefix_padding_ms=500,
                    suffix_padding_ms=200,
                ),
            ),
        )
    )
```

### Complete integration code

The `agent.py` imports key classes from `rtc.py`, which implements the server-side Agora Python Voice SDK, facilitating communication and managing audio streams. 

<details>
<summary>Complete code for `agent.py`</summary>
<CodeBlock showLineNumbers language="python">
{`import abc
import asyncio
import base64
import json
import logging
import os
from builtins import anext
from typing import Any, Callable, assert_never

from agora.rtc.rtc_connection import RTCConnection, RTCConnInfo
from attr import dataclass
from dotenv import load_dotenv
from pydantic import BaseModel

from realtime_agent.realtimeapi import messages
from realtime_agent.realtimeapi.client import RealtimeApiClient
from realtime_agent.realtimeapi.util import SAMPLE_RATE,CHANNELS

from .agora.rtc import Channel, ChatMessage, RtcEngine, RtcOptions
from .parse_args import parse_args_realtimekit

logger = logging.getLogger(__name__)

async def wait_for_remote_user(channel: Channel) -> int:
    remote_users = list(channel.remote_users.keys())
    if len(remote_users) > 0:
        return remote_users[0]
    
    future = asyncio.Future[int]()
    
    channel.once("user_joined", lambda conn, user_id: future.set_result(user_id))
    
    try:
        remote_user = await future
        return remote_user
    except Exception as e:
        logger.error(f"Error waiting for remote user: {e}")
        raise

@dataclass(frozen=True, kw_only=True)
class InferenceConfig:
    system_message: str | None = None
    turn_detection: messages.TurnDetection | None = None # MARK: CHECK!
    voice: messages.Voices | None = None


@dataclass(frozen=True, kw_only=True)
class LocalFunctionToolDeclaration:
    """Declaration of a tool that can be called by the model, and runs a function locally on the tool context."""

    name: str
    description: str
    parameters: dict[str, Any]
    function: Callable[..., Any]

    def model_description(self) -> dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters,
            },
        }


@dataclass(frozen=True, kw_only=True)
class PassThroughFunctionToolDeclaration:
    """Declaration of a tool that can be called by the model."""

    name: str
    description: str
    parameters: dict[str, Any]

    def model_description(self) -> dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters,
            },
        }


ToolDeclaration = LocalFunctionToolDeclaration | PassThroughFunctionToolDeclaration


@dataclass(frozen=True, kw_only=True)
class LocalToolCallExecuted:
    json_encoded_output: str


@dataclass(frozen=True, kw_only=True)
class ShouldPassThroughToolCall:
    decoded_function_args: dict[str, Any]


ExecuteToolCallResult = LocalToolCallExecuted | ShouldPassThroughToolCall


class ToolContext(abc.ABC):
    _tool_declarations: dict[str, ToolDeclaration]

    def __init__(self) -> None:
        # TODO should be an ordered dict
        self._tool_declarations = {}

    def register_function(
        self,
        *,
        name: str,
        description: str = "",
        parameters: dict[str, Any],
        fn: Callable[..., Any],
    ) -> None:
        self._tool_declarations[name] = LocalFunctionToolDeclaration(
            name=name, description=description, parameters=parameters, function=fn
        )

    def register_client_function(
        self,
        *,
        name: str,
        description: str = "",
        parameters: dict[str, Any],
    ) -> None:
        self._tool_declarations[name] = PassThroughFunctionToolDeclaration(
            name=name, description=description, parameters=parameters
        )

    async def execute_tool(
        self, tool_name: str, encoded_function_args: str
    ) -> ExecuteToolCallResult | None:
        tool = self._tool_declarations.get(tool_name)
        if not tool:
            return None

        args = json.loads(encoded_function_args)
        assert isinstance(args, dict)

        if isinstance(tool, LocalFunctionToolDeclaration):
            logger.info(f"Executing tool {tool_name} with args {args}")
            result = await tool.function(**args)
            logger.info(f"Tool {tool_name} executed with result {result}")
            return LocalToolCallExecuted(json_encoded_output=json.dumps(result))

        if isinstance(tool, PassThroughFunctionToolDeclaration):
            return ShouldPassThroughToolCall(decoded_function_args=args)

        assert_never(tool)

    def model_description(self) -> list[dict[str, Any]]:
        return [v.model_description() for v in self._tool_declarations.values()]


class ClientToolCallResponse(BaseModel):
    tool_call_id: str
    result: dict[str, Any] | str | float | int | bool | None = None


@dataclass(frozen=True, kw_only=True)
class RTCConfigure:
    APP_ID: str
    TOKEN: str = ""

class RealtimeKitAgent:
    engine: RtcEngine
    channel: Channel
    client: RealtimeApiClient
    audio_queue: asyncio.Queue[bytes] = asyncio.Queue()
    message_queue: asyncio.Queue[messages.ResponseAudioTranscriptDelta] = asyncio.Queue()
    message_done_queue: asyncio.Queue[messages.ResponseAudioTranscriptDone] = asyncio.Queue()
    tools: ToolContext | None = None

    _client_tool_futures: dict[str, asyncio.Future[ClientToolCallResponse]]

    @classmethod
    async def setup_and_run_agent(
        cls,
        *,
        engine: RtcEngine,
        options: RtcOptions,
        inference_config: InferenceConfig,
        tools: ToolContext | None,
    ) -> None:
        channel = engine.create_channel(options)
        await channel.connect()

        try:
            async with RealtimeApiClient(
                base_uri=os.getenv("REALTIME_API_BASE_URI", "wss://api.openai.com"),
                api_key=os.getenv("OPENAI_API_KEY"),
                verbose=False,
            ) as client:
                await client.send_message(
                    messages.SessionUpdate(
                        session=messages.SessionUpdateParams(
                            #MARK: check this
                            turn_detection=inference_config.turn_detection,
                            tools=tools.model_description() if tools else None,
                            tool_choice="auto",
                            instructions=inference_config.system_message,
                        )
                    )
                )

                [start_session_message, _] = await asyncio.gather(
                    *[
                        anext(client.listen()),
                        client.send_message(
                            messages.UpdateConversationConfig(
                                system_message=inference_config.system_message,
                                output_audio_format=messages.AudioFormats.PCM16,
                                voice=inference_config.voice,
                                tools=tools.model_description() if tools else None,
                                transcribe_input=False,
                            )
                        ),
                    ]
                )
                # assert isinstance(start_session_message, messages.StartSession)
                logger.info(
                    f"Session started: {start_session_message.session.id} model: {start_session_message.session.model}"
                )

                agent = cls(
                    client=client,
                    tools=tools,
                    channel=channel,
                )
                await agent.run()

        finally:
            engine.destroy()

    @classmethod
    async def entry_point(
        cls,
        *,
        engine: RtcEngine,
        options: RtcOptions,
        inference_config: InferenceConfig,
        tools: ToolContext | None = None,
    ) -> None:
        await cls.setup_and_run_agent(
            engine=engine, options=options, inference_config=inference_config, tools=tools
        )

    def __init__(
        self,
        *,
        client: RealtimeApiClient,
        tools: ToolContext | None,
        channel: Channel,
    ) -> None:
        self.client = client
        self.tools = tools
        self._client_tool_futures = {}
        self.channel = channel
        self.subscribe_user = None

    async def run(self) -> None:
        try:
            def log_exception(t: asyncio.Task[Any]) -> None:
                if not t.cancelled() and t.exception():
                    logger.error(
                        "unhandled exception",
                        exc_info=t.exception(),
                    )
            
            logger.info("Waiting for remote user to join")
            self.subscribe_user = await wait_for_remote_user(self.channel)
            logger.info(f"Subscribing to user {self.subscribe_user}")
            await self.channel.subscribe_audio(self.subscribe_user)

            async def on_user_left(agora_rtc_conn: RTCConnection, user_id: int, reason: int):
                logger.info(f"User left: {user_id}")
                if self.subscribe_user == user_id:
                    self.subscribe_user = None
                    logger.info("Subscribed user left, disconnecting")
                    await self.channel.disconnect()
                    
            self.channel.on("user_left", on_user_left)

            disconnected_future = asyncio.Future[None]()

            def callback(agora_rtc_conn: RTCConnection, conn_info: RTCConnInfo, reason):
                logger.info(f"Connection state changed: {conn_info.state}")
                if conn_info.state == 1:
                    if not disconnected_future.done():
                        disconnected_future.set_result(None)

            self.channel.on("connection_state_changed", callback)

            asyncio.create_task(self._stream_input_audio_to_model()).add_done_callback(
                log_exception
            )
            asyncio.create_task(
                self._stream_audio_queue_to_audio_output()
            ).add_done_callback(log_exception)

            asyncio.create_task(self._process_model_messages()).add_done_callback(
                log_exception
            )

            await disconnected_future
            logger.info("Agent finished running")
        except asyncio.CancelledError:
            logger.info("Agent cancelled")

    async def _stream_input_audio_to_model(self) -> None:
        while self.subscribe_user is None:
            await asyncio.sleep(0.1)
        audio_frames = self.channel.get_audio_frames(self.subscribe_user)
        async for audio_frame in audio_frames:
            try:
                # send the frame to the model via the API client
                await self.client.send_audio_data(audio_frame.data)
            except Exception as e:
                logger.error(f"Error sending audio data to model: {e}")

    async def _stream_audio_queue_to_audio_output(self) -> None:
        while True:
            # audio queue contains audio data from the model, send it the end-user via our local audio source
            frame = await self.audio_queue.get()
            await self.channel.push_audio_frame(frame)
            await asyncio.sleep(0)  # allow other tasks to run         
        

    async def _process_model_messages(self) -> None:
        async for message in self.client.listen():
            # logger.info(f"Received message {message=}")
            match message:
                case messages.ResponseAudioDelta():
                    # logger.info("Received audio message")
                    await self.audio_queue.put(base64.b64decode(message.delta))

                case messages.ResponseAudioTranscriptDelta():
                    logger.info(f"Received text message {message=}")
                    await self.channel.chat.send_message(ChatMessage(message=message.model_dump_json(), msg_id=message.item_id))

                case messages.ResponseAudioTranscriptDone():
                    logger.info(f"Text message done: {message=}")
                    await self.channel.chat.send_message(ChatMessage(message=message.model_dump_json(), msg_id=message.item_id))

                # case messages.MessageAdded():        
                    # pass
                case messages.InputAudioBufferSpeechStarted():
                    pass
                case messages.InputAudioBufferSpeechStopped():
                    pass
                #  InputAudioBufferCommitted
                case messages.InputAudioBufferCommitted():
                    pass
                # case messages.ServerAddMessage():
                    # pass
                # ItemCreated
                case messages.ItemCreated():
                    pass
                # ResponseCreated
                case messages.ResponseCreated():
                    pass

                # ResponseOutputItemAdded
                case messages.ResponseOutputItemAdded():
                    pass

                # ResponseContenPartAdded
                case messages.ResponseContenPartAdded():
                    pass
                # ResponseAudioDone
                case messages.ResponseAudioDone():
                    pass
                # ResponseContentPartDone
                case messages.ResponseContentPartDone():
                    pass
                # ResponseOutputItemDone
                case messages.ResponseOutputItemDone():
                    pass
                case _:
                    logger.warning(f"Unhandled message {message=}")

async def shutdown(loop, signal=None):
    """Gracefully shut down the application."""
    if signal:
        logger.info(f"Received exit signal {signal.name}...")
    
    tasks = [t for t in asyncio.all_tasks() if t is not asyncio.current_task()]
    
    logger.info(f"Cancelling {len(tasks)} outstanding tasks")
    for task in tasks:
        task.cancel()

    await asyncio.gather(*tasks, return_exceptions=True)
    loop.stop()

if __name__ == "__main__":
    load_dotenv()
    
    options = parse_args_realtimekit()
    logger.info(f"app_id: channel_id: {options['channel_name']}, uid: {options['uid']}")
    
    if not os.environ.get("AGORA_APP_ID") :
        raise ValueError("Need to set environment variable AGORA_APP_ID")
    
    asyncio.run(
        RealtimeKitAgent.entry_point(
            engine=RtcEngine(appid=os.environ.get("AGORA_APP_ID"), appcert=os.environ.get("AGORA_APP_CERT")),
            options=RtcOptions(
                channel_name=options['channel_name'],
                uid=options['uid'],
                sample_rate=SAMPLE_RATE,
                channels=CHANNELS
            ),
            inference_config=InferenceConfig(
                system_message="""\
You are a helpful assistant. If asked about the weather make sure to use the provided tool to get that information. \\
If you are asked a question that requires a tool, say something like "working on that" and dont provide a concrete response \\
until you have received the response to the tool call.\\
""",
                voice=messages.Voices.Alloy,
                turn_detection=messages.ServerVAD(
                    threshold=0.5,
                    prefix_padding_ms=500,
                    suffix_padding_ms=200,
                ),
            ),
        )
    )
`}
</CodeBlock>
</details>

## Test the code

1. **Update the values for** `AGORA_APP_ID`, `AGORA_APP_CERT`, **and** `OPENAI_API_KEY` **in the project's** `.env` **file**.  

   This step ensures that the necessary credentials for Agora and OpenAI are correctly configured in your project.

2. **Execute the following command to run the demo**:

   ```bash
   python3 agent.py --channel_name=your_channel_name --uid=your_user_id
   ```

   This command launches the `agent.py` script, initializing the Agora channel and the OpenAI API connection. Replace `your_channel_name` with the desired channel name and `your_user_id` with a unique user ID.

## Reference

This section contains additional information or links to relevant documentation that complements the current page or explains other aspects of the product.

- Checkout the [Demo project on GitHub](https://github.com/AgoraIO/agora-openai-converse)
- [API reference for `rtc.py`](https://api-reference-git-python-voice-implementation-agora-gdxe.vercel.app/voice-sdk/python/rtc-py-api.html)
- [Voice calling quickstart (Python)](/voice-calling/get-started/get-started-sdk?platform=python)