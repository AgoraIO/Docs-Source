---
title: OpenAI Realtime API
sidebar_position: 2
platform_selector: false
description: >
 Integrate OpenAI Realtime MLLM into Conversational AI Engine.
---

import ParameterList, { Parameter } from '@site/src/components/rest-api/ParameterList';

OpenAI Realtime provides multimodal large language model capabilities with real-time audio processing, enabling natural voice conversations without separate ASR/TTS components.

### Enable MLLM

To enable MLLM functionality, set `enable_mllm` to `true` under `advanced_features`.

```json
{
 "advanced_features": {
   "enable_mllm": true
 }
}
```

### Sample configuration

The following example shows a starting `mllm` parameter configuration you can use when you [Start a conversational AI agent](../../rest-api/join).

```json
{
  "mllm": {
    "url": "wss://api.openai.com/v1/realtime",
    "api_key": "<openai_api_key>",
    "params": {
      "model": "gpt-4o-realtime-preview",
      "voice": "coral",
      "instructions": "You are a Conversational AI Agent, developed by Agora.",
      "input_audio_transcription": {
        "language": "<language>",
        "model": "gpt-4o-mini-transcribe",
        "prompt": "expect words related to real-time engagement"
      }
    },
    "max_history": 50,
    "greeting_message": "<greetings>",
    "output_modalities": ["text", "audio"],
    "vendor": "openai",
    "style": "openai"
  }
}
```

### Key parameters

<ParameterList title="mllm" required={true}>
  <Parameter name="url" type="string" required={true}>  
  The WebSocket URL for OpenAI Realtime API. 
  </Parameter>
  <Parameter name="api_key" type="string" required={true}>
  The API key used for authentication. Get your API key from the [OpenAI Console](https://platform.openai.com/api-keys).
  </Parameter>
  <Parameter name="params" type="object" required={false}>
    Additional configuration parameters for the OpenAI Realtime API.
  
    <Parameter name="model" type="string" required={false}>
    The model identifier. 
    </Parameter>
    
    <Parameter name="voice" type="string" required={false}>
    The voice identifier for audio output. 
    </Parameter>
    
    <Parameter name="instructions" type="string" required={false}>
    System instructions that define the assistant's behavior and personality.
    </Parameter>
    
    <Parameter name="input_audio_transcription" type="object" required={false}>
    Configuration for audio input transcription.
    
      <Parameter name="language" type="string" required={false}>
      The language code for transcription (For example, "en", "es", "fr").
      </Parameter>
      
      <Parameter name="model" type="string" required={false}>
      The transcription model to use. 
      </Parameter>
      
      <Parameter name="prompt" type="string" required={false}>
      Context prompt to improve transcription accuracy.
      </Parameter>
    </Parameter>
  </Parameter>
  <Parameter name="max_history" type="integer" required={false}>
  The number of conversation history messages to maintain. Cannot exceed the model's context window.
  </Parameter>
  <Parameter name="greeting_message" type="string" required={false}>
  Initial message the agent speaks when a user joins the channel.
  </Parameter>
  <Parameter name="output_modalities" type="array[string]" required={false}>
  Output format options: `["text", "audio"]` for both text and voice responses.
  </Parameter>
  <Parameter name="vendor" type="string" required={false}>
  MLLM provider identifier. Set to `openai` for OpenAI Realtime API.
  </Parameter>
  <Parameter name="style" type="string" required={false}>
  API request style. Set to `openai` for OpenAI Realtime API format.
  </Parameter>
</ParameterList>

For comprehensive API reference, real-time capabilities, and detailed parameter descriptions, see the [OpenAI Realtime API documentation](https://platform.openai.com/docs/guides/realtime).
