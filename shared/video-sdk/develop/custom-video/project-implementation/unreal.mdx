<PlatformWrapper platform="unreal">

### Initialize MediaEngine

Before implementing custom video features, obtain the `MediaEngine` interface from the initialized `RtcEngine`:

```cpp
void InitAgoraEngine(FString APP_ID, FString TOKEN, FString CHANNEL_NAME)
{
    // Initialize RtcEngine context and event handler
    agora::rtc::RtcEngineContext RtcEngineContext;
    UserRtcEventHandler = MakeShared<FUserRtcEventHandler>(this);
    std::string StdStrAppId = TCHAR_TO_UTF8(*APP_ID);
    RtcEngineContext.appId = StdStrAppId.c_str();
    RtcEngineContext.eventHandler = UserRtcEventHandler.Get();
    RtcEngineContext.channelProfile = agora::CHANNEL_PROFILE_TYPE::CHANNEL_PROFILE_LIVE_BROADCASTING;
    
    // Initialize the RtcEngine
    int ret = AgoraUERtcEngine::Get()->initialize(RtcEngineContext);
    
    // Query for the MediaEngine interface
    int ret = AgoraUERtcEngine::Get()->queryInterface(INTERFACE_ID_TYPE::AGORA_IID_MEDIA_ENGINE, (void**)&MediaEngineManager);
}
```

<Admonition type="info" title="Note">
The MediaEngine is not created directly. Instead, it's obtained as an interface from the initialized RtcEngine using the `queryInterface` method with `AGORA_IID_MEDIA_ENGINE`.
</Admonition>

### Custom video capture

The following figure shows the workflow you implement to capture and stream a custom video source in your <Vpl k="CLIENT"/>.

<details>
<summary>Custom video capture</summary>

![API call sequence](/images/video-sdk/custom-video-capture-unreal.svg)
</details>

Take the following steps to implement this workflow:

1. **Set up the external video source**

    To use custom video frames instead of the camera feed, configure the SDK to accept external video data.

    The following code enables the external video source mode and specifies the type as `VIDEO_FRAME`, indicating you will push raw pixel data to the SDK.

    ```cpp
    void SetExternalVideoSource()
    {
        agora::rtc::SenderOptions sendoptions;
        int ret = MediaEngineManager->setExternalVideoSource(true, false, agora::media::EXTERNAL_VIDEO_SOURCE_TYPE::VIDEO_FRAME, sendoptions);
        UBFL_Logger::Print(FString::Printf(TEXT("%s setExternalVideoSource ret %d"), *FString(FUNCTION_MACRO), ret), LogMsgViewPtr);
    }
    ```

2. **Join a channel**

    Enable audio and video, set the client role, and join the channel.

    ```cpp
    void JoinChannel()
    {
        AgoraUERtcEngine::Get()->enableAudio();
        AgoraUERtcEngine::Get()->enableVideo();
        AgoraUERtcEngine::Get()->setClientRole(CLIENT_ROLE_BROADCASTER);
        int ret = AgoraUERtcEngine::Get()->joinChannel(TCHAR_TO_UTF8(*Token), TCHAR_TO_UTF8(*ChannelName), "", 0);
    }
    ```

3. **Implement custom video capture**

    Set up a callback to capture frames from Unreal Engine's rendering pipeline. Register for the back buffer ready event to capture rendered frames.

    ```cpp
    void InitAgoraWidget(FString APP_ID, FString TOKEN, FString CHANNEL_NAME)
    {
        // ... other initialization code ...
        
        // Register for back buffer ready callback
        if (FSlateApplication::IsInitialized())
        {
            eventId = FSlateApplication::Get().GetRenderer()->OnBackBufferReadyToPresent().AddUObject(this, &UCustomCaptureVideoScene::OnBackBufferReady_RenderThread);
        }
    }
    ```

4. **Push video frames**

    Capture frames from Unreal Engine's rendering pipeline on the render thread, convert them to raw BGRA pixel format, and send them to the Agora SDK as external video frames.

    <Admonition type="info" title="Timestamp Sync">
    To synchronize audio and video streams, use system timestamp for the `timestamp` field in the `ExternalVideoFrame`.
    </Admonition>

    ```cpp
    void OnBackBufferReady_RenderThread(SWindow& window, const FTexture2DRHIRef& BackBuffer)
    {
        FRHICommandListImmediate& RHICmdList = FRHICommandListExecutor::GetImmediateCommandList();
        auto width = BackBuffer->GetSizeX();
        auto height = BackBuffer->GetSizeY();
        FIntRect Rect(0, 0, BackBuffer->GetSizeX(), BackBuffer->GetSizeY());
        TArray<FColor> Data;

        RHICmdList.ReadSurfaceData(BackBuffer, Rect, Data, FReadSurfaceDataFlags());
        
        if (UserExternalVideoFrame == nullptr)
        {
            UserExternalVideoFrame = new agora::media::base::ExternalVideoFrame();
        }
        
        // Configure the video frame
        UserExternalVideoFrame->type = agora::media::base::ExternalVideoFrame::VIDEO_BUFFER_TYPE::VIDEO_BUFFER_RAW_DATA;
        UserExternalVideoFrame->format = agora::media::base::VIDEO_PIXEL_FORMAT::VIDEO_PIXEL_BGRA;
        UserExternalVideoFrame->stride = BackBuffer->GetSizeX();
        UserExternalVideoFrame->height = BackBuffer->GetSizeY();
        UserExternalVideoFrame->cropLeft = 10;
        UserExternalVideoFrame->cropTop = 10;
        UserExternalVideoFrame->cropRight = 10;
        UserExternalVideoFrame->cropBottom = 10;
        UserExternalVideoFrame->rotation = 0;
        UserExternalVideoFrame->timestamp = getTimeStamp();
        
        if (UserExternalVideoFrame->buffer == nullptr)
        {
            UserExternalVideoFrame->buffer = (uint8*)FMemory::Malloc(BackBuffer->GetSizeX() * BackBuffer->GetSizeY() * 4);
        }
        
        if (Data.Num() > 4)
        {
            FMemory::Memcpy(UserExternalVideoFrame->buffer, Data.GetData(), BackBuffer->GetSizeX() * BackBuffer->GetSizeY() * 4);
            if (MediaEngineManager != nullptr)
            {
                // Push the video frame to the SDK
                MediaEngineManager->pushVideoFrame(UserExternalVideoFrame);
            }
        }
    }

    std::time_t getTimeStamp()
    {
        std::chrono::time_point<std::chrono::system_clock, std::chrono::milliseconds> tp = 
            std::chrono::time_point_cast<std::chrono::milliseconds>(std::chrono::system_clock::now());
        std::time_t timestamp = tp.time_since_epoch().count();
        return timestamp;
    }
    ```

    <Admonition type="info" title="Information">
    The sample code demonstrates converting Unreal's BGRA format to raw video data. Agora video capture supports pushing external video frames in other formats; refer to `VIDEO_PIXEL_FORMAT`.
    </Admonition>

5. **Cleanup**

    When finished unregister the callback and clean up resources.

    ```cpp
    void NativeDestruct()
    {
        Super::NativeDestruct();
        
        // Remove the back buffer callback
        FSlateApplication::Get().GetRenderer()->OnBackBufferReadyToPresent().Remove(eventId);
        
        UnInitAgoraEngine();
    }

    void UnInitAgoraEngine()
    {
        if (AgoraUERtcEngine::Get() != nullptr)
        {
            AgoraUERtcEngine::Get()->leaveChannel();
            AgoraUERtcEngine::Get()->unregisterEventHandler(UserRtcEventHandler.Get());
            AgoraUERtcEngine::Release();
            MediaEngineManager = nullptr;
        }
    }
    ```

### Custom video rendering

To implement custom video rendering in your <Vpl k="CLIENT" />, refer to the following steps:

1. Set up `onCaptureVideoFrame` or `onRenderVideoFrame` callback to obtain the video data to be played.
2. Implement video rendering and playback yourself.

</PlatformWrapper>
