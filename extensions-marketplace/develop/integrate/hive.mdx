---
title: "Hive"
sidebar_position: 6
type: docs
description: >
    Use Hive Visual Moderation API in Agora SDK to empower your app with accurate content moderation
---
export const toc = [{}];

Hive content moderation enables you to monitor livestream for inappropriate content such as nudity, violence, drugs, and hate. This page shows you how to use Hive Visual Moderation API in Agora's Video SDK for accurate content moderation of livestreams.

<PlatformWrapper notAllowed="android,ios,macos,windows">
This extension is not provided for this platform.
</PlatformWrapper>
<PlatformWrapper notAllowed="web,flutter,react-native">


## Understand the tech

Hive Visual Moderation API and Agora SDK work together as follows:

![](/images/extensions-marketplace/hive-diagram.png)

1. The video stream from the channel is encrypted and transmitted to the Agora proxy server.
2. The proxy server encapsulates the video stream information, encrypts it, and transmits it to Hive, a third-party moderation service provider.
3. The moderation service provider returns the review results to your callback server.
4. You implement your own business logic based on the review results.

The server-server transmission scheme simplifies monitoring and ensures security of the service. In addition, it gives you complete control over the business logic. When your business server receives a review result indicating content violation, you can close the channel, show a prompt in the UI, ban the user, or deduct points for the client.

## Prerequisites

In order to set up Hive content moderation you must have:

- Implemented <Link to="../../../interactive-live-streaming/get-started/get-started-sdk"><Vg k="GET_STARTED"/> for
  <Vg k="ILS" /></Link> using <Vg k="VSDK" /> `4.2.0` or greater.
- Activated <Link to="{{Global.AGORA_CONSOLE_URL}}/marketplace/extension/introduce?serviceName=hive">Hive Visual Moderation API</Link> on <Vg k="CONSOLE" />.
- Configured Hive Visual Moderation API by sending an email to support@agora.io with the following information:
    - **App ID**: Your App ID from <Vg k="CONSOLE"/>.
    - **Detection interval**: The time interval between capturing content from a video stream and submitting it for review.
    - **Callback server address**:	The address of your `HTTPS` callback server that you use to receive review
  results from Hive. The review effect starts automatically when the user joins the channel and continues for the duration of the call.

## Receive review results from Hive

To use Hive, you set up an `HTTPS` business server that receives review result callbacks from the moderation service provider. Hive returns review results to your callback URL in the form of an `HTTPS` request. The request body contains the `classes` array under `output`, showing the likelihood `score` for each type of content. The following is an example of a review result callback from Hive:

```json
{
  "id": "dd52c0d0-9ec7-11ea-98a3-4b92424b8366",
  "project_id": 18416,
  "metadata": null,
  "status": [
    {
      "status": {
        "code": "0",
        "message": "SUCCESS"
      },
      "response": {
        "input": {
          "hash": "a71690e72e5cabafc73dc2717818fc6d",
          "inference_client_version": "4.0.8",
          "model": "textmod_svs_2langs_release_test2",
          "model_type": "TEXT_CLASSIFICATION",
          "model_version": 1,
          "text": "test data",
          "id": "2846b170-a079-11ea-b023-6bfe10549ae0",
          "created_on": "2020-05-28T00:21:21.543Z",
          "user_id": 6994,
          "project_id": 18416,
          "charge": "0.00100",
          "media": {
            "mimetype": null
          },
          "config_version": 1,
          "config_tag": "default"
        },
        "output": [
          {
            "time": 0,
            "classes": [
              {
                "class": "suggestive",
                "score": 0.0010710965501463823
              },
              {
                "class": "sexual",
                "score": 0.0027024835147116755
              },
              {
                "class": "no_sexual",
                "score": 0.9962264199351419
              },
              {
                "class": "self_harm",
                "score": 0.0002235677990901144
              },
              {
                "class": "violence",
                "score": 0.0007041907670250179
              },
              {
                "class": "no_violence",
                "score": 0.999072241433885
              },
              {
                "class": "yes_spam",
                "score": 0.000881996410983426
              },
              {
                "class": "no_spam",
                "score": 0.9991180035890167
              }
            ],
            "start_char_index": 0,
            "end_char_index": 16
          }
        ]
      }
    }
  ],
  "resent_on": "2020-05-28T00:28:02.718Z",
  "resent_by": "api",
  "from_cache": false
}
```
After the review results are received from Hive at the specified callback URL, you can process and analyze the results using the [Visual Content Moderation subclass](https://docs.thehive.ai/docs/visual-content-moderation). Here's an example of how you can do this:

```java
import org.json.JSONArray;
import org.json.JSONException;
import org.json.JSONObject;

// Parse the review results from the request body
JSONObject reviewResults = new JSONObject(requestBody);
JSONArray status = reviewResults.getJSONArray("status");
JSONObject response = status.getJSONObject(0).getJSONObject("response");
JSONArray output = response.getJSONArray("output");
JSONObject outputObj = output.getJSONObject(0);

// Retrieve the classes from the output
JSONArray classes = outputObj.getJSONArray("classes");

// Define the thresholds for each class
JSONObject thresholds = new JSONObject();
thresholds.put("suggestive", 0.1);
thresholds.put("sexual", 0.2);
thresholds.put("self_harm", 0.1);
thresholds.put("violence", 0.1);
thresholds.put("spam", 0.1);

// Analyze the classes using the thresholds
for (int i = 0; i < classes.length(); i++) {
    JSONObject c = classes.getJSONObject(i);
    String className = c.getString("class");
    double score = c.getDouble("score");
    double threshold = thresholds.getDouble(className);
    if (score > threshold) {
        System.out.println("The response contains sensitive material of type " + className + " with score " + score + ".");
    }
}
```

</PlatformWrapper>
