<PlatformWrapper platform="windows">

### Implement the user interface

To enable or disable processing of captured raw video data, add a button to the user interface:

    1. Go to menu **View** > **Other Windows** > **Resource View**.
    
        If the **Resource View** window isn't the top-most window, select the **Resource View** tab to bring it to the top.
    
    1. In **Resource View**, go to **AgoraImplementation.rc** > **Dialog** and double-click `IDD_AGORAIMPLEMENTATION_DIALOG`.
        
        The resource opens inside the **Dialog Editor**. 

    1. Click **View** > **ToolBox**. The **Toolbox** opens.

    1. From **ToolBox**, drag **Button** to the surface of the **Dialog Editor**.

    1. In **Properties**, update the **Caption** field to `Zoom In`.

### Handle the system logic

This sections describes the steps required to use the relevant libraries and declare the necessary variables, and set up access to the UI elements.

1.  **Define a variable to manage video processing**

        From **Solution Explorer**, open `AgoraImplementationDlg.cpp` and define below variable globally:
        
        ```cpp
        bool isZoomed = false;
        ```
2.    **Start and stop video processing through UI**
    
        When a user presses the button `Zoom In`, it enables video processing to capture the video frame and procees it for zooming in. This will be a flip button, you can flip it for `Zoom In` and `Zoom Out`. To implement this workflow, in **Dialog Editor**, double-click **Zom In**. **Dialog Editor** automatically creates and opens an event listener for you. Add the following code to the event listener you just created.
   
        ```cpp
        // Toggle the zoom state
        isZoomed = !isZoomed;

        // Get a handle to the parent control of the button
        CWnd* pParent = GetDlgItem(IDC_BUTTON4);

        // Cast the control to a CButton object
        CButton* pButtonCtrl = static_cast<CButton*>(pParent);

        // Set the button text based on the zoom state
        if (isZoomed)
        {
            pButtonCtrl->SetWindowText(_T("Zoom Out"));
        }
        else
        {
            pButtonCtrl->SetWindowText(_T("Zoom In"));
        }
        ```
### Implement processing of raw video and audio data

To register and use video and audio frame observers in your <Vpl k="CLIENT" />, take the following steps:

1.  **Set up the video and audio frame observer**
    1. Implement video and audio frame observer interface `IVideoFrameObserver` and `IAudioFrameObserver`. 
    Put below code in `AgoraImplementationDlg.h` before the class declarion of `AgoraEventHandler`:

        ```cpp
        class CustomVideoFrameObserver : public IVideoFrameObserver {
        public:
            CustomVideoFrameObserver() : originalYBuffer(nullptr), originalUBuffer(nullptr), originalVBuffer(nullptr) {}
            ~CustomVideoFrameObserver() {
                delete[] originalYBuffer;
                delete[] originalUBuffer;
                delete[] originalVBuffer;
            }
            virtual bool CustomVideoFrameObserver::onCaptureVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onSecondaryCameraCaptureVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onSecondaryPreEncodeCameraVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onScreenCaptureVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onPreEncodeScreenVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onSecondaryScreenCaptureVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onSecondaryPreEncodeScreenVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onRenderVideoFrame(const char* channelId, rtc::uid_t remoteUid, VideoFrame& videoFrame)override;
            virtual bool onPreEncodeVideoFrame(VideoFrame& videoFrame)override;
            virtual bool onMediaPlayerVideoFrame(VideoFrame& videoFrame, int mediaPlayerId)override;
            virtual bool onTranscodedVideoFrame(VideoFrame& videoFrame)override;
            virtual VIDEO_FRAME_PROCESS_MODE CustomVideoFrameObserver::getVideoFrameProcessMode()override;
        private:
            uint8_t* originalYBuffer;
            uint8_t* originalUBuffer;
            uint8_t* originalVBuffer;
        };

        class CustomAudioFrameObserver: public IAudioFrameObserver {
            virtual bool onPlaybackAudioFrameBeforeMixing(const char* channelId, rtc::uid_t uid, AudioFrame& audioFrame)override;
            virtual bool onRecordAudioFrame(const char* channelId, AudioFrame& audioFrame)override;
            virtual bool onPlaybackAudioFrame(const char* channelId, AudioFrame& audioFrame)override;
            virtual bool onMixedAudioFrame(const char* channelId, AudioFrame& audioFrame)override;
            virtual bool onEarMonitoringAudioFrame(AudioFrame& audioFrame)override;
            virtual int getObservedAudioFramePosition()override;
            virtual AudioParams getPlaybackAudioParams()override;
            virtual AudioParams getRecordAudioParams()override;
            virtual AudioParams getMixedAudioParams()override;
            virtual AudioParams getEarMonitoringAudioParams()override;
        };
        ```

    1. Add the video and audio frame observers object:

        In `AgoraImplementationDlg.h`, add the following code after `AgoraEventHandler agoraEventHandler;`

        ```cpp
        // Video and audio frame observers objects
        CustomVideoFrameObserver* video_frame_observer = new CustomVideoFrameObserver();
        CustomAudioFrameObserver* audio_frame_observer = new CustomAudioFrameObserver();
        ```
    1. Provide member functions definitions you declared in `CustomVideoFrameObserver` and `CustomAudioFrameObserver`. In `AgoraImplementationDlg.cpp`, add the following before `CAboutDlg()`:

        1. *Implement video frame observer callbacks*:
        
            `IVideoFrameObserver` gives you access to each local video frame after it is captured and access to each remote video frame before it is played back. In this example, your modify the captured video frame buffer to crop and scale the frame and play a zoomed-in version of the video. 

            ```cpp
            // IVideoFrameObserver Implementation
            // "onCaptureVideoFrame()" is actually responsible for catching each frame on registering the video frame observer. 
            bool CustomVideoFrameObserver::onCaptureVideoFrame(VideoFrame& videoFrame)
            {
                if (isZoomed) {

                    int originalWidth = videoFrame.width;
                    int originalHeight = videoFrame.height;

                    int newWidth = originalWidth / 2;
                    int newYStride = newWidth;
                    int newHeight = originalHeight / 2;

                    // Create temporary buffers for the cropped frame data
                    uint8_t* newYBuffer = new uint8_t[newWidth * newHeight];
                    uint8_t* newUBuffer = new uint8_t[newWidth * newHeight / 4];
                    uint8_t* newVBuffer = new uint8_t[newWidth * newHeight / 4];

                    for (int y = 0; y < newHeight; ++y) {
                        for (int x = 0; x < newWidth; ++x) {
                            // Copy Y plane
                            newYBuffer[y * newYStride + x] = videoFrame.yBuffer[y * videoFrame.yStride + x];

                            // Copy U and V planes for every 2x2 block of pixels
                            if (y % 2 == 0 && x % 2 == 0) {
                                int newIndexUV = (y / 2) * (newWidth / 2) + (x / 2);
                                int originalIndexUV = (y / 2) * (videoFrame.uStride) + (x / 2);

                                newUBuffer[newIndexUV] = videoFrame.uBuffer[originalIndexUV];
                                newVBuffer[newIndexUV] = videoFrame.vBuffer[originalIndexUV];
                            }
                        }
                    }

                    // Update videoFrame with the new width, height, and strides
                    videoFrame.width = newWidth;
                    videoFrame.height = newHeight;
                    videoFrame.yStride = newYStride;
                    videoFrame.uStride = newWidth / 2;
                    videoFrame.vStride = newWidth / 2;

                    // Check if the original buffers have already been stored
                    if (!originalYBuffer) {
                        originalYBuffer = videoFrame.yBuffer;
                        originalUBuffer = videoFrame.uBuffer;
                        originalVBuffer = videoFrame.vBuffer;
                    }

                    // Update videoFrame to reference the new buffers
                    videoFrame.yBuffer = newYBuffer;
                    videoFrame.uBuffer = newUBuffer;
                    videoFrame.vBuffer = newVBuffer;

                }
                
                // Return true to indicate that pre-processing is successful and the frame should not be ignored
                return true;
            }

            // Note that `getVideoFrameProcessMode()` is need to override with 'PROCESS_MODE_READ_WRITE' to get updated video frames
            IVideoFrameObserver::VIDEO_FRAME_PROCESS_MODE CustomVideoFrameObserver::getVideoFrameProcessMode() {
                return VIDEO_FRAME_PROCESS_MODE::PROCESS_MODE_READ_WRITE;
            }

            // Rest the below functions are dummy "do-nothing" implentaion just to sake for overriding of interface pure virtual functions.
            bool CustomVideoFrameObserver::onSecondaryCameraCaptureVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver :: onSecondaryPreEncodeCameraVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onScreenCaptureVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onPreEncodeScreenVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onSecondaryScreenCaptureVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::CustomVideoFrameObserver::onSecondaryPreEncodeScreenVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onRenderVideoFrame(const char* channelId, rtc::uid_t remoteUid, VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onPreEncodeVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onMediaPlayerVideoFrame(VideoFrame& videoFrame, int mediaPlayerId)
            {
                return false;
            }

            bool CustomVideoFrameObserver::onTranscodedVideoFrame(VideoFrame& videoFrame)
            {
                return false;
            }
            ```
        Note that `getVideoFrameProcessMode()` is need to override with `PROCESS_MODE_READ_WRITE` in order for your raw data changes to take effect.

        2. *Implement audio frame observer callbacks*:
            
            `IAudioFrameObserver` gives you access to each audio frame after it is captured or access to each audio frame before it is played back. 

            ```cpp
            // IAudioFrameObserver Implementation
            // User can provide implementation for "onRecordAudioFrame()", "onPlaybackAudioFrame()" and "onMixedAudioFrame()" as per scenario. 
            bool CustomAudioFrameObserver::onRecordAudioFrame(const char* channelId, AudioFrame& audioFrame)
            {
                // Gets the captured audio frame.
                // Add code here to process the recorded audio.
                return true;
            }

            bool CustomAudioFrameObserver::onPlaybackAudioFrame(const char* channelId, AudioFrame& audioFrame)
            {
                // Gets the audio frame for playback.
                // Add code here to process the playback audio.
                return true;
            }

            bool CustomAudioFrameObserver::onMixedAudioFrame(const char* channelId, AudioFrame& audioFrame)
            {
                // Retrieves the mixed captured and playback audio frame.
                // Add code here to process the mixed captured playback audio
                return true;
            }

            // Rest the below functions are dummy "do-nothing" implentaion just to sake for overriding of interface pure virtual functions.
            bool CustomAudioFrameObserver::onPlaybackAudioFrameBeforeMixing(const char* channelId, rtc::uid_t uid, AudioFrame& audioFrame)
            {
                return false;
            }

            bool CustomAudioFrameObserver::onEarMonitoringAudioFrame(AudioFrame& audioFrame)
            {
                return false;
            }

            int CustomAudioFrameObserver::getObservedAudioFramePosition()
            {
                return 0;
            }

            IAudioFrameObserver::AudioParams CustomAudioFrameObserver::getPlaybackAudioParams()
            {
                return AudioParams();
            }

            IAudioFrameObserver::AudioParams CustomAudioFrameObserver::getRecordAudioParams()
            {
                return AudioParams();
            }

            IAudioFrameObserver::AudioParams CustomAudioFrameObserver::CustomAudioFrameObserver::getMixedAudioParams()
            {
                return AudioParams();
            }

            IAudioFrameObserver::AudioParams CustomAudioFrameObserver::getEarMonitoringAudioParams()
            {
                return AudioParams();
            }       
            ```
2.  **Register the video and audio frame observers**

    To receive callbacks declared in `IVideoFrameObserver` and `IAudioFrameObserver`, you must register the video and audio frame observers with the <Vg k="ENGINE" /> before joining a channel. To specify the format of audio frames captured by each `IAudioFrameObserver` callback, use the `setRecordingAudioFrameParameters`, `setPlaybackAudioFrameParameters` and `setMixedAudioFrameParameters` methods. To do this, follow the below steps:

    1. In `AgoraImplementationDlg.h`, add the following code after `void setupVideoSDKEngine();`:
      
        ```cpp
        bool EnableAudioVideoCapture(bool bEnable);
        ```
    
    1. Define `EnableAudioVideoCapture()`. Add below code in `AgoraImplementationDlg.cpp`, before `CAboutDlg()`:

        ```cpp
        bool CAgoraImplementationDlg::EnableAudioVideoCapture(bool bEnable)
        {
            agora::util::AutoPtr<agora::media::IMediaEngine> mediaEngine;
            //query interface agora::AGORA_IID_MEDIA_ENGINE in the engine.
            mediaEngine.queryInterface(agoraEngine, agora::rtc::AGORA_IID_MEDIA_ENGINE);
            int nRet = 0;
            agora::base::AParameter apm(agoraEngine);
            if (mediaEngine.get() == NULL)
                return FALSE;
            if (bEnable) {
                
                // Register video & audio frame observer
                nRet = mediaEngine->registerVideoFrameObserver(video_frame_observer);
                nRet = mediaEngine->registerAudioFrameObserver(audio_frame_observer);

                // Set the format of the captured raw audio data.
                int SAMPLE_RATE = 16000, SAMPLE_NUM_OF_CHANNEL = 1, SAMPLES_PER_CALL = 1024;

                agoraEngine->setRecordingAudioFrameParameters(SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL,
                    RAW_AUDIO_FRAME_OP_MODE_READ_WRITE, SAMPLES_PER_CALL);

                agoraEngine->setPlaybackAudioFrameParameters(SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL,
                    RAW_AUDIO_FRAME_OP_MODE_READ_WRITE, SAMPLES_PER_CALL);

                agoraEngine->setMixedAudioFrameParameters(SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL, SAMPLES_PER_CALL);

            }
            else {
                nRet = mediaEngine->registerVideoFrameObserver(NULL);
                nRet = mediaEngine->registerAudioFrameObserver(NULL);
            }
            return nRet == 0 ? TRUE : FALSE;
        }
        ```

    1. To execute this method before joining the channel, add the following to event listener  of `Join` buttton  (`OnBnClickedButton2()` in this example where `joinChannel()` executes) before `agoraEngine->enableAudio()`:

        ```cpp
        // Enable audio & video frame capture by registering the frames.
        EnableAudioVideoCapture(TRUE);
        ```
3. **Unregister the video and audio frame observers when you leave a channel**
    
    When you leave a channel, you unregister the frame observers by disabling the `EnableAudioVideoCapture()` method with a `false` argument. To do this, add the following to the event listener  of `Leave` buttton  (`OnBnClickedButton1()` in this example where `leaveChannel()` executes) after `agoraEngine->disableAudio();`:

        ```cpp
        // Unregister audio & video frame.
		EnableAudioVideoCapture(FALSE);
        ```
</PlatformWrapper>