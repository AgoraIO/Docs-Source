import CodeBlock from '@theme/CodeBlock';
import CodeRtcPy from '@docs/assets/code/open-ai-integration/rtc-py.mdx';
import Prerequisites from '@docs/shared/common/prerequisites/python.mdx';

Integrating Agora’s real-time audio communication capabilities with OpenAI’s language models enables dynamic, conversational AI experiences. This guide shows you how to set up a Python project that combines Agora’s server-side Voice SDK with OpenAI’s API to create an interactive, voice-driven assistant.

## Understand the tech

The `RealtimeKitAgent` class manages the integration by connecting to an Agora channel for real-time audio streaming and to OpenAI's API for processing audio input and generating AI-driven responses. Audio frames captured from the Agora channel are streamed to OpenAI's API, where the AI processes the input. The API responses, which include transcribed text and synthesized voice output, are then delivered back to the Agora channel.

The code sets up tools that can be executed locally or passed through the API. This allows the AI to perform specific tasks, such as retrieving data from external sources. The agent processes various message types from OpenAI, such as audio responses, transcription updates, and error messages, and sends them to users through the Agora audio channel, facilitating continuous interaction.

The following figure illustrates the integration topology:

![](/images/voice-sdk/open-ai-Integration-topology.png)

## Prerequisites

<Prerequisites />

## Set up the project

Follow these steps to set up your Python integration project:

1. Create a new folder for the project.

   ```bash
   mkdir realtime-agent
   cd realtime-agent/

   ```

1. Create the following structure for your project:

   ```
   /realtime-agent
       ├── __init__.py
       ├── .env
       ├── agent.py
       ├── agora
       │   ├── __init__.py
       │   ├── requirements.txt
       │   └── rtc.py
       └── realtimeapi
           ├── __init__.py
           ├── client.py
           ├── messages.py
           └── util.py
   ```

   <Admonition type="info" title="Note">
     This project uses the OpenAI [`realtimeapi-examples`](https://openai.com/api/) package.Download the project and unzip it into your
     `realtime-agent` folder.
   </Admonition>

   The following descriptions provide an overview of the key files in the project:

   - `agent.py`: The primary script responsible for executing the `RealtimeKitAgent`. It integrates Agora's functionality from the `agora/rtc.py` module and OpenAI's capabilities from the `realtimeapi` package.
   - `agora/rtc.py`: Contains an implementation of the server-side Agora Python Voice SDK.
   - `realtimeapi/`: Contains the classes and methods that interact with OpenAI’s Realtime API.

   The [Complete code](#complete-integration-code) for `agent.py` and `rtc.py` is provided at the bottom of this page.

1. Open your `.env` file and add the following keys:

   ```python
   # Agora RTC app ID
   AGORA_APP_ID=your_agora_app_id

   # OpenAI API key for authentication
   OPENAI_API_KEY=your_openai_api_key_here
   ```

1. Install the dependencies:

   ```bash
   pip install -r requirements.txt
   ```

## Implementation

The `RealtimeKitAgent` class integrates Agora's audio communication capabilities with OpenAI's AI services. This class manages audio streams, handles communication with the OpenAI API, and processes AI-generated responses, providing a seamless conversational AI experience.

### Connect to Agora and OpenAI

The `setup_and_run_agent` method sets up the `RealtimeKitAgent` by connecting to an Agora channel using the provided `RtcEngine` and initializing a session with the OpenAI Realtime API client. It sends configuration messages to set up the session and define conversation parameters, such as the system message and output audio format, before starting the agent's operations. The method uses asynchronous execution to handle both listening for the session start and sending conversation configuration updates concurrently. It ensures that the connection is properly managed and cleaned up after use, even in cases of exceptions, early exits, or shutdowns.

<Admonition type="info" title="Note">
  UIDs in the Python SDK are set using a string value. Agora recommends using only numerical values for UID strings to ensure compatibility
  with all Agora products and extensions.
</Admonition>

```python
@classmethod
async def setup_and_run_agent(
    cls,
    *,
    engine: RtcEngine,
    inference_config: InferenceConfig,
    tools: ToolContext | None,
) -> None:
    # Connect to a channel using the provided RtcEngine
    channel = await engine.connect(channelId="realtimekit_agora", uid="123")

    try:
        # Create and enter a context manager for the RealtimeApiClient
        async with RealtimeApiClient(
            base_uri=os.getenv("REALTIME_API_BASE_URI", "wss://api.openai.com"),
            api_key=os.getenv("OPENAI_API_KEY"),
            verbose=False,
        ) as client:
            # Send a message to update the session configuration
            await client.send_message(
                messages.UpdateSessionConfig(
                    session=messages.SessionResource(),
                )
            )

            # Concurrently wait for the start session message and send the conversation config
            [start_session_message, _] = await asyncio.gather(
                *[
                    anext(client.listen()),
                    client.send_message(
                        messages.UpdateConversationConfig(
                            system_message=inference_config.system_message,
                            output_audio_format=messages.AudioFormats.PCM16,
                            voice=inference_config.voice,
                            tools=tools.model_description() if tools else None,
                            transcribe_input=False,
                        )
                    ),
                ]
            )

            # Ensure the received message is of the correct type
            assert isinstance(start_session_message, messages.StartSession)

            # Print session information
            print(
                f"Session started: {start_session_message.session.id} model: {start_session_message.session.model}"
            )

            # Create an instance of the agent
            agent = cls(
                client=client,
                tools=tools,
                channel=channel,
            )

            # Run the agent
            await agent.run()

    finally:
        # Ensure disconnection and shutdown occur, even if an exception is raised
        await engine.disconnect()
        await shutdown(asyncio.get_event_loop())
```

### Initialize the RealtimeKitAgent

The `RealtimeKitAgent` class constructor accepts an OpenAI `RealtimeApiClient`, an optional `ToolContext` for function registration, and an Agora channel for managing audio communication. This setup initializes the agent to process audio streams, register tools (if provided), and interacts with the AI model.

```python
def __init__(
    self,
    *,
    client: RealtimeApiClient,
    tools: ToolContext | None,
    channel: Channel,
) -> None:
    self.client = client
    self.tools = tools
    self._client_tool_futures = {}
    self.channel = channel
```

### Launch the Agent

The `entry_point` method serves as the primary entry for launching the agent. It calls `setup_and_run_agent` with the necessary parameters, initializing the agent and activating its core functionalities.

```python
@classmethod
async def entry_point(
    cls,
    *,
    engine: RtcEngine,                      # The Agora RTC engine instance for audio streaming
    inference_config: InferenceConfig,      # Configuration for the AI inference (e.g., system message, voice)
    tools: ToolContext | None = None,       # Optional tool context for registering functions
) -> None:
    # Call the method to set up and run the agent, passing in the necessary parameters
    await cls.setup_and_run_agent(
        engine=engine, inference_config=inference_config, tools=tools
    )
```

The asynchronous `run` method orchestrates the main operations of the `RealtimeKitAgent`. It manages audio streaming, processes tasks related to audio input, output, and model messages, and ensures exception handling is in place.

```python
async def run(self) -> None:
    # Log unhandled exceptions that occur in tasks
    def log_exception(t: asyncio.Task[Any]) -> None:
        if not t.cancelled() and t.exception():
            logger.error(
                "Unhandled exception",
                exc_info=t.exception(),
            )

    # Future used to detect when the agent is disconnected
    disconnected_future = asyncio.Future[None]()

    # Set the result for the disconnected future when the agent is disconnected
    def _on_disconnected() -> None:
        if not disconnected_future.done():
            disconnected_future.set_result(None)

    # Event listener for disconnection (commented out for now)
    # self.room.on("disconnected", _on_disconnected)

    # Start streaming audio input to the AI model, with exception logging
    asyncio.create_task(self._stream_input_audio_to_model()).add_done_callback(
        log_exception
    )

    # Start streaming audio output (synthesized responses) back to the users, with exception logging
    asyncio.create_task(
        self._stream_audio_queue_to_audio_output()
    ).add_done_callback(log_exception)

    # Start processing model messages (e.g., transcriptions, updates), with exception logging
    asyncio.create_task(self._process_model_messages()).add_done_callback(
        log_exception
    )

    # Wait until the disconnection future is resolved, meaning the agent has disconnected
    await disconnected_future
    logger.info("Agent finished running")  # Log that the agent has completed its operation
```

### Stream input audio to the AI model

The asynchronous method `_stream_input_audio_to_model` captures audio frames from the Agora channel and sends them to the OpenAI API client for real-time processing by the AI model.

```python
async def _stream_input_audio_to_model(self) -> None:
    # Retrieve audio frames from the Agora channel
    audio_frames = self.channel.get_audio_frames()

    # Loop through each audio frame received from the channel
    async for audio_frame in audio_frames:
        # Send the audio frame's data to the AI model via the OpenAI API client
        await self.client.send_audio_data(audio_frame.data)
```

### Stream audio from the AI model to the user

The asynchronous method `_stream_audio_queue_to_audio_output` handles the playback of processed audio data from the AI model. It retrieves audio frames from a queue and sends them to the Agora channel, allowing users to hear AI-generated responses in real-time.

```python
async def _stream_audio_queue_to_audio_output(self) -> None:
    while True:
        # Retrieve the next processed audio frame from the queue (AI model's response)
        frame = await self.audio_queue.get()

        # Send the audio frame to the Agora channel for playback to the user
        await self.channel.push_audio_frame(frame)

        # Yield control to allow other tasks to run, improving responsiveness
        await asyncio.sleep(0)
```

The asynchronous method `_process_model_messages` listens for messages from the OpenAI API client and processes them based on their type. It handles a variety of message types, including audio deltas, transcriptions, and errors. The method updates the user chat with transcribed text, queues audio for playback, and manages other session-related events, such as tool calls and generation states.

```python
async def _process_model_messages(self) -> None:
    # Listen for incoming messages from the OpenAI API client
    async for message in self.client.listen():
        # Process each type of message received from the client
        match message:
            case messages.ResponseAudioDelta():
                # Handle audio response deltas by decoding and adding them to the audio queue
                await self.audio_queue.put(base64.b64decode(message.delta))

            case messages.ResponseAudioTranscriptionDelta():
                # Log and send transcribed text updates to the Agora chat channel
                logger.info(f"Received text message {message=}")
                await self.channel.chat.send_message(ChatMessage(message=message.delta, msg_id=message.output_item_id))

            case messages.ResponseAudioTranscriptionDone():
                # Handle completion of transcription and send the final text message
                logger.info(f"Text message done: {message=}")
                await self.channel.chat.send_message(ChatMessage(message=message.value, msg_id=message.output_item_id, done=True))

            case messages.MessageAdded():
                # Placeholder for handling other message types (currently not used)
                pass

            case messages.ServerAddMessage():
                # Placeholder for handling server-side messages (currently not used)
                pass

            case messages.VADSpeechStarted():
                # Placeholder for handling voice activity detection start
                pass

            case messages.VADSpeechStopped():
                # Placeholder for handling voice activity detection stop
                pass

            case messages.GenerationCanceled():
                # Log when a generation process is canceled
                logger.info(f"Server turn canceled: {message=}")

            case messages.GenerationFinished():
                # Log when the generation process is finished (e.g., no more text appending)
                logger.info(f"Server turn finished: {message=}")
                # TODO: Implement behavior to mark generation completion
                # await self.channel.generation_finished()

            case messages.AddContent(type=messages.AddContentType.TOOL_CALL):
                # TODO: Implement streaming tool calls when a tool call is added to the content
                logger.info(f"Received tool call buffer add {message=}")

            case messages.RealtimeError(error=error):
                # Log any errors received from the OpenAI client
                logger.error(f"Received error message {error=}")

            case _:
                # Log any unhandled or unknown message types
                logger.warning(f"Unhandled message {message=}")
```

### Complete integration code

The `agent.py` script integrates the code components presented in this section into reusable Python classes that you can extend for your own applications.

<details>
<summary>Complete code for `agent.py`</summary>
<CodeBlock showLineNumbers language="python">
{`import abc
import asyncio
import base64
import json
import logging
import os
from builtins import anext
from typing import Any, Callable, assert_never

from attr import dataclass
from dotenv import load_dotenv
from pydantic import BaseModel

from realtimekit.realtimeapi import messages
from realtimekit.realtimeapi.client import RealtimeApiClient

from .agora.rtc import Channel, Chat, ChatMessage, RtcEngine

# Logger configuration

logger = logging.getLogger(**name**)

# Data classes for configuration and tool declarations

@dataclass(frozen=True, kw_only=True)
class InferenceConfig:
    """Configuration for the inference process."""
    system_message: str | None = None
    turn_detection: messages.TurnDetectionTypes | None = None
    voice: messages.Voices | None = None

@dataclass(frozen=True, kw_only=True)
class LocalFunctionToolDeclaration:
    """Declaration of a tool that can be called by the model, and runs a function locally on the tool context."""

    name: str
    description: str
    parameters: dict[str, Any]
    function: Callable[..., Any]

    def model_description(self) -> dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters,
            },
        }

@dataclass(frozen=True, kw_only=True)
class PassThroughFunctionToolDeclaration:
    """Declaration of a tool that can be called by the model, and is passed through the LiveKit client."""

    name: str
    description: str
    parameters: dict[str, Any]

    def model_description(self) -> dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters,
            },
        }

# Type alias for tool declarations

ToolDeclaration = LocalFunctionToolDeclaration | PassThroughFunctionToolDeclaration

@dataclass(frozen=True, kw_only=True)
class LocalToolCallExecuted:
    json_encoded_output: str

@dataclass(frozen=True, kw_only=True)
class ShouldPassThroughToolCall:
    decoded_function_args: dict[str, Any]

# Type alias for tool execution results

ExecuteToolCallResult = LocalToolCallExecuted | ShouldPassThroughToolCall

class ToolContext(abc.ABC):
    """Abstract base class for managing tool declarations and executions."""
    _tool_declarations: dict[str, ToolDeclaration]

    def __init__(self) -> None:
        # TODO: This should be an ordered dict
        self._tool_declarations = {}

    def register_function(
        self,
        *,
        name: str,
        description: str = "",
        parameters: dict[str, Any],
        fn: Callable[..., Any],
    ) -> None:
        """Register a local function as a tool."""
        self._tool_declarations[name] = LocalFunctionToolDeclaration(
            name=name, description=description, parameters=parameters, function=fn
        )

    def register_client_function(
        self,
        *,
        name: str,
        description: str = "",
        parameters: dict[str, Any],
    ) -> None:
        """Register a client function as a tool."""
        self._tool_declarations[name] = PassThroughFunctionToolDeclaration(
            name=name, description=description, parameters=parameters
        )

    async def execute_tool(
        self, tool_name: str, encoded_function_args: str
    ) -> ExecuteToolCallResult | None:
        """Execute a tool based on its name and provided arguments."""
        tool = self._tool_declarations.get(tool_name)
        if not tool:
            return None

        args = json.loads(encoded_function_args)
        assert isinstance(args, dict)

        if isinstance(tool, LocalFunctionToolDeclaration):
            logger.info(f"Executing tool {tool_name} with args {args}")
            result = await tool.function(**args)
            logger.info(f"Tool {tool_name} executed with result {result}")
            return LocalToolCallExecuted(json_encoded_output=json.dumps(result))

        if isinstance(tool, PassThroughFunctionToolDeclaration):
            return ShouldPassThroughToolCall(decoded_function_args=args)

        assert_never(tool)

    def model_description(self) -> list[dict[str, Any]]:
        """Generate a description of all registered tools for the model."""
        return [v.model_description() for v in self._tool_declarations.values()]

class ClientToolCallResponse(BaseModel):
    tool_call_id: str
    result: dict[str, Any] | str | float | int | bool | None = None

class RealtimeKitAgent:
    """Main agent class for handling real-time communication and processing."""
    engine: RtcEngine
    channel: Channel
    client: RealtimeApiClient
    audio_queue: asyncio.Queue[bytes] = asyncio.Queue()
    message_queue: asyncio.Queue[messages.ResonseAudioTranscriptionDelta] = asyncio.Queue()
    message_done_queue: asyncio.Queue[messages.ResonseAudioTranscriptionDone] = asyncio.Queue()
    tools: ToolContext | None = None

    _client_tool_futures: dict[str, asyncio.Future[ClientToolCallResponse]]

    @classmethod
    async def setup_and_run_agent(
        cls,
        *,
        engine: RtcEngine,
        inference_config: InferenceConfig,
        tools: ToolContext | None,
    ) -> None:
        """Set up and run the agent with the provided configuration."""
        # Connect to a channel using the provided RtcEngine
        channel = await engine.connect(channelId="realtimekit_agora", uid="123")

        try:
            # Create and enter a context manager for the RealtimeApiClient
            async with RealtimeApiClient(
                base_uri=os.getenv("REALTIME_API_BASE_URI", "wss://api.openai.com"),
                api_key=os.getenv("OPENAI_API_KEY"),
                verbose=False,
            ) as client:
                # Send a message to update the session configuration
                await client.send_message(
                    messages.UpdateSessionConfig(
                        session=messages.SessionResource(),
                        # turn_detection=inference_config.turn_detection,
                        # transcribe_input=False,
                        # input_audio_format=messages.AudioFormats.PCM16,
                        # vads=messages.VADConfig(),
                    )
                )

                # Concurrently wait for the start session message and send the conversation config
                [start_session_message, _] = await asyncio.gather(
                    *[
                        anext(client.listen()),
                        client.send_message(
                            messages.UpdateConversationConfig(
                                system_message=inference_config.system_message,
                                output_audio_format=messages.AudioFormats.PCM16,
                                voice=inference_config.voice,
                                tools=tools.model_description() if tools else None,
                                transcribe_input=False,
                            )
                        ),
                    ]
                )

                # Ensure the received message is of the correct type
                assert isinstance(start_session_message, messages.StartSession)

                # Print session information
                print(
                    f"Session started: {start_session_message.session.id} model: {start_session_message.session.model}"
                )

                # Create an instance of the agent
                agent = cls(
                    client=client,
                    tools=tools,
                    channel=channel,
                )

                # Run the agent
                await agent.run()

        finally:
            # Ensure disconnection and shutdown occur, even if an exception is raised
            await engine.disconnect()
            await shutdown(asyncio.get_event_loop())

    @classmethod
    async def entry_point(
        cls,
        *,
        engine: RtcEngine,
        inference_config: InferenceConfig,
        tools: ToolContext | None = None,
    ) -> None:
        """Entry point for setting up and running the agent."""
        await cls.setup_and_run_agent(
            engine=engine, inference_config=inference_config, tools=tools
        )

    def __init__(
        self,
        *,
        client: RealtimeApiClient,
        tools: ToolContext | None,
        channel: Channel,
    ) -> None:
        """Initialize the RealtimeKitAgent."""
        self.client = client
        self.tools = tools
        self._client_tool_futures = {}
        self.channel = channel

    async def run(self) -> None:
        """Main loop for running the agent."""
        def log_exception(t: asyncio.Task[Any]) -> None:
            """Log unhandled exceptions from tasks."""
            if not t.cancelled() and t.exception():
                logger.error(
                    "Unhandled exception",
                    exc_info=t.exception(),
                )

        disconnected_future = asyncio.Future[None]()

        def _on_disconnected() -> None:
            """Callback for when the agent is disconnected."""
            if not disconnected_future.done():
                disconnected_future.set_result(None)

        # self.room.on("disconnected", _on_disconnected)

        # Create and monitor tasks for streaming audio and processing messages
        asyncio.create_task(self._stream_input_audio_to_model()).add_done_callback(
            log_exception
        )
        asyncio.create_task(self._stream_audio_queue_to_audio_output()).add_done_callback(
            log_exception)

        asyncio.create_task(self._process_model_messages()).add_done_callback(
            log_exception
        )

        await disconnected_future
        logger.info("Agent finished running")

    async def _stream_input_audio_to_model(self) -> None:
        """Stream input audio frames to the model."""
        audio_frames = self.channel.get_audio_frames()
        async for audio_frame in audio_frames:
            # send the frame to the model via the API client
            await self.client.send_audio_data(audio_frame.data)

    async def _stream_audio_queue_to_audio_output(self) -> None:
        """Stream audio from the queue to the audio output."""
        while True:
            # audio queue contains audio data from the model, send it the end-user via our local audio source
            frame = await self.audio_queue.get()
            await self.channel.push_audio_frame(frame)
            await asyncio.sleep(0)  # allow other tasks to run

    async def _process_model_messages(self) -> None:
        """Process messages received from the model."""
        async for message in self.client.listen():
            match message:
                case messages.ResonseAudioDelta():
                    # Process incoming audio data
                    await self.audio_queue.put(base64.b64decode(message.delta))

                case messages.ResonseAudioTranscriptionDelta():
                    logger.info(f"Received text transcription delta: {message=}")
                    await self.channel.chat.send_message(ChatMessage(message=message.delta, msg_id=message.output_item_id))

                case messages.ResonseAudioTranscriptionDone():
                    logger.info(f"Text transcription completed: {message=}")
                    await self.channel.chat.send_message(ChatMessage(message=message.value, msg_id=message.output_item_id, done=True))

                case messages.MessageAdded():
                    # Handle message addition event
                    pass

                case messages.ServerAddMessage():
                    # Handle server message addition event
                    pass

                case messages.VADSpeechStarted():
                    # Handle Voice Activity Detection speech start event
                    pass

                case messages.VADSpeechStopped():
                    # Handle Voice Activity Detection speech stop event
                    pass

                case messages.GenerationCanceled():
                    logger.info(f"Server generation canceled: {message=}")

                case messages.GenerationFinished():
                    logger.info(f"Server generation finished: {message=}")
                    # TODO: Implement logic to mark the end of text appending

                case messages.AddContent(type=messages.AddContentType.TOOL_CALL):
                    logger.info(f"Received tool call content: {message=}")
                    # TODO: Implement streaming tool calls

                case messages.RealtimeError(error=error):
                    logger.error(f"Received error message: {error=}")
                    # TODO: Determine if session termination is necessary

                case _:
                    logger.warning(f"Unhandled message type: {message=}")

async def shutdown(loop, signal=None):
    """Gracefully shut down the application."""
    if signal:
        print(f"Received exit signal {signal.name}...")

        tasks = [t for t in asyncio.all_tasks() if t is not asyncio.current_task()]

        print(f"Cancelling {len(tasks)} outstanding tasks")
        for task in tasks:
            task.cancel()

        await asyncio.gather(*tasks, return_exceptions=True)
        loop.stop()

if **name** == "**main**": # Load environment variables and run the agent
    load_dotenv()
    asyncio.run(
        RealtimeKitAgent.entry_point(
            engine=RtcEngine(appid=os.getenv("AGORA_APP_ID")),
            inference_config=InferenceConfig(
                system_message="""\\
You are a helpful assistant. If asked about the weather, make sure to use the provided tool to get that information. \\
If you are asked a question that requires a tool, say something like "working on that" and don't provide a concrete response \\
until you have received the response to the tool call.\\
""",
                voice=messages.Voices.Alloy,
                turn_detection=messages.TurnDetectionTypes.SERVER_VAD,
            ),
        )
    )
`}

</CodeBlock>
</details>

The `agent.py` imports key classes from `rtc.py`, which implements the server-side Agora Python Voice SDK,, facilitating communication and managing audio streams. For SDK setup and dependencies, refer to [Voice calling quickstart](/voice-calling/get-started/get-started-sdk?platform=python).

Below is the complete code for `rtc.py`.

<details>
  <summary>Complete code for `rtc.py`</summary>
  <CodeRtcPy />
</details>

## Test the code

1. **Update the values for** `AGORA_APP_ID` **and** `OPENAI_API_KEY` **in the project's** `.env` **file**.  
   This step ensures that the necessary credentials for Agora and OpenAI are correctly configured in your project.

2. **Execute the following command to run your app**:

   ```bash
   python3 agent.py
   ```

   This command launches the `agent.py` script, initializing the Agora channel and the OpenAI API connection.

## Reference

This section contains additional information or links to relevant documentation that complements the current page or explains other aspects of the product.

- [API reference for `rtc.py`](https://api-reference-git-python-voice-implementation-agora-gdxe.vercel.app/voice-sdk/python/rtc-py-api.html)
- [Voice calling quickstart (Python)](/voice-calling/get-started/get-started-sdk?platform=python)
