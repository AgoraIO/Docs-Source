<PlatformWrapper platform="android">

If your target platform is Android 12 or higher, add the `android.permission.BLUETOOTH_CONNECT` permission to the `AndroidManifest.xml` file of the Android project to enable the Bluetooth function of the Android system.

### v4.2.0

v4.2.0 was released on May 24, 2023.

#### Compatibility changes

If you use the features mentioned in this section, ensure that you modify the implementation of the relevant features after upgrading the SDK.

**1. Channel media options**

- `publishCustomAudioTrackEnableAec` in `ChannelMediaOptions` is deleted. Use `publishCustomAudioTrack` instead.
- `publishCustomAudioSourceId` in `ChannelMediaOptions` is renamed to `publishCustomAudioTrackId`.

**2. Miscellaneous**

- `onApiCallExecuted` is deleted. Agora recommends getting the results of the API implementation through relevant channels and media callbacks.
- `startChannelMediaRelay`, `updateChannelMediaRelay`, `startChannelMediaRelayEx`, and `updateChannelMediaRelayEx` are deprecated. Use `startOrUpdateChannelMediaRelay` and `startOrUpdateChannelMediaRelayEx` instead.


#### New features

**1. AI Noise Suppression**

This release introduces public APIs for the AI Noise Suppression function. Once enabled, the SDK automatically detects and reduces background noises. Whether in bustling public venues or real-time competitive arenas that demand lightning-fast responsiveness, this function guarantees optimal audio clarity, providing users with an elevated audio experience. You can enable this function through the newly-introduced `setAINSMode` method and set the noise reduction mode as balance, aggressive, or low latency according to your scenarios.

<div class="alert note">Agora charges separately for this function. See [AI Noise Suppression unit pricing](pricing#ai-noise-suppression-pricing).</div>

**2. Cross-device synchronization**

In real-time collaborative singing scenarios, network issues can cause inconsistencies in the downlinks of different client devices. To address this, this release introduces `getNtpWallTimeInMs` for obtaining the current Network Time Protocol (NTP) time. By using this method to synchronize lyrics and music across multiple client devices, users can achieve synchronized singing and lyrics progression, resulting in a better collaborative experience.


#### Improvements

**1. Improved voice changer**

This release introduces the `setLocalVoiceFormant` method that allows you to adjust the formant ratio to change the timbre of the voice. This method can be used together with the `setLocalVoicePitch` method to adjust the pitch and timbre of voice at the same time, enabling a wider range of voice transformation effects.

**2. Improved compatibility with audio file types**

As of v4.2.0, you can use the following methods to open files with a URI starting with `content://`:
- `startAudioMixing` [2/2]
- `playEffect` [3/3]
- `open` [2/2]
- `openWithMediaSource`

**3. Channel media relay**

This release introduces `startOrUpdateChannleMediaRelay` and `startOrUpdateChannleMediaRelayEx`, allowing for a simpler and smoother way to start and update media relay across channels. With these methods, developers can easily start the media relay across channels and update the target channels for media relay with a single method. Additionally, the internal interaction frequency has been optimized, effectively reducing latency in function calls.

**4. Custom audio tracks**

To better meet the needs of custom audio capture scenarios, this release adds `createCustomAudioTrack` and `destroyCustomAudioTrack` for creating and destroying custom audio tracks. Two types of audio tracks are also provided for users to choose from, further improving the flexibility of capturing external audio source:

- Mixable audio track: Supports mixing multiple external audio sources and publishing them to the same channel, suitable for multi-channel audio capture scenarios.
- Direct audio track: Only supports publishing one external audio source to a single channel, suitable for low-latency audio capture scenarios.


#### Issues fixed

This release fixed the following issues:

- Occasional crashes occurred on Android devices when users joined or left a channel.
- When the host frequently switched the user role between broadcaster and audience in a short period of time, the audience members could not hear the audio of the host.
- Occasional failure when enabling in-ear monitoring.
- Occasional echo.
- Abnormal client status caused by an exception in the `onRemoteAudioStateChanged` callback.

#### API changes

**Added**

- `startOrUpdateChannelMediaRelay`
- `startOrUpdateChannelMediaRelayEx`
- `getNtpWallTimeInMs`
- `setAINSMode`
- `createAudioCustomTrack`
- `destroyAudioCustomTrack`
- `AudioTrackConfig`
- `AudioTrackType`
- The `mDomainLimit` and `mAutoRegisterAgoraExtensions` members in `RtcEngineConfig`

**Deprecated**

- `startChannelMediaRelay`
- `startChannelMediaRelayEx`
- `updateChannelMediaRelay`
- `updateChannelMediaRelayEx`
- `onChannelMediaRelayEvent`

**Deleted**

- `onApiCallExecuted`
- `publishCustomAudioTrackEnableAec` in `ChannelMediaOptions` in `ChannelMediaOptions`

### v4.1.1

v4.1.1 was released on February 8, 2023.

#### New features

**Instant audio frame rendering**

This release adds the `enableInstantMediaRendering` method to enable instant rendering mode for audio and video frames, which can speed up the first video or audio frame rendering after the user joins the channel.

#### Issues fixed

This release fixed the following issues:

- Playing audio files with a sample rate of 48 kHz failed.
- In real-time chorus scenarios, remote users heard noises and echoes when an OPPO R11 device joined the channel in loudspeaker mode.
- When the playback of the local music finished, the `onAudioMixingFinished` callback was not properly triggered.
- At the moment when a user left a channel, a request for leaving was not sent to the server and the leaving behavior was incorrectly determined by the server as timed out.



#### API changes

**Added**

`enableInstantMediaRendering`

### v4.1.0

v4.1.0 was released on December 15, 2022.

#### New features

**1. Headphone equalization effect**

This release adds the `setHeadphoneEQParameters` method, which is used to adjust the low- and high-frequency parameters of the headphone EQ. This is mainly useful in spatial audio scenarios. If you cannot achieve the expected headphone EQ effect after calling `setHeadphoneEQPreset`, you can call `setHeadphoneEQParameters` to adjust the EQ.


**2. MPUDP (MultiPath UDP) (Beta)**

As of this release, the SDK supports MPUDP protocol, which enables you to connect and use multiple paths to maximize the use of channel resources based on the UDP protocol. You can use different physical NICs on both mobile and desktop and aggregate them to effectively combat network jitter and improve transmission quality.

> To enable this feature, contact <a href="mailto:sales-us@agora.io">sales-us@agora.io</a>.


**3. Multi-channel management**

This release adds a series of multi-channel related methods that you can call to manage audio stream in multi-channel scenarios.

- The `muteLocalAudioStreamEx` method is used to cancel or resume publishing a local audio stream.
- The `muteAllRemoteAudioStreamsEx` is used to cancel or resume the subscription of all remote users to audio stream.
- The `startRtmpStreamWithoutTranscodingEx`, `startRtmpStreamWithTranscodingEx`, `updateRtmpTranscodingEx`, and `stopRtmpStreamEx` methods are used to implement Media Push in multi-channel scenarios.
- The `startChannelMediaRelayEx`, `updateChannelMediaRelayEx`, `pauseAllChannelMediaRelayEx`, `resumeAllChannelMediaRelayEx`, and `stopChannelMediaRelayEx` methods are used to relay media streams across channels in multi-channel scenarios.
- Adds the `leaveChannelEx` [2/2] method. Compared with the `leaveChannelEx` [1/2] method, a new options parameter is added, which is used to choose whether to stop recording with the microphone when leaving a channel in a multi-channel scenario.

**4. Client role switching**

In order to enable users to know whether the switched user role is low-latency or ultra-low-latency, this release adds the `newRoleOptions` parameter to the `onClientRoleChanged` callback. The value of this parameter is as follows:

- `AUDIENCE_LATENCY_LEVEL_LOW_LATENCY` (1): Low latency.
- `AUDIENCE_LATENCY_LEVEL_ULTRA_LOW_LATENCY` (2): Ultra-low latency.

#### Improvements

**1. Bluetooth permissions**

To simplify integration, as of this release, you can use the SDK to enable Android users to use Bluetooth normally without adding the `BLUETOOTH_CONNECT` permission.


**2. Relaying media streams across channels**

This release optimizes the `updateChannelMediaRelay` method as follows:

- Before v4.1.0: If the target channel update fails due to internal reasons in the server, the SDK returns the error code `RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_REFUSED`(8), and you need to call the `updateChannelMediaRelay` method again.
- v4.1.0 and later: If the target channel update fails due to internal server reasons, the SDK retries the update until the target channel update is successful.

**3. Reconstructed AIAEC algorithm**

This release reconstructs the AEC algorithm based on the AI method. Compared with the traditional AEC algorithm, the new algorithm can preserve the complete, clear, and smooth near-end vocals under poor echo-to-signal conditions, significantly improving the system's echo cancellation and dual-talk performance. This gives users a more comfortable call and live-broadcast experience. AIAEC is suitable for conference calls, chats, karaoke, and other scenarios.


**Other improvements**

This release includes the following additional improvements:

- Reduces the latency when pushing external audio sources.
- Improves the performance of echo cancellation when using the `AUDIO_SCENARIO_MEETING` scenario.
- Enhances the ability to identify different network protocol stacks and improves the SDK's access capabilities in multiple-operator network scenarios.

#### Issues fixed

This release fixed the following issues:

- Audience members heard buzzing noises when the host switched between speakers and earphones during live streaming.
- The call `getExtensionProperty` failed and returned an empty string.

#### API changes

**Added**

- `setHeadphoneEQParameters`

- `leaveChannelEx` [2/2]

- `muteLocalAudioStreamEx`

- `muteAllRemoteAudioStreamsEx`

- `startRtmpStreamWithoutTranscodingEx`

- `startRtmpStreamWithTranscodingEx`

- `updateRtmpTranscodingEx`

- `stopRtmpStreamEx`

- `startChannelMediaRelayEx`

- `updateChannelMediaRelayEx`

- `pauseAllChannelMediaRelayEx`

- `resumeAllChannelMediaRelayEx`

- `stopChannelMediaRelayEx`

- `followEncodeDimensionRatio` in `CameraCapturerConfiguration`

- `newRoleOptions` in `onClientRoleChanged`

- `adjustUserPlaybackSignalVolumeEx`

**Deprecated**

- `onApiCallExecuted`. Use the callbacks triggered by specific methods instead.

**Deleted**

- Removes `RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_REFUSED`(8) in `onChannelMediaRelayEvent` callback

#### Known issues

-   The package manager download is listed as 4.1.0-1. This is the correct download for Voice SDK for Android v4.1.0.

### v4.0.1

v4.0.1 was released on September 29, 2022.

#### New features

**1. In-ear monitoring**

This release adds `getEarMonitoringAudioParams` callback to set the audio data format of the in-ear monitoring. You can use your own audio effect processing module to pre-process the audio frame data of the in-ear monitoring to implement custom audio effects. After calling `registerAudioFrameObserver` to register the audio observer, set the audio data format in the return value of the `getEarMonitoringAudioParams` callback. The SDK calculates the sampling interval based on the return value of the callback, and triggers the `onEarMonitoringAudioFrame` callback based on the sampling interval.

**2. Audio capture device test**

This release adds support for testing local audio capture devices before joining channel. You can call `startRecordingDeviceTest` to start the audio capture device test. After the test is complete, call the `stopPlaybackDeviceTest` method to stop the audio capture device test.

**3. Local network connection types**

To make it easier for users to know the connection type of the local network at any stage, this release adds the `getNetworkType` method. You can use this method to get the type of network connection in use, including UNKNOWN, DISCONNECTED, LAN, WIFI, 2G, 3G, 4G, 5G. When the local network connection type changes, the SDK triggers the `onNetworkTypeChanged` callback to report the current network connection type.


**4. Audio stream filter**

This release introduces filtering audio streams based on volume. Once this function is enabled, the Agora server ranks all audio streams by volume and transports 3 audio streams with the highest volumes to the receivers by default. The number of audio streams to be transported can be adjusted; you can contact [support@agora.io](mailto:support@agora.io) to adjust this number according to your scenarios.

Meanwhile, Agora supports publishers to choose whether or not the audio streams being published are to be filtered based on volume. Streams that are not filtered will bypass this filter mechanism and transported directly to the receivers. In scenarios where there are a number of publishers, enabling this function helps reducing the bandwidth and device system pressure for the receivers.

To enable this function, contact [support@agora.io](mailto:support@agora.io).


**5. Spatial audio effect**

This release adds the following features applicable to spatial audio effect scenarios, which can effectively enhance the user's sense of presence experience in virtual interactive scenarios.

- Sound insulation area: You can set a sound insulation area and sound attenuation parameter by calling `setZones`. When the sound source (which can be a user or the media player) and the listener belong to the inside and outside of the sound insulation area, the listner experiences an attenuation effect similar to that of the sound in the real environment when it encounters a building partition. You can also set the sound attenuation parameter for the media player and the user, respectively, by calling `setPlayerAttenuation` and `setRemoteAudioAttenuation`, and specify whether to use that setting to force an override of the sound attenuation paramter in `setZones`.
- Doppler sound: You can enable Doppler sound by setting the `enable_doppler` parameter in `SpatialAudioParams`, and the receiver experiences noticeable tonal changes in the event of a high-speed relative displacement between the source source and receiver (such as in a racing game scenario).
- Headphone equalizer: You can use a preset headphone equalization effect by calling the `setHeadphoneEQPreset` method to improve the hearing of the headphones.


#### Issues fixed

This release fixed the following issues.

1. In online meeting scenarios, the local user and the remote user might not hear each other after the local user is interrupted by a call.
2. After calling `setCloudProxy` to set the cloud proxy, calling `joinChannelEx` to join multiple channels failed.

#### API changes

**Added**

- `getEarMonitoringAudioParams`
- `stopRecordingDeviceTest`
- `stopRecordingDeviceTest`
- `getNetworkType`
- `isAudioFilterable` in the `ChannelMediaOptions`
- `setZones`
- `setPlayerAttenuation`
- `setRemoteAudioAttenuation`
- `muteRemoteAudioStream`
- `SpatialAudioParams`
- `setHeadphoneEQPreset`
- `HEADPHONE_EQUALIZER_PRESET`

**Deprecated**

- `startEchoTest` [2/3]



### v4.0.0

v4.0.0 was released on September 15, 2022.

#### Compatibility changes

**1. Integration change**

This release has optimized the implementation of some features, resulting in incompatibility with v3.7.x. The following are the main features with compatibility changes:

- Multiple channel
- Media stream publishing control
- Warning codes

After upgrading the SDK, you need to update the code in your app according to your business scenarios. For details, see [Migrate from v3.7.x to v<Vg k = "VSDK_RELEASE"/>](./develop/migration-guide).

**2. Callback exception handling**

To facilitate troubleshooting, as of this release, the SDK no longer catches exceptions that are thrown by your own code implementation when triggering callbacks in the `IRtcEngineEventHandler` class. You need to catch and handle the exceptions yourself; otherwise, it can cause a crash.

#### New features

**1. Multiple media tracks**

This release supports one `RtcEngine` instance to collect multiple audio sources at the same time and publish them to the remote users by setting `RtcEngineEx` and `ChannelMediaOptions.`

After calling `joinChannel` to join the first channel, call `joinChannelEx` multiple times to join multiple channels, and publish the specified stream to different channels through different user ID (`localUid`) and `ChannelMediaOptions` settings.

You can also experience the following features with the multi-channel capability:

- Publish multiple sets of audio streams to the remote users through different user IDs (`uid`).
- Mix multiple audio streams and publish to the remote users through a user ID (`uid`).

**2. Agora media player**

To make it easier for users to integrate the Agora SDK and reduce the SDK's package size, this release introduces the Agora media player. After calling the `createMediaPlayer` method to create a media player object, you can then call the methods in the `IMediaPlayer` class to experience a series of functions, such as playing local and online media files, preloading a media file, changing the CDN route for playing according to your network conditions, or sharing the audio streams being played with remote users.

**3. Brand-new AI Noise Suppression**

The SDK supports a new version of AI noise reduction (in comparison to the basic AI noise reduction in v3.7.x). The new AI noise reduction has better vocal fidelity, cleaner noise suppression, and adds a dereverberation option. To enable this feature, contact [sales-us@agora.io](mailto:sales-us@agora.io).

**4. Ultra-high audio quality**

To make the audio clearer and restore more details, this release adds the `ULTRA_HIGH_QUALITY_VOICE` enumeration. In scenarios that mainly feature the human voice, such as chat or singing, you can call `setVoiceBeautifierPreset` and use this enumeration to experience ultra-high audio quality.

**5. Spatial audio**

This feature is in experimental status. To enable this feature, contact [sales-us@agora.io](mailto:sales-us@agora.io). Contact [technical support](mailto:support@agora.io) if needed.

You can set the spatial audio for the remote user as following:

- Local Cartesian Coordinate System Calculation: This solution uses the `ILocalSpatialAudioEngine` class to implement spatial audio by calculating the spatial coordinates of the remote user. You need to call `updateSelfPosition` and `updateRemotePosition` to update the spatial coordinates of the local and remote users, respectively, so that the local user can hear the spatial audio effect of the remote user.
  ![Spatial effect](/images/video-sdk/video-call-spatial.png)

You can also set the spatial audio for the media player as following:

- Local Cartesian Coordinate System Calculation: This solution uses the `ILocalSpatialAudioEngine` class to implement spatial audio. You need to call `updateSelfPosition` and `updatePlayerPositionInfo` to update the spatial coordinates of the local user and media player, respectively, so that the local user can hear the spatial audio effect of media player.
  ![Spatial effect](/images/video-sdk/spatial-audio-effect.png)


**6. Real-time chorus**

This release gives real-time chorus the following abilities:

- Two or more choruses are supported.
- Each singer is independent of each other. If one singer fails or quits the chorus, the other singers can continue to sing.
- Very low latency experience. Each singer can hear each other in real time, and the audience can also hear each singer in real time.

This release adds the `AUDIO_SCENARIO_CHORUS` enumeration. With this enumeration, users can experience ultra-low latency in real-time chorus when the network conditions are good.

**7. Extensions from the Agora extensions marketplace**

In order to enhance the real-time audio interactive activities based on the Agora SDK, this release supports the one-stop solution for the extensions from the <Link to="{{GLOBAL.APP_ID_LINK}}/en/agora-extensions-marketplace/">Agora extensions marketplace</Link>:

- Easy to integrate: The integration of modular functions can be achieved simply by calling an API, and the integration efficiency is improved by nearly 95%.
- Extensibility design: The modular and extensible SDK design style endows the Agora SDK with good extensibility, which enables developers to quickly build real-time interactive apps based on the Agora extensions marketplace ecosystem.
- Build an ecosystem: A community of real-time audio and video apps has developed that can accommodate a wide range of developers, offering a variety of extension combinations. After integrating the extensions, developers can build richer real-time interactive functions. For details, see [Use an Extension](../develop/use-an-extension).
- Become a vendor: Vendors can integrate their products with Agora SDK in the form of extensions, display and publish them in the Agora extensions marketplace, and build a real-time interactive ecosystem for developers together with Agora. For details on how to develop and publish extensions, see [Become a Vendor](/extensions-marketplace/get-started/quickstart-implement).

**8. Enhanced channel management**

To meet the channel management requirements of various business scenarios, this release adds the following functions to the `ChannelMediaOptions` structure:

- Sets or switches the publishing of multiple audio sources.
- Sets or switches channel profile and user role.
- Controls audio publishing delay.

Set `ChannelMediaOptions` when calling `joinChannel` or `joinChannelEx` to specify the publishing and subscription behavior of a media stream, for example, whether to subscribe to the audio streams of remote users. After joining the channel, call `updateChannelMediaOptions` to update the settings in `ChannelMediaOptions` at any time, for example, to switch the published audio sources.

**9. Subscription allowlists and blocklists**

This release introduces subscription allowlists and blocklists for remote audio streams. You can add a user ID that you want to subscribe to in your allowlist, or add a user ID for the streams you do not wish to see to your blocklists. You can experience this feature through the following APIs, and in scenarios that involve multiple channels, you can call the following methods in the `RtcEngineEx` interface:

- `setSubscribeAudioBlacklist`：Set the audio subscription blocklist.
- `setSubscribeAudioWhitelist`：Set the audio subscription allowlist.

If a user is added in a blocklist and a allowlist at the same time, only the blocklist takes effect.

**10. Set audio scenarios**

To make it easier to change audio scenarios, this release adds the `setAudioScenario` method. For example, if you want to change the audio scenario from `AUDIO_SCENARIO_DEFAULT` to `AUDIO_SCENARIO_GAME_STREAMING` when you are in a channel, you can call this method.

#### Improvements

**1. Fast channel switching**

This release can achieve the same switching speed as `switchChannel` in v3.7.x through the `leaveChannel` and `joinChannel` methods so that you don't need to take the time to call the `switchChannel` method.

**2. Voice pitch of the local user**
This release adds `voicePitch` in `AudioVolumeInfo` of `onAudioVolumeIndication`. You can use `voicePitch` to get the local user's voice pitch and perform business functions such as rating for singing.

**3. Device permission management**

This release adds the `onPermissionError` method, which is automatically reported when the audio capture device or camera does not obtain the appropriate permission. You can enable the corresponding device permission according to the prompt of the callback.

</PlatformWrapper>

