
<PlatformWrapper platform="unity">

### Implement the user interface

To enable or disable processing of captured raw video data, add a button to the user interface:

    1. Right-click **Sample Scene**, then click **UI** > **Button - TextMeshPro**. A button appears in the **Scene** Canvas.

    2. In **Inspector**, rename **Button** to **ZoomButton**, then change the following coordinates:

    * **Pos X** - 350
    * **Pos Y** - 172

### Handle the system logic

This sections describes the steps required to use the relevant libraries and declare the necessary variables, and set up access to the UI elements.

1.  **Add the required library to access the UI elements**

    In your script file, add the following after the last import statement:

    ```csharp
    using TMPro;
    ```

1.  **Define a variable to manage video processing**

    In your script file, add the following declaration to `NewBehaviourScript`:

    ```csharp
    private bool isZoomed = false;
    private TMP_Text zoomButton;
    ```

1. **Access the UI elements programmatically**

    To setup the event listener for the **ZoomButton**, in your script file, add the following at the end of `SetupUI`:

    ```csharp
    go = GameObject.Find("ZoomButton");
    go.GetComponent<Button>().onClick.AddListener(setZoom);
    zoomButton = go.GetComponentInChildren<TextMeshProUGUI>(true);
    zoomButton.text = "Zoom In";
    zoomButton.fontSize = 14;
    ```

### Implement processing of raw video and audio data

To register and use video and audio frame observers in your <Vpl k="CLIENT" />, take the following steps:

1.  **Set up the audio frame observer**

    `IAudioFrameObserver` gives you access to each audio frame after it is captured or access to each audio frame before it is played back. To setup the `IAudioFrameObserver`, in your script file, add the following code to `NewBehaviourScript`:

    ```csharp
    internal class AudioFrameObserver : IAudioFrameObserver
    {
        private readonly NewBehaviourScript _videoSample;

        internal AudioFrameObserver(NewBehaviourScript videoSample)
        {
            _videoSample = videoSample;
        }

        // Sets whether to receives remote video data in multiple channels.
        public virtual bool IsMultipleChannelFrameWanted()
        {
            return true;
        }

        // Occurs each time the player receives an audio frame.
        public virtual bool OnFrame(AudioPcmFrame videoFrame)
        {
            return true;
        }

        // Retrieves the mixed captured and playback audio frame.
        public virtual bool OnMixedAudioFrame(string channelId, AudioFrame audioFrame)
        {
            return true;
        }

        // Gets the audio frame for playback.
        public virtual bool OnPlaybackAudioFrame(string channelId, AudioFrame audioFrame)
        {
            return true;
        }

        // Retrieves the audio frame of a specified user before mixing.
        public virtual bool OnPlaybackAudioFrameBeforeMixing(string channelId, uint uid, AudioFrame audioFrame)
        {
            return true;
        }

        // Gets the playback audio frame before mixing from multiple channels.
        public virtual bool OnPlaybackAudioFrameBeforeMixingEx(string channelId, uint uid, AudioFrame audioFrame)
        {
            return false;
        }

        // Gets the captured audio frame.
        public virtual bool OnRecordAudioFrame(string channelId, AudioFrame audioFrame)
        {
            return true;
        }
    }
    ```

2.  **Set up the video frame observer**

    `IVideoFrameObserver` gives you access to each local video frame after it is captured and access to each remote video frame before it is played back. In this example, you modify the captured video frame buffer to crop and scale the frame and play a zoomed-in version of the video. To set up `IVideoFrameObserver`, in your script file, add the following code to `NewBehaviourScript`:

    ```csharp
    internal class VideoFrameObserver : IVideoFrameObserver
    {
        private readonly NewBehaviourScript _videoSample;

        internal VideoFrameObserver(NewBehaviourScript videoSample)
        {
            _videoSample = videoSample;
        }

        // Occurs each time the SDK receives a video frame before encoding.
        public virtual bool OnCaptureVideoFrame(VideoFrame videoFrame, VideoFrameBufferConfig config)
        {
            if (_videoSample.isZoomed)
            {
                // Add the captured video frame's modification code here
            }
            return true;
        }

        // Sets the frame position for the video observer.
        public virtual VIDEO_OBSERVER_POSITION GetObservedFramePosition()
        {
            return VIDEO_OBSERVER_POSITION.POSITION_POST_CAPTURER | VIDEO_OBSERVER_POSITION.POSITION_PRE_RENDERER;
        }

        // Occurs each time the SDK receives a video frame before encoding.
        public virtual bool OnPreEncodeVideoFrame(VideoFrame videoFrame, VideoFrameBufferConfig config)
        {
            return true;
        }

        // Occurs each time the SDK receives a video frame sent by the remote user.
        public virtual bool OnRenderVideoFrame(string channelId, uint uid, VideoFrame videoFrame)
        {
            return true;
        }
    }
    ```

3.  **Register the video and audio frame observers**

    To receive callbacks declared in `IVideoFrameObserver` and `IAudioFrameObserver`, in your script file, you must register the video and audio frame observers with the <Vg k="ENGINE" /> before joining a channel. To specify the format of audio frames captured by each `IAudioFrameObserver`, use the `SetRecordingAudioFrameParameters`, `SetMixedAudioFrameParameters`, and `SetPlaybackAudioFrameParameters` methods. To do this, add the following lines in the top of `Join`:

    ```csharp
    RtcEngine.RegisterAudioFrameObserver(new AudioFrameObserver(this));
    RtcEngine.RegisterVideoFrameObserver(new VideoFrameObserver(this));

    // Set the format of the captured raw audio data.
    int SAMPLE_RATE = 16000, SAMPLE_NUM_OF_CHANNEL = 1, SAMPLES_PER_CALL = 1024;

    RtcEngine.SetRecordingAudioFrameParameters(SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL,
    RAW_AUDIO_FRAME_OP_MODE_TYPE.RAW_AUDIO_FRAME_OP_MODE_READ_WRITE, SAMPLES_PER_CALL);
    RtcEngine.SetPlaybackAudioFrameParameters(SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL,
    RAW_AUDIO_FRAME_OP_MODE_TYPE.RAW_AUDIO_FRAME_OP_MODE_READ_WRITE, SAMPLES_PER_CALL);
    RtcEngine.SetMixedAudioFrameParameters(SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL, SAMPLES_PER_CALL);
    ```

4.  **Unregister the video and audio observers when you leave a channel**

    When you leave a channel, you unregister the frame observers by calling the unregister frame observer method. To implement this workflow, in your script file, add the following lines to `Leave` before `RtcEngine.LeaveChannel();`:

    ```csharp
    RtcEngine.UnRegisterAudioFrameObserver();
    RtcEngine.UnRegisterVideoFrameObserver();
    ```

5.  **Start and stop video processing**

    When a user presses the button, enable or disable video processing. To implement this workflow, in your script file, add the following method to `NewBehaviourScript`:

    ```csharp
    public void setZoom()
    {
        isZoomed = !isZoomed;

        if (isZoomed)
        zoomButton.text = "Zoom Out";
        else
        zoomButton.text = "Zoom In";
    }
    ```

</PlatformWrapper>