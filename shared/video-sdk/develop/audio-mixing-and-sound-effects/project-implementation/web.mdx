
<PlatformWrapper platform="web">

## Implement audio mixing

To implement audio mixing in your project, take the following steps:

1. **Create a buffer source track**

    <Vg k="VSDK"/> offers the `createBufferSourceAudioTrack` method that enables you to read a local or online audio file, and create a corresponding local audio track object `BufferSourceAudioTrack`:

    ```javascript
    // Create an audio track using online music
    const audioFileTrack = await AgoraRTC.createBufferSourceAudioTrack({
        source: "https://web-demos-static.agora.io/agora/smlt.flac",
    });
    console.log("create audio file track success");
    ```

    Audio tracks created from audio files follow a different audio data processing flow than microphone audio tracks. After creating a track using an audio file, if you directly call `audioFileTrack.play` or `client.publish([audioFileTrack])`, you do not hear the music either locally or remotely. 
    
    You can publish the following audio tracks in the channel.
    
    1. **MicrophoneAudioTrack**

        For microphone audio tracks, the SDK continuously collects the latest audio data (`AudioBuffer`) from the target microphone device.

        ![MicrophoneAudioTrack](https://web-cdn.agora.io/docs-files/1608477676258)

        * After you call the `play` method, the audio data is sent to the `LocalPlayback` component, allowing the local user to hear it.
        
        * When the `publish` method is called, the audio data is transmitted to <Vg k= "AGORA_BACKEND"/> and eventually heard by the remote user.
        The microphone audio track continues to acquire audio data until the `close` method is invoked, at which point the audio track becomes unavailable.

    1. **BufferSourceAudioTrack**

        For audio files, the <Vg k="VSDK"/> does not collect audio data; instead, it achieves a similar effect by reading files, shown in the following figure.

        ![BufferSourceAudioTrack](https://web-cdn.agora.io/docs-files/1608477687221)

        The key distinctions between collecting audio data and reading files are as follows:

        1. **Continuous vs. controlled reading:**
            * Collection of audio data is continuous and cannot be paused, focusing on capturing the latest audio data.
            * File reading provides more flexibility. You can pause, jump to specific positions, or loop playback. These operations are core functions of `BufferSourceAudioTrack`.

        1. **Initiating file reading:**
            * After creating an audio track from an audio file, the SDK does not automatically read the file. You need to use `BufferSourceAudioTrack`'s `startProcessAudioBuffer` method to initiate the reading and audio data processing. You then call the `play` and `publish` methods to make the audio file audible locally and remotely.

1. **Enable audio mixing**

    <Vg k="VSDK"/> supports publishing multiple audio tracks. You can mix audio by publishing `BufferSourceAudioTrack` together with the audio tracks created through the microphone. To enable audio mixing, refer to the following code:

    ```javascript
    // Create a microphone audio track
    const microphoneTrack = await AgoraRTC.createMicrophoneAudioTrack();
    
    // Start processing audio data from the audio file
    audioFileTrack.startProcessAudioBuffer();
    
    // Publish both the audio file track and the microphone track to begin mixing
    await client.publish([microphoneTrack, audioFileTrack]);
    
    // To stop mixing, either stop processing audio data from the file
    audioFileTrack.stopProcessAudioBuffer();
    
    // Or directly unpublish the audio file track
    await client.unpublish([audioFileTrack]);
    ```

1. **Manage audio mixing**

    To handle audio mixing, refer to the following code:

    ```javascript
    // Pause processing audio data
    audioFileTrack.pauseProcessAudioBuffer();
    // Resume processing audio data
    audioFileTrack.resumeProcessAudioBuffer();
    // Stop processing audio data
    audioFileTrack.stopProcessAudioBuffer();
    // Start processing audio data in the loop mode
    audioFileTrack.startProcessAudioBuffer({ loop: true });
    
    // Get the current playback progress (seconds)
    audioFileTrack.getCurrentTime();
    // Total duration of the current audio file (seconds)
    audioFileTrack.duration;
    // Jump to the position at 50 seconds
    audioFileTrack.seekAudioBuffer(50);
    ```

</PlatformWrapper>