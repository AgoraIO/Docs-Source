<PlatformWrapper platform="unity">
import KnownIssues from '@docs/shared/voice-sdk/reference/known-issues/unity.mdx';

### Known issues

<KnownIssues />

### v4.5.1

v4.5.1 was released on March 13, 2025.

#### New features

1. **AI conversation scenario**

   This version adds the `AUDIO_SCENARIO_AI_CLIENT` audio scenario specifically designed for interacting with the conversational AI agent created by [Conversational AI Engine](https://docs.agora.io/en/conversational-ai/overview/product-overview). This scenario optimizes the audio transmission algorithm based on AI-generated voice characteristics, ensuring stable voice data transmission even in weak network conditions with up to 80% packet loss. It enhances conversation continuity and reliability while adapting to complex network conditions.

1. **16 KB memory page size**

   Starting from Android 15, the system [supports 16 KB memory page sizes](https://developer.android.com/guide/practices/page-sizes). To maintain app stability and performance, the SDK now includes compatibility for both 4 KB and 16 KB memory page sizes. This enhancement ensures reliable operation across a wider range of devices and helps prevent crashes on devices using the newer memory configuration.

#### Improvements

- Reduces the SDK initialization time on specific device models. (iOS)

#### Issues fixed

This release fixes the following issues:

- Apps that integrated the Agora SDK and set the `targetSdkVersion` to 34 encountered crashes when attempting to enable screen sharing for the first time on an Android 14 system. (Android)
- When joining two or more channels simultaneously, and calling the `TakeSnapshotEx [1/2]` method to take screenshots of the local video streams in each channel consecutively, the screenshot of the first channel failed.
- When using the `Pause` method to pause playback, then calling `Seek` to move to a specified position, and finally calling `Play` to continue playback, the Media Player resumed from the position where it was paused, not the new specified position.
- When using the Media Player, the file path of the media resource returned by the `GetPlaySrc` did not change after calling the `SwitchSrc` method to switch to a new media resource.
- When using Bluetooth headphones on specific device models for audio and video interactions, adjusting the phone volume would occasionally change the media volume instead of the Bluetooth volume. (Android)
- During audio and video interactions, the local user occasionally experienced a black screen when watching the video streams of remote users. (Android)
- On specific device models, after calling `SetCameraExposureFactor` to set the exposure coefficient of the current camera at a specific angle of the device, the video screen occasionally became dark when the device was moved to another angle. (Android)
- When playing a CDN live stream, the video occasionally froze for an extended period after recovering from an interruption. (Android)
- When pushing video frames in i420 format to the channel, using CVPixelBuffer to handle these frames caused a crash. (iOS)
- Calling `SetupLocalVideo` to set up two views, then calling `EnableFaceDetection` to start face detection, no face information can be detected in the subsequently passed views. (iOS)
- In a screen sharing scenario, the receiving-end user saw a green line on the shared image. (iOS)
- In the interactive live streaming scenario, after joining a channel to watch live streams using `string` user id, the audience members occasionally saw that the audio was not synchronized with the video.
- Plugins sometimes did not work when using AI noise suppression and AI echo cancellation plugins at the same time.

### v4.5.0

v4.5.0 was released on December 10, 2024.

#### Compatibility changes

This version includes optimizations to some features, including changes to SDK behavior, API renaming and deletion. To ensure normal operation of the project, update the code in the app after upgrading to this release.

1. **Member Parameter Type Changes**

   This version has made the following modifications to some API members or parameters:

   | API                            | Members/Parameters                                         | Change                       |
   | ------------------------------ | ---------------------------------------------------------- | ---------------------------- |
   | `StartScreenCaptureByWindowId` | `windowId`                                               | Changed from `view_t` to `long`  |
   | `ScreenCaptureConfiguration`   | <ul><li>`displayId`</li><li>`windowId`</li></ul>        | Changed from `unit` to  `long`   |
   | `ScreenCaptureSourceInfo`      | <ul><li>`sourceDisplayId`</li><li>`sourceId`</li></ul> | Changed from `view_t` to  `long` |

1. **Changes in strong video noise suppression implementation**

   This version adjusts the implementation of strong video noise suppression. `VIDEO_DENOISER_LEVEL_STRENGTH` is removed from `VIDEO_DENOISER_LEVEL`.

   Instead, after enabling video noise suppression by calling `SetVideoDenoiserOptions`, you can call the `SetBeautyEffectOptions` method to enable the beauty skin smoothing feature. Using both together will achieve better video noise suppression effects. For strong noise suppression, it is recommended to set the skin smoothing parameters as detailed in `SetVideoDenoiserOptions`.

   Additionally, due to this adjustment, to achieve the best low-light enhancement effect with a focus on image quality, you need to enable video noise suppression first and use specific settings as detailed in `SetLowlightEnhanceOptions`.

1. **Changes in camera plug and unplug status (macOS, Windows)**

   In previous versions, when the camera was unplugged and replugged, the `OnVideoDeviceStateChanged` callback would report the device status as `MEDIA_DEVICE_STATE_ACTIVE`(1) (device in use). Starting from this version, after the camera is replugged, the device status will change to `MEDIA_DEVICE_STATE_IDLE`(0) (device ready).

1. **Changes in video encoding preferences**

   To enhance the userâ€™s video interaction experience, this version optimizes the default preferences for video encoding:

   - In the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_compressionpreference.html">`COMPRESSION_PREFERENCE`</Link> enumeration class, a new `PREFER_COMPRESSION_AUTO` (-1) enumeration is added, replacing the original `PREFER_QUALITY` (1) as the default value. In this mode, the SDK will automatically choose between `PREFER_LOW_LATENCY` or `PREFER_QUALITY` based on your video scene settings to achieve the best user experience.
   - In the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_degradationpreference.html">`DEGRADATION_PREFERENCE`</Link> enumeration class, a new `MAINTAIN_AUTO` (-1) enumeration is added, replacing the original `MAINTAIN_QUALITY` (1) as the default value. In this mode, the SDK will automatically choose between `MAINTAIN_FRAMERATE`, `MAINTAIN_BALANCED`, or `MAINTAIN_RESOLUTION` based on your video scene settings to achieve the optimal overall quality experience (QoE).

1. **16 KB memory page size**

   Starting from Android 15, the system adds support for 16 KB memory page size, as detailed in [Support 16 KB page sizes](https://developer.android.com/guide/practices/page-sizes). To ensure the stability and performance of the app, starting from this version, the SDK supports 16 KB memory page size, ensuring seamless operation on devices with both 4 KB and 16 KB memory page sizes, enhancing compatibility and preventing crashes.

#### New features

1. **Live show scenario**

   This version adds the `APPLICATION_SCENARIO_LIVESHOW`(3) (Live Show) enumeration to <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_videoapplicationscenariotype.html">`VIDEO_APPLICATION_SCENARIO_TYPE`</Link>. You can call `SetVideoScenario` to set the video business scenario to show room. To meet the high requirements for first frame rendering time and image quality in this scenario, the SDK has optimized strategies to significantly improve the first frame rendering experience and image quality, while enhancing the image quality in weak network environments and on low-end devices.

1. **Maximum frame rate for video rendering**

   This version adds the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setlocalrendertargetfps">`SetLocalRenderTargetFps`</Link> and <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setremoterendertargetfps">`SetRemoteRenderTargetFps`</Link> methods, which support setting the maximum frame rate for video rendering locally and remotely. The actual frame rate for video rendering by the SDK will be as close to this value as possible.

   In use-cases where the frame rate requirement for video rendering is not high (e.g., screen sharing, online education) or when the remote end uses mid-to-low-end devices, you can use this set of methods to limit the video rendering frame rate, thereby reducing CPU consumption and improving system performance.

1. **Filter effects**

   This version introduces the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setfiltereffectoptions">`SetFilterEffectOptions`</Link> method. You can pass a cube map file (`.cube`) in the `config` parameter to achieve custom filter effects such as whitening, vivid, cool, black and white, etc. Additionally, the SDK provides a built-in `built_in_whiten_filter.cube` file for quickly achieving a whitening filter effect.

1. **Local audio mixing**

   This version introduces the local audio mixing feature. You can call the `StartLocalAudioMixer` method to mix the audio streams from the local microphone, media player, sound card, and remote audio streams into a single audio stream, which can then be published to the channel. When you no longer need audio mixing, you can call the `StopLocalAudioMixer` method to stop local audio mixing. During the mixing process, you can call the `UpdateLocalAudioMixerConfiguration` method to update the configuration of the audio streams being mixed.

   Example use cases for this feature include:

   - By utilizing the local video mixing feature, the associated audio streams of the mixed video streams can be simultaneously captured and published.
   - In live streaming use-cases, users can receive audio streams within the channel, mix multiple audio streams locally, and then forward the mixed audio stream to other channels.
   - In educational use-cases, teachers can mix the audio from interactions with students locally and then forward the mixed audio stream to other channels.

1. **External `MediaProjection` (Android)**

   This version introduces the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setexternalmediaprojection">`SetExternalMediaProjection`</Link> method, which allows you to set an external `MediaProjection` and replace the `MediaProjection` applied by the SDK.

   If you have the capability to apply for `MediaProjection` on your own, you can use this feature to achieve more flexible screen capture.

1. **EGL context (Android)**

   This version introduces the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setexternalremoteeglcontext">`SetExternalRemoteEglContext`</Link> method, which is used to set the EGL context for rendering remote video streams. When using Texture format video data for remote video self-rendering, you can use this method to replace the SDK's default remote EGL context, achieving unified EGL context management.

1. **Color space settings**

   This version adds the **colorSpace** parameter to `VideoFrame` and `ExternalVideoFrame`. You can use this parameter to set the color space properties of the video frame. By default, the color space uses Full Range and BT.709 standard configuration. You can flexibly adjust according to your own capture or rendering needs, further enhancing the customization capabilities of video processing.

1. **Other features**

   - <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengineeventhandler.html#callback_irtcengineeventhandler_onlocalvideostatechanged">`OnLocalVideoStateChanged`</Link> callback adds the `LOCAL_VIDEO_STREAM_REASON_DEVICE_DISCONNECTED` enumeration, indicating that the currently used video capture device has been disconnected (e.g., unplugged). (Windows)
   - <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_mediadevicestatetype.html">`MEDIA_DEVICE_STATE_TYPE`</Link> adds the `MEDIA_DEVICE_STATE_PLUGGED_IN` enumeration, indicating that the device has been plugged in. (Windows)

#### Improvements

1. **Virtual background algorithm optimization**

   This version upgrades the virtual background algorithm, making the segmentation between the portrait and the background more accurate. There is no background exposure, the body contour of the portrait is complete, and the detail recognition of fingers is significantly improved. Additionally, the edges between the portrait and the background are more stable, reducing edge jumping and flickering in continuous video frames.

1. **Snapshot at specified video observation points**

   This version introduces the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_takesnapshot2">`TakeSnapshot [2/2]`</Link> and <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengineex_takesnapshotex2">`TakeSnapshotEx [2/2]`</Link> methods. You can use the `config` parameter when calling these methods to take snapshots at specified video observation points, such as before encoding, after encoding, or before rendering, to achieve more flexible snapshot effects.

1. **Custom audio capture improvements**

   This version adds the `enableAudioProcessing` member parameter to <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_audiotrackconfig.html">`AudioTrackConfig`</Link>, which is used to control whether to enable 3A audio processing for custom audio capture tracks of the `AUDIO_TRACK_DIRECT` type. The default value of this parameter is `false`, meaning that audio processing is not enabled. Users can enable it as needed, enhancing the flexibility of custom audio processing.

1. **Other improvements**

   - In use-cases where Alpha transparency effects are achieved by stitching video frames and Alpha data, the rendering performance on the receiving end has been improved, effectively reducing stuttering and latency. (Android, iOS)
   - Optimizes the logic for calling `QueryDeviceScore` to obtain device score levels, improving the accuracy of the score results.
   - Supports using virtual cameras in YV12 format as video capture devices. (Windows)
   - When calling `SwitchSrc` to switch between live streams or on-demand streams of different resolutions, smooth and seamless switching can be achieved. An automatic retry mechanism has been added in case of switching failures. The SDK will automatically retry 3 times after a failure. If it still fails, the `OnPlayerEvent` callback will report the `PLAYER_EVENT_SWITCH_ERROR` event, indicating an error occurred during media resource switching.
   - When calling `SetPlaybackSpeed` to set the playback speed of an audio file, the minimum supported speed is 0.3x.

#### Issues fixed

This version fixes the following issues:

- When calling `StartScreenCaptureByWindowId` to share the screen, the window capture area specified by **regionRect** was inaccurate, resulting in incorrect width and height of the screen sharing window seen by the receiving end. (Windows)
- When the video source type of the sender is in JPEG format, the frame rate on the receiving end occasionally falls below expectations. (Android, iOS)
- During audio and video interaction, after being interrupted by a system call, the user volume reported by the `OnAudioVolumeIndication` callback was incorrect. (Android)
- When the receiving end subscribes to the low-quality video stream by default and does not automatically subscribe to any video stream when joining the channel, calling `MuteRemoteVideoStream (uid, false)` after joining the channel to resume receiving the video stream results in receiving the high-quality video stream. (Android)
- Occasional errors of not finding system files during audio and video interaction on Windows 7 systems. (Windows)
- When calling `FollowSystemRecordingDevice` or `FollowSystemPlaybackDevice` to set the audio capture or playback device used by the SDK to not follow the system default audio playback device, the local audio state callback `OnLocalAudioStateChanged` is not triggered when the audio device is removed. (Windows)
- Occasional instances where the receiving end cannot hear the sender during audio and video interaction. (iOS)
- During audio and video interaction, if the sender's device system version is iOS 17, the receiving end occasionally cannot hear the sender. (iOS)
- In live streaming use-cases, the time taken to reconnect to the live room after the audience end disconnects due to network switching is longer than expected. (iOS)
- No sound when playing online media resources using the media player after the app starts. (iOS)
- Occasional instances of no sound in audio capture after resuming from being interrupted by other system apps during audio and video interaction. (iOS)
- Calling `StartAudioMixing [1/2]` and then immediately calling `PauseAudioMixing` to pause the music file playback does not take effect.
- Occasional crashes during audio and video interaction. (Android)

### v4.4.0

v4.4.0 was released on August 29, 2024.

#### Compatibility changes

This version includes optimizations to some features, including changes to SDK behavior and API renaming and deletion.
To ensure normal operation of the project, update the code in the app after upgrading to this release.

1. To distinguish context information in different extension callbacks, this version removes the original extension callbacks and adds corresponding callbacks that contain context information (see the table below). You can identify the extension name, the user ID, and the service provider name through `ExtensionContext` in each callback.

   | Original callback    | New callback                |
   | -------------------- | ------------------------------- |
   | `onExtensionEvent`   | `OnExtensionEventWithContext`   |
   | `onExtensionStarted` | `OnExtensionStartedWithContext` |
   | `onExtensionStopped` | `OnExtensionStoppedWithContext` |
   | `onExtensionError`   | `OnExtensionErrorWithContext`   |

#### New features

1. **Voice AI tuner**

   This version introduces the voice AI tuner feature, which can enhance the sound quality and tone, similar to a
   physical sound card. You can enable the voice AI tuner feature by calling the `EnableVoiceAITuner` method. Pass in the sound effect types supported in the `VOICE_AI_TUNER_TYPE` enum to achieve effects like deep voice, cute voice,
    husky singing voice, and so on.

#### Improvements

1. **Adaptive hardware decoding support (Android, Windows)**

   This release introduces adaptive hardware decoding support, enhancing rendering smoothness on low-end devices and effectively reducing system load.

1. **Rendering performance enhancement (Windows)**

   DirectX 11 renderer is now enabled by default on Windows devices, providing high-performance and high-quality graphics rendering capabilities.

1. **Other improvements**

   This version also includes the following improvements:

   - Optimizes the transmission strategy: Calling `EnableInstantMediaRendering` no longer impacts the security of the transmission link.
   - Adds the `channelId` parameter to `Metadata`, which is used to get the channel name from which the metadata is sent.
   - Deprecates redundant enumeration values `CLIENT_ROLE_CHANGE_FAILED_REQUEST_TIME_OUT` and `CLIENT_ROLE_CHANGE_FAILED_CONNECTION_FAILED` in `CLIENT_ROLE_CHANGE_FAILED_REASON`.

#### Issues fixed

This release fixed the following issues:

- Occasional app crashes occurred when multiple remote users joined the channel simultaneously during real-time
interaction (iOS).
- After the sender called `StartDirectCdnStreaming` to start direct CDN streaming, frequent switching or toggling of the
 network occasionally resulted in a black screen on the receiver's end without a streaming failure callback on the sender's end (iOS).
- Audio playback failed when pushing external audio data using `PushAudioFrame` and the sample rate was not set to a recommended value, such as 22050 Hz and 11025 Hz.

### v4.3.2

v4.3.2 was released on June 6, 2024.

#### Improvements

This release enhances the usability of the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setremotesubscribefallbackoption">setRemoteSubscribeFallbackOption</Link> method by removing the timing requirements for invocation. It can now be called both before and after joining the channel to dynamically switch audio and video stream fallback options in weak network conditions.

#### Issues fixed

This version fixed the following issues:

- Local audio capture failed after joining a channel while answering a system phone call and hanging up, causing remote users to not hear any sound (Android).
- During the interaction process on certain devices (for example, Redmi Note8), after answering and hanging up a system call, local media files were played without sound and no sound was heard from the remote end (Android).
- The app occasionally crashed when remote users left the channel.
- When playing an audio file using <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_startaudiomixing">StartAudioMixing [1/2]</Link> and the playing finished, the SDK sometimes failed to trigger the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengineeventhandler.html#callback_irtcengineeventhandler_onaudiomixingstatechanged">OnAudioMixingStateChanged</Link> (`AUDIO_MIXING_STATE_STOPPED`, `AUDIO_MIXING_REASON_ALL_LOOPS_COMPLETED`) callback that reports that the playing is completed (iOS).
- When calling the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_playeffect3">PlayEffect</Link> method to play sound effect files shorter than 1 second with `loopCount` set to `0`, there was no sound (iOS).


### v4.3.1

v4.3.1 was released on May 9, 2024.

#### New features

1. **Privacy manifest file (iOS)**

   To meet Apple's safety compliance requirements for app publication, the SDK now includes a privacy manifest file, `PrivacyInfo.xcprivacy`, detailing the SDK's API calls that access or use user data, along with a description of the types of data collected.

   <Admonition type="info" title="Note"> If you need to publish an app with SDK versions prior to v4.3.1 to the Apple App Store, manually add the `PrivacyInfo.xcprivacy` file to your Xcode project. </Admonition>

1. **Data stream encryption**

   This version adds `datastreamEncryptionEnabled` to <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_encryptionconfig.html">EncryptionConfig</Link> for enabling data stream encryption. You can set this when you activate encryption with <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_enableencryption">EnableEncryption</Link>. If there are issues causing failures in data stream encryption or decryption, these can be identified by the newly added `ENCRYPTION_ERROR_DATASTREAM_DECRYPTION_FAILURE` and `ENCRYPTION_ERROR_DATASTREAM_ENCRYPTION_FAILURE` enumerations.

1. **Other features**

   - A new method <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengineex_enableencryptionex">EnableEncryptionEx</Link> is added for enabling media stream or data stream encryption in multi-channel use-cases.
   - A new method <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setaudiomixingplaybackspeed">SetAudioMixingPlaybackSpeed</Link> is introduced for setting the playback speed of audio files.
   - A new method <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengineex_getcallidex">GetCallIdEx</Link> is introduced for retrieving call IDs in multi-channel use-cases.

#### Improvements

1. **Audio device type detection (macOS)**

   This version adds the following methods to obtain the information and type of audio playback and recording devices:

   - <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_iaudiodevicemanager_getplaybackdefaultdevice2">GetPlaybackDefaultDevice [2/2]</Link>
   - <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_iaudiodevicemanager_getrecordingdefaultdevice2">GetRecordingDefaultDevice [2/2]</Link>
   - <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_iaudiodevicemanager.html#api_iaudiodevicemanager_getplaybackdeviceinfo2">GetPlaybackDeviceInfo [2/2]</Link>
   - <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_iaudiodevicemanager.html#api_iaudiodevicemanager_getrecordingdeviceinfo2">GetRecordingDeviceInfo [2/2]</Link>

1. **CPU consumption reduction of in-ear monitoring**

   This release adds an enumerator `EAR_MONITORING_FILTER_REUSE_POST_PROCESSING_FILTER` in `EAR_MONITORING_FILTER_TYPE`. For complex audio processing use-cases, you can specify this option to reuse the audio filter post sender-side processing in in-ear monitoring, thereby reducing CPU consumption. Note that this option may increase the latency of in-ear monitoring, which is suitable for latency-tolerant use-cases requiring low CPU consumption.

1. **Other improvements**

   This version also includes the following improvements:

   - In <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_audioeffectpreset.html">AUDIO_EFFECT_PRESET</Link>, a new enumeration `ROOM_ACOUSTICS_CHORUS` (chorus effect) is added, enhancing the spatial presence of vocals in chorus use-cases.
   - In <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_remoteaudiostats.html">RemoteAudioStats</Link>, a new `e2eDelay` field is added to report the delay from when the audio is captured on the sending end to when the audio is played on the receiving end.

#### Issues fixed

This version fixed the following issues:

- Hosts using certain models of devices in the speaker mode experienced occasional local audio capture failures when switching the app process to the background and then back to the foreground, preventing remote users from hearing the host's audio (Android).
- An occasional echo was observed when playing the audio stream of a specified user before mixing (macOS, Windows).
- During interactions, when a local user set the system default playback device to speakers, there was no sound from the remote end  (Windows).

#### API changes

**Added**

- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_enablecameracenterstage">EnableCameraCenterStage</Link> (iOS, macOS)
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_iscameracenterstagesupported">IsCameraCenterStageSupported</Link> (iOS, macOS)
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setcamerastabilizationmode">SetCameraStabilizationMode</Link> (iOS)
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_camerastabilizationmode.html">CAMERA_STABILIZATION_MODE</Link> (iOS)
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_imediaengine_registerfaceinfoobserver">RegisterFaceInfoObserver</Link>
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_imediaengine_unregisterfaceinfoobserver">UnregisterFaceInfoObserver</Link>
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_ifaceinfoobserver.html#class_ifaceinfoobserver">IFaceInfoObserver</Link>
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_ifaceinfoobserver.html#callback_ifaceinfoobserver_onfaceinfo">OnFaceInfo</Link>
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_mediasourcetype.html">MEDIA_SOURCE_TYPE</Link> adds `SPEECH_DRIVEN_VIDEO_SOURCE`
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_videosourcetype.html">VIDEO_SOURCE_TYPE</Link> adds `VIDEO_SOURCE_SPEECH_DRIVEN`
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_encryptionconfig.html">EncryptionConfig</Link> adds `datastreamEncryptionEnabled`
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_encryptionerrortype.html">ENCRYPTION_ERROR_TYPE</Link> adds the following enumerations:
  - `ENCRYPTION_ERROR_DATASTREAM_DECRYPTION_FAILURE`
  - `ENCRYPTION_ERROR_DATASTREAM_ENCRYPTION_FAILURE`
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_iaudiodevicemanager_getplaybackdefaultdevice2">GetPlaybackDefaultDevice [2/2]</Link> (macOS),
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_iaudiodevicemanager_getrecordingdefaultdevice2">GetRecordingDefaultDevice [2/2]</Link> (macOS),
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_iaudiodevicemanager.html#api_iaudiodevicemanager_getplaybackdeviceinfo2">GetPlaybackDeviceInfo [2/2]</Link> (macOS)
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_iaudiodevicemanager.html#api_iaudiodevicemanager_getrecordingdeviceinfo2">GetRecordingDeviceInfo [2/2]</Link> (macOS)
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_remoteaudiostats.html">RemoteAudioStats</Link> adds `e2eDelay`
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_errorcodetype.html">ERROR_CODE_TYPE</Link> adds `ERR_DATASTREAM_DECRYPTION_FAILED`
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_audioeffectpreset.html">AUDIO_EFFECT_PRESET</Link> adds `ROOM_ACOUSTICS_CHORUS`, enhancing the spatial presence of vocals in chorus use-cases.
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengineex_getcallidex">GetCallIdEx</Link>
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengineex_enableencryptionex">EnableEncryptionEx</Link>
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setaudiomixingplaybackspeed">SetAudioMixingPlaybackSpeed</Link>
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_querycamerafocallengthcapability">QueryCameraFocalLengthCapability</Link>(Android, iOS)
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_focallengthinfo.html">FocalLengthInfo</Link> (Android, iOS)
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_camerafocallengthtype.html">CAMERA_FOCAL_LENGTH_TYPE</Link> (Android, iOS)
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_cameracapturerconfiguration.html">CameraCapturerConfiguration</Link> adds a new member `cameraFocalLengthType` (Android, iOS)
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_cameracapturerconfiguration.html">CameraCapturerConfiguration</Link> adds a new member `cameraId` (Android)
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_earmonitoringfiltertype.html">EAR_MONITORING_FILTER_TYPE</Link> adds a new enumeration `EAR_MONITORING_FILTER_BUILT_IN_AUDIO_FILTERS`


### v4.3.0

v4.3.0 was released on February 28, 2024.

#### Compatibility changes

This release has optimized the implementation of some functions, involving renaming or deletion of some APIs. To ensure the normal operation of the project, you need to update the code in the app after upgrading to this release.

1. **Renaming parameters in callbacks**

   In order to make the parameters in some callbacks and the naming of enumerations in enumeration classes easier to understand, the following modifications have been made in this release. Please modify the parameter settings in the callbacks after upgrading to this release.

   | Callback                           | Original parameter name | New parameter name |
   | ---------------------------------- | ----------------------- | ----------------------- |
   | `OnLocalAudioStateChanged`         | `error`                 | `reason`                |
   | `onLocalVideoStateChanged`         | `error`                 | `reason`                |
   | `OnDirectCdnStreamingStateChanged` | `error`                 | `reason`                |
   | `OnRtmpStreamingStateChanged`      | `errCode`               | `reason`                |

   | Original enumeration class   | New enumeration class     |
   | ---------------------------- | ----------------------------- |
   | `LOCAL_AUDIO_STREAM_ERROR`   | `LOCAL_AUDIO_STREAM_REASON`   |
   | `LOCAL_VIDEO_STREAM_ERROR`   | `LOCAL_VIDEO_STREAM_REASON`   |
   | `DIRECT_CDN_STREAMING_ERROR` | `DIRECT_CDN_STREAMING_REASON` |
   | `MEDIA_PLAYER_ERROR`         | `MEDIA_PLAYER_REASON`         |
   | `RTMP_STREAM_PUBLISH_ERROR`  | `RTMP_STREAM_PUBLISH_REASON`  |

   **Note:** For specific renaming of enumerations, please refer to [API changes](#api-changes).

1. **Channel media relay**

   To improve interface usability, this release removes some methods and callbacks for channel media relay. Use the alternative options listed in the table below:

   | Deleted methods and callbacks                                | Alternative methods and callbacks  |
   | ------------------------------------------------------------ | ---------------------------------- |
   | <ul><li>`startChannelMediaRelay`</li><li>`updateChannelMediaRelay`</li></ul> | `startOrUpdateChannelMediaRelay`   |
   | <ul><li>`startChannelMediaRelayEx`</li><li>`updateChannelMediaRelayEx`</li></ul> | `startOrUpdateChannelMediaRelayEx` |
   | `onChannelMediaRelayEvent`                                   | `onChannelMediaRelayStateChanged`  |

1. **Audio route**

   Starting with this release, `routeBluetooth` in <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_audioroute.html">AudioRoute</Link> is renamed to `ROUTE_BLUETOOTH_DEVICE_HFP`, representing a Bluetooth device using the HFP protocol. `ROUTE_BLUETOOTH_DEVICE_A2DP`(10) is added to represent a Bluetooth device using the A2DP protocol

1. **Audio loopback capturing (Windows, macOS)**

    - Before v4.3.0, if you called the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDk}}/class_irtcengine.html#api_irtcengine_disableaudio">DisableAudio</Link> method to disable the audio module, audio loopback capturing would not be disabled.
    - As of v4.3.0, if you call the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_disableaudio">DisableAudio</Link> method to disable the audio module, audio loopback capturing will be disabled as well. If you need to enable audio loopback capturing, you need to enable the audio module by calling the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_enableaudio">EnableAudio</Link> method and then call <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_enableloopbackrecording">EnableLoopbackRecording</Link>.

1. **Log encryption behavior changes**

   For security and performance reasons, as of this release, the SDK encrypts logs and no longer supports printing plaintext logs via the console.

   Refer to the following solutions for different needs:

      - If you need to know the API call status, please check the API logs and print the SDK callback logs yourself.
      - For any other special requirements, please contact [technical support](mailto:support@agora.io) and provide the corresponding encrypted logs.


#### New features

1. **Query device score**

   This release adds the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_querydevicescore">QueryDeviceScore</Link> method to query the device's score level to ensure that the user-set parameters do not exceed the device's capabilities. For example, in HD or UHD video use-cases, you can first call this method to query the device's score. If the returned score is low (for example, below 60), you need to lower the video resolution to avoid affecting the video experience. The minimum device score required for different business use-cases is varied. For specific score recommendations, please contact [technical support](mailto:support@agora.io).

1. **Select different audio tracks for local playback and streaming**

   This release introduces the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_Imediaplayer_selectmultiaudiotrack">SelectMultiAudioTrack</Link> method that allows you to select different audio tracks for local playback and streaming to remote users. For example, in use-cases like online karaoke, the host can choose to play the original sound locally and publish the accompaniment in the channel. Before using this function, you need to open the media file through the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_imediaplayer.html#api_imediaplayer_openwithmediasource">OpenWithMediaSource</Link> method and enable this function by setting the `enableMultiAudioTrack` parameter in <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_mediasource.html">MediaSource</Link>.

1. **Others**

   This release has passed the test verification of the following APIs and can be applied to the entire series of RTC 4.x SDK.

   - <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setremotesubscribefallbackoption">SetRemoteSubscribeFallbackOption</Link>: Sets fallback option for the subscribed video stream in weak network conditions.
   - <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengineeventhandler.html#callback_irtcengineeventhandler_onremotesubscribefallbacktoaudioonly">OnRemoteSubscribeFallbackToAudioOnly</Link>: Occurs when the subscribed video stream falls back to audio-only stream due to weak network conditions or switches back to the video stream after the network conditions improve.
   - <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_iaudiodevicemanager.html#api_iaudiodevicemanager_getrecordingdevicevolume">GetRecordingDeviceVolume</Link>(Windows): Sets the volume of the audio capturing device.
   - <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_imediaplayer.html#api_imediaplayer_setplayeroption">SetPlayerOption</Link> and <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_imediaplayer.html#api_imediaplayer_setplayeroption2">SetPlayerOption</Link>: Sets media player options for providing technical previews or special customization features.
   - <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengine_enablecustomaudiolocalplayback">EnableCustomAudioLocalPlayback</Link>: Sets whether to enable the local playback of external audio source.

#### Improvements

1. **SDK task processing scheduling optimization**

   This release optimizes the scheduling mechanism for internal tasks within the SDK, with improvements in the following aspects:

   - The speed of video rendering and audio playback for both remote and local first frames improves by 10% to 20%.
   - The API call duration and response time are reduced by 5% to 50%.
   - The SDK's parallel processing capability significantly improves, delivering higher video quality (720P, 24 fps) even on lower-end devices. Additionally, image processing remains more stable in use-cases involving high resolutions and frame rates.
   - The stability of the SDK is further enhanced, leading to a noticeable decrease in the crash rate across various specific use-cases.

1. **In-ear monitoring volume boost**

   This release provides users with more flexible in-ear monitoring audio adjustment options, supporting the ability to set the in-ear monitoring volume to four times the original volume by calling <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_setinearmonitoringvolume">SetInEarMonitoringVolume</Link>.

1. **Spatial audio effects usability improvement**

   - This release optimizes the design of the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_ilocalspatialaudioengine.html#api_ibasespatialaudioengine_setzones">SetZones</Link> method, supporting the ability to set the `zones` parameter to `NULL`, indicating the clearing of all echo cancellation zones.
   - As of this release, it is no longer necessary to unsubscribe from the audio streams of all remote users within the channel before calling the methods in <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_ilocalspatialaudioengine.html#class_ilocalspatialaudioengine">ILocalSpatialAudioEngine</Link>.

1. **Other improvements**

   This release also includes the following improvements:

   - This release optimizes the SDK's domain name resolution strategy, improving the stability of calling to resolve domain names in complex network environments.
   - When passing in an image with transparent background as the virtual background image, the transparent background can be filled with customized color.
   - This release adds the `earMonitorDelay` and `aecEstimatedDelay` members in <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_localaudiostats.html">LocalAudioStats</Link> to report ear monitor delay and acoustic echo cancellation (AEC) delay, respectively.
   - The <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_imediaplayersourceobserver.html#callback_imediaplayersourceobserver_onplayercachestats">OnPlayerCacheStats</Link> callback is added to report the statistics of the media file being cached. This callback is triggered once per second after file caching is started.
   - The <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_imediaplayersourceobserver.html#callback_imediaplayersourceobserver_onplayerplaybackstats">OnPlayerPlaybackStats</Link> callback is added to report the statistics of the media file being played. This callback is triggered once per second after the media file starts playing. You can obtain information like the audio and video bitrate of the media file through <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_playerplaybackstats.html">PlayerPlaybackStats</Link>.

#### Issues fixed

This release fixed the following issues:

- When sharing two screen sharing video streams simultaneously, the reported `captureFrameRate` in the <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengineeventhandler.html#callback_irtcengineeventhandler_onlocalvideostats">OnLocalVideoStats</Link> callback is 0, which is not as expected.

#### API changes

**Added**

- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengineex.html#api_irtcengine_enablecustomaudiolocalplayback">EnableCustomAudioLocalPlayback</Link>
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_irtcengine_querydevicescore">QueryDeviceScore</Link>
- The `CUSTOM_VIDEO_SOURCE` enumeration in <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_mediasourcetype.html">MEDIA_SOURCE_TYPE</Link>
- The `ROUTE_BLUETOOTH_DEVICE_A2DP` enumeration in <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/enum_audioroute.html">AudioRoute</Link>
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_irtcengine.html#api_Imediaplayer_selectmultiaudiotrack">SelectMultiAudioTrack</Link>
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_imediaplayersourceobserver.html#callback_imediaplayersourceobserver_onplayercachestats">OnPlayerCacheStats</Link>
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_imediaplayersourceobserver.html#callback_imediaplayersourceobserver_onplayerplaybackstats">OnPlayerPlaybackStats</Link>
- <Link to="{{Global.API_REF_UNITY_ROOT_VOICE_SDK}}/class_playerplaybackstats.html">PlayerPlaybackStats</Link>

**Modified**

- All `ERROR` fields in the following enumerations are changed to `REASON`:

  - `LOCAL_AUDIO_STREAM_ERROR_OK`
  - `LOCAL_AUDIO_STREAM_ERROR_FAILURE`
  - `LOCAL_AUDIO_STREAM_ERROR_DEVICE_NO_PERMISSION`
  - `LOCAL_AUDIO_STREAM_ERROR_DEVICE_BUSY`
  - `LOCAL_AUDIO_STREAM_ERROR_RECORD_FAILURE`
  - `LOCAL_AUDIO_STREAM_ERROR_ENCODE_FAILURE`
  - `LOCAL_AUDIO_STREAM_ERROR_RECORD_INVALID_ID`
  - `LOCAL_AUDIO_STREAM_ERROR_PLAYOUT_INVALID_ID`
  - `LOCAL_VIDEO_STREAM_ERROR_OK`
  - `LOCAL_VIDEO_STREAM_ERROR_FAILURE`
  - `LOCAL_VIDEO_STREAM_ERROR_DEVICE_NO_PERMISSION`
  - `LOCAL_VIDEO_STREAM_ERROR_DEVICE_BUSY`
  - `LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE`
  - `LOCAL_VIDEO_STREAM_ERROR_CODEC_NOT_SUPPORT`
  - `LOCAL_VIDEO_STREAM_ERROR_DEVICE_NOT_FOUND`
  - `LOCAL_VIDEO_STREAM_ERROR_DEVICE_DISCONNECTED`
  - `LOCAL_VIDEO_STREAM_ERROR_DEVICE_INVALID_ID`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_MINIMIZED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_CLOSED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_OCCLUDED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_NO_PERMISSION`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_PAUSED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_RESUMED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_HIDDEN`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_HIDDEN`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_MINIMIZED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_FAILURE`
  - `LOCAL_VIDEO_STREAM_ERROR_DEVICE_SYSTEM_PRESSURE`
  - `DIRECT_CDN_STREAMING_ERROR_OK`
  - `DIRECT_CDN_STREAMING_ERROR_FAILED`
  - `DIRECT_CDN_STREAMING_ERROR_AUDIO_PUBLICATION`
  - `DIRECT_CDN_STREAMING_ERROR_VIDEO_PUBLICATION`
  - `DIRECT_CDN_STREAMING_ERROR_NET_CONNECT`
  - `DIRECT_CDN_STREAMING_ERROR_BAD_NAME`
  - `PLAYER_ERROR_NONE`
  - `PLAYER_ERROR_INVALID_ARGUMENTS`
  - `PLAYER_ERROR_INTERNAL`
  - `PLAYER_ERROR_NO_RESOURCE`
  - `PLAYER_ERROR_INVALID_MEDIA_SOURCE`
  - `PLAYER_ERROR_UNKNOWN_STREAM_TYPE`
  - `PLAYER_ERROR_OBJ_NOT_INITIALIZED`
  - `PLAYER_ERROR_CODEC_NOT_SUPPORTED`
  - `PLAYER_ERROR_VIDEO_RENDER_FAILED`
  - `PLAYER_ERROR_INVALID_STATE`
  - `PLAYER_ERROR_URL_NOT_FOUND`
  - `PLAYER_ERROR_INVALID_CONNECTION_STATE`
  - `PLAYER_ERROR_SRC_BUFFER_UNDERFLOW`
  - `PLAYER_ERROR_INTERRUPTED`
  - `PLAYER_ERROR_NOT_SUPPORTED`
  - `PLAYER_ERROR_TOKEN_EXPIRED`
  - `PLAYER_ERROR_UNKNOWN`
  - `RTMP_STREAM_PUBLISH_ERROR_OK`
  - `RTMP_STREAM_PUBLISH_ERROR_INVALID_ARGUMENT`
  - `RTMP_STREAM_PUBLISH_ERROR_ENCRYPTED_STREAM_NOT_ALLOWED`
  - `RTMP_STREAM_PUBLISH_ERROR_CONNECTION_TIMEOUT`
  - `RTMP_STREAM_PUBLISH_ERROR_INTERNAL_SERVER_ERROR`
  - `RTMP_STREAM_PUBLISH_ERROR_RTMP_SERVER_ERROR`
  - `RTMP_STREAM_PUBLISH_ERROR_TOO_OFTEN`
  - `RTMP_STREAM_PUBLISH_ERROR_REACH_LIMIT`
  - `RTMP_STREAM_PUBLISH_ERROR_NOT_AUTHORIZED`
  - `RTMP_STREAM_PUBLISH_ERROR_STREAM_NOT_FOUND`
  - `RTMP_STREAM_PUBLISH_ERROR_FORMAT_NOT_SUPPORTED`
  - `RTMP_STREAM_PUBLISH_ERROR_NOT_BROADCASTER`
  - `RTMP_STREAM_PUBLISH_ERROR_TRANSCODING_NO_MIX_STREAM`
  - `RTMP_STREAM_PUBLISH_ERROR_NET_DOWN`
  - `RTMP_STREAM_PUBLISH_ERROR_INVALID_PRIVILEGE`
  - `RTMP_STREAM_UNPUBLISH_ERROR_OK`

**Deleted**

- `StartChannelMediaRelay`
- `UpdateChannelMediaRelay`
- `StartChannelMediaRelayEx`
- `UpdateChannelMediaRelayEx`
- `OnChannelMediaRelayEvent`
- `CHANNEL_MEDIA_RELAY_EVENT`

### v4.2.6

v4.2.6 was released on November 24, 2023.

#### Issues fixed

This release fixed the following issue:

- When using an iOS 16 or later device with Bluetooth headphones connected before joining the channel, the audio routing after joining the channel was not as expected: Audio was played from the speaker, not the Bluetooth headphones (iOS).

### v4.2.4

v4.2.4 was released on October 25, 2023.

#### Issues fixed

This release fixes the following issue:

The `AgoraRtcWrapper` version number in `CFBundleShortVersionString` on iOS and macOS is wrong, which interferes with submitting the App to the App Store.

### v4.2.3

v4.2.3 was released on October 20, 2023.

#### Improvements

This release includes the following improvements:

- Optimizes the logic of handling invalid parameters. When you call the `SetPlaybackSpeed` method to set the playback speed of audio files, if you pass an invalid parameter, the SDK returns the error code -2, which means that you need to reset the parameter.
- Optimizes the logic of Token parsing, in order to prevent an app from crashing when an invalid token is passed in.

#### Issues fixed

This release fixed the following issues:

- Occasional crashes when joining a channel on macOS.
- Occasional failure of joining a channel when the local system time was not set correctly.
- When calling the `PlayEffect` method to play two audio files using the same `soundId`, the first audio file was sometimes played repeatedly.
- When the host called the `StartAudioMixing` [2/2] method to play music, sometimes the host couldn't hear the music while the remote users could hear it on Android.
- Occasional crashes occurred on certain Android devices.
- In channels joined by calling `JoinChannelEx` exclusively, calling `SetEnableSpeakerphone` did not result in switching audio route from the speaker to the headphone on Android.

#### API changes

**Added**

- The following enumerations in `OnLocalVideoStateChanged` on Windows and macOS:
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_PAUSED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_RESUMED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_HIDDEN`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_HIDDEN`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_MINIMIZED`
- `d3d11_texture_2d` and `texture_slice_index` members in `ExternalVideoFrame` on Windows
- `VIDEO_TEXTURE_ID3D11TEXTURE2D` in `VIDEO_PIXEL_FORMAT` on Windows
- `EnableContentInspectEx`
- `CONTENT_INSPECT_IMAGE_MODERATION` in `CONTENT_INSPECT_TYPE`
- `serverConfig` in `ContentInspectConfig`
- `IsFeatureAvailableOnDevice`
- `FeatureType`

### v4.2.2

This version was released on August 1, 2023.

#### Compatibility changes

If you use the features mentioned in this section, ensure that you modify the implementation of the relevant features after upgrading the SDK.

1. **Audio frame observer**

The following methods in the `IAudioFrameObserver` class are deleted:

- `GetObservedAudioFramePosition`: Use the newly-added `position` parameter in  `RegisterAudioFrameObserver` instead.
- `GetPlaybackAudioParams`: Use `SetPlaybackAudioFrameParameters` instead.
- `GetRecordAudioParams`: Use `SetRecordingAudioFrameParameters` instead.
- `GetMixedAudioParams`: Use `SetMixedAudioFrameParameters` instead.
- `GetEarMonitoringAudioParams`: Use `SetEarMonitoringAudioFrameParameters` instead.

2. **Metadata**

This release deletes `GetMaxMetadataSize` and `OnReadyToSendMetadata` in the `IMetadataObserver` class. You can use the newly-added `SetMaxMetadataSize` and `SendMetadata` methods instead.

#### New features

1. **Wildcard token**

   This release introduces wildcard tokens. Agora supports setting the channel name used for generating a token as a wildcard character. The token generated can be used to join any channel if you use the same user id. In use-cases involving multiple channels, such as switching between different channels, using a wildcard token can avoid repeated application of tokens every time users joining a new channel, which reduces the pressure on your token server. See [Deploy a token server](/video-calling/token-authentication/deploy-token-server#generate-wildcard-tokens).

   <div class="alert info">All 4.x SDKs support using wildcard tokens.</div>

2. **Preloading channels**

   This release adds `PreloadChannel[1/2]` and `PreloadChannel[2/2]` methods, which allows a user whose role is set as audience to preload channels before joining one. Calling the method can help shortening the time of joining a channel, thus reducing the time it takes for audience members to hear and see the host.

   When preloading more than one channels, Agora recommends that you use a wildcard token for preloading to avoid repeated application of tokens every time you joining a new channel, thus saving the time for switching between channels. See [Deploy a token server](/video-calling/token-authentication/deploy-token-server#generate-wildcard-tokens).


#### Improvements

**Channel media relay**

The number of target channels for media relay has been increased to 6. When calling `StartOrUpdateChannelMediaRelay` and `StartOrUpdateChannelMediaRelayEx`, you can specify up to 6 target channels.

This release also includes the following additional improvements:

To improve the switching experience between multiple audio routes, this release adds the `SetRouteInCommunicationMode` method. This method can switch the audio route from a Bluetooth headphone to the earpiece, wired headphone or speaker in communication volume mode ([`MODE_IN_COMMUNICATION`](https://developer.android.google.cn/reference/kotlin/android/media/AudioManager?hl=en#mode_in_communication)). (Android)

#### Issues fixed

This release fixed the following issues:

- Occasionally, noise occurred when the local user listened to their own and remote audio after joining the channel. (macOS)
- Slow channel reconnection after the connection was interrupted due to network reasons.
- In multi-device audio recording use-cases, after repeatedly plugging and unplugging or enabling/disabling the audio recording device, no sound could be heard occasionally when calling the `StartRecordingDeviceTest` to start an audio capturing device test. (Windows)

#### API changes

**Added**

- `PreloadChannel[1/2]`
- `PreloadChannel[2/2]`
- `UpdatePreloadChannelToken`
- `SetRouteInCommunicationMode` (Android)
- `SetMaxMetadataSize`
- `SendMetadata`
- `position` parameter in `RegisterAudioFrameObserver`

**Deleted**

- `GetObservedAudioFramePosition`
- `GetPlaybackAudioParams`
- `GetRecordAudioParams`
- `GetMixedAudioParams`
- `GetEarMonitoringAudioParams`
- `GetMaxMetadataSize`
- `OnReadyToSendMetadata`

### v4.2.1

This version was released on June 21, 2023.

#### Improvements

This version improves the network transmission strategy, enhancing the smoothness of audio interactions.

#### Fixed Issues

This version fixed the following issues:

- Inability to join channels caused by SDK's incompatibility with some older versions of AccessToken.
- After the sending end called `SetAINSMode` to activate AI noise reduction, occasional echo was observed by the receiving end.
- Brief noise occurred while playing media files using the media player.
- Occasional crash after calling the `DestroyMediaPlayer` method. (iOS)


### v4.2.0

v4.2.0 was released on May 29, 2023.

#### Compatibility changes

If you use the features mentioned in this section, ensure that you modify the implementation of the relevant features after upgrading the SDK.

**1. Channel media options**

- `PublishCustomAudioTrackEnableAec` in `ChannelMediaOptions` is deleted. Use `PublishCustomAudioTrack` instead.
- `PublishCustomAudioSourceId` in `ChannelMediaOptions` is renamed to `PublishCustomAudioTrackId`.

**2. Virtual sound card (macOS)**

As of v4.2.0, Agora supports third-party virtual sound cards. You can use a third-party virtual sound card as the audio input or output device for the SDK. You can use the `stateChanged` callback to see whether the current input or output device selected by the SDK is a virtual sound card.

<div class="alert info">If you set AgoraALD or Soundflower as the default input or output device when joining a channel, you will not hear audio.</div>

**3. Miscellaneous**

- `OnApiCallExecuted` is deleted. Agora recommends getting the results of the API implementation through relevant channels and media callbacks.

- The `IAudioFrameObserver` class is renamed to `IAudioPcmFrameSink`, thus the prototypes of the following methods are updated accordingly:

  - `OnFrame`
  - `RegisterAudioFrameObserver` [1/2] and `RegisterAudioFrameObserver`[2/2] in `IMediaPlayer`

- `StartChannelMediaRelay`, `UpdateChannelMediaRelay`, `StartChannelMediaRelayEx`, and `UpdateChannelMediaRelayEx` are deprecated. Use `StartOrUpdateChannelMediaRelay` and `StartOrUpdateChannelMediaRelayEx` instead.

#### New features

**1. AI Noise Suppression**

This release introduces public APIs for the AI Noise Suppression function. Once enabled, the SDK automatically detects and reduces background noises. Whether in bustling public venues or real-time competitive arenas that demand lightning-fast responsiveness, this function guarantees optimal audio clarity, providing users with an elevated audio experience. You can enable this function through the newly-introduced `setAINSMode` method and set the noise reduction mode as balance, aggressive, or low latency according to your use-case.

<Admonition type="info">Agora charges separately for this function. See [AI Noise Suppression unit pricing](pricing#ai-noise-suppression-pricing).</Admonition>

**2. Cross-device synchronization**

In real-time collaborative singing use-cases, network issues can cause inconsistencies in the downlinks of different client devices. To address this, this release introduces `GetNtpWallTimeInMs` for obtaining the current Network Time Protocol (NTP) time. By using this method to synchronize lyrics and music across multiple client devices, users can achieve synchronized singing and lyrics progression, resulting in a better collaborative experience.

**3. Instant frame rendering**

This release adds the `EnableInstantMediaRendering` method to enable instant rendering mode for audio  frames, which can speed up the first audio frame rendering after the user joins the channel.

#### Improvements

**1. Voice changer**

This release introduces the `SetLocalVoiceFormant` method that allows you to adjust the formant ratio to change the timbre of the voice. This method can be used together with the `SetLocalVoicePitch` method to adjust the pitch and timbre of voice at the same time, enabling a wider range of voice transformation effects.

**2. Improved compatibility with audio file types (Android)**

As of v4.2.0, you can use the following methods to open files with a URI starting with `Content://` :
- `StartAudioMixing` [2/2]
- `PlayEffect` [3/3]
- `Open`
- `OpenWithMediaSource`

**3. Channel media relay**

This release introduces `StartOrUpdateChannelMediaRelay` and `StartOrUpdateChannelMediaRelayEx`, allowing for a simpler and smoother way to start and update media relay across channels. With these methods, developers can easily start the media relay across channels and update the target channels for media relay with a single method. Additionally, the internal interaction frequency has been optimized, effectively reducing latency in function calls.

**4. Custom audio tracks**

To better meet the needs of custom audio capture use-cases, this release adds `CreateCustomAudioTrack` and `DestroyCustomAudioTrack` for creating and destroying custom audio tracks. Two types of audio tracks are also provided for users to choose from, further improving the flexibility of capturing external audio source:

- Mixable audio track: Supports mixing multiple external audio sources and publishing them to the same channel, suitable for multi-channel audio capture use-cases.
- Direct audio track: Only supports publishing one external audio source to a single channel, suitable for low-latency audio capture use-cases.

#### Issues fixed

This release fixed the following issues:

**Android**

- Occasional crashes occur on Android devices when users joining or leaving a channel.
- Occasional failure when enabling in-ear monitoring.
- Occasional echo.
- In real-time chorus use-cases, remote users heard noises and echoes when an OPPO R11 device joined the channel in the loudspeaker mode.
- When the playback of the local music finished, the `OnAudioMixingFinished` callback was not properly triggered.
- Abnormal client status caused by an exception in the `OnRemoteAudioStateChanged` callback.

**iOS**

- Abnormal client status caused by an exception in the `OnRemoteAudioStateChanged` callback.

**All platforms**

- When the host frequently switched the user role between broadcaster and audience in a short period of time, the audience members could not hear the audio of the host.
- Playing audio files with a sample rate of 48 kHz failed.

#### API changes

**Added**

- `StartOrUpdateChannelMediaRelay`
- `StartOrUpdateChannelMediaRelayEx`
- `GetNtpWallTimeInMs`
- `CreateAudioCustomTrack`
- `DestroyAudioCustomTrack`
- `AudioTrackConfig`
- `AUDIO_TRACK_TYPE`
- The `domainLimit` and `autoRegisterAgoraExtensions` members in `RtcEngineContext`
- The `channelId` and `uid` parameters in `OnRecorderStateChanged` and `OnRecorderInfoUpdated` callbacks
- `EnableInstantMediaRendering`

**Deprecated**

- `StartChannelMediaRelay`
- `StartChannelMediaRelayEx`
- `UpdateChannelMediaRelay`
- `UpdateChannelMediaRelayEx`
- `OnChannelMediaRelayEvent`
- `CHANNEL_MEDIA_RELAY_EVENT`

**Deleted**

- `OnApiCallExecuted`
- `PublishCustomAudioTrackEnableAec ` in ` ChannelMediaOptions`

### v4.1.0

v4.1.0 was released on December 20, 2022.

#### New features

**1. In-ear monitoring**

This release adds support for in-ear monitoring. You can call `EnableInEarMonitoring` to enable the in-ear monitoring function.

After successfully enabling the in-ear monitoring function, you can call `RegisterAudioFrameObserver` to register the audio observer, and the SDK triggers the `OnEarMonitoringAudioFrame` callback to report the audio frame data. You can use your own audio effect processing module to preprocess the audio frame data of the in-ear monitoring to implement custom audio effects. Agora recommends that you choose one of the following two methods to set the audio data format of the in-ear monitoring:

- Call the `SetEarMonitoringAudioFrameParameters` method to set the audio data format of in-ear monitoring. The SDK calculates the sampling interval based on the parameters in this method and triggers the `OnEarMonitoringAudioFrame` callback based on the sampling interval.
- Set the audio data format in the return value of the `GetEarMonitoringAudioParams` callback. The SDK calculates the sampling interval based on the return value of the callback and triggers the `OnEarMonitoringAudioFrame` callback based on the sampling interval.

To adjust the in-ear monitoring volume, you can call `SetInEarMonitoringVolume`.

**2. Audio capture device test (Android)**

This release adds support for testing local audio capture devices before joining a channel. You can call `StartRecordingDeviceTest` to start the audio capture device test. After the test is complete, call the `StopPlaybackDeviceTest` method to stop the audio capture device test.

**3. Local network connection types**

To make it easier for users to know the connection type of the local network at any stage, this release adds the `GetNetworkType` method. You can use this method to get the type of network connection in use. The available values are `UNKNOWN`, `DISCONNECTED`, `LAN`, `WIFI`, `2G`, `3G`, `4G`, and `5G`. When the local network connection type changes, the SDK triggers the `OnNetworkTypeChanged` callback to report the current network connection type.

**4. Audio stream filter**

This release introduces filtering audio streams based on volume. Once this function is enabled, the Agora server ranks all audio streams by volume and transports the three audio streams with the highest volumes to the receivers by default. The number of audio streams to be transported can be adjusted; contact [support@agora.io](support@agora.io) to adjust this number according to your use-case.

Agora also supports publishers in choosing whether the audio streams being published are to be filtered based on volume. Streams that are not filtered bypass this filter mechanism and are transported directly to the receivers. In use-cases with a number of publishers, enabling this function helps reduce the bandwidth and device system pressure for the receivers.

<div class="alert info">To enable this function, contact <a href="support@agora.io">support@agora.io</a>.</div>

**5. Loopback device (Windows)**

The SDK uses the playback device as the loopback device by default. As of 4.1.0, you can specify a loopback device separately and publish the captured audio to the remote end.

- `SetLoopbackDevice`: Specifies the loopback device. If you do not want the current playback device to be the loopback device, you can call this method to specify another device as the loopback device.
- `GetLoopbackDevice`: Gets the current loopback device.
- `FollowSystemLoopbackDevice`: Whether the loopback device follows the default playback device of the system.

**6. Spatial audio effect**

This release adds the following features applicable to spatial audio effect use-cases, which can effectively enhance the user's sense-of-presence experience in virtual interactive use-cases.

- Sound insulation area: You can set a sound insulation area and sound attenuation parameter by calling `SetZones`. When the sound source (which can be a user or the media player) and the listener belong to the inside and outside of the sound insulation area, the listener experiences an attenuation effect similar to that of the sound in the real environment when it encounters a building partition. You can also set the sound attenuation parameter for the media player and the user by calling `SetPlayerAttenuation` and `SetRemoteAudioAttenuation` respectively, and specify whether to use that setting to force an override of the sound attenuation parameter in `SetZones`.
- Doppler sound: You can enable Doppler sound by setting the `enable_doppler` parameter in `SpatialAudioParams`. The receiver experiences noticeable tonal changes in the event of a high-speed relative displacement between the source and receiver (such as in a racing game use-case).
- Headphone equalizer: You can use a preset headphone equalization effect by calling the `SetHeadphoneEQPreset` method to improve the audio experience for users with headphones.

**7. Headphone equalization effect**

This release adds the `SetHeadphoneEQParameters` method, which is used to adjust the low- and high-frequency parameters of the headphone EQ. This is mainly useful in spatial audio use-cases. If you cannot achieve the expected headphone EQ effect after calling `SetHeadphoneEQPreset`, you can call `setHeadphoneEQParameters` to adjust the EQ.

**8. MPUDP (MultiPath UDP) (Beta)**

As of this release, the SDK supports MPUDP protocol, which enables you to connect and use multiple paths to maximize the use of channel resources based on the UDP protocol. You can use different physical NICs on both mobile and desktop and aggregate them to effectively combat network jitter and improve transmission quality.

<div class="alert info">To enable this feature, contact <a href="support@agora.io">support@agora.io</a>.</div>

**9. Register extensions (Windows)**

This release adds the `RegisterExtension` method for registering extensions. When using a third-party extension, you need to call the extension-related APIs in the following order:

`loadExtensionProvider` -> `registerExtension` -> `setExtensionProviderProperty` -> `enableExtension`

**10. Device management (Windows, macOS)**

This release adds a series of callbacks to help you better understand the status of your audio devices:

- `OnAudioDeviceStateChanged`: Occurs when the status of the audio device changes.
- `OnAudioDeviceVolumeChanged`: Occurs when the volume of an audio device or app changes.

**11. Multi-channel management**

This release adds a series of multi-channel-related methods that you can call to manage audio streams in multi-channel use-cases.

- The `MuteLocalAudioStreamEx` method is used to cancel or resume publishing a local audio stream.
- The `MuteAllRemoteAudioStreamsEx`  is used to cancel or resume the subscription of all remote users to audio streams.
- The `StartRtmpStreamWithoutTranscodingEx`, `StartRtmpStreamWithTranscodingEx`, `UpdateRtmpTranscodingEx`, and `StopRtmpStreamEx` methods are used to implement Media Push in multi-channel use-cases.
- The `StartChannelMediaRelayEx`, `UpdateChannelMediaRelayEx`, `PauseAllChannelMediaRelayEx`, `ResumeAllChannelMediaRelayEx`, and `StopChannelMediaRelayEx` methods are used to relay media streams across channels in multi-channel use-cases.
- The `LeaveChannelEx` [2/2] method. Compared with the `LeaveChannelEx` [1/2] method, a new `options` parameter is added, which is used to choose whether to stop recording with the microphone when leaving a channel in a multi-channel use-case.

**12. Client role switching**

In order to enable users to know whether the switched user role is low-latency or ultra-low-latency, this release adds the `newRoleOptions` parameter to the `OnClientRoleChanged` callback. The value of this parameter is as follows:

- `AUDIENCE_LATENCY_LEVEL_LOW_LATENCY` (1): Low latency.
- `AUDIENCE_LATENCY_LEVEL_ULTRA_LOW_LATENCY` (2): Ultra-low latency.

#### Improvements

**1. Bluetooth permissions (Android)**

To simplify integration, as of this release, you can use the SDK to enable Android users to use Bluetooth normally without adding the `BLUETOOTH_CONNECT`permission.

**2. Relaying media streams across channels**

This release optimizes the `UpdateChannelMediaRelay` method as follows:

- Before v4.1.0: If the target channel update fails due to internal reasons in the server, the SDK returns the error code `RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_REFUSED`(8), and you need to call the `UpdateChannelMediaRelay` method again.
- v4.1.0 and later: If the target channel update fails due to internal server reasons, the SDK retries the update until the target channel update is successful.

**3. Reconstructed AIAEC algorithm**

This release reconstructs the AEC algorithm based on the AI method. Compared with the traditional AEC algorithm, the new algorithm can preserve the complete, clear, and smooth near-end vocals under poor echo-to-signal conditions, significantly improving the system's echo cancellation and dual-talk performance. This gives users a more comfortable call and live-broadcast experience. AIAEC is suitable for conference calls, chats, karaoke, and other use-cases.

**Other improvements**

This release includes the following additional improvements:

- Reduces the latency when pushing external audio sources.
- Improves the performance of echo cancellation when using the `AUDIO_SCENARIO_MEETING` scenario.
- Enhances the ability to identify different network protocol stacks and improves the SDK's access capabilities in multiple-operator network scenarios.

#### Issues fixed

This release fixed the following issues:

**All**

  - The call `GetExtensionProperty` failed and returned an empty string.
  - Audience members heard buzzing noises when the host switched between speakers and earphones during live streaming.
  - Crashes occurred if you call the `RegisterAudioEncodedFrameObserver` method after failing to initialize  `RtcEngine`.

**Android**

  - After calling `SetCloudProxy` to set the cloud proxy, calling `JoinChannelEx` to join multiple channels failed.
  - In online meeting use-cases, the local user and the remote user occasionally could not hear each other after the local user was interrupted by a call.

**iOS**

  - Calling `StartAudioMixing` to play music files in the `ipod-library://item` path failed.

**macOS**

  - After starting and stopping the audio capture device test, there was no sound when the audio playback device was subsequently started.

#### API changes

**Added**

- `EnableInEarMonitoring`
- `SetEarMonitoringAudioFrameParameters`
- `OnEarMonitoringAudioFrame`
- `SetInEarMonitoringVolume`
- `GetEarMonitoringAudioParams`
- `StartRecordingDeviceTest` (Android)
- `StopRecordingDeviceTest` (Android)
- `GetNetworkType`
- `SetRecordingDeviceVolume`  (Windows)
- `isAudioFilterable` in `ChannelMediaOptions`
- `SetLoopbackDevice`
- `GetLoopbackDevice`
- `FollowSystemLoopbackDevice`
- `SetZones`
- `SetPlayerAttenuation`
- `SetRemoteAudioAttenuation`
- `MuteRemoteAudioStream`
- `SpatialAudioParams`
- `SetHeadphoneEQPreset`
- `HEADPHONE_EQUALIZER_PRESET`
- `SetHeadphoneEQParameters`
- `LeaveChannelEx` [2/2]
- `MuteLocalAudioStreamEx`
- `MuteAllRemoteAudioStreamsEx`
- `StartRtmpStreamWithoutTranscodingEx`
- `StartRtmpStreamWithTranscodingEx`
- `UpdateRtmpTranscodingEx`
- `StopRtmpStreamEx`
- `StartChannelMediaRelayEx`
- `UpdateChannelMediaRelayEx`
- `PauseAllChannelMediaRelayEx`
- `ResumeAllChannelMediaRelayEx`
- `StopChannelMediaRelayEx`
- `newRoleOptions` in `OnClientRoleChanged`
- `AdjustUserPlaybackSignalVolumeEx`
- `EnableAudioVolumeIndicationEx`
- `OnAudioDeviceStateChanged ` (Windows,macOS)
- `OnAudioDeviceVolumeChanged ` (Windows,macOS)
- `SetParameters` in `IRtcEngine` (Windows)

**Deprecated**

- `StartEchoTest` [2/3]
- `OnApiCallExecuted`. Use the callbacks triggered by specific methods instead.

**Deleted**

- Removes `RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_REFUSED`(8) in `OnChannelMediaRelayEvent` callback.

### v<Vg k = "VSDK_LATEST_4_0_0"/>

v<Vg k = "VSDK_LATEST_4_0_0"/> was released on September 28, 2022.

#### Compatibility changes

This release has optimized the implementation of some features, resulting in incompatibility with v<Vg k = "VSDK_PREVIOUS_RELEASE"/>. The following are the main features with compatibility changes:
- Multiple channel
- Media stream publishing control
- Warning codes

After upgrading the SDK, you need to update the code in your app according to your business use-cases. For details, see [Migration guide](../reference/migration-guide).

#### New features

**1. Multiple media tracks**

This release supports one `IRtcEngine` instance to collect multiple audio and video sources at the same time and publish them to the remote users by setting `IRtcEngineEx` and `ChannelMediaOptions.`

- After calling `JoinChannel` to join the first channel, call `JoinChannelEx` multiple times to join multiple channels, and publish the specified stream to different channels through different user ID (`localUid`) and `ChannelMediaOptions` settings.
- You can simultaneously publish multiple sets of video streams captured by multiple cameras or screen sharing by setting `publishSecondaryCameraTrack` and `publishSecondaryScreenTrack` in `ChannelMediaOptions`. (Windows)

This release adds `CreateCustomVideoTrack` method to implement video custom capture. You can refer to the following steps to publish multiple custom captured video in the channel:

1. Create a custom video track: Call the `CreateCustomVideoTrack` method to create a video track, and get the video track ID.
2. Set the custom video track to be published in the channel: In each channel's `ChannelMediaOptions`, set the `customVideoTrackId` parameter to the ID of the video track you want to publish, and set `publishCustomVideoTrack` to `true`.
3. Pushing an external video source: Call `PushVideoFrame`, and specify `videoTrackId` as the ID of the custom video track in step 2 in order to publish the corresponding custom video source in multiple channels.

You can also experience the following features with the multi-channel capability:

- Publish multiple sets of audio and video streams to the remote users through different user IDs (`uid`).
- Mix multiple audio streams and publish to the remote users through a user ID (`uid`).
- Combine multiple video streams and publish them to the remote users through a user ID (`uid`).

**2. Ultra HD resolution (Beta)**

In order to improve the interactive video experience, the SDK optimizes the whole process of video capture, encoding, decoding and rendering, and now supports 4K resolution. The improved FEC (Forward Error Correction) algorithm enables adaptive switches according to the frame rate and number of video frame packets, which further reduces the video stuttering rate in 4K scenes.

Additionally, you can set the encoding resolution to 4K (3840 Ã— 2160) and the frame rate to 60 fps when calling `SetVideoEncoderConfiguration`. The SDK supports automatic fallback to the appropriate resolution and frame rate if your device does not support 4K.

> **_NOTE:_** This feature has certain requirements with regards to device performance and network bandwidth, and the supported upstream and downstream frame rates vary on different platforms. To experience this feature, contact [support@agora.io](mailto:support@agora.io).

**3. Agora media player**

To make it easier for users to integrate the Agora SDK and reduce the SDK's package size, this release introduces the Agora media player.  You can then call the methods in the `IMediaPlayer` class to experience a series of functions:

- Plays local and online media files.
- Preloads media files.
- Changes the CDN route for playing media files according your network conditions.
- Shares the audio and video streams being played with remote users.
- Caches data when playing media files.

**3. Brand-new AI Noise Suppression**

The SDK supports a new version of AI noise reduction (in comparison to the basic AI noise reduction in v<Vg k = "VSDK_PREVIOUS_RELEASE"/>). The new AI noise reduction has better vocal fidelity, cleaner noise suppression, and adds a dereverberation option. To experience this feature, contact support@agora.io.

**5. Ultra-high audio quality**

To make the audio clearer and restore more details, this release adds the `ULTRA_HIGH_QUALITY_VOICE` enumeration. In use-cases that mainly feature the human voice, such as chat or singing, you can call `SetVoiceBeautifierPreset` and use this enumeration to experience ultra-high audio quality.

**6. Spatial audio**

> **_NOTE:_** This feature is in experimental status. To enable this feature, contact support@agora.io. Contact [Technical Support](mailto:support@agora.io) if needed.

You can set the spatial audio for the remote user as following:

- Local Cartesian Coordinate System Calculation Solution: This solution uses the `ILocalSpatialAudioEngine` class to implement spatial audio by calculating the spatial coordinates of the remote user. You need to call `UpdateSelfPosition` and `UpdateRemotePosition` to update the spatial coordinates of the local and remote users respectively, so that the local user can hear the spatial audio of the remote user.
![Spatial effect](/images/video-sdk/video-call-spatial.png)

- Local Cartesian Coordinate System Calculation Solution: This solution uses the `ILocalSpatialAudioEngine` class to implement spatial audio. You need to call `UpdateSelfPosition` and `UpdatePlayerPositionInfo` to update the spatial coordinates of the local user and media player, respectively, so that the local user can hear the spatial audio effect of media player.
![Spatial effect](/images/video-sdk/spatial-audio-effect.png)

**7.** **Real-time chorus**

This release gives real-time chorus the following abilities:

- Two or more choruses are supported.
- Each singer is independent of each other. If one singer fails or quits the chorus, the other singers can continue to sing.
- Very low latency experience. Each singer can hear each other in real time, and the audience can also hear each singer in real time.

This release adds the `AUDIO_SCENARIO_CHORUS` enumeration in `AUDIO_SCENARIO_TYPE`. With this enumeration, users can experience ultra-low latency in real-time chorus when the network conditions are good.

**8. Enhanced channel management**

To meet the channel management requirements of various business use-cases, this release adds the following functions to the `ChannelMediaOptions` structure:

- Sets or switches the publishing of multiple audio and video sources.
- Sets or switches channel profile and user role.
- Sets or switches the stream type of the subscribed video.
- Controls audio publishing delay.

Set `ChannelMediaOptions` when calling `JoinChannel` or `JoinChannelEx` to specify the publishing and subscription behavior of a media stream, for example, whether to publish video streams captured by cameras or screen sharing, and whether to subscribe to the audio and video streams of remote users. After joining the channel, call `UpdateChannelMediaOptions` to update the settings in `ChannelMediaOptions` at any time, for example, to switch the published audio and video sources.

**9. Screen sharing**

This release optimizes the screen sharing function. You can enable this function through the following ways.

On Windows and macOS:

- Call the `StartScreenCaptureByDisplayId` method before joining a channel, and then call `JoinChannel[2/2]`  to join a channel and set `publishScreenTrack`or `publishSecondaryScreenTrack` as `true`.
- Call the `StartScreenCaptureByDisplayId` method after joining a channel, and then call `UpdateChannelMediaOptions` to set `publishScreenTrack` or `publishSecondaryScreenTrack` as `true`.

On Android and iOS:

- Call the `StartScreenCapture` method before joining a channel, and then call `JoinChannel[2/2]`  to join a channel and set `publishScreenCaptureVideo` as `true`.
- Call the `StartScreenCapture` method after joining a channel, and then call `UpdateChannelMediaOptions` to set `publishScreenCaptureVideo` as `true`.

**10. Subscription allowlists and blocklists**

This release introduces subscription allowlists and blocklists for remote audio and video streams. You can add the user ID that you want to subscribe to in your allowlist, or in your blocklist if you do not want to subscribe to. You can experience this feature through the following APIs, and in use-cases that involve multiple channels, you can call the following methods in the `IRtcEngineEx` interface.

- `SetSubscribeAudioBlacklist`ï¼šSet the audio subscription blocklist.
- `SetSubscribeAudioWhitelist`ï¼šSet the audio subscription allowlist.
- `SetSubscribeVideoBlacklist`ï¼šSet the video subscription blocklist.
- `SetSubscribeVideoWhitelist`ï¼šSet the video subscription allowlist.

If a user is added in a blocklist and allowlist at the same time, only the blocklist takes effect.

**11. Set audio scenarios**

To make it easier to change audio scenarios, this release adds the `SetAudioScenario` method. For example, if you want to change the audio scenario from `AUDIO_SCENARIO_DEFAULT` to `AUDIO_SCENARIO_GAME_STREAMING` when you are in a channel, you can call this method.

**12. Replace video feeds with images**

This release supports replacing video feeds with images when publishing video streams. You can call the `EnableVideoImageSource` method to enable this function and choose your own images through the `options` parameter. If you disable this function, the remote users see the video feeds that you publish.

**13. Local video transcoder**

This release introduces local video transcoder with which you can locally merge multiple video streams into one. Common use-cases are as follows:

When streaming or using media push, you can merge the frames of multiple anchors into one locally.

To do this, you should merge multi-channel video streams collected locally (such as video captured by camera, screen sharing stream, video files and pictures) into one video stream. Then, release the merged stream in the channel.

You can call the `StartLocalVideoTranscoder` method to enable the local video transcoder and call the `StopLocalVideoTranscoder` method to stop the local video transcoder; After the local video transcoder is enabled, you can call `UpdateLocalTranscoderConfiguration` to update the configuration of the local video transcoder.

**14. Video device management**

A video capture device may support a variety of video formats, each of which supports a different combination of video frame width, video frame height, and frame rate.

This release introduces the `NumberOfCapabilities` and `GetCapability` method to obtain the number of video formats supported by video capture devices and the details of video frames under specified video formats. When you call the `StartPrimaryCameraCapture` or `StartSecondaryCameraCapture` method to capture video using camera, you can obtain the video with the specified video format.
The SDK will automatically select the video format for video capture equipment according to your settings in `VideoEncoderConfiguration`. In general, you don't need to use this set of new methods.

#### Improvements

**1. Fast channel switching**

This release can achieve the same switching speed as `SwitchChannel` in v<Vg k = "VSDK_PREVIOUS_RELEASE"/> through the`LeaveChannel` and `JoinChannel `methods so that you don't need to take the time to call the `SwitchChannel `method.

**2. Push external video frames**

This releases supports pushing video frames in I422 format. You can call the `PushVideoFrame` method to push such video frames to the SDK.

**3. Monitor the width and height of videos**

This adds the `OnTextureSizeModify` callback that can be used to monitor any change in the width and height of videos.

**4. Voice pitch of the local user**
This release adds `voicePitch` in `AudioVolumeInfo` of `OnAudioVolumeIndication`. You can use `voicePitch` to get the local user's voice pitch and perform business functions such as rating for singing.

**5. Video preview**

This release improves the implementation logic of `StartPreview`. You can call the `StartPreview ` method to enable video preview at any time.

 **6. Video types of subscription**

You can call the `SetRemoteDefaultVideoStreamType ` method to choose the video stream type when subscribing streams.
</PlatformWrapper>
