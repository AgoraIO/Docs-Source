
<PlatformWrapper platform="unreal">

### Handle the system logic

This sections describes the steps required to use the relevant libraries, declare the necessary variables, and set up access to the UI
elements.

1.  **Import the required Unreal library**

    To add the texture library for the local and remote video rendering, in `MyUserWidget.h`, add the following statement before `#include "MyUserWidget.generated.h"`:

    ``` cpp
    #include "Engine/Texture2D.h"
    ```

2.  **Define the variables to manage audio and video processing**

    In `MyUserWidget.h`, add the following declaration to the `UMyUserWidget`:

    ``` java
    UTexture2D* LocalRenderTexture;
	FSlateBrush LocalRenderBrush;
	UTexture2D* RemoteRenderTexture;
	FSlateBrush RemoteRenderBrush;
	agora::media::IMediaEngine* MediaEngine;
	class VideoFrameEventHandler* handler;
	TUniquePtr<FUpdateTextureRegion2D> UpdateTextureRegionProxy;
    class AudioFrameEventHandler* audioHandler;
    ```

### Implement processing of raw video and audio data

To register and use video and audio frame observers in your <Vpl k="CLIENT" />, take the following steps:

1.  **Set up the audio frame observer**

    `IAudioFrameObserver` gives you access to each audio frame after it is captured or access to each audio frame before it is played back. To setup the `IAudioFrameObserver`, do the following:
    
    1. In `MyUserWidget.h`, add the following class after `UMyUserWidget`:
        
        ```cpp
        class AudioFrameEventHandler : public agora::media::IAudioFrameObserver
        {
            public:
            AudioFrameEventHandler(UMyUserWidget* customAudioAndVideo)
            {
                agoraImplementation = customAudioAndVideo;
            }
            ~AudioFrameEventHandler() {}
            bool onPlaybackAudioFrameBeforeMixing(const char* channelId, agora::rtc::uid_t uid, agora::media::IAudioFrameObserverBase::AudioFrame& audioFrame) override;
            bool onRecordAudioFrame(const char* channelId, agora::media::IAudioFrameObserverBase::AudioFrame& audioFrame) override;
            bool onPlaybackAudioFrame(const char* channelId, agora::media::IAudioFrameObserverBase::AudioFrame& audioFrame) override;
            bool onMixedAudioFrame(const char* channelId, agora::media::IAudioFrameObserverBase::AudioFrame& audioFrame) override;
            bool onEarMonitoringAudioFrame(AudioFrame& audioFrame);
            AudioParams getEarMonitoringAudioParams();
            int getObservedAudioFramePosition() override;
            agora::media::IAudioFrameObserverBase::AudioParams getPlaybackAudioParams() override;
            agora::media::IAudioFrameObserverBase::AudioParams getRecordAudioParams() override;
            agora::media::IAudioFrameObserverBase::AudioParams getMixedAudioParams() override;
            private:
            UMyUserWidget* agoraImplementation;
            agora::media::IAudioFrameObserverBase::AudioParams audioParams;
        };
        ```

    2. In `MyUserWidget.cpp`, add the following callbacks before `setupVideoSDKEngine`:

        ```cpp
        bool AudioFrameEventHandler::onPlaybackAudioFrameBeforeMixing(const char* channelId, rtc::uid_t uid, AudioFrame& audioFrame)
        {
            return true;
        }
        bool AudioFrameEventHandler::onRecordAudioFrame(const char* channelId, AudioFrame& audioFrame)
        {
            return true;
        }
        bool AudioFrameEventHandler::onPlaybackAudioFrame(const char* channelId, AudioFrame& audioFrame)
        {
            return true;
        }
        bool AudioFrameEventHandler::onMixedAudioFrame(const char* channelId, AudioFrame& audioFrame)
        {
            return true;
        }
        bool AudioFrameEventHandler::onEarMonitoringAudioFrame(AudioFrame& audioFrame)
        {
            return true;
        }
        agora::media::IAudioFrameObserverBase::AudioParams AudioFrameEventHandler::getEarMonitoringAudioParams()
        {
            return agoraImplementation->audioParams;
        }
        int AudioFrameEventHandler::getObservedAudioFramePosition()
        {
            return (int)(AUDIO_FRAME_POSITION::AUDIO_FRAME_POSITION_PLAYBACK |
            AUDIO_FRAME_POSITION::AUDIO_FRAME_POSITION_RECORD |
            AUDIO_FRAME_POSITION::AUDIO_FRAME_POSITION_BEFORE_MIXING |
            AUDIO_FRAME_POSITION::AUDIO_FRAME_POSITION_MIXED);
        }
        agora::media::IAudioFrameObserverBase::AudioParams AudioFrameEventHandler::getPlaybackAudioParams()
        {
            return agoraImplementation->audioParams;
        }
        agora::media::IAudioFrameObserverBase::AudioParams AudioFrameEventHandler::getRecordAudioParams()
        {
            return agoraImplementation->audioParams;
        }
        agora::media::IAudioFrameObserverBase::AudioParams AudioFrameEventHandler::getMixedAudioParams()
        {
            return agoraImplementation->audioParams;
        }
        ```

2.  **Set up the video frame observer**

    `IVideoFrameObserver` gives you access to each local video frame after it is captured and access to each remote video frame before it is played back. In this example, your read the captured video frames to create textures that you use to render the local and remote video frames. To set up `IVideoFrameObserver` in your <Vpl k = "CLIENT"/>, do the following:

    1. In `MyUserWidget.h`, add the following class after `UMyUserWidget`:

        ``` cpp
        class VideoFrameEventHandler : public agora::media::IVideoFrameObserver
        {
            public:	
            VideoFrameEventHandler(UMyUserWidget *customAudioAndVideo) 
            {
                agoraImplementation = customAudioAndVideo;
            }
            ~VideoFrameEventHandler() {}
            virtual bool onCaptureVideoFrame(VideoFrame& videoFrame) override;
            virtual bool onPreEncodeVideoFrame(VideoFrame& videoFrame) override;
            virtual bool onSecondaryCameraCaptureVideoFrame(VideoFrame& videoFrame) override;
            virtual bool onSecondaryPreEncodeCameraVideoFrame(VideoFrame& videoFrame) override;
            virtual bool onScreenCaptureVideoFrame(VideoFrame& videoFrame) override;
            virtual bool onPreEncodeScreenVideoFrame(VideoFrame& videoFrame) override;
            virtual bool onMediaPlayerVideoFrame(VideoFrame& videoFrame, int mediaPlayerId) override;
            virtual bool onSecondaryScreenCaptureVideoFrame(VideoFrame& videoFrame) override;
            virtual bool onSecondaryPreEncodeScreenVideoFrame(VideoFrame& videoFrame) override;
            virtual agora::media::IVideoFrameObserver::VIDEO_FRAME_PROCESS_MODE getVideoFrameProcessMode() override;
            virtual agora::media::base::VIDEO_PIXEL_FORMAT getVideoFormatPreference() override;
            virtual bool getRotationApplied() override;
            virtual bool getMirrorApplied() override;
            virtual uint32_t getObservedFramePosition() override;
            virtual bool isExternal() override;
            virtual bool onRenderVideoFrame(const char* channelId, rtc::uid_t remoteUid, VideoFrame& videoFrame) override;
            virtual bool onTranscodedVideoFrame(VideoFrame& videoFrame) override;
            private:
            UMyUserWidget* agoraImplementation;
        };
        ```
    2. In `MyUserWidget.cpp`, add the following callbacks before `NativeDestruct`:

        ```cpp
        bool VideoFrameEventHandler::onPreEncodeVideoFrame(VideoFrame& videoFrame)
        {
            UE_LOG(LogTemp, Warning, TEXT("VideoFrameEventHandler::onPreEncodeVideoFrame"));
            return true;
        }
        bool VideoFrameEventHandler::onSecondaryCameraCaptureVideoFrame(VideoFrame& videoFrame)
        {
            UE_LOG(LogTemp, Warning, TEXT("VideoFrameEventHandler::onPreEncodeVideoFrame"));
            return true;
        }
        bool VideoFrameEventHandler::onSecondaryPreEncodeCameraVideoFrame(VideoFrame& videoFrame)
        {
            UE_LOG(LogTemp, Warning, TEXT("VideoFrameEventHandler::onSecondaryPreEncodeCameraVideoFrame"));
            return true;
        }
        bool VideoFrameEventHandler::onScreenCaptureVideoFrame(VideoFrame& videoFrame)
        {
            UE_LOG(LogTemp, Warning, TEXT("VideoFrameEventHandler::onScreenCaptureVideoFrame"));
            return true;
        }
        bool VideoFrameEventHandler::onPreEncodeScreenVideoFrame(VideoFrame& videoFrame)
        {
            UE_LOG(LogTemp, Warning, TEXT("VideoFrameEventHandler::onPreEncodeScreenVideoFrame"));
            return true;
        }
        bool VideoFrameEventHandler::onMediaPlayerVideoFrame(VideoFrame& videoFrame, int mediaPlayerId)
        {
            return true;
        }
        bool VideoFrameEventHandler::onSecondaryScreenCaptureVideoFrame(VideoFrame& videoFrame)
        {
            UE_LOG(LogTemp, Warning, TEXT("VideoFrameEventHandler::onSecondaryScreenCaptureVideoFrame"));
            return true;
        }
        bool VideoFrameEventHandler::onSecondaryPreEncodeScreenVideoFrame(VideoFrame& videoFrame)
        {
            UE_LOG(LogTemp, Warning, TEXT("VideoFrameEventHandler::onSecondaryPreEncodeScreenVideoFrame"));
            return true;
        }
        agora::media::IVideoFrameObserver::VIDEO_FRAME_PROCESS_MODE VideoFrameEventHandler::getVideoFrameProcessMode()
        {
            return PROCESS_MODE_READ_WRITE;
        }
        agora::media::base::VIDEO_PIXEL_FORMAT VideoFrameEventHandler::getVideoFormatPreference()
        {
            return agora::media::base::VIDEO_PIXEL_RGBA;
        }
        bool VideoFrameEventHandler::getRotationApplied()
        {
            return true;
        }
        bool VideoFrameEventHandler::getMirrorApplied()
        {
            return true;
        }
        uint32_t VideoFrameEventHandler::getObservedFramePosition()
        {
            return agora::media::base::POSITION_POST_CAPTURER | agora::media::base::POSITION_PRE_RENDERER;
        }
        bool VideoFrameEventHandler::isExternal()
        {
            return true;
        }
        bool VideoFrameEventHandler::onRenderVideoFrame(const char* channelId, rtc::uid_t remoteUid, VideoFrame& videoFrame)
        {
            AsyncTask(ENamedThreads::GameThread, [=]()
            {
                UE_LOG(LogTemp, Warning, TEXT("UMyUserWidget::onRenderVideoFrame"));
                if (agoraImplementation->RemoteRenderTexture == nullptr || !agoraImplementation->RemoteRenderTexture->IsValidLowLevel())
                {
                    agoraImplementation->RemoteRenderTexture = UTexture2D::CreateTransient(videoFrame.width, videoFrame.height, PF_R8G8B8A8);
                }
                else
                {
                    int yStride = videoFrame.yStride;
                    agoraImplementation->UpdateTextureRegionProxy = MakeUnique<FUpdateTextureRegion2D>(0, 0, 0, 0, videoFrame.width, videoFrame.height);
                    UTexture2D* tex = (UTexture2D*)agoraImplementation->RemoteRenderTexture;
                    uint8* raw = (uint8*)tex->GetPlatformData()->Mips[0].BulkData.Lock(LOCK_READ_WRITE);
                    memcpy(raw, videoFrame.yBuffer, videoFrame.height * videoFrame.width * 4);
                    tex->GetPlatformData()->Mips[0].BulkData.Unlock();
                    delete[] raw;
                    tex->UpdateTextureRegions(0, 1, agoraImplementation->UpdateTextureRegionProxy.Get(), yStride, (uint32)4, static_cast<uint8_t*>(raw));
                    agoraImplementation->RemoteRenderBrush.SetResourceObject(tex);
                    if (agoraImplementation->remoteView != nullptr) 
                    {
                        agoraImplementation->remoteView->SetBrush(agoraImplementation->RemoteRenderBrush);
                    }
                }
            });
            return true;
        }
        bool VideoFrameEventHandler::onCaptureVideoFrame(VideoFrame& videoFrame)
        {
            UE_LOG(LogTemp, Warning, TEXT("VideoFrameEventHandler::onCaptureVideoFrame"));
            AsyncTask(ENamedThreads::GameThread, [=]()
            {
                if (agoraImplementation->LocalRenderTexture == nullptr || !agoraImplementation->LocalRenderTexture->IsValidLowLevel())
                {
                    UE_LOG(LogTemp, Warning, TEXT("VideoFrameEventHandler::CreateTransient"));
                    agoraImplementation->LocalRenderTexture = UTexture2D::CreateTransient(videoFrame.width, videoFrame.height, PF_R8G8B8A8);
                }
                else
                {
                    int yStride = videoFrame.yStride;
                    agoraImplementation->UpdateTextureRegionProxy = MakeUnique<FUpdateTextureRegion2D>(0, 0, 0, 0, videoFrame.width, videoFrame.height);
                    UTexture2D* tex = (UTexture2D*)agoraImplementation->LocalRenderTexture;
                    uint8* raw = (uint8*)tex->GetPlatformData()->Mips[0].BulkData.Lock(LOCK_READ_WRITE);
                    memcpy(raw, videoFrame.yBuffer, videoFrame.height * videoFrame.width * 4);
                    tex->GetPlatformData()->Mips[0].BulkData.Unlock();
                    tex->UpdateTextureRegions(0, 1, agoraImplementation->UpdateTextureRegionProxy.Get(), yStride, (uint32)4, static_cast<uint8_t*>(raw));
                    delete[] raw;
                    agoraImplementation->LocalRenderBrush.SetResourceObject(tex);
                    if (agoraImplementation->localView != nullptr) 
                    {
                        UE_LOG(LogTemp, Warning, TEXT("VideoFrameEventHandler::New brush applied"));
                        agoraImplementation->localView->SetBrush(agoraImplementation->LocalRenderBrush);
                    }
                }
            });
            return true;
        }
        ```
        Note that you must set the return value in `getVideoFrameProcessMode` to `PROCESS_MODE_READ_WRITE` in order for your raw data changes to take effect.

3.  **Register the video and audio frame observers**

    To receive callbacks declared in `IVideoFrameObserver` and `IAudioFrameObserver`, you must register the video and audio frame observers with the <Vg k="ENGINE" /> before joining a channel. To specify the format of audio frames captured by each `IAudioFrameObserver` callback, use the `setRecordingAudioFrameParameters`, `setMixedAudioFrameParameters` and `setPlaybackAudioFrameParameters` methods. To do this, in `MyUserWidget.cpp`, add the following at the end of `setupVideoSDKEngine`:

    ``` cpp
    agoraEngine->queryInterface(AGORA_IID_MEDIA_ENGINE, (void**)&MediaEngine);
    handler = new VideoFrameEventHandler(this);
    int res = MediaEngine->registerVideoFrameObserver(handler);
    audioHandler = new AudioFrameEventHandler(this);
    MediaEngine->registerAudioFrameObserver(audioHandler);
    audioHandler = new AudioFrameEventHandler(this);
    MediaEngine->registerAudioFrameObserver(audioHandler);
    // Set the format of the captured raw audio data.
    int SAMPLE_RATE = 16000, SAMPLE_NUM_OF_CHANNEL = 1, SAMPLES_PER_CALL = 1024;
    agoraEngine->setRecordingAudioFrameParameters(SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL,
        RAW_AUDIO_FRAME_OP_MODE_READ_WRITE, SAMPLES_PER_CALL);
    agoraEngine->setPlaybackAudioFrameParameters(SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL,
        RAW_AUDIO_FRAME_OP_MODE_READ_WRITE, SAMPLES_PER_CALL);
    agoraEngine->setMixedAudioFrameParameters(SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL, SAMPLES_PER_CALL);
    ```

4.  **Unregister the video and audio observers when you close the <Vpl k = "CLIENT"/>**

    When you close the <Vpl k = "CLIENT"/>, you unregister the frame observers by calling the register frame observer method again with a `null` pointer. To do this, in `MyUserWidget.cpp`, add the following lines to `NativeDestruct` before `agoraEngine->unregisterEventHandler(this);`:

    ``` cpp
    MediaEngine->registerAudioFrameObserver(nullptr);
    MediaEngine->registerVideoFrameObserver(nullptr);
    ```

</PlatformWrapper>