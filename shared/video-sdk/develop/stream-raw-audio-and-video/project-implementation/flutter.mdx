
<PlatformWrapper platform="flutter">

### Implement processing of raw video and audio data

To access and process raw video and audio data in your <Vpl k="CLIENT" />, take the following steps:

1.  **Set up the audio frame observer**

    `AudioFrameObserver` gives you access to each audio frame after it is captured or access to each audio frame before it is played back. To setup an instance of the `AudioFrameObserver`, add the following lines to the `_MyAppState` class after the variable declarations:

    ```dart
    AudioFrameObserver audioFrameObserver = AudioFrameObserver(
        onRecordAudioFrame: (String channelId, AudioFrame audioFrame) {
            // Gets the captured audio frame
        },
        onPlaybackAudioFrame: (String channelId, AudioFrame audioFrame) {
            // Gets the audio frame for playback
            debugPrint('[onPlaybackAudioFrame] audioFrame: ${audioFrame.toJson()}');
        }
    );
    ```

2.  **Set up the video frame observer**

    `VideoFrameObserver` gives you access to each local video frame after it is captured and access to each remote video frame before it is played back. To set up an instance of `VideoFrameObserver`, add the following lines to the `_MyAppState` class after the variable declarations:

    ```dart
    VideoFrameObserver videoFrameObserver = VideoFrameObserver(
        onCaptureVideoFrame: (VideoFrame videoFrame) {
            // The video data that this callback gets has not been pre-processed
            // After pre-processing, you can send the processed video data back
            // to the SDK through this callback
            debugPrint('[onCaptureVideoFrame] videoFrame: ${videoFrame.toJson()}');
        },
        onRenderVideoFrame: (String channelId, int remoteUid, VideoFrame videoFrame) {
            // Occurs each time the SDK receives a video frame sent by the remote user.
            // In this callback, you can get the video data before encoding.
            // You then process the data according to your particular scenario.
        }
    );
    ```
    
3.  **Register the video and audio frame observers**

    To receive callbacks declared in `videoFrameObserver` and `audioFrameObserver`, you must register the video and audio frame observers with the <Vg k="ENGINE" /> before joining a channel. To specify the format of audio frames captured by each `AudioFrameObserver` callback, use the `setRecordingAudioFrameParameters`, `setMixedAudioFrameParameters` and `setPlaybackAudioFrameParameters` methods. To do this, add the following lines at the top of the `join()` method:

    ```dart
    // Set the format of raw audio data.
    int SAMPLE_RATE = 16000, SAMPLE_NUM_OF_CHANNEL = 1, SAMPLES_PER_CALL = 1024;

    agoraEngine.setRecordingAudioFrameParameters(
        sampleRate: SAMPLE_RATE,
        channel: SAMPLE_NUM_OF_CHANNEL,
        mode: RawAudioFrameOpModeType.rawAudioFrameOpModeReadWrite,
        samplesPerCall: SAMPLES_PER_CALL);
    agoraEngine.setPlaybackAudioFrameParameters(
        sampleRate: SAMPLE_RATE,
        channel: SAMPLE_NUM_OF_CHANNEL,
        mode: RawAudioFrameOpModeType.rawAudioFrameOpModeReadWrite,
        samplesPerCall: SAMPLES_PER_CALL);
    agoraEngine.setMixedAudioFrameParameters(
        sampleRate: SAMPLE_RATE,
        channel: SAMPLE_NUM_OF_CHANNEL,
        samplesPerCall: SAMPLES_PER_CALL);

    agoraEngine.getMediaEngine().registerAudioFrameObserver(audioFrameObserver);
    agoraEngine.getMediaEngine().registerVideoFrameObserver(videoFrameObserver);
    ```

4.  **Unregister the video and audio observers when you leave a channel**

    When you leave a channel, you unregister the frame observers by calling the unregister methods. To do this, add the following lines to the `leave()` method before `agoraEngine.leaveChannel();`:

    ```dart
    agoraEngine.getMediaEngine().unregisterAudioFrameObserver(audioFrameObserver);
    agoraEngine.getMediaEngine().unregisterVideoFrameObserver(videoFrameObserver);
    ```

</PlatformWrapper>