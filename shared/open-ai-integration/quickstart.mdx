import CodeRtcPy from '@docs/assets/code/open-ai-integration/rtc-py.mdx';
import Prerequisites from '@docs/shared/common/prerequisites/python.mdx';
import CompleteCode from './complete-code.mdx'

Integrating Agora's real-time audio communication capabilities with OpenAI's language models enables dynamic, conversational AI experiences. This guide shows you how to set up a Python project that combines Agora's server-side Voice SDK with OpenAI's API to create an interactive, voice-driven assistant.

## Understand the tech

The `RealtimeKitAgent` class manages the integration by connecting to an Agora channel for real-time audio streaming and to OpenAI's API for processing audio input and generating AI-driven responses. Audio frames captured from the Agora channel are streamed to OpenAI's API, where the AI processes the input. The API responses, which include transcribed text and synthesized voice output, are then delivered back to the Agora channel.

The code sets up tools that can be executed locally or passed through the API. This allows the AI to perform specific tasks, such as retrieving data from external sources. The agent processes various message types from OpenAI, such as audio responses, transcription updates, and error messages, and sends them to users through the Agora audio channel, facilitating continuous interaction.

The following figure illustrates the integration topology:

![](/images/voice-sdk/open-ai-Integration-topology.png)

## Prerequisites

<Prerequisites />

- FFmpeg

    ```bash
    sudo apt install ffmpeg
    ```

## Set up the project

This guide walks you through the core elements of the [Agora Conversational AI Demo](https://github.com/AgoraIO/agora-openai-converse) integrating Agora's Python SDK with OpenAI's Realtime API:

1. Create a new folder for the project:

    ```
    mkdir realtime_agent
    cd realtime_agent/
    ```

1. Create the base project structure:

    ```
    touch {__init__.py,.env,agent.py,parse_args.py,tools.py,main.py,utils.py,logger.py,requirements.txt}
    ```

    Import the OpenAI Realtime API example code. 

    <Admonition type="info" title="Note">
    This project uses the OpenAI [`realtimeapi-examples`](https://openai.com/api/) package. Download the project and unzip it into your `realtime_agent` folder.
    </Admonition>

    The project structure should look like this:

    ```
    /realtime_agent
      ├── __init__.py
      ├── .env
      ├── main.py
      ├── agent.py
      ├── tools.py
      ├── utils.py
      ├── logger.py
      ├── parse_args.py
      ├── requirements.txt
      └── realtimeapi
          ├── __init__.py
          ├── client.py
          ├── messages.py
          └── util.py
    ```

1. Add the following dependencies to the `requirements.txt` file:

    ```
    agora-python-server-sdk>=2.0.5
    agora-realtime-ai-api==1.0.5
    aiohappyeyeballs==2.4.0
    aiohttp==3.10.6
    aiohttp[speedups]
    aiosignal==1.3.1
    annotated-types==0.7.0
    anyio==4.4.0
    attrs==24.2.0
    black==24.4.2
    certifi==2024.7.4
    cffi==1.17.1
    click==8.1.7
    colorlog>=6.0.0
    distro==1.9.0
    frozenlist==1.4.1
    h11==0.14.0
    httpcore==1.0.5
    httpx==0.27.0
    idna==3.10
    iniconfig==2.0.0
    multidict==6.1.0
    mypy==1.10.1
    mypy-extensions==1.0.0
    numpy==1.26.4
    numpy>=1.21.0
    openai==1.37.1
    packaging==24.1
    pathspec==0.12.1
    platformdirs==4.2.2
    pluggy==1.5.0
    psutil==5.9.8
    protobuf==5.27.2
    PyAudio==0.2.14
    pyaudio>=0.2.11
    pycparser==2.22
    pydantic==2.9.2
    pydantic_core==2.23.4
    pydub==0.25.1
    pyee==12.0.0
    PyJWT==2.8.0
    pytest==8.2.2
    python-dotenv==1.0.1
    ruff==0.5.2
    six==1.16.0
    sniffio==1.3.1
    sounddevice==0.4.7
    sounddevice>=0.4.6
    tqdm==4.66.4
    types-protobuf==4.25.0.20240417
    typing_extensions==4.12.2
    watchfiles==0.22.0
    yarl==1.12.1
    ```

1. Open the `.env` file and fill in the values for the environment variables:

   ```python
    # Agora RTC App ID and App Certificate
    AGORA_APP_ID=
    AGORA_APP_CERT=

    # OpenAI API key and model 
    OPENAI_API_KEY=
    OPENAI_MODEL=

    # Port of api server
    SERVER_PORT=

    # Override this if you want to develop against a local dev server
    # REALTIME_API_BASE_URI=ws://localhost:8081
   ```

1. Create a virtual environment and activate it:

   ```bash
   python3 -m venv venv && source venv/bin/activate
   ```

1. Install the required dependencies:

   ```bash
   pip install -r requirements.txt
   ```

Overview of key files:

- `agent.py`: The main script responsible for executing the `RealtimeKitAgent`. It integrates Agora's functionality from the `rtc.py` module and OpenAI's capabilities from the `realtimeapi` package.
- `rtc.py`: Part of the `agora-realtime-ai-api` package, this file is used in `agent.py` and contains an AI-specific implementation of Agora's server-side Python Voice SDK.
- `main.py`: Sets up an HTTP server that handles real-time agent processes.
- `tools.py`: Classes for registering and invoking tools.
- `parse_args.py`: Parses the command-line arguments used to customize the channel name and user ID when running script.
- `realtimeapi/`: Contains the classes and methods that interact with OpenAI's Realtime API.

The [complete code](#complete-integration-code) for files in the `realtime_agent` folder is provided at the bottom of this page.

## Implementation

Before diving into the implementation details, it is essential to establish a solid foundation. Start by copying the base integration code provided below to the `agent.py` file. This framework includes the core structure and necessary imports for your agent. From here, we will proceed step by step to implement each function.

```python
import asyncio
import base64
import logging
import os
from builtins import anext
from typing import Any

from agora.rtc.rtc_connection import RTCConnection, RTCConnInfo
from attr import dataclass

from .agora.rtc import Channel, ChatMessage, RtcEngine, RtcOptions
from .logger import setup_logger
from .realtimeapi import messages
from .realtimeapi.client import RealtimeApiClient
from .tools import ClientToolCallResponse, ToolContext
from .utils import PCMWriter

# Set up the logger 
logger = setup_logger(name=__name__, log_level=logging.INFO)

def _monitor_queue_size(queue: asyncio.Queue, queue_name: str, threshold: int = 5) -> None:
    """Alert the system or developer when the asynchronous queue grows too long."""
    queue_size = queue.qsize()
    if queue_size > threshold:
        logger.warning(f"Queue {queue_name} size exceeded {threshold}: current size {queue_size}")


async def wait_for_remote_user(channel: Channel) -> int:
    """Wait for a remote user to join the channel.
    - Implement logic to handle user joining events.
    - Set the result when a user joins or handle errors appropriately.
    """
    pass

@dataclass(frozen=True, kw_only=True)
class InferenceConfig:
    """Data class for inference configuration.
    - Populate with the necessary parameters for the agent's inference.
    - Configure turn detection, system message, and voice parameters.
    """
    system_message: str | None = None
    turn_detection: messages.ServerVADUpdateParams | None = None  
    voice: messages.Voices | None = None


class RealtimeKitAgent:
    engine: RtcEngine
    channel: Channel
    client: RealtimeApiClient
    audio_queue: asyncio.Queue[bytes] = asyncio.Queue()

    message_queue: asyncio.Queue[messages.ResponseAudioTranscriptDelta] = (
        asyncio.Queue()
    )
    message_done_queue: asyncio.Queue[messages.ResponseAudioTranscriptDone] = (
        asyncio.Queue()
    )
    tools: ToolContext | None = None

    _client_tool_futures: dict[str, asyncio.Future[ClientToolCallResponse]]

    @classmethod
    async def setup_and_run_agent(
        cls,
        *,
        engine: RtcEngine,
        options: RtcOptions,
        inference_config: InferenceConfig,
        tools: ToolContext | None,
    ) -> None:
        """Set up and run the agent.
        - Initialize the RTC engine, connect to the channel, and configure the inference setup.
        - Implement the setup and teardown logic for the agent.
        """
        pass

    def __init__(
        self,
        *,
        client: RealtimeApiClient,
        tools: ToolContext | None,
        channel: Channel,
    ) -> None:        
        """Initialize tool context and declarations."""
        pass

    async def run(self) -> None:
        """Run the agent's main loop, handling audio streams and messages.
        - Implement logic for processing audio input, handling model messages, and managing the user session.
        """
        pass

    async def rtc_to_model(self) -> None:
        """Stream input audio to the model.
        - Implement logic to capture audio from the Agora channel and send it to the model.
        """
        pass

    async def model_to_rtc(self) -> None:
        """Stream audio from the queue to the audio output.
        - Implement logic to retrieve audio from the queue and push it to the Agora channel.
        """
        pass

    async def _process_model_messages(self) -> None:
        """Process incoming messages from the model.
        - Implement logic to handle and respond to different message types from the model.
        """
        pass
```

### RealtimeKitAgent

The `RealtimeKitAgent` class integrates Agora's real-time audio communication with OpenAI’s AI services. It handles streaming, communication with the OpenAI API, and AI responses, creating a seamless conversational experience.

### Connect to Agora and OpenAI

The `setup_and_run_agent` method connects to an Agora channel using `RtcEngine`, and sets up a session with OpenAI’s Realtime API. It configures the session parameters, such as system messages and voice settings, and uses asynchronous tasks to concurrently listen for the session to start and update the conversation configuration. In the base `agent.py` file, replace the placeholder with the following implementation.

```python
    @classmethod
    async def setup_and_run_agent(
        cls,
        *,
        engine: RtcEngine,
        options: RtcOptions,
        inference_config: InferenceConfig,
        tools: ToolContext | None,
    ) -> None:
        channel = engine.create_channel(options)
        await channel.connect()

        try:
            async with RealtimeApiClient(
                base_uri=os.getenv("REALTIME_API_BASE_URI", "wss://api.openai.com"),
                api_key=os.getenv("OPENAI_API_KEY"),
                verbose=False,
            ) as client:
                await client.send_message(
                    messages.SessionUpdate(
                        session=messages.SessionUpdateParams(
                            turn_detection=inference_config.turn_detection,
                            tools=tools.model_description() if tools else [],
                            tool_choice="auto",
                            input_audio_format="pcm16",
                            output_audio_format="pcm16",
                            instructions=inference_config.system_message,
                            voice=inference_config.voice,
                            model=os.environ.get("OPENAI_MODEL", "gpt-4o-realtime-preview-2024-10-01"),
                            modalities=["text", "audio"],
                            temperature=0.8,
                            max_response_output_tokens="inf",
                        )
                    )
                )

                start_session_message = await anext(client.listen())
                logger.info(
                    f"Session started: {start_session_message.session.id} model: {start_session_message.session.model}"
                )

                agent = cls(
                    client=client,
                    tools=tools,
                    channel=channel,
                )
                await agent.run()

        finally:
            await channel.disconnect()
            await client.shutdown()
```

### Initialize the RealtimeKitAgent

The constructor for `RealtimeKitAgent` sets up the OpenAI client, optional tools, and Agora channel to manage real-time audio communication. In `agent.py`, add the following code after the `setup_and_run_agent` method:

```python
    def __init__(
        self,
        *,
        client: RealtimeApiClient,
        tools: ToolContext | None,
        channel: Channel,
    ) -> None:
        self.client = client
        self.tools = tools
        self._client_tool_futures = {}
        self.channel = channel
        self.subscribe_user = None
        self.write_pcm = os.environ.get("WRITE_AGENT_PCM", "false") == "true"
        logger.info(f"Write PCM: {self.write_pcm}")
```

### Launch the Agent

The `run` method is the core of the `RealtimeKitAgent`. It manages the agent’s operations by handling audio streams, subscribing to remote users, and processing both incoming and outgoing messages. This method also ensures proper exception handling and graceful shutdown. Following are the key functions of this method:

- **Waiting for Remote Users**: The agent waits for a remote user to join the Agora channel and subscribes to their audio stream.
- **Task Management**: The agent initiates tasks for audio input, audio output, and processing messages from OpenAI, ensuring that they run concurrently.
- **Connection State Handling**: It monitors changes in connection state and handles user disconnections, ensuring the agent shuts down gracefully.

After the `def __init__`, method in `agent.py`, replace the `run` placeholder with the following:

```python
    async def run(self) -> None:
        try:

            def log_exception(t: asyncio.Task[Any]) -> None:
                if not t.cancelled() and t.exception():
                    logger.error(
                        "unhandled exception",
                        exc_info=t.exception(),
                    )

            logger.info("Waiting for remote user to join")
            self.subscribe_user = await wait_for_remote_user(self.channel)
            logger.info(f"Subscribing to user {self.subscribe_user}")
            await self.channel.subscribe_audio(self.subscribe_user)

            async def on_user_left(
                agora_rtc_conn: RTCConnection, user_id: int, reason: int
            ):
                logger.info(f"User left: {user_id}")
                if self.subscribe_user == user_id:
                    self.subscribe_user = None
                    logger.info("Subscribed user left, disconnecting")
                    await self.channel.disconnect()

            self.channel.on("user_left", on_user_left)

            disconnected_future = asyncio.Future[None]()

            def callback(agora_rtc_conn: RTCConnection, conn_info: RTCConnInfo, reason):
                logger.info(f"Connection state changed: {conn_info.state}")
                if conn_info.state == 1:
                    if not disconnected_future.done():
                        disconnected_future.set_result(None)

            self.channel.on("connection_state_changed", callback)

            asyncio.create_task(self.rtc_to_model()).add_done_callback(log_exception)
            asyncio.create_task(self.model_to_rtc()).add_done_callback(log_exception)

            asyncio.create_task(self._process_model_messages()).add_done_callback(
                log_exception
            )

            await disconnected_future
            logger.info("Agent finished running")
        except asyncio.CancelledError:
            logger.info("Agent cancelled")
        except Exception as e:
            logger.error(f"Error running agent: {e}")
            raise
```

### Communicate with the AI model

The `RealtimeKitAgent` is responsible for managing real-time audio communication between Agora and OpenAI’s AI model. It implements this through two core streaming methods:

- `rtc_to_model`: Captures audio frames from the Agora channel and streams them to OpenAI’s model for processing.
- `model_to_rtc`: Handles the output by pushing audio responses from OpenAI’s model back to the Agora channel for playback.

Additionally, the agent must process messages received from the OpenAI model. This is handled by the `_process_model_messages` method.

#### Stream input audio to the AI model

The `rtc_to_model` method captures audio frames from the Agora channel and streams them to OpenAI’s model for processing. This method runs continuously, retrieving audio frames from the subscribed user and forwarding them through the OpenAI API.

The code implements the following key features:

- **Subscription check**: Ensures that a remote user is subscribed before capturing any audio frames.
- **Audio frame processing**: Sends each audio frame from the Agora channel to OpenAI’s model.
- **Error handling**: Logs any errors that occur during the audio streaming process.

Replace the `rtc_to_model` placeholder with the following implementation in `agent.py`:

```python
    async def rtc_to_model(self) -> None:
        if self.subscribe_user is None:
            await asyncio.sleep(0.1)

        audio_frames = self.channel.get_audio_frames(self.subscribe_user)

        # Initialize PCMWriter for receiving audio
        pcm_writer = PCMWriter(prefix="rtc_to_model", write_pcm=self.write_pcm)

        try:
            async for audio_frame in audio_frames:
                # Process received audio (send to model)
                _monitor_queue_size(self.audio_queue, "audio_queue")
                await self.client.send_audio_data(audio_frame.data)

                # Write PCM data if enabled
                await pcm_writer.write(audio_frame.data)

                await asyncio.sleep(0)  # Yield control to allow other tasks to run

        except asyncio.CancelledError:
            # Write any remaining PCM data before exiting
            await pcm_writer.flush()
            raise  # Re-raise the exception to propagate cancellation
```

#### Stream audio queue to audio output

The `model_to_rtc` method streams audio generated by OpenAI’s model back to the Agora channel. It retrieves audio data from an internal queue and pushes it to Agora for real-time playback.

The code implements the following key features:

- **Audio queue management**: Retrieves audio data from an asynchronous queue filled with responses from OpenAI’s model.
- **Efficient task management**: After processing each audio frame, the method yields control to ensure other tasks can run concurrently.
- **Real-time playback**: Audio data is pushed to the Agora channel for immediate playback to the user.

Replace the `model_to_rtc` placeholder with the following implementation:

```python
    async def model_to_rtc(self) -> None:
        # Initialize PCMWriter for sending audio
        pcm_writer = PCMWriter(prefix="model_to_rtc", write_pcm=self.write_pcm)

        try:
            while True:
                # Get audio frame from the model output
                frame = await self.audio_queue.get()

                # Process sending audio (to RTC)
                await self.channel.push_audio_frame(frame)

                # Write PCM data if enabled
                await pcm_writer.write(frame)
```

#### Process model messages

In addition to handling audio streaming, the agent must process messages received from the OpenAI model. The `_process_model_messages` method listens for these messages and takes appropriate actions based on the type of message, such as audio responses, transcripts, and various model-generated outputs.

The code implements the following key features:

- **Message handling**: The method listens for various message types, including audio data, text transcripts, and other outputs, and processes them accordingly.

    ```python
    async def _process_model_messages(self) -> None:
        # Continuously listen for incoming messages from OpenAI
        async for message in self.client.listen():
            match message:
                # Handle different message types
    ```    

- **Queue management**: For audio messages, the data is decoded and placed in the audio queue for playback.
- **Real-time response**: Text messages and other outputs are immediately sent back to the Agora chat.

### Audio and message flow

The agent manages real-time audio and message flow between Agora and OpenAI as follows:

- `rtc_to_model`: Continuously captures audio from the Agora channel and streams it to OpenAI.
- `model_to_rtc`: Retrieves audio responses from OpenAI and plays them back in real-time.
- `_process_model_messages`: Listens for and processes various message types, such as audio and transcripts and ensures timely delivery to the Agora channel.

### Message processing 

The message processing logic in `RealtimeKitAgent` is central to how the agent interacts with OpenAI’s model and the Agora channel. Messages received from the model can include audio data, text transcripts, or other responses, and the agent needs to process these accordingly to ensure smooth real-time communication.

The `_process_model_messages` method listens for incoming messages and handles them according to their type, ensuring the appropriate action is taken, such as playing back audio, sending text transcripts, or invoking tools.

The code implements the following key features:

- **Listening for messages**: The agent continuously listens for incoming messages from OpenAI’s model.
- **Handling audio data**: If the message contains audio data, it is placed in a queue for playback to the Agora channel.
- **Handling transcripts**: If the message contains partial or final text transcripts, they are processed and sent to the Agora chat.
- **Handling other responses**: Additional message types, such as tool invocations and other outputs are processed as needed.

#### Handling Text Transcripts

The agent receives partial or completed text transcripts. These are identified and handled by their message types:

- `ResponseAudioTranscriptDelta`: Represents partial transcripts.
- `ResponseAudioTranscriptDone`: Indicates a completed transcript.

For both types, the agent sends the transcript to the Agora chat as a message.

```python
case messages.ResponseAudioTranscriptDelta():
    logger.info(f"Received text message {message=}")
    asyncio.create_task(self.channel.chat.send_message(
        ChatMessage(
            message=message.model_dump_json(), msg_id=message.item_id
        )
    ))

case messages.ResponseAudioTranscriptDone():
    logger.info(f"Text message done: {message=}")
    asyncio.create_task(self.channel.chat.send_message(
        ChatMessage(
            message=message.model_dump_json(), msg_id=message.item_id
        )
    ))
```

#### Handling Other Responses

The agent handles a variety of other message types from OpenAI’s model. These include tool calls, errors, or other output from the model. In the event of an unhandled message type, the agent logs a warning for further investigation.

Replace the `_process_model_messages` placeholder with the following implementation:

```python
    async def _process_model_messages(self) -> None:
        async for message in self.client.listen():
            # logger.info(f"Received message {message=}")
            match message:
                case messages.ResponseAudioDelta():
                    # logger.info("Received audio message")
                    self.audio_queue.put_nowait(base64.b64decode(message.delta))
                    # loop.call_soon_threadsafe(self.audio_queue.put_nowait, base64.b64decode(message.delta))
                    logger.info(f"TMS:ResponseAudioDelta: response_id:{message.response_id},item_id: {message.item_id}")
                case messages.ResponseAudioTranscriptDelta():
                    logger.info(f"Received text message {message=}")
                    asyncio.create_task(self.channel.chat.send_message(
                        ChatMessage(
                            message=message.model_dump_json(), msg_id=message.item_id
                        )
                    ))
                case messages.ResponseAudioTranscriptDone():
                    logger.info(f"Text message done: {message=}")
                    asyncio.create_task(self.channel.chat.send_message(
                        ChatMessage(
                            message=message.model_dump_json(), msg_id=message.item_id
                        )
                    ))
                case messages.InputAudioBufferSpeechStarted():
                    await self.channel.clear_sender_audio_buffer()
                    # clear the audio queue so audio stops playing
                    while not self.audio_queue.empty():
                        self.audio_queue.get_nowait()
                    logger.info(f"TMS:InputAudioBufferSpeechStarted: item_id: {message.item_id}")
                case messages.InputAudioBufferSpeechStopped():
                    pass
                #  InputAudioBufferCommitted
                case messages.InputAudioBufferCommitted():
                    pass
                # ItemCreated
                case messages.ItemCreated():
                    pass
                # ResponseCreated
                case messages.ResponseCreated():
                    pass
                # ResponseDone
                case messages.ResponseDone():
                    pass
                # ResponseOutputItemAdded
                case messages.ResponseOutputItemAdded():
                    pass
                # ResponseContentPartAdded
                case messages.ResponseContentPartAdded():
                    pass
                # ResponseAudioDone
                case messages.ResponseAudioDone():
                    pass
                # ResponseContentPartDone
                case messages.ResponseContentPartDone():
                    pass
                # ResponseOutputItemDone
                case messages.ResponseOutputItemDone():
                    pass
                case _:
                    logger.warning(f"Unhandled message {message=}")
```

Using these components, the agent handles audio, transcripts, and other messages in real-time, ensuring that it responds appropriately to OpenAI model’s output and maintain seamless communication with the Agora channel.

### Wait for a remote user

The `wait_for_remote_user` function is a key component of the agent's functionality. It listens for an event where a remote user joins the Agora channel. This function will block until a user joins or until it times out after 60 seconds.

The method implements the following:

- **Event listener**: The function listens for the `user_joined` event from the Agora SDK. When a user joins the channel, it captures the user ID and signals that a user has joined using `remote_user_joined.set()`.
- **Timeout handling**: If no user joins within `60 seconds`, a `TimeoutError` is raised, which is logged as an error.
- **Cleanup**: After successfully getting a user ID or timing out, the event listener is removed using `channel.off("user_joined", on_user_joined)`.

In `agent.py`, replace the placeholder code with: 

```python
async def wait_for_remote_user(channel: Channel) -> int:
    remote_users = list(channel.remote_users.keys())
    if len(remote_users) > 0:
        return remote_users[0]

    future = asyncio.Future[int]()

    channel.once("user_joined", lambda conn, user_id: future.set_result(user_id))

    try:
        # Wait for the remote user with a timeout 
        remote_user = await asyncio.wait_for(future, timeout=15.0)
        return remote_user
    except KeyboardInterrupt:
        future.cancel()
        
    except Exception as e:
        logger.error(f"Error waiting for remote user: {e}")
        raise
```

### Add model to RealtimeApiClient

Modify the `realtimeapi/client.py` file to include the model name as part of the `self.url`. This ensures the appropriate model is used when interacting with the OpenAI API.

Update the `self.url` definition as follows:

```python
self.url = f"{base_uri}{path}?model={os.environ.get('OPENAI_MODEL')}"
```

This adjustment ensures that the model specified in your environment variables `OPENAI_MODEL` is included in the API requests made by the `RealtimeApiClient`.

### Tool Management

The tool management system extends the agents functionality by allowing OpenAI’s model to invoke specific tools. These tools can either run locally or pass data back to the model for further processing. By registering tools and executing them based on incoming messages, the agent adds the capability and flexibility to handling a variety of tasks.

Tool management implements the following key features:

- **Tool registration**: Register both local function tools and pass-through tools, making them available for execution.
- **Tool execution**: Execute tools in response to requests from the OpenAI model, running them locally or passing data back to the model.
- **Tool context**: The `ToolContext` class manages the tools, providing methods to register and execute them as needed.

#### Tool Registration

Registering tools during the setup process makes them available for the model to call. The `tools.py` file defines classes that allow tools to be registered under two categories:

- **Local function tools**: Executed directly by the agent on the local context.

    ```python
    @dataclass(frozen=True, kw_only=True)
    class LocalFunctionToolDeclaration:
        """Declaration of a tool that can be called by the model, and runs a function locally on the tool context."""

        name: str
        description: str
        parameters: dict[str, Any]
        function: Callable[..., Any]

        def model_description(self) -> dict[str, Any]:
            return {
                "type": "function",
                "function": {
                    "name": self.name,
                    "description": self.description,
                    "parameters": self.parameters,
                },
            }
    ```

- **Pass-through tools**: These tools send data back to OpenAI’s model without it being executed locally.

    ```python
    @dataclass(frozen=True, kw_only=True)
    class PassThroughFunctionToolDeclaration:
        """Declaration of a tool that can be called by the model."""

        name: str
        description: str
        parameters: dict[str, Any]

        def model_description(self) -> dict[str, Any]:
            return {
                "type": "function",
                "function": {
                    "name": self.name,
                    "description": self.description,
                    "parameters": self.parameters,
                },
            }
    ```

The `ToolContext` class manages all available tools. It provides the logic for both registering tools and executing them when requested by the OpenAI model.

```python
class ToolContext(abc.ABC):
    """Represents the tool context for registering and executing tools.
    - Implement logic for registering both local and pass-through tools.
    - Provide methods for executing tools and returning results.
    """
    _tool_declarations: dict[str, ToolDeclaration]

    def __init__(self) -> None:
        # TODO should be an ordered dict
        self._tool_declarations = {}

    def register_function(
        self,
        *,
        name: str,
        description: str = "",
        parameters: dict[str, Any],
        fn: Callable[..., Any],
    ) -> None:
        self._tool_declarations[name] = LocalFunctionToolDeclaration(
            name=name, description=description, parameters=parameters, function=fn
        )

    def register_client_function(
        self,
        *,
        name: str,
        description: str = "",
        parameters: dict[str, Any],
    ) -> None:
        self._tool_declarations[name] = PassThroughFunctionToolDeclaration(
            name=name, description=description, parameters=parameters
        )
```

#### Tool Execution

Once tools are registered, the agent can execute them in response to messages from OpenAI’s model. The agent listens for tool call requests and either executes the tool locally or passes data back to the model.

The `execute_tool` method of the `ToolContext` class retrieves the tool by name and runs it with the provided arguments. If it is a local function tool, the agent executes the function and returns the result. If it is a pass-through tool, it simply returns the decoded arguments to the model for further processing.

```python
    async def execute_tool(
        self, tool_name: str, encoded_function_args: str
    ) -> ExecuteToolCallResult | None:
        tool = self._tool_declarations.get(tool_name)
        if not tool:
            return None

        args = json.loads(encoded_function_args)
        assert isinstance(args, dict)

        if isinstance(tool, LocalFunctionToolDeclaration):
            logger.info(f"Executing tool {tool_name} with args {args}")
            result = await tool.function(**args)
            logger.info(f"Tool {tool_name} executed with result {result}")
            return LocalToolCallExecuted(json_encoded_output=json.dumps(result))

        if isinstance(tool, PassThroughFunctionToolDeclaration):
            return ShouldPassThroughToolCall(decoded_function_args=args)

        assert_never(tool)
```

#### Tool description

The `model_description` method of the `ToolContext` class generates a description of all registered tools, which is passed back to the model so it knows what tools are available for invocation.

```python
    def model_description(self) -> list[dict[str, Any]]:
        # Returns a description of all registered tools, making them available for the model
        return [v.model_description() for v in self._tool_declarations.values()]
```
#### Tool invocation in message processing

It is important to highlight how tools are invoked. During message processing, certain messages may trigger tool invocations, prompting the agent to execute the relevant tool.

The following flow illustrates how this works:

1. The OpenAI model sends a message that includes a tool call.
2. The `_process_model_messages` method identifies the tool call request.
3. The agent retrieves the relevant tool from the `ToolContext` and executes it, either locally or by passing data back to the model.

This integration between **message processing** and **tool management** ensures that the agent can extend its capabilities dynamically, performing tasks or calculations in real-time based on incoming requests.

With these pieces in place, the agent can effectively manage tool registration and execution, ensuring that it can handle a variety of tasks as directed by the OpenAI model. This structure allows the agent to either execute functions locally or pass them to the model for further handling.

## Set up a server

The `main.py` script sets up an HTTP server that handles real-time agent processes using Agora's RTC engine and RealtimeKit agents. It includes routes for starting and stopping agents, manages processes for different channels, and handles cleanup and shutdown procedures. The script manages these agents asynchronously.

### Run the agent

The `run_agent_in_process` method starts a RealtimeKit agent in a new process, handling Agora RTC initialization with the necessary credentials and agent configuration.

```python
def run_agent_in_process(
    engine_app_id: str,
    engine_app_cert: str,
    channel_name: str,
    uid: int,
    inference_config: InferenceConfig,
):  # Set up signal forwarding in the child process
    signal.signal(signal.SIGINT, handle_agent_proc_signal)  # Forward SIGINT
    signal.signal(signal.SIGTERM, handle_agent_proc_signal)  # Forward SIGTERM
    asyncio.run(
        RealtimeKitAgent.setup_and_run_agent(
            engine=RtcEngine(appid=engine_app_id, appcert=engine_app_cert),
            options=RtcOptions(
                channel_name=channel_name,
                uid=uid,
                sample_rate=SAMPLE_RATE,
                channels=CHANNELS,
                enable_pcm_dump= os.environ.get("WRITE_RTC_PCM", "false") == "true"
            ),
            inference_config=inference_config,
            tools=None,
        )
    )
```

### Shutdown gracefully

The `shutdown` function gracefully cancels running tasks and stopping the event loop. This prevents tasks from hanging and ensures resources are properly released.

```python
async def shutdown(app):
    logger.info("Shutting down server, cleaning up processes...")
    for channel_name, process in active_processes.items():
        if process.is_alive():
            logger.info(
                f"Terminating process for channel {channel_name} (PID: {process.pid})"
            )
            await asyncio.to_thread(os.kill, process.pid, signal.SIGKILL)
            await asyncio.to_thread(process.join)  # Ensure process has terminated
    active_processes.clear()
    logger.info("All processes terminated, shutting down server")
```

Copy the [complete code](#complete-integration-code) for `main.py` and paste it into the corresponding file in your folder structure.

<CompleteCode />

## Test the Code

### Setup and run the backend

To set up and run the backend, take the following steps:

1. Make sure that you have updated the files in the `realtime_agent` folder with
the [complete code](#complete-integration-code).

1. Update the values for `AGORA_APP_ID`, `AGORA_APP_CERT`, and `OPENAI_API_KEY` in the project's** `.env` file.

   Ensure that the necessary credentials for Agora and OpenAI are correctly configured in your project’s environment file.

1. Execute the following command to run the demo agent:

   ```bash
   python -m realtime_agent.main agent --channel_name=<channel_name> --uid=<agent_uid>
   ```

   Replace `<channel_name>` with the desired channel name and `<agent_uid>` with a unique user ID.

### Start HTTP server

To start the HTTP server:

    ```bash
    python -m realtime_agent.main server
    ```

The server provides a simple layer for managing agent processes.

#### POST /start

This api starts an agent with given graph and override properties. The started agent will join into the specified channel, and subscribe to the uid which your browser/device's rtc use to join.

| Param    | Description |
| -------- | ------- |
| `channel_name` | Use the same channel name that your browser/device joins, agent needs to be in the same channel to communicate.  |
| `uid`    | The user ID that the AI agent uses to join.   |

Example:

```bash
curl 'http://localhost:8080/start_agent' \
  -H 'Content-Type: application/json' \
  --data-raw '{
    "channel_name": "test",
    "uid": 123
  }'
```

#### POST /stop

This api stops the agent you started

| Param    | Description |
| -------- | ------- |
| `channel_name` | Use the same channel name you used to start the agent. |

Example:
```bash
curl 'http://localhost:8080/stop_agent' \
  -H 'Content-Type: application/json' \
  --data-raw '{
    "channel_name": "test"
  }'
```

### Front-end for testing

Use Agora's [Voice Call Demo](https://webdemo.agora.io/basicVoiceCall/index.html) for testing. Join with your AppID and generate a token from the project's settings page on the [Agora Console](https://console.agora.io/).

## Reference

Additional relevant documentation that complements the current page or explains other aspects of the product.

- Checkout the [Demo project on GitHub](https://github.com/AgoraIO/openai-realtime-python)
- [API reference for `rtc.py`](https://api-reference-git-python-voice-implementation-agora-gdxe.vercel.app/voice-sdk/python/rtc-py-api.html)
- [Voice calling quickstart (Python)](/voice-calling/get-started/get-started-sdk?platform=python)