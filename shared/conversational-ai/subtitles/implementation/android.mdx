import CodeBlock from '@theme/CodeBlock';

1. **Integrate the toolkit**

    Copy the [`convoaiApi`](https://github.com/AgoraIO-Community/Conversational-AI-Demo/tree/main/Android/scenes/convoai/src/main/java/io/agora/scene/convoai/convoaiApi) folder to your project and import the toolkit before calling the toolkit API. Refer to [Folder structure](#folder-structure) to understand the role of each file.

1. **Create a toolkit instance**

    Create a configuration object with the <Vg k="VSDK"/> and <Vg k="SIG" /> engine instances. Set the subtitle rendering mode, then use the configuration to create a toolkit instance.

    <CodeBlock language="kotlin" showLineNumbers>
    {`// Create configuration objects for the RTC and RTM instances
    val config = ConversationalAIAPIConfig(
        rtcEngine = rtcEngineInstance,
        rtmClient = rtmClientInstance,

        // Set the transcription subtitle rendering mode. Options:
        // - TranscriptionRenderMode.Word: Renders subtitles word by word.
        // - TranscriptionRenderMode.Text: Renders the full sentence at once.
        
        renderMode = TranscriptionRenderMode.Word,
        enableLog = true
    )
    // Create component instance
    val api = ConversationalAIAPIImpl(config)`}
    </CodeBlock>

1. **Subscribe to the channel**

    Subtitles are delivered through <Vg k="SIG" /> channel messages. To receive subtitle data, call `subscribeMessage` before starting the agent session.
    
    <CodeBlock language="kotlin" showLineNumbers>
    {`api.subscribeMessage("channelName") { error ->
        if (error != null) {
            // Handle error
        }
    }`}
    </CodeBlock>

1. **Receive subtitles**

    Call the `addHandler` method to register your implementation of the subtitle transcription callback.

    <CodeBlock language="kotlin" >
    {`api.addHandler(covEventHandler)`}
    </CodeBlock>

1. **Implement subtitle UI rendering logic**

    Inherit your subtitle UI module from the `IConversationSubtitleCallback` interface. Implement the `onTranscriptionUpdated` method to handle the logic for rendering subtitles to the UI.

    <CodeBlock language="kotlin" showLineNumbers>
    {` private val covEventHandler = object : IConversationalAIAPIEventHandler {
    override fun onTranscriptionUpdated(agentUserId: String, transcription: Transcription) {
            // Handle subtitle data and update the UI here
        }      
    }`}
    </CodeBlock>



1. **Add a Conversational AI agent to the channel**

    To [start a <Vpd k="AGENT" />](/conversational-ai/rest-api/join), configure the following parameters in your `POST` request:

    | Parameter       | Description   | Required |
    | ----------------| ------------- | -------- |
    | `advanced_features.enable_rtm: true`    | Starts the <Vg k="SIG" /> service | Yes  |
    | `parameters.data_channel: "rtm"`  | Enables <Vg k="SIG" /> as the data transmission channel | Yes |
    | `parameters.enable_metrics: true`  | Enables agent performance data collection    | Optional |
    | `parameters.enable_error_message: true` | Enables reporting of agent error events  | Optional |

    After a successful response, the agent joins the specified <Vg k="VSDK"/> channel and is ready to interact with the user.


1. **Unsubscribe from the channel**

    After an agent session ends, unsubscribe from channel messages to release subtitle-related resources:

    <CodeBlock language="kotlin" >
    {`api.unsubscribeMessage("channelName") { error ->
        if (error != null) {
            // Handle the error
        }
    }`}
    </CodeBlock>

1. **Release resources**

    At the end of each call, use the `destroy` method to clean up the cache.

    <CodeBlock language="kotlin" >
    {`api.destroy()`}
    </CodeBlock>

