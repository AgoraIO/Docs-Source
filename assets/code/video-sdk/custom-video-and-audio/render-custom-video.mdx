<PlatformWrapper platform="android">
    ```kotlin
    fun customLocalVideoPreview(): TextureView {
        // Create TextureView
        previewTextureView = TextureView(mContext)
        // Add a SurfaceTextureListener
        previewTextureView.surfaceTextureListener = surfaceTextureListener

        return previewTextureView
    }

    private val surfaceTextureListener: SurfaceTextureListener = object : SurfaceTextureListener {
        @RequiresApi(Build.VERSION_CODES.O)
        override fun onSurfaceTextureAvailable(
            surface: SurfaceTexture,
            width: Int,
            height: Int
        ) {
            // Invoked when a TextureView's SurfaceTexture is ready for use.
            if (mPreviewing) {
                // Already previewing custom video
                return
            }
            sendMessage("Surface Texture Available")
            mTextureDestroyed = false

            // Set up previewSurfaceTexture
            previewSurfaceTexture = SurfaceTexture(true)
            previewSurfaceTexture!!.setOnFrameAvailableListener(onFrameAvailableListener)

            // Add code here to:
            // * set up and configure the custom video source
            // * set SurfaceTexture of the custom video source to previewSurfaceTexture
            sendMessage("Add your code to configure a custom video source")

            // Start preview
            mPreviewing = true
        }

        override fun onSurfaceTextureSizeChanged(
            surface: SurfaceTexture,
            width: Int,
            height: Int
        ) {
        }

        override fun onSurfaceTextureDestroyed(surface: SurfaceTexture): Boolean {
            mTextureDestroyed = true
            return false
        }

        override fun onSurfaceTextureUpdated(surface: SurfaceTexture) {}
    }
    ```
</PlatformWrapper>
<PlatformWrapper platform="ios, macos">
    <Vg k="VSDK" /> does not support rendering video frames captured in the push mode. You need to implement a custom video renderer using methods from outside the SDK.

    For this, [`AVCaptureDevice`](https://developer.apple.com/documentation/avfoundation/avcapturedevice) and [`AVCaptureSession`](https://developer.apple.com/documentation/avfoundation/avcapturesession) can be used to capture frames and manage capturing sessions.

    Have a look at [`CustomAudioVideoView`](https://github.com/AgoraIO/video-sdk-samples-ios/blob/main/custom-video-and-audio/CustomAudioVideoView.swift) for more details.
</PlatformWrapper>
<PlatformWrapper platform="react-js">
    ```typescript
    const CustomVideoComponent: React.FC<{ customVideoTrack: ILocalVideoTrack | null }> = ({ customVideoTrack }) => {
        const agoraContext = useAgoraContext();
        useEffect(() => {
            if (customVideoTrack && agoraContext.localCameraTrack) {
                const mediaStreamTrack = customVideoTrack.getMediaStreamTrack();
                agoraContext.localCameraTrack.replaceTrack(mediaStreamTrack, true)
                .then(() => console.log("The default local video track has been changed"))
                .catch((error) => { console.log(error) })
            }
            return () => {
                customVideoTrack?.stop(); // Stop the custom video track when the component unmounts
            };
        }, [agoraContext.localCameraTrack, customVideoTrack]);
        return <></>;
    };
    ```
    - <Link to="{{Global.API_REF_WEB_ROOT}}/interfaces/ilocalvideotrack.html#getmediastreamtrack">getMediaStreamTrack</Link>
    - <Link to="{{Global.API_REF_WEB_ROOT}}/interfaces/ilocalvideotrack.html#replacetrack">replaceTrack</Link>
    - <Link to="{{Global.API_REF_WEB_ROOT}}/interfaces/ilocalvideotrack.html#stop">stop</Link>

</PlatformWrapper>