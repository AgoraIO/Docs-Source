
import Implementation from './implementation/index.mdx';
import Reference from './reference/index.mdx';
import Tech from '@docs/shared/conversational-ai/toolkit/tech.mdx';
import Prerequisites from '@docs/shared/conversational-ai/toolkit/prerequisites.mdx';

When interacting with conversational AI in real time, you can enable real-time subtitles to display the conversation content. This page explains how to implement real-time subtitles in your app.

## Understand the tech

<Tech />

The toolkit receives subtitle transcription content through the `onTranscriptionUpdated` callback and supports monitoring the following types of subtitle data:

* **Agent captions**: Transcribes the agent’s speech. Includes real-time updates and final results.

* **User captions**: Transcribes the user’s speech. Supports real-time display and status management.

* **Transcription status**: Reports status updates such as in progress, completed, or interrupted.

The following diagram outlines the step-by-step process to integrate live subtitle functionality into your application:

<details>
<summary>Subtitles rendering workflow</summary>

![](/images/conversational-ai/subtitles-workflow.svg)
</details>

## Prerequisites

<Prerequisites />

## Implementation

This section describes how to receive subtitle content from the subtitle processing module and display it on your app UI.

<Implementation />

## Reference 

This section contains content that completes the information on this page, or points you to documentation that explains other aspects to this product.

<Reference />


