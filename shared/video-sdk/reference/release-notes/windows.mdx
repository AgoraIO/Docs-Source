<PlatformWrapper platform="windows">

## v4.3.1

v4.3.1 was released on April XX, 2024.

#### New features

1. **Data stream encryption**

   This version adds `datastreamEncryptionEnabled` to <Link to="{{Global.API_REF_CPP_ROOT}}/class_encryptionconfig.html">EncryptionConfig</Link> for enabling data stream encryption. You can set this when you activate encryption with <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_enableencryption">enableEncryption</Link>. If there are issues causing failures in data stream encryption or decryption, these can be identified by the newly added `ENCRYPTION_ERROR_DATASTREAM_DECRYPTION_FAILURE` and `ENCRYPTION_ERROR_DATASTREAM_ENCRYPTION_FAILURE` enumerations.

1. **Adaptive configuration for low-quality video streams**

   This version introduces adaptive configuration for low-quality video streams. When you activate dual-stream mode and set up low-quality video streams on the sending side using <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_setdualstreammode2">setDualStreamMode [2/2]</Link>, the SDK defaults to the following behaviors:

   - The default encoding resolution for low-quality video streams is set to 50% of the original video encoding resolution.
   - The bitrate for the small streams is automatically matched based on the video resolution and frame rate, eliminating the need for manual specification.

1. **Other features**

   - New method <Link to="{{Global.API_REF_CPP_ROOT}}/api-ref/rtc/windows/API/toc_network#api_irtcengineex_enableencryptionex">enableEncryptionEx</Link> is added for enabling media stream or data stream encryption in multi-channel scenarios.
   - New method <Link to="{{Global.API_REF_CPP_ROOT}}/api-ref/rtc/windows/API/toc_audio_mixing#api_irtcengine_setaudiomixingplaybackspeed">setAudioMixingPlaybackSpeed</Link> is introduced for setting the playback speed of audio files.
   - New method <Link to="{{Global.API_REF_CPP_ROOT}}/api-ref/rtc/windows/API/toc_network#api_irtcengineex_getcallidex">getCallIdEx</Link> is introduced for retrieving call IDs in multi-channel scenarios.

1. **Beta features**

    - Speech driven avatar is released in beta. See [beta documentation](https://docs-beta.agora.io/en/video-calling/overview/release-notes) for details.

#### Improvements

1. **Optimization for game scenario screen sharing**

   This version specifically optimizes screen sharing for game scenarios, enhancing performance, stability, and clarity in ultra-high definition (4K, 60 fps) game scenarios, resulting in a clearer, smoother, and more stable gaming experience for players.

1. **Virtual background algorithm optimization**

   To enhance the accuracy and stability of human segmentation when activating virtual backgrounds against solid colors, this version optimizes the green screen segmentation algorithm:

   - Supports recognition of any solid color background, no longer limited to green screens.
   - Improves accuracy in recognizing background colors and reduces the background exposure during human segmentation.
   - After segmentation, the edges of the human figure (especially around the fingers) are more stable, significantly reducing flickering at the edges.

1. **CPU consumption reduction of in-ear monitoring**

   This release adds an enumerator `EAR_MONITORING_FILTER_REUSE_POST_PROCESSING_FILTER` in `EAR_MONITORING_FILTER_TYPE`. For complex audio processing scenarios, you can specify this option to reuse the audio filter post sender-side processing in in-ear monitoring, thereby reducing CPU consumption. Note that this option may increase the latency of in-ear monitoring, which is suitable for latency-tolerant scenarios requiring low CPU consumption.

1. **Other improvements**

   This version also includes the following improvements:

   - Optimization of video encoding and decoding strategies in non-screen sharing scenarios to save system performance overhead.
   - Enhanced media player capabilities to handle WebM format videos, including support for rendering alpha channels.
   - In <Link to="{{Global.API_REF_CPP_ROOT}}/enum_audioeffectpreset.html">AUDIO_EFFECT_PRESET</Link>, a new enumeration `ROOM_ACOUSTICS_CHORUS` (chorus effect) is added, enhancing the spatial presence of vocals in chorus scenarios.
   - In <Link to="{{Global.API_REF_CPP_ROOT}}/class_remoteaudiostats.html">RemoteAudioStats</Link>, a new `e2eDelay` field is added to report the delay from when the audio is captured on the sending end to when the audio is played on the receiving end.

#### Issues fixed

This version fixed the following issues:

- Fixed an issue where SEI data output did not synchronize with video rendering when playing media streams containing SEI data using the media player.
- In screen sharing scenarios, when the app enabled sound card capture with <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_enableloopbackrecording">enableLoopbackRecording</Link> to capture audio from the shared screen, the transmission of sound card captured audio failed after a local user manually disabled the local audio capture device, causing remote users to not hear the shared screen's audio.
- When a user plugged and unplugged a Bluetooth or wired headset once, the audio state change callback <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengineeventhandler.html#callback_irtcengineeventhandler_onaudiodevicestatechanged">onAudioDeviceStateChanged</Link> was triggered multiple times.
- During interactions, when a local user set the system default playback device to speakers using <Link to="{{Global.API_REF_CPP_ROOT}}/class_iaudiodevicecollection.html#api_iaudiodevicecollection_setdevice">setDevice</Link>, there was no sound from the remote end.
- When sharing an Excel document window, remote users occasionally saw a green screen.
- On devices using Intel graphics cards, occasionally there was a performance regression when publishing a small video stream.

#### API changes

**Added**

- <Link to="{{Global.API_REF_CPP_ROOT}}/api_imediaengine_registerfaceinfoobserver.html">registerFaceInfoObserver</Link>
- <Link to="{{Global.API_REF_CPP_ROOT}}/API/class_ifaceinfoobserver.html">IFaceInfoObserver</Link>
- <Link to="{{Global.API_REF_CPP_ROOT}}/API/callback_ifaceinfoobserver_onfaceinfo.html">onFaceInfo</Link>
- <Link to="{{Global.API_REF_CPP_ROOT}}/enum_mediasourcetype.html">MEDIA_SOURCE_TYPE</Link> adds `SPEECH_DRIVEN_VIDEO_SOURCE`
- <Link to="{{Global.API_REF_CPP_ROOT}}/enum_videosourcetype.html">VIDEO_SOURCE_TYPE</Link> adds `VIDEO_SOURCE_SPEECH_DRIVEN`
- <Link to="{{Global.API_REF_CPP_ROOT}}/class_encryptionconfig.html">EncryptionConfig</Link> adds `datastreamEncryptionEnabled`
- <Link to="{{Global.API_REF_CPP_ROOT}}/enum_encryptionerrortype.html">ENCRYPTION_ERROR_TYPE</Link> adds the following enumerations:
    - `ENCRYPTION_ERROR_DATASTREAM_DECRYPTION_FAILURE`
    - `ENCRYPTION_ERROR_DATASTREAM_ENCRYPTION_FAILURE`
- <Link to="{{Global.API_REF_CPP_ROOT}}/class_remoteaudiostats.html">RemoteAudioStats</Link> adds `e2eDelay`
- <Link to="{{Global.API_REF_CPP_ROOT}}/enum_errorcodetype.html">ERROR_CODE_TYPE</Link> adds `ERR_DATASTREAM_DECRYPTION_FAILED`
- <Link to="{{Global.API_REF_CPP_ROOT}}/enum_audioeffectpreset.html">AUDIO_EFFECT_PRESET</Link> adds `ROOM_ACOUSTICS_CHORUS`, enhancing the spatial presence of vocals in chorus scenarios.
- <Link to="{{Global.API_REF_CPP_ROOT}}/">getCallIdEx</Link>
- <Link to="{{Global.API_REF_CPP_ROOT}}/"></Link>
- <Link to="{{Global.API_REF_CPP_ROOT}}/"></Link>
- <Link to="{{Global.API_REF_CPP_ROOT}}/"></Link> adds a new enumeration `EAR_MONITORING_FILTER_BUILT_IN_AUDIO_FILTERS`

### v4.3.0

v4.3.0 was released on February 22, 2024.

#### Compatibility changes

This release has optimized the implementation of some functions, involving renaming or deletion of some APIs. To ensure the normal operation of the project, you need to update the code in the app after upgrading to this release.

1. **Renaming parameters in callbacks**

   In order to make the parameters in some callbacks and the naming of enumerations in enumeration classes easier to understand, the following modifications have been made in this release. Please modify the parameter settings in the callbacks after upgrading to this release.

   | Callback                           | Original parameter name | New parameter name |
   | ---------------------------------- | ----------------------- | ----------------------- |
   | `onLocalAudioStateChanged`         | `error`                 | `reason`                |
   | `onLocalVideoStateChanged`         | `error`                 | `reason`                |
   | `onDirectCdnStreamingStateChanged` | `error`                 | `reason`                |
   | `onPlayerSourceStateChanged`       | `ec`                    | `reason`                |
   | `onRtmpStreamingStateChanged`      | `errCode`               | `reason`                |

   | Original enumeration class   | New enumeration class     |
   | ---------------------------- | ----------------------------- |
   | `LOCAL_AUDIO_STREAM_ERROR`   | `LOCAL_AUDIO_STREAM_REASON`   |
   | `LOCAL_VIDEO_STREAM_ERROR`   | `LOCAL_VIDEO_STREAM_REASON`   |
   | `DIRECT_CDN_STREAMING_ERROR` | `DIRECT_CDN_STREAMING_REASON` |
   | `MEDIA_PLAYER_ERROR`         | `MEDIA_PLAYER_REASON`         |
   | `RTMP_STREAM_PUBLISH_ERROR`  | `RTMP_STREAM_PUBLISH_REASON`  |

   **Note:** For specific renaming of enumerations, please refer to [API changes](#api-changes).

2. **Channel media relay**

   To improve interface usability, this release removes some methods and callbacks for channel media relay. Use the alternative options listed in the table below:

   | Deleted methods and callbacks                                | Alternative methods and callbacks  |
   | ------------------------------------------------------------ | ---------------------------------- |
   | <ul><li>`startChannelMediaRelay`</li><li>`updateChannelMediaRelay`</li></ul> | `startOrUpdateChannelMediaRelay`   |
   | <ul><li>`startChannelMediaRelayEx`</li><li>`updateChannelMediaRelayEx`</li></ul> | `startOrUpdateChannelMediaRelayEx` |
   | `onChannelMediaRelayEvent`                                   | `onChannelMediaRelayStateChanged`  |

3. **Reasons for local video state changes**

   This release makes the following modifications to the enumerations in the <Link to="{{Global.API_REF_CPP_ROOT}}/enum_localvideostreamerror.html">LOCAL_VIDEO_STREAM_ERROR</Link> class:

   - The value of `LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_PAUSED` (formerly `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_PAUSED`) has been changed from 23 to 28.
   - The value of `LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_RESUMED` (formerly `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_RESUMED`) has been changed from 24 to 29.
   - The `LOCAL_VIDEO_STREAM_ERROR_CODEC_NOT_SUPPORT` enumeration has been changed to `LOCAL_VIDEO_STREAM_REASON_CODEC_NOT_SUPPORT`.

4. **Audio loopback capturing**

   - Before v4.3.0, if you call the <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_disableaudio">disableAudio</Link> method to disable the audio module, audio loopback capturing will not be disabled.

   - As of v4.3.0, if you call the <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_disableaudio">disableAudio</Link> method to disable the audio module, audio loopback capturing will be disabled as well. If you need to enable audio loopback capturing, you need to enable the audio module by calling the <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_enableaudio">enableAudio</Link> method and then call <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_enableloopbackrecording">enableLoopbackRecording</Link>.

5. **Log encryption behavior changes**

    For security and performance reasons, as of this release, the SDK encrypts logs and no longer supports printing plaintext logs via the console.

    Refer to the following solutions for different needs:

    - If you need to know the API call status, please check the API logs and print the SDK callback logs yourself.
    - For any other special requirements, please contact [technical support](mailto:support@agora.io) and provide the corresponding encrypted logs.

#### New features

1. **Local preview with multiple views**

   This release supports local preview with simultaneous display of multiple frames, where the videos shown in the frames are positioned at different observation positions along the video link. Examples of usage are as follows:

   1. Call <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_setuplocalvideo">setupLocalVideo</Link> to set the first view: Set the `position` parameter to `POSITION_POST_CAPTURER_ORIGIN` (introduced in this release) in `VideoCanvas`. This corresponds to the position after local video capture and before preprocessing. The video observed here does not have preprocessing effects.
   2. Call <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_setuplocalvideo">setupLocalVideo</Link> to set the second view: Set the `position` parameter to `POSITION_POST_CAPTURER` in `VideoCanvas`, the video observed here has the effect of video preprocessing.
   3. Observe the local preview effect: The first view is the original video of a real person; the second view is the virtual portrait after video preprocessing (including image enhancement, virtual background, and local preview of watermarks) effects.

2. **Query Device Score**

   This release adds the <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_querydevicescore">queryDeviceScore</Link> method to query the device's score level to ensure that the user-set parameters do not exceed the device's capabilities. For example, in HD or UHD video scenarios, you can first call this method to query the device's score. If the returned score is low (for example, below 60), you need to lower the video resolution to avoid affecting the video experience. The minimum device score required for different business scenarios is varied. For specific score recommendations, please contact [technical support](mailto:support@agora.io).

3. **Select different audio tracks for local playback and streaming**

   This release introduces the <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_Imediaplayer_selectmultiaudiotrack">selectMultiAudioTrack</Link> method that allows you to select different audio tracks for local playback and streaming to remote users. For example, in scenarios like online karaoke, the host can choose to play the original sound locally and publish the accompaniment in the channel. Before using this function, you need to open the media file through the <Link to="{{Global.API_REF_CPP_ROOT}}/class_imediaplayer.html#api_imediaplayer_openwithmediasource">openWithMediaSource</Link> method and enable this function by setting the `enableMultiAudioTrack` parameter in <Link to="{{Global.API_REF_CPP_ROOT}}/class_mediasource.html">MediaSource</Link>.

4. **Others**

   This release has passed the test verification of the following APIs and can be applied to the entire series of RTC 4.x SDK.

   - <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_setremotesubscribefallbackoption">setRemoteSubscribeFallbackOption</Link>: Sets fallback option for the subscribed video stream in weak network conditions.
   - <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengineeventhandler.html#callback_irtcengineeventhandler_onremotesubscribefallbacktoaudioonly">onRemoteSubscribeFallbackToAudioOnly</Link>: Occurs when the subscribed video stream falls back to audio-only stream due to weak network conditions or switches back to the video stream after the network conditions improve.
   - <Link to="{{Global.API_REF_CPP_ROOT}}/class_iaudiodevicemanager.html#api_iaudiodevicemanager_setplaybackdevicevolume">setPlaybackDeviceVolume</Link>: Sets the volume of the audio playback device.
   - <Link to="{{Global.API_REF_CPP_ROOT}}/class_iaudiodevicemanager.html#api_iaudiodevicemanager_getrecordingdevicevolume">getRecordingDeviceVolume</Link>: Sets the volume of the audio capturing device.
   - <Link to="{{Global.API_REF_CPP_ROOT}}/class_imediaplayer.html#api_imediaplayer_setplayeroption">setPlayerOption</Link>: Sets media player options for providing technical previews or special customization features.
   - <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_enablecustomaudiolocalplayback">enableCustomAudioLocalPlayback</Link>: Sets whether to enable the local playback of external audio source.

#### Improvements

1. **SDK task processing scheduling optimization**

   This release optimizes the scheduling mechanism for internal tasks within the SDK, with improvements in the following aspects:

   - The speed of video rendering and audio playback for both remote and local first frames improves by 10% to 20%.
   - The API call duration and response time are reduced by 5% to 50%.
   - The SDK's parallel processing capability significantly improves, delivering higher video quality (720P, 24 fps) even on lower-end devices. Additionally, image processing remains more stable in scenarios involving high resolutions and frame rates.
   - The stability of the SDK is further enhanced, leading to a noticeable decrease in the crash rate across various specific scenarios.

1. **In-ear monitoring volume boost**

   This release provides users with more flexible in-ear monitoring audio adjustment options, supporting the ability to set the in-ear monitoring volume to four times the original volume by calling <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_setinearmonitoringvolume">setInEarMonitoringVolume</Link>.

1. **Spatial audio effects usability improvement**

   - This release optimizes the design of the <Link to="{{Global.API_REF_CPP_ROOT}}/class_ibasespatialaudioengine.html#api_ibasespatialaudioengine_setzones">setZones</Link> method, supporting the ability to set the `zones` parameter to `NULL`, indicating the clearing of all echo cancellation zones.
   - As of this release, it is no longer necessary to unsubscribe from the audio streams of all remote users within the channel before calling the methods in <Link to="{{Global.API_REF_CPP_ROOT}}/class_ilocalspatialaudioengine.html#class_ilocalspatialaudioengine">ILocalSpatialAudioEngine</Link> class.

1. **Other Improvements**

   This release also includes the following improvements:

   - The <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengineeventhandler.html#callback_irtcengineeventhandler_onlocalvideostatechanged">onLocalVideoStateChanged</Link> callback is improved with the inclusion of the `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_AUTO_FALLBACK` enumeration, signaling unexpected errors during the screen sharing process (potentially due to window blocking failure), resulting in performance degradation without impacting the screen sharing process itself.
   - This release optimizes the SDK's domain name resolution strategy, improving the stability of calling to resolve domain names in complex network environments.
   - When passing in an image with transparent background as the virtual background image, the transparent background can be filled with customized color.
   - This release adds the `earMonitorDelay` and `aecEstimatedDelay` members in <Link to="{{Global.API_REF_CPP_ROOT}}/class_localaudiostats.html">LocalAudioStats</Link> to report ear monitor delay and acoustic echo cancellation (AEC) delay, respectively.
   - The <Link to="{{Global.API_REF_CPP_ROOT}}/class_imediaplayersourceobserver.html#callback_imediaplayersourceobserver_onplayercachestats">onPlayerCacheStats</Link> callback is added to report the statistics of the media file being cached. This callback is triggered once per second after file caching is started.
   - The <Link to="{{Global.API_REF_CPP_ROOT}}/class_imediaplayersourceobserver.html#callback_imediaplayersourceobserver_onplayerplaybackstats">onPlayerPlaybackStats</Link> callback is added to report the statistics of the media file being played. This callback is triggered once per second after the media file starts playing. You can obtain information like the audio and video bitrate of the media file through <Link to="{{Global.API_REF_CPP_ROOT}}/class_playerplaybackstats.html">PlayerPlaybackStats</Link>.

#### Issues fixed

This release fixed the following issues:

- When sharing two screen sharing video streams simultaneously, the reported `captureFrameRate` in the <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengineeventhandler.html#callback_irtcengineeventhandler_onlocalvideostats">onLocalVideoStats</Link> callback is 0, which is not as expected.
- When sharing in a specified screen area, the mouse coordinates within the shared area are inaccurate. When the mouse is near the border of the shared area, the mouse may not be visible in the shared screen.
- The SDK failed to detect any changes in the audio routing after plugging in and out 3.5mm earphones.

#### API changes

**Added**

- The `subviewUid` member in <Link to="{{Global.API_REF_CPP_ROOT}}/class_videocanvas.html">VideoCanvas</Link>
- <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_enablecustomaudiolocalplayback">enableCustomAudioLocalPlayback</Link>
- <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_irtcengine_querydevicescore">queryDeviceScore</Link>
- The `CUSTOM_VIDEO_SOURCE` enumeration in <Link to="{{Global.API_REF_CPP_ROOT}}/enum_mediasourcetype.html">MEDIA_SOURCE_TYPE</Link>
- The `ROUTE_BLUETOOTH_DEVICE_A2DP` enumeration in <Link to="{{Global.API_REF_CPP_ROOT}}/enum_audioroute.html">AudioRoute</Link>
- <Link to="{{Global.API_REF_CPP_ROOT}}/class_irtcengine.html#api_Imediaplayer_selectmultiaudiotrack">selectMultiAudioTrack</Link>
- <Link to="{{Global.API_REF_CPP_ROOT}}/class_imediaplayersourceobserver.html#callback_imediaplayersourceobserver_onplayercachestats">onPlayerCacheStats</Link>
- <Link to="{{Global.API_REF_CPP_ROOT}}/class_imediaplayersourceobserver.html#callback_imediaplayersourceobserver_onplayerplaybackstats">onPlayerPlaybackStats</Link>
- <Link to="{{Global.API_REF_CPP_ROOT}}/class_playerplaybackstats.html">PlayerPlaybackStats</Link>

**Modified**

- All `ERROR` fields in the following enumerations are changed to `REASON`:
  - `LOCAL_AUDIO_STREAM_ERROR_OK`
  - `LOCAL_AUDIO_STREAM_ERROR_FAILURE`
  - `LOCAL_AUDIO_STREAM_ERROR_DEVICE_NO_PERMISSION`
  - `LOCAL_AUDIO_STREAM_ERROR_DEVICE_BUSY`
  - `LOCAL_AUDIO_STREAM_ERROR_RECORD_FAILURE`
  - `LOCAL_AUDIO_STREAM_ERROR_ENCODE_FAILURE`
  - `LOCAL_AUDIO_STREAM_ERROR_RECORD_INVALID_ID`
  - `LOCAL_AUDIO_STREAM_ERROR_PLAYOUT_INVALID_ID`
  - `LOCAL_VIDEO_STREAM_ERROR_OK`
  - `LOCAL_VIDEO_STREAM_ERROR_FAILURE`
  - `LOCAL_VIDEO_STREAM_ERROR_DEVICE_NO_PERMISSION`
  - `LOCAL_VIDEO_STREAM_ERROR_DEVICE_BUSY`
  - `LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE`
  - `LOCAL_VIDEO_STREAM_ERROR_CODEC_NOT_SUPPORT`
  - `LOCAL_VIDEO_STREAM_ERROR_DEVICE_NOT_FOUND`
  - `LOCAL_VIDEO_STREAM_ERROR_DEVICE_DISCONNECTED`
  - `LOCAL_VIDEO_STREAM_ERROR_DEVICE_INVALID_ID`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_MINIMIZED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_CLOSED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_OCCLUDED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_NO_PERMISSION`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_PAUSED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_RESUMED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_HIDDEN`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_HIDDEN`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_MINIMIZED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_FAILURE`
  - `LOCAL_VIDEO_STREAM_ERROR_DEVICE_SYSTEM_PRESSURE`
  - `DIRECT_CDN_STREAMING_ERROR_OK`
  - `DIRECT_CDN_STREAMING_ERROR_FAILED`
  - `DIRECT_CDN_STREAMING_ERROR_AUDIO_PUBLICATION`
  - `DIRECT_CDN_STREAMING_ERROR_VIDEO_PUBLICATION`
  - `DIRECT_CDN_STREAMING_ERROR_NET_CONNECT`
  - `DIRECT_CDN_STREAMING_ERROR_BAD_NAME`
  - `PLAYER_ERROR_NONE`
  - `PLAYER_ERROR_INVALID_ARGUMENTS`
  - `PLAYER_ERROR_INTERNAL`
  - `PLAYER_ERROR_NO_RESOURCE`
  - `PLAYER_ERROR_INVALID_MEDIA_SOURCE`
  - `PLAYER_ERROR_UNKNOWN_STREAM_TYPE`
  - `PLAYER_ERROR_OBJ_NOT_INITIALIZED`
  - `PLAYER_ERROR_CODEC_NOT_SUPPORTED`
  - `PLAYER_ERROR_VIDEO_RENDER_FAILED`
  - `PLAYER_ERROR_INVALID_STATE`
  - `PLAYER_ERROR_URL_NOT_FOUND`
  - `PLAYER_ERROR_INVALID_CONNECTION_STATE`
  - `PLAYER_ERROR_SRC_BUFFER_UNDERFLOW`
  - `PLAYER_ERROR_INTERRUPTED`
  - `PLAYER_ERROR_NOT_SUPPORTED`
  - `PLAYER_ERROR_TOKEN_EXPIRED`
  - `PLAYER_ERROR_UNKNOWN`
  - `RTMP_STREAM_PUBLISH_ERROR_OK`
  - `RTMP_STREAM_PUBLISH_ERROR_INVALID_ARGUMENT`
  - `RTMP_STREAM_PUBLISH_ERROR_ENCRYPTED_STREAM_NOT_ALLOWED`
  - `RTMP_STREAM_PUBLISH_ERROR_CONNECTION_TIMEOUT`
  - `RTMP_STREAM_PUBLISH_ERROR_INTERNAL_SERVER_ERROR`
  - `RTMP_STREAM_PUBLISH_ERROR_RTMP_SERVER_ERROR`
  - `RTMP_STREAM_PUBLISH_ERROR_TOO_OFTEN`
  - `RTMP_STREAM_PUBLISH_ERROR_REACH_LIMIT`
  - `RTMP_STREAM_PUBLISH_ERROR_NOT_AUTHORIZED`
  - `RTMP_STREAM_PUBLISH_ERROR_STREAM_NOT_FOUND`
  - `RTMP_STREAM_PUBLISH_ERROR_FORMAT_NOT_SUPPORTED`
  - `RTMP_STREAM_PUBLISH_ERROR_NOT_BROADCASTER`
  - `RTMP_STREAM_PUBLISH_ERROR_TRANSCODING_NO_MIX_STREAM`
  - `RTMP_STREAM_PUBLISH_ERROR_NET_DOWN`
  - `RTMP_STREAM_PUBLISH_ERROR_INVALID_PRIVILEGE`
  - `RTMP_STREAM_UNPUBLISH_ERROR_OK`

**Deleted**

- `startChannelMediaRelay`
- `updateChannelMediaRelay`
- `startChannelMediaRelayEx`
- `updateChannelMediaRelayEx`
- `onChannelMediaRelayEvent`
- `CHANNEL_MEDIA_RELAY_EVENT`


### v4.2.6

v4.2.6 was released on November 17, 2023.

#### Issues fixed

This release fixed the following issue:

- In specific scenarios, such as when the network packet loss rate was high or when the broadcaster left the channel without destroying the engine and then re-joined the channel, the video on the receiving end stuttered or froze.

### v4.2.3

v4.2.3 was released on October 11, 2023.

#### New features

1. **Update video screenshot and upload**

   To facilitate the integration of third-party video moderation services from Agora Extensions Marketplace, this version has the following changes:

   - The `CONTENT_INSPECT_IMAGE_MODERATION` enumeration is added in `CONTENT_INSPECT_TYPE` which means using video moderation extensions from Agora Extensions Marketplace to take video screenshots and upload them.
   - An optional parameter `serverConfig` is added in `ContentInspectConfig`, which is for server-side configuration related to video screenshot and upload via extensions from Agora Extensions Marketplace. By configuring this parameter, you can integrate multiple third-party moderation extensions and achieve flexible control over extension switches and other features. For more details, please contact [technical support](mailto:support@agora.io).

   In addition, this version also introduces the `enableContentInspectEx` method, which supports taking screenshots for multiple video streams and uploading them.

1. **ID3D11Texture2D Rendering**

   As of this release, the SDK supports video formats of type ID3D11Texture2D, improving the rendering effect of video frames in game scenarios. You can set `format` to `VIDEO_TEXTURE_ID3D11TEXTURE2D` when pushing external raw video frames to the SDK by calling `pushVideoFrame`. By setting the `d3d11_texture_2d` and `texture_slice_index` properties, you can determine the ID3D11Texture2D texture object to use.

1. **Local video status error code update**

   In order to help users understand the exact reasons for local video errors in screen sharing scenarios, the following sets of enumerations have been added to the `onLocalVideoStateChanged` callback:

   - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_PAUSED`(23): Screen capture has been paused. Common scenarios for reporting this error code: The current screen may have been switched to a secure desktop, such as a UAC dialog box or Winlogon desktop.
   - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_RESUMED`(24): Screen capture has resumed from the paused state.
   - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_HIDDEN`(25): The window being captured on the current screen is in a hidden state and is not visible on the current screen.
   - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_HIDDEN`(26): The window for screen capture has been restored from the hidden state.
   - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_MINIMIZED`(27): The window for screen capture has been restored from the minimized state.

1. **Check device support for advanced features**

   This version adds the `isFeatureAvailableOnDevice` method to check whether the capability of the current device meets the requirements of the specified advanced feature, such as virtual background and image enhancement.

   Before using advanced features, you can check whether the current device supports these features based on the call result. This helps to avoid performance degradation or unavailable features when enabling advanced features on low-end devices. Based on the return value of this method, you can decide whether to display or enable the corresponding feature button, or notify the user when the device's capabilities are insufficient.

   In addition, since this version, calling `enableVirtualBackground` and `setBeautyEffectOptions` automatically triggers a test on the capability of the current device. When the device is considered underperformed, the error code `-4:ERR_NOT_SUPPORTED` is returned, indicating the device does not support the feature.

#### Improvements

1. **Optimize virtual background memory usage**

   This version has upgraded the virtual background algorithm, reducing the memory usage of the virtual background feature. Compared to the previous version, the memory consumption of the app during the use of the virtual background feature on low-end devices has been reduced by approximately 4% to 10% (specific values may vary depending on the device model and platform).

1. **Screen sharing scenario optimization**

   This release optimizes the performance and encoding efficiency in ultra-high-definition (4K, 60 fps) game sharing scenarios, effectively reducing the system resource usage during screen sharing.

**Other Improvements**

This release includes the following additional improvements:

- Optimizes the logic of handling invalid parameters. When you call the `setPlaybackSpeed` method to set the playback speed of audio files, if you pass an invalid parameter, the SDK returns the error code -2, which means that you need to reset the parameter.
- Optimizes the logic of Token parsing, in order to prevent an app from crash when an invalid token is passed in.

#### Issues fixed

This release fixed the following issues:

- Occasional crashes and dropped frames occurred in screen sharing scenarios.
- Occasional failure of joining a channel when the local system time was not set correctly.
- When calling the `playEffect` method to play two audio files using the same `soundId`, the first audio file was sometimes played repeatedly.
- Calling `takeSnapshotEx` once receives the `onSnapshotTaken` callback for multiple times.

#### API changes

**Added**

- The following enumerations in `onLocalVideoStateChanged`:
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_PAUSED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_RESUMED`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_HIDDEN`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_HIDDEN`
  - `LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_MINIMIZED`
- `d3d11_texture_2d` and `texture_slice_index` members in `ExternalVideoFrame`.
- `VIDEO_TEXTURE_ID3D11TEXTURE2D` in `VIDEO_PIXEL_FORMAT`.
- `enableContentInspectEx`
- `CONTENT_INSPECT_IMAGE_MODERATION` in `CONTENT_INSPECT_TYPE`.
- `serverConfig` in `ContentInspectConfig`
- `isFeatureAvailableOnDevice`
- `FeatureType`

### v4.2.2

v4.2.2 was released on july 27, 2023.

#### New features

1. **Wildcard token**

   This release introduces wildcard tokens. Agora supports setting the channel name used for generating a token as a wildcard character. The token generated can be used to join any channel if you use the same user id. In scenarios involving multiple channels, such as switching between different channels, using a wildcard token can avoid repeated application of tokens every time users joining a new channel, which reduces the pressure on your token server. See [Secure authentication with tokens](/en/video-calling/get-started/authentication-workflow).

   <div class="alert note"> All 4.x SDKs support using wildcard tokens.</div>

2. **Preloading channels**

   This release adds `preloadChannel[1/2]` and `preloadChannel[2/2]` methods, which allows a user whose role is set as audience to preload channels before joining one. Calling the method can help shortening the time of joining a channel, thus reducing the time it takes for audience members to hear and see the host.

   When preloading more than one channels, Agora recommends that you use a wildcard token for preloading to avoid repeated application of tokens every time you joining a new channel, thus saving the time for switching between channels. See [Secure authentication with tokens](/en/video-calling/get-started/authentication-workflow).

3. **Customized background color of video canvas**

   In this release, the `backgroundColor` member has been added to `VideoCanvas`, which allows you to customize the background color of the video canvas when setting the properties of local or remote video display.

4. **Publishing video streams from different sources**

   This release adds the following members in `ChannelMediaOptions` to allow you publish video streams captured from the third and fourth camera or screen:

   - `publishThirdCameraTrack`: Publishing the video stream captured from the third camera.
   - `publishFourthCameraTrack`: Publishing the video stream captured from the fourth camera.
   - `publishThirdScreenTrack`: Publishing the video stream captured from the third screen.
   - `publishFourthScreenTrack`: Publishing the video stream captured from the fourth screen.

   <div class="alert note">For one <code>RtcConnection</code>, Agora supports publishing multiple audio streams and one video stream at the same time.</div>

#### Improvements

1. **Virtual Background Algorithm Upgrade**

   This version has upgraded the portrait segmentation algorithm of the virtual background, which comprehensively improves the accuracy of portrait segmentation, the smoothness of the portrait edge with the virtual background, and the fit of the edge when the person moves. In addition, it optimizes the precision of the person's edge in scenarios such as meetings, offices, homes, and under backlight or weak light conditions.

2. **Channel media relay**

   The number of target channels for media relay has been increased to 6. When calling `startOrUpdateChannelMediaRelay` and `startOrUpdateChannelMediaRelayEx`, you can specify up to 6 target channels.

3. **Enhancement in video codec query capability**

   To improve the video codec query capability, this release adds the `codecLevels` member in `CodecCapInfo`. After successfully calling `queryCodecCapability`, you can obtain the hardware and software decoding capability levels of the device for H.264 and H.265 video formats through `codecLevels`.

This release includes the following additional improvements:

1. The SDK automatically adjusts the frame rate of the sending end based on the screen sharing scenario. Especially in document sharing scenarios, this feature avoids exceeding the expected video bitrate on the sending end to improve transmission efficiency and reduce network burden.
2. To help users understand the reasons for more types of remote video state changes, the `REMOTE_VIDEO_STATE_REASON_CODEC_NOT_SUPPORT` enumeration has been added to the `onRemoteVideoStateChanged` callback, indicating that the local video decoder does not support decoding the received remote video stream.

#### Issues fixed

This release fixed the following issues:

- Slow channel reconnection after the connection was interrupted due to network reasons.
- In screen sharing scenarios, the delay of seeing the shared screen was occasionally higher than expected on some devices.
- In custom video capturing scenarios, `setBeautyEffectOptions`, `setLowlightEnhanceOptions`, `setVideoDenoiserOptions`, and `setColorEnhanceOptions` could not load extensions automatically.
- In multi-device audio recording scenarios, after repeatedly plugging and unplugging or enabling/disabling the audio recording device, no sound could be heard occasionally when calling the `startRecordingDeviceTest` to start an audio capturing device test.

#### API changes

**Added**

- `preloadChannel[1/2]`
- `preloadChannel[2/2]`
- `updatePreloadChannelToken`
- The following members in `ChannelMediaOptions`:
  - `publishThirdCameraTrack`
  - `publishFourthCameraTrack`
  - `publishThirdScreenTrack`
  - `publishFourthScreenTrack`
- `CodecCapLevels`
- `VIDEO_CODEC_CAPABILITY_LEVEL`
- `backgroundColor` in `VideoCanvas`
- `codecLevels` in `CodecCapInfo`
- `REMOTE_VIDEO_STATE_REASON_CODEC_NOT_SUPPORT` in `REMOTE_VIDEO_STATE_REASON`

### v4.2.1

This version was released on June 21, 2023.

#### Improvements

This version improves the network transmission strategy, enhancing the smoothness of audio and video interactions.

#### Fixed Issues

This version fixed the following issues:

- Inability to join channels caused by SDK's incompatibility with some older versions of AccessToken.
- After the sending end called `setAINSMode` to activate AI noise reduction, occasional echo was observed by the receiving end.
- Brief noise occurred while playing media files using the media player.
- When the sending end mixed and published two streams of video captured by two cameras locally, the video from the second camera was occasionally missing on the receiving end.

### v4.2.0

v4.2.0 was released on May 24, 2023.

#### Compatibility changes

If you use the features mentioned in this section, ensure that you modify the implementation of the relevant features after upgrading the SDK.

**1. Video capture**

This release optimizes the APIs for camera and screen capture function. As of v4.2.0, ensure you use the alternative methods listed in the table below and specify the video source by setting the `sourceType` parameter.

| Deleted Methods                                              | Alternative Methods       |
| :----------------------------------------------------------- | :------------------------ |
| <li>`startPrimaryCameraCapture`</li><li>`startSecondaryCameraCapture`</li> | `startCameraCapture`      |
| <li>`stopPrimaryCameraCapture`</li><li>`stopSecondaryCameraCapture`</li> | `stopCameraCapture`       |
| <li>`startPrimaryScreenCapture`</li><li>`startSecondaryScreenCapture`</li> | `startScreenCapture`[2/2] |
| <li>`stopPrimaryScreenCapture`</li><li>`stopSecondaryScreenCapture`</li> | `stopScreenCapture`[2/2]  |

**2. Video data acquisition**

- The `onCaptureVideoFrame` and `onPreEncodeVideoFrame` callbacks are added with a new parameter called `sourceType`, which is used to indicate the specific video source type.
- The following callbacks are deleted. Get the video source type through the `sourceType` parameter in the `onPreEncodeVideoFrame` and `onCaptureVideoFrame` callbacks.
  - `onSecondaryPreEncodeCameraVideoFrame`
  - `onScreenCaptureVideoFrame`
  - `onPreEncodeScreenVideoFrame`
  - `onSecondaryPreEncodeScreenVideoFrame`

**3. Channel media options**

- `publishCustomAudioTrackEnableAec` in `ChannelMediaOptions` is deleted. Use `publishCustomAudioTrack` instead.
- `publishTrancodedVideoTrack` in `ChannelMediaOptions` is renamed to `publishTranscodedVideoTrack`.
- `publishCustomAudioSourceId` in `ChannelMediaOptions` is renamed to `publishCustomAudioTrackId`.

**4. Local video mixing**

- The `VideoInputStreams` in `LocalTranscoderConfiguration` is changed to `videoInputStreams`.
- The `MEDIA_SOURCE_TYPE` in `TranscodingVideoStream` is changed to `VIDEO_SOURCE_TYPE`.

**5. Miscellaneous**

- `onApiCallExecuted` is deleted. Agora recommends getting the results of the API implementation through relevant channels and media callbacks.
- The `IAudioFrameObserver` class is renamed to `IAudioPcmFrameSink`, thus the prototypes of the following methods are updated accordingly:
  - `onFrame`
  - `registerAudioFrameObserver` [1/2] and `registerAudioFrameObserver`[2/2] in `IMediaPlayer`
- `enableDualStreamMode`[1/2] and `enableDualStreamMode`[2/2] are deprecated. Use `setDualStreamMode`[1/2] and `setDualStreamMode`[2/2] instead.
- `startChannelMediaRelay`, `updateChannelMediaRelay`, `startChannelMediaRelayEx`, and `updateChannelMediaRelayEx` are deprecated. Use `startOrUpdateChannelMediaRelay` and `startOrUpdateChannelMediaRelayEx` instead.

#### New features

**1. AI Noise Suppression**

This release introduces public APIs for the AI Noise Suppression function. Once enabled, the SDK automatically detects and reduces background noises. Whether in bustling public venues or real-time competitive arenas that demand lightning-fast responsiveness, this function guarantees optimal audio clarity, providing users with an elevated audio experience. You can enable this function through the newly-introduced `setAINSMode` method and set the noise reduction mode as balance, aggressive, or low latency according to your scenarios.

<div class="alert note">Agora charges separately for this function. See [AI Noise Suppression unit pricing](pricing#ai-noise-suppression-pricing).</div>


**2. Enhanced Virtual Background**

To increase the fun of real-time video calls and protect user privacy, this version has enhanced the Virtual Background feature. You can now set custom backgrounds of various types by calling the `enableVirtualBackground` method, including:

- Process the background as alpha information without replacement, only separating the portrait and the background. This can be combined with the local video mixing feature to achieve a portrait-in-picture effect.
- Replace the background with various formats of local videos.


See [Virtual Background documentation](../enable-features/virtual-background).

**3. Video scenario settings**

This release introduces `setVideoScenario` for setting the video application scene. The SDK will automatically enable the best practice strategy based on different scenes, adjusting key performance indicators to optimize video quality and improve user experience. Whether it is a formal business meeting or a casual online gathering, this feature ensures that the video quality meets the requirements.

Currently, this feature provides targeted optimizations for real-time video conferencing scenarios, including:

- Automatically activate multiple anti-weak-network technologies to enhance the capability and performance of low-quality video streams in meeting scenarios where high bitrates are required, ensuring smoothness when multiple streams are subscribed by the receiving end.
- Monitor the number of subscribers for the high-quality and low-quality video streams in real time, dynamically adjusting the configuration of the high-quality stream and dynamically enabling or disabling the low-quality stream, to save uplink bandwidth and consumption.

**4. Local video mixing**

This release adds the `onLocalVideoTranscoderError` callback. When there is an error in starting or updating the local video mixing, the SDK triggers this callback to report the reason for the failure.

**5. Cross-device synchronization**

In real-time collaborative singing scenarios, network issues can cause inconsistencies in the downlinks of different client devices. To address this, this release introduces `getNtpWallTimeInMs` for obtaining the current Network Time Protocol (NTP) time. By using this method to synchronize lyrics and music across multiple client devices, users can achieve synchronized singing and lyrics progression, resulting in a better collaborative experience.

#### Improvements

**1. Voice changer**

This release introduces the `setLocalVoiceFormant` method that allows you to adjust the formant ratio to change the timbre of the voice. This method can be used together with the `setLocalVoicePitch` method to adjust the pitch and timbre of voice at the same time, enabling a wider range of voice transformation effects.

**2. Enhanced rendering compatibility**

This release enhances the rendering compatibility of the SDK. Issues like black screens caused by rendering failures on certain devices are fixed.

**3. Audio and video synchronization**

For custom video and audio capture scenarios, this release introduces `getCurrentMonotonicTimeInMs` for obtaining the current Monotonic Time. By passing this value into the timestamps of audio and video frames, developers can accurately control the timing of their audio and video streams, ensuring proper synchronization.

**4. Multi-camera capture and multi-screen capture**

This release introduces `startCameraCapture` and `startScreenCapture`[2/2]. By calling these methods multiple times and specifying the `sourceType` parameter, developers can start capturing video streams from multiple cameras and screens for local video mixing or multi-channel publishing. This is particularly useful for scenarios such as remote medical care and online education, where multiple cameras and displays need to be connected.

**5. Channel media relay**

This release introduces `startOrUpdateChannelMediaRelay` and `startOrUpdateChannelMediaRelayEx`, allowing for a simpler and smoother way to start and update media relay across channels. With these methods, developers can easily start the media relay across channels and update the target channels for media relay with a single method. Additionally, the internal interaction frequency has been optimized, effectively reducing latency in function calls.

**6. Custom audio tracks**

To better meet the needs of custom audio capture scenarios, this release adds `createCustomAudioTrack` and `destroyCustomAudioTrack` for creating and destroying custom audio tracks. Two types of audio tracks are also provided for users to choose from, further improving the flexibility of capturing external audio source:

- Mixable audio track: Supports mixing multiple external audio sources and publishing them to the same channel, suitable for multi-channel audio capture scenarios.
- Direct audio track: Only supports publishing one external audio source to a single channel, suitable for low-latency audio capture scenarios.

#### Issues fixed

This release fixed the issue that when the host frequently switched the user role between broadcaster and audience in a short period of time, the audience members could not hear the audio of the host.

#### API changes

**Added**

- `startCameraCapture`
- `stopCameraCapture`
- `startScreenCapture`[2/2]
- `stopScreenCapture`[2/2]
- `startOrUpdateChannelMediaRelay`
- `startOrUpdateChannelMediaRelayEx`
- `getNtpWallTimeInMs`
- `setVideoScenario`
- `getCurrentMonotonicTimeInMs`
- `onLocalVideoTranscoderError`
- `setAINSMode`
- `createAudioCustomTrack`
- `destroyAudioCustomTrack`
- `AudioTrackConfig`
- `AUDIO_TRACK_TYPE`
- `VIDEO_APPLICATION_SCENARIO_TYPE`
- `SCREEN_CAPTURE_FRAMERATE_CAPABILITY`
- The `domainLimit` and `autoRegisterAgoraExtensions` members in `RtcEngineContext`
- The `sourceType` parameter in `onCaptureVideoFrame` and `onPreEncodeVideoFrame` callbacks
- The `BACKGROUND_NONE` and `BACKGROUND_VIDEO` enumerators in `BACKGROUND_SOURCE_TYPE`

**Deprecated**

- `enableDualStreamMode`[1/2]
- `enableDualStreamMode`[2/2]
- `startChannelMediaRelay`
- `startChannelMediaRelayEx`
- `updateChannelMediaRelay`
- `updateChannelMediaRelayEx`
- `onChannelMediaRelayEvent`
- `CHANNEL_MEDIA_RELAY_EVENT`

**Deleted**

- `startPrimaryScreenCapture`
- `startSecondaryScreenCapture`
- `stopPrimaryScreenCapture`
- `stopSecondaryScreenCapture`
- `startPrimaryCameraCapture`
- `startSecondaryCameraCapture`
- `stopPrimaryCameraCapture`
- `stopSecondaryCameraCapture`
- `onSecondaryPreEncodeCameraVideoFrame`
- `onScreenCaptureVideoFrame`
- `onPreEncodeScreenVideoFrame`
- `onSecondaryPreEncodeScreenVideoFrame`
- `onApiCallExecuted`
- `publishCustomAudioTrackEnableAec ` in ` ChannelMediaOptions`

### v4.1.1

 v4.1.1 was released on February 8, 2023.

 #### Compatibility changes

As of this release, the SDK optimizes the video encoder algorithm and upgrades the default video encoding resolution from 640 × 360 to 960 × 540 to accommodate improvements in device performance and network bandwidth, providing users with a full-link HD experience in various audio and video interaction scenarios.

Call the `setVideoEncoderConfiguration` method to set the expected video encoding resolution in the video encoding parameters configuration.

<div class="alert note">The increase in the default resolution affects the aggregate resolution and thus the billing rate. See <a href="./pricing">Pricing</a>.</div>

 #### New features

**1. Instant frame rendering**

This release adds the `enableInstantMediaRendering` method to enable instant rendering mode for audio and video frames, which can speed up the first video or audio frame rendering after the user joins the channel.

**2. Video rendering tracing**

This release adds the `startMediaRenderingTracing` and `startMediaRenderingTracingEx` methods. The SDK starts tracing the rendering status of the video frames in the channel from the moment this method is called and reports information about the event through the `onVideoRenderingTracingResult` callback.

Agora recommends that you use this method in conjunction with the UI settings, such as buttons and sliders, in your app. For example, call this method when the user clicks
**Join Channel** button and then get the indicators in the video frame rendering process through the `onVideoRenderingTracingResult` callback.
This enables developers to optimize the indicators and improve the user experience.

#### Improvements

**Video frame observer**

As of this release, the SDK optimizes the `onRenderVideoFrame` callback, and the meaning of the return value is different depending on the video processing mode:

- When the video processing mode is `PROCESS_MODE_READ_ONLY`, the return value is reserved for future use.
- When the video processing mode is `PROCESS_MODE_READ_WRITE`, the SDK receives the video frame when the return value is `true`. The video frame is discarded when the return value is `false`.

#### Issues fixed

This release fixed the following issues:

- When using Agora Media Player to play RTSP video streams, the video images sometimes appeared pixelated.
- Playing audio files with a sample rate of 48 kHz failed.
- Adding an alpha channel to an image in PNG or GIF format failed when the local client mixed video streams.
- After joining the channel, remotes users saw a watermark even though the watermark was deleted.
- If a watermark was added after starting screen sharing, the watermark did not display the screen.
- When joining a channel and accessing an external camera, calling `setDevice` to specify the video capture device as the external camera did not take effect.
- When trying to outline the shared window and put it on top, the shared window did not stay on top of other windows.
- When there were multiple video streams in a channel, calling some video enhancement APIs occasionally failed.

#### API changes

**Added**

- `enableInstantMediaRendering`
- `startMediaRenderingTracing`
- `startMediaRenderingTracingEx`
- `onVideoRenderingTracingResult`
- `MEDIA_RENDER_TRACE_EVENT`
- `VideoRenderingTracingInfo`

**Deleted**

- `enableRemoteSuperResolution`
- `superResolutionType` in `RemoteVideoStats`

### v4.1.0

v4.1.0 was released on December 15, 2022.

#### New features

**1. Headphone equalization effect**

This release adds the `setHeadphoneEQParameters` method, which is used to adjust the low- and high-frequency parameters of the headphone EQ. This is mainly useful in spatial audio scenarios. If you cannot achieve the expected headphone EQ effect after calling `setHeadphoneEQPreset`, you can call `setHeadphoneEQParameters` to adjust the EQ.

**2. Encoded video frame observer**

This release adds the `setRemoteVideoSubscriptionOptions` and `setRemoteVideoSubscriptionOptionsEx` methods. When you call the `registerVideoEncodedFrameObserver` method to register a video frame observer for the encoded video frames, the SDK subscribes to the encoded video frames by default. If you want to change the subscription options, you can call these new methods to set them.

For more information about registering video observers and subscription options, see the API reference.

**3. MPUDP (MultiPath UDP) (Beta)**

As of this release, the SDK supports MPUDP protocol, which enables you to connect and use multiple paths to maximize the use of channel resources based on the UDP protocol. You can use different physical NICs on both mobile and desktop and aggregate them to effectively combat network jitter and improve transmission quality.

> To enable this feature, contact <a href="mailto:support@agora.io">support@agora.io</a>.

**4. Register extensions**

This release adds the `registerExtension` method for registering extensions. When using a third-party extension, you need to call the extension-related APIs in the following order:

`loadExtensionProvider` -> `registerExtension` -> `setExtensionProviderProperty` -> `enableExtension`



**5. Device management**

This release adds a series of callbacks to help you better understand the status of your audio and video devices:

- `onVideoDeviceStateChanged`: Occurs when the status of the video device changes.
- `onAudioDeviceStateChanged`: Occurs when the status of the audio device changes.
- `onAudioDeviceVolumeChanged`: Occurs when the volume of an audio device or app changes.


**6. Camera capture options**

This release adds the `followEncodeDimensionRatio` member in `CameraCapturerConfiguration`, which enables you to set whether to follow the video aspect ratio already set in `setVideoEncoderConfiguration` when capturing video with the camera.



**7. Multi-channel management**

This release adds a series of multi-channel related methods that you can call to manage audio and video streams in multi-channel scenarios.

- The `muteLocalAudioStreamEx` and `muteLocalVideoStreamEx` methods are used to cancel or resume publishing a local audio or video stream, respectively.
- The `muteAllRemoteAudioStreamsEx` and `muteAllRemoteVideoStreamsEx` are used to cancel or resume the subscription of all remote users to audio or video streams, respectively.
- The `startRtmpStreamWithoutTranscodingEx`, `startRtmpStreamWithTranscodingEx`, `updateRtmpTranscodingEx`, and `stopRtmpStreamEx` methods are used to implement Media Push in multi-channel scenarios.
- The `startChannelMediaRelayEx`, `updateChannelMediaRelayEx`, `pauseAllChannelMediaRelayEx`, `resumeAllChannelMediaRelayEx`, and `stopChannelMediaRelayEx` methods are used to relay media streams across channels in multi-channel scenarios.
- Adds the `leaveChannelEx` [2/2] method. Compared with the `leaveChannelEx` [1/2] method, a new options parameter is added, which is used to choose whether to stop recording with the microphone when leaving a channel in a multi-channel scenario.

**8. Video encoding preferences**

In general scenarios, the default video encoding configuration meets most requirements. For certain specific scenarios, this release adds the `advanceOptions` member in `VideoEncoderConfiguration` for advanced settings of video encoding properties:

- `compressionPreference`: The compression preferences for video encoding, which is used to select low-latency or high-quality video preferences.
- `encodingPreference`: The video encoder preference, which is used to select adaptive preference, software encoder preference, or hardware encoder video preferences.


**9. Client role switching**

In order to enable users to know whether the switched user role is low-latency or ultra-low-latency, this release adds the `newRoleOptions` parameter to the `onClientRoleChanged` callback. The value of this parameter is as follows:

- `AUDIENCE_LATENCY_LEVEL_LOW_LATENCY` (1): Low latency.
- `AUDIENCE_LATENCY_LEVEL_ULTRA_LOW_LATENCY` (2): Ultra-low latency.

**10. Brand-new AI Noise Suppression**

The SDK supports a new version of AI noise reduction (in comparison to the basic AI noise reduction in v3.7.x). The new AI noise reduction has better vocal fidelity, cleaner noise suppression, and adds a dereverberation option.

To experience this feature, contact <a href="mailto:support@agora.io ">support@agora.io</a>.

**11. Spatial audio effect**

This release adds the following features applicable to spatial audio effect scenarios, which can effectively enhance the user's sense of presence experience in virtual interactive scenarios.

- Sound insulation area: You can set a sound insulation area and sound attenuation parameter by calling `setZones`. When the sound source (which can be a user or the media player) and the listener belong to the inside and outside of the sound insulation area, the listner experiences an attenuation effect similar to that of the sound in the real environment when it encounters a building partition. You can also set the sound attenuation parameter for the media player and the user, respectively, by calling `setPlayerAttenuation` and `setRemoteAudioAttenuation`, and specify whether to use that setting to force an override of the sound attenuation paramter in `setZones`.
- Doppler sound: You can enable Doppler sound by setting the `enable_doppler` parameter in `SpatialAudioParams`, and the receiver experiences noticeable tonal changes in the event of a high-speed relative displacement between the source source and receiver (such as in a racing game scenario).
- Headphone equalizer: You can use a preset headphone equalization effect by calling the `setHeadphoneEQPreset` method to improve the hearing of the headphones.

#### Improvements

**1. Screen sharing**

In addition to the usability enhancements detailed in the <a href="#bugfix">fixed issued</a> section, this release includes a number of functional improvements to screen sharing, as follows:

- New `minimizeWindow` member in `ScreenCaptureSourceInfo` to indicate whether the target window is minimized.
- New `enableHighLight`, `highLightColor`, and `highLightWidth` members in `ScreenCaptureParameters` so that you can place a border around the target window or screen when screen sharing.
- Compatibility with a greater number of mainstream apps, including WPS Office, Microsoft Office PowerPoint, Visual Studio Code, Adobe Photoshop, Windows Media Player, and Scratch.
- Compatibility with additional devices and operating systems, including: Window 8 systems, devices without discrete graphics cards, and dual graphics devices.
- Support for Ultra HD video (4K, 60 fps) on devices that meet the requirements. Agora recommends a device with an Intel Core i7-9750H CPU @ 2.60 GHz or better.


**2. Relaying media streams across channels**

This release optimizes the `updateChannelMediaRelay` method as follows:

- Before v4.1.0: If the target channel update fails due to internal reasons in the server, the SDK returns the error code `RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_REFUSED`(8), and you need to call the `updateChannelMediaRelay` method again.
- v4.1.0 and later: If the target channel update fails due to internal server reasons, the SDK retries the update until the target channel update is successful.

**3. Reconstructed AIAEC algorithm**

This release reconstructs the AEC algorithm based on the AI method. Compared with the traditional AEC algorithm, the new algorithm can preserve the complete, clear, and smooth near-end vocals under poor echo-to-signal conditions, significantly improving the system's echo cancellation and dual-talk performance. This gives users a more comfortable call and live-broadcast experience. AIAEC is suitable for conference calls, chats, karaoke, and other scenarios.


**4. Virtual background**

This release optimizes the virtual background algorithm. Improvements include the following:

* The boundaries of virtual backgrounds are handled in a more nuanced way and image matting is is now extremely thin.
* The stability of the virtual background is improved whether the portrait is still or moving, effectively eliminating the problem of background flickering and exceeding the range of the picture.
* More application scenarios are now supported, and a user obtains a good virtual background effect day or night, indoors or out.
* A larger variety of postures are now recognized, when half the body is motionless, the body is shaking, the hands are swinging, or there is fine finger movement. This helps to achieve a good virtual background effect in conjunction with many different gestures.

**Other improvements**

This release includes the following additional improvements:

- Reduces the latency when pushing external audio sources.
- Improves the performance of echo cancellation when using the `AUDIO_SCENARIO_MEETING` scenario.
- Improves the smoothness of SDK video rendering.
- Reduces the CPU usage and power consumption of the local device when the host calls the `muteLocalVideoStream` method.
- Enhances the ability to identify different network protocol stacks and improves the SDK's access capabilities in multiple-operator network scenarios.


<a name="bugfix"></a>

#### Issues fixed

This release fixed the following issues:

- In screen sharing scenarios, when the user minimized and then restored the shared window, the remote video occasionally switched to the low-quality stream.
- When the host started screen sharing during live streaming, the audience members sometimes heard echoes.
- In screen sharing scenarios, the system volume of the local user occasionally decreased.
- In screen sharing scenarios, a black screen appeared when sharing a screen between a landscape monitor and a portrait monitor.
- In screen sharing scenarios with a window excluded, the application crashed when the specified shared area exceeded the screen resolution.
- The application failed to exclude a window using the `startScreenCaptureByDisplayId` method for screen sharing.
- In screen sharing scenarios, the screen seen by the remote user occasionally crashed, lagged, or displayed a black screen.
- The uplink network quality reported by the `onNetworkQuality` callback was inaccurate for the user who was sharing a screen.
- In screen sharing scenarios, when the user shared the screen by window, the mouse in the shared screen was not in its actual position.
- When switching from a non-screen sharing scenario to a screen sharing one, the application occasionally crashed if the user did not switch the resolution accordingly.
- Audience members heard buzzing noises when the host switched between speakers and earphones during live streaming.
- The call `getExtensionProperty` failed and returned an empty string.
- When entering a live streaming room that has been played for a long time as an audience, the time for the first frame to be rendered was shortened.


#### **API changes**

**Added**

- `setHeadphoneEQParameters`

- `setRemoteVideoSubscriptionOptions`

- `setRemoteVideoSubscriptionOptionsEx`

- `VideoSubscriptionOptions`

- `leaveChannelEx [2/2]`

- `muteLocalAudioStreamEx`

- `muteLocalVideoStreamEx`

- `muteAllRemoteAudioStreamsEx`

- `muteAllRemoteVideoStreamsEx`

- `startRtmpStreamWithoutTranscodingEx`

- `startRtmpStreamWithTranscodingEx`

- `updateRtmpTranscodingEx`

- `stopRtmpStreamEx`

- `startChannelMediaRelayEx`

- `updateChannelMediaRelayEx`

- `pauseAllChannelMediaRelayEx`

- `resumeAllChannelMediaRelayEx`

- `stopChannelMediaRelayEx`

- `followEncodeDimensionRatio` in`CameraCapturerConfiguration`

- `hwEncoderAccelerating` in `LocalVideoStats`

- `advanceOptions in VideoEncoderConfiguration`

- `newRoleOptions in onClientRoleChanged`

- `adjustUserPlaybackSignalVolumeEx`

- `onVideoDeviceStateChanged`

- `onAudioDeviceStateChanged`

- `onAudioDeviceVolumeChanged`



**Deprecated**

- `onApiCallExecuted`. Use the callbacks triggered by specific methods instead.


**Deleted**

- Removes `RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_REFUSED`(8) in `onChannelMediaRelayEvent` callback.

### v4.0.1

v4.0.1 was released on September 29, 2022.

#### Compatibility changes

This release deletes the `sourceType` parameter in `enableDualStreamMode` [3/3] and `enableDualStreamModeEx`, and the `enableDualStreamMode` [2/3] method, because the SDK supports enabling dual-stream mode for various video sources captured by custom capture or SDK, you don't need to specify the video source type any more.

#### New features

**1. In-ear monitoring**

This release adds support for in-ear monitoring. You can call `enableInEarMonitoring` to enable the in-ear monitoring function.

After successfully enabling the in-ear monitoring function, you can call `registerAudioFrameObserver` to register the audio observer, and the SDK triggers the `onEarMonitoringAudioFrame` callback to report the audio frame data. You can use your own audio effect processing module to pre-process the audio frame data of the in-ear monitoring to implement custom audio effects. Agora recommends that you choose one of the following two methods to set the audio data format of the in-ear monitoring:

- Call the `setEarMonitoringAudioFrameParameters` method to set the audio data format of in-ear monitoring. The SDK calculates the sampling interval based on the parameters in this method, and triggers the `onEarMonitoringAudioFrame` callback based on the sampling interval.
- Set the audio data format in the return value of the `getEarMonitoringAudioParams` callback. The SDK calculates the sampling interval based on the return value of the callback, and triggers the onEarMonitoringAudioFrame callback based on the sampling interval.

To adjust the in-ear monitoring volume, you can call `setInEarMonitoringVolume`.




**2. Local network connection types**

To make it easier for users to know the connection type of the local network at any stage, this release adds the `getNetworkType` method. You can use this method to get the type of network connection in use, including UNKNOWN, DISCONNECTED, LAN, WIFI, 2G, 3G, 4G, 5G. When the local network connection type changes, the SDK triggers the `onNetworkTypeChanged` callback to report the current network connection type.



**3. Audio stream filter**

This release introduces filtering audio streams based on volume. Once this function is enabled, the Agora server ranks all audio streams by volume and transports 3 audio streams with the highest volumes to the receivers by default. The number of audio streams to be transported can be adjusted; you can contact [support@agora.io](support@agora.io) to adjust this number according to your scenarios.

Meanwhile, Agora supports publishers to choose whether or not the audio streams being published are to be filtered based on volume. Streams that are not filtered will bypass this filter mechanism and transported directly to the receivers. In scenarios where there are a number of publishers, enabling this function helps reducing the bandwidth and device system pressure for the receivers.


To enable this function, contact <a href="mailto:support@agora.io">technical support</a>.



**4. Dual-stream mode**

This release optimizes the dual-stream mode, you can call `enableDualStreamMode` and `enableDualStreamModeEx` before and after joining a channel.

The implementation of subscribing low-quality video stream is expanded. The SDK enables the low-quality video stream auto mode on the sender by default (the SDK does not send low-quality video streams), you can follow these steps to enable sending low-quality video streams:

1. The host at the receiving end calls `setRemoteVideoStreamType` or `setRemoteDefaultVideoStreamType` to initiate a low-quality video stream request.
2. After receiving the application, the sender automatically switches to sending low-quality video stream mode.

If you want to modify the default behavior above, you can call `setDualStreamMode`[1/2] or `setDualStreamMode`[2/2] and set the `mode` parameter to `DISABLE_SIMULCAST_STREAM` (always do not send low-quality video streams) or `ENABLE_SIMULCAST_STREAM` (always send low-quality video streams).



**5. Loopback device**

The SDK uses the playback device as the loopback device by default. Since <Vg k = "VSDK_LATEST_RELEASE_TWO"/>, you can specify a loopback device separately and publish the captured audio to the remote end.

- `setLoopbackDevice`：Specifies the loopback device. If you do not want the current playback device to be the loopback device, you can call this method to specify another device as the loopback device.
- `getLoopbackDevice`：Gets the current loopback device.
- `followSystemLoopbackDevice`：Whether the loopback device follows the default playback device of the system.

#### Improvements

**1. Video information change callback**

This release optimizes the trigger logic of `onVideoSizeChanged`, which can also be triggered and report the local video size change when `startPreview` is called separately.



**2. First video frame rendering**

This release speeds up the first video frame rendering time to improve the video experience.


#### Issues fixed

This release fixed the following issues.

1. When `stopPreview` was called to disable the local video preview, the virtual background that has been set up was occasionally invalidated.
2. Occasional crash when exiting a channel and joining it multiple times with virtual background enabled and set to blur effect.
3. If the local client used a 1920 x 1080 camera as the video capture source, the resolution of the remote video was occasionally inconsistent with the local client.
4. When capturing video through the camera, if the video aspect ratio set in `CameraCapturerConfiguration` wass inconsistent with that set in `setVideoEncoderConfiguration`, the aspect ratio of the local video preview was not rendered according to the latter setting.
5. When calling `setVideoEncoderConfigurationEx` in the channel to increase the resolution of the video, it occasionally failed.
6. When using the Agora media player to play videos, after you play and pause the video, and then call the seek method to specify a new position for playback, the video image might remain unchanged; if you call the resume method to resume playback, the video might be played in a speed faster than the original one.

#### API changes

**Added**

- `enableInEarMonitoring`
- `setEarMonitoringAudioFrameParameters`
- `onEarMonitoringAudioFrame`
- `setInEarMonitoringVolume`
- `getEarMonitoringAudioParams`
- `getNetworkType`
- `setRecordingDeviceVolume`
- `isAudioFilterable` in the `ChannelMediaOptions`
- `setDualStreamMode` [1/2]
- `setDualStreamMode` [2/2]
- `setDualStreamModeEx`
- `SIMULCAST_STREAM_MODE`
- `setLoopbackDevice`
- `getLoopbackDevice`
- `followSystemLoopbackDevice`
- `setZones`
- `setPlayerAttenuation`
- `setRemoteAudioAttenuation`
- `muteRemoteAudioStream`
- `SpatialAudioParams`
- `setHeadphoneEQPreset`
- `HEADPHONE_EQUALIZER_PRESET`

**Modified**

- `enableDualStreamMode` [1/3]
- `enableDualStreamMode` [3/3]
- `enableDualStreamModeEx`



**Deprecated**

- `startEchoTest` [2/3]

**Deleted**

- `enableDualStreamMode` [2/3]

### v4.0.0

v4.0.0 was released on September 15, 2022.

#### Compatibility changes

**Integration change**

This release has optimized the implementation of some features, resulting in incompatibility with v3.7.x. The following are the main features with compatibility changes:

- Multiple channel
- Media stream publishing control
- Custom video capture and rendering (Media IO)
- Warning codes

After upgrading the SDK, you need to update the code in your app according to your business scenarios. For details, see [Migrate from v3.7.x to v4.0.0](../develop/migration-guide).


#### New features

**1. Multiple media tracks**

This release supports one `IRtcEngine` instance to collect multiple audio and video sources at the same time and publish them to the remote users by setting `RtcEngineEx` and `ChannelMediaOptions.`

- After calling `joinChannel` to join the first channel, call `joinChannelEx` multiple times to join multiple channels, and publish the specified stream to different channels through different user ID (`localUid`) and `ChannelMediaOptions` settings.
- You can simultaneously publish multiple sets of video streams captured by multiple cameras or screen sharing by setting `publishSecondaryCameraTrack` and `publishSecondaryScreenTrack` in `ChannelMediaOptions`.

This release adds `createCustomVideoTrack` method to implement video custom capture. You can refer to the following steps to publish multiple custom captured video in the channel:

1. Create a custom video track: Call this method to create a video track, and get the video track ID.
2. Set the custom video track to be published in the channel: In each channel's `ChannelMediaOptions`, set the `customVideoTrackId` parameter to the ID of the video track you want to publish, and set `publishCustomVideoTrack` to `true`.
3. Pushing an external video source: Call `pushVideoFrame`, and specify `videoTrackId` as the ID of the custom video track in step 2 in order to publish the corresponding custom video source in multiple channels.

You can also experience the following features with the multi-channel capability:

- Publish multiple sets of audio and video streams to the remote users through different user IDs (`uid`).
- Mix multiple audio streams and publish to the remote users through a user ID (`uid`).
- Combine multiple video streams and publish them to the remote users through a user ID (`uid`).

**2. Ultra HD resolution (Beta)**

In order to improve the interactive video experience, the SDK optimizes the whole process of video capture, encoding, decoding and rendering, and now supports 4K resolution. The improved FEC (Forward Error Correction) algorithm enables adaptive switches according to the frame rate and number of video frame packets, which further reduces the video stuttering rate in 4K scenes.

Additionally, you can set the encoding resolution to 4K (3840 × 2160) and the frame rate to 60 fps when calling `SetVideoEncoderConfiguration`. The SDK supports automatic fallback to the appropriate resolution and frame rate if your device does not support 4K.

This feature has certain requirements with regards to device performance and network bandwidth, and the supported upstream and downstream frame rates vary on different platforms. To enable this feature, contact [support@agora.io](mailto:support@agora.io).

The increase in the default resolution affects the aggregate resolution and thus the billing rate. See <a href="./pricing">Pricing</a>.

**3. Build-in media player**

To make it easier for users to integrate the Agora SDK and reduce the SDK's package size, this release introduces the Agora media player. After calling the `createMediaPlayer` method to create a media player object, you can then call the methods in the `IMediaPlayer` class to experience a series of functions, such as playing local and online media files, preloading a media file, changing the CDN route for playing according to your network conditions, or sharing the audio and video streams being played with remote users.

**4. Ultra-high audio quality**

To make the audio clearer and restore more details, this release adds the `ULTRA_HIGH_QUALITY_VOICE` enumeration. In scenarios that mainly feature the human voice, such as chat or singing, you can call `setVoiceBeautifierPreset` and use this enumeration to experience ultra-high audio quality.

**5. Spatial audio**

<div class="alert info">This feature is in experimental status. To enable this feature, contact <a href="mailto:support@agora.io ">support@agora.io</a>. Contact <a href="mailto:support@agora.io">technical support</a> if needed.</div>

You can set the spatial audio for the remote user as following:

- Local Cartesian Coordinate System Calculation: This solution uses the `ILocalSpatialAudioEngine` class to implement spatial audio by calculating the spatial coordinates of the remote user. You need to call `updateSelfPosition` and `updateRemotePosition` to update the spatial coordinates of the local and remote users, respectively, so that the local user can hear the spatial audio effect of the remote user.
  ![Spatial effect](/images/video-sdk/video-call-spatial.png)

You can also set the spatial audio for the media player as following:

- Local Cartesian Coordinate System Calculation: This solution uses the `ILocalSpatialAudioEngine` class to implement spatial audio. You need to call `updateSelfPosition` and `updatePlayerPositionInfo` to update the spatial coordinates of the local user and media player, respectively, so that the local user can hear the spatial audio effect of media player.
  ![Spatial effect](/images/video-sdk/spatial-audio-effect.png)



**6. Real-time chorus**

This release gives real-time chorus the following abilities:

- Two or more choruses are supported.
- Each singer is independent of each other. If one singer fails or quits the chorus, the other singers can continue to sing.
- Very low latency experience. Each singer can hear each other in real time, and the audience can also hear each singer in real time.

This release adds the `AUDIO_SCENARIO_CHORUS` enumeration in `AUDIO_SCENARIO_TYPE`. With this enumeration, users can experience ultra-low latency in real-time chorus when the network conditions are good.

**7. Extensions from the Agora extensions marketplace**

In order to enhance the real-time audio and video interactive activities based on the Agora SDK, this release supports the one-stop solution for the extensions from the <Link to="{{GLOBAL.APP_ID_LINK}}/en/agora-extensions-marketplace/">Agora extensions marketplace</Link>:

- Easy to integrate: The integration of modular functions can be achieved simply by calling an API, and the integration efficiency is improved by nearly 95%.
- Extensibility design: The modular and extensible SDK design style endows the Agora SDK with good extensibility, which enables developers to quickly build real-time interactive apps based on the Agora extensions marketplace ecosystem.
- Build an ecosystem: A community of real-time audio and video apps has developed that can accommodate a wide range of developers, offering a variety of extension combinations. After integrating the extensions, developers can build richer real-time interactive functions. For details, see [Use an Extension](../develop/use-an-extension).
- Become a vendor: Vendors can integrate their products with Agora SDK in the form of extensions, display and publish them in the Agora extensions marketplace, and build a real-time interactive ecosystem for developers together with Agora. For details on how to develop and publish extensions, see [Become a Vendor](/extensions-marketplace/get-started/quickstart-implement).

**8. Enhanced channel management**

To meet the channel management requirements of various business scenarios, this release adds the following functions to the `ChannelMediaOptions` structure:

- Sets or switches the publishing of multiple audio and video sources.
- Sets or switches channel profile and user role.
- Sets or switches the stream type of the subscribed video.
- Controls audio publishing delay.

Set `ChannelMediaOptions` when calling `joinChannel` or `joinChannelEx` to specify the publishing and subscription behavior of a media stream, for example, whether to publish video streams captured by cameras or screen sharing, and whether to subscribe to the audio and video streams of remote users. After joining the channel, call `updateChannelMediaOptions` to update the settings in `ChannelMediaOptions` at any time, for example, to switch the published audio and video sources.

**9. Screen sharing**

This release optimizes the screen sharing function. You can enable this function in the following ways.

- Call the `StartScreenCaptureByDisplayId` method before joining a channel, and then call `JoinChannel` [2/2] to join a channel and set `publishScreenTrack` or `publishSecondaryScreenTrack` as true.
- Call the `StartScreenCaptureByDisplayId` method after joining a channel, and then call `UpdateChannelMediaOptions` to set `publishScreenTrack` or `publishSecondaryScreenTrack` as true.

**10. Subscription allowlists and blocklists**

This release introduces subscription allowlists and blocklists for remote audio and video streams. You can add a user ID that you want to subscribe to in your whitelist, or add a user ID for the streams you do not wish to see to your blacklists. You can experience this feature through the following APIs, and in scenarios that involve multiple channels, you can call the following methods in the `IRtcEngineEx` interface:

- `SetSubscribeAudioBlacklist`：Set the audio subscription blocklist.
- `SetSubscribeAudioWhitelist`：Set the audio subscription allowlist.
- `SetSubscribeVideoBlacklist`：Set the video subscription blocklist.
- `SetSubscribeVideoWhitelist`：Set the video subscription allowlist.

If a user is added in a blacklist and a whitelist at the same time, only the blacklist takes effect.

**11. Set audio scenarios**

To make it easier to change audio scenarios, this release adds the `SetAudioScenario` method. For example, if you want to change the audio scenario from `AUDIO_SCENARIO_DEFAULT` to `AUDIO_SCENARIO_GAME_STREAMING` when you are in a channel, you can call this method.

**12. Local video mixing**

This release adds a series of APIs supporting local video mixing functions. You can mix multiple video streams into one video stream locally. Common scenarios are as follows:

- In interactive live streaming scenarios with cohosts or when using the Media Push function, you can merge the screens of multiple hosts into one view locally.
- In scenarios where you capture multiple local video streams (for example, video captured by cameras, screen sharing streams, video files or pictures), you can and merge them into one video stream and then publish the mixed video stream in the channel.

You can call the `startLocalVideoTranscoder` method to start local video mixing and call the `stopLocalVideoTranscoder` method to stop local video mixing. After the local video mixing starts, you can call `updateLocalTranscoderConfiguration` to update the local video mixing configuration.

**13. Video device management**

Video capture devices can support multiple video formats, each supporting a different combination of video frame width, video frame height, and frame rate.

This release adds the `numberOfCapabilities` and `getCapability` methods for getting the number of video formats supported by the video capture device and the details of the video frames in the specified video format. When calling the `startPrimaryCameraCapture` or `startSecondaryCameraCapture` method to capture video using the camera, you can use the specified video format.
<div class="alert info">The SDK automatically selects the best video format for the video capture device based on your settings in <code>VideoEncoderConfiguration</code>, so normally you should not need to use these new methods.</div>

#### Improvements

**1. Fast channel switching**

This release can achieve the same switching speed as `SwitchChannel` in v3.7.x through the `LeaveChannel` and `JoinChannel `methods so that you don't need to take the time to call the `SwitchChannel `method.

**2. Push external video frames**

This releases supports pushing video frames in I422 format. You can call the `pushVideoFrame`[1/2] method to push such video frames to the SDK.

**3. Voice pitch of the local user**
This release adds `voicePitch` in `AudioVolumeInfo` of `onAudioVolumeIndication`. You can use `voicePitch` to get the local user's voice pitch and perform business functions such as rating for singing.


**4. Video preview**

This release improves the implementation logic of `startPreview`. You can call the `startPreview `method to enable video preview at any time.

**5. Video types of subscription**

You can call the `setRemoteDefaultVideoStreamType` method to choose the video stream type when subscribing to streams.
</PlatformWrapper>