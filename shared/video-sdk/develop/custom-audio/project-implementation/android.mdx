<PlatformWrapper platform="android">
This section shows you how to implement custom audio capture and render audio from a custom source.

### Custom audio capture

Refer to the following call sequence diagram to implement custom audio capture in your app:

<details>
<summary>Custom audio capture process</summary>

![Custom audio capture](/images/video-sdk/custom-audio-capture-with-custom-track.svg)
</details>

Follow these steps to implement custom audio capture in your project:

1. After initializing `RtcEngine`, call `createCustomAudioTrack` to create a custom audio track and obtain the audio track ID.

    ```java
    AudioTrackConfig config = new AudioTrackConfig();
    config.enableLocalPlayback = false;
    customAudioTrack = engine.createCustomAudioTrack(Constants.AudioTrackType.AUDIO_TRACK_MIXABLE, config);
    ```

2. Call `joinChannel` to join the channel. In `ChannelMediaOptions`, set `publishCustomAudioTrackId` to the audio track ID obtained in step 1, and set `publishCustomAudioTrack` to `true` to publish the custom audio track.

    <Admonition type="info" title="Information">
    To use `enableCustomAudioLocalPlayback` for local playback of an external audio source, or to adjust the volume of a custom audio track with `adjustCustomAudioPlayoutVolume`, set `enableAudioRecordingOrPlayout` to `true` in `ChannelMediaOptions`.
    </Admonition>

    ```java
    ChannelMediaOptions option = new ChannelMediaOptions();
    option.clientRoleType = Constants.CLIENT_ROLE_BROADCASTER;
    option.autoSubscribeAudio = true;
    option.autoSubscribeVideo = true;
    // In the audio self-collection scenario, the audio collected by the microphone is not published
    option.publishMicrophoneTrack = false;
    // Publish the custom audio track
    option.publishCustomAudioTrack = true;
    // Set the custom audio track ID
    option.publishCustomAudioTrackId = customAudioTrack;
    // Join the channel
    int res = engine.joinChannel(accessToken, channelId, 0, option);
    ```

3. <Vg k="COMPANY"/> provides the [AudioFileReader.java](https://github.com/AgoraIO/API-Examples/blob/main/Android/APIExample/app/src/main/java/io/agora/api/example/utils/AudioFileReader.java) sample to demonstrate how to read and publish PCM-format audio data from a local file. In a production environment, you create a custom audio acquisition module based on your business needs.

4. Call `pushExternalAudioFrame` to send the captured audio frame to the SDK through the custom audio track. Ensure that the `trackId` matches the audio track ID you obtained by calling `createCustomAudioTrack`. Set `sampleRate`, `channels`, and `bytesPerSample` to define the sampling rate, number of channels, and bytes per sample of the external audio frame.

    <Admonition type="info" title="Information">
    For audio and video synchronization, <Vg k="COMPANY"/> recommends calling `getCurrentMonotonicTimeInMs` to get the systemâ€™s current monotonic time and setting the `timestamp` accordingly.
    </Admonition>

    ```java
    audioPushingHelper = new AudioFileReader(requireContext(), (buffer, timestamp) -> {
        if (joined && engine != null && customAudioTrack != -1) {
            // Push external audio frames to SDK
            int ret = engine.pushExternalAudioFrame(buffer, timestamp,
                    AudioFileReader.SAMPLE_RATE,
                    AudioFileReader.SAMPLE_NUM_OF_CHANNEL,
                    Constants.BytesPerSample.TWO_BYTES_PER_SAMPLE,
                    customAudioTrack);
            Log.i(TAG, "pushExternalAudioFrame times:" + (++pushTimes) + ", ret=" + ret);
        }
    });
    ```

5. To stop publishing custom audio, call `destroyCustomAudioTrack` to destroy the custom audio track.

    ```java
    // Destroy the custom audio track
    engine.destroyCustomAudioTrack(customAudioTrack);
    ```

### Custom audio rendering

This section shows you how to implement custom audio rendering. Refer to the following call sequence diagram to implement custom audio rendering in your <Vpl k="CLIENT" />:

<details>
<summary>Custom audio rendering workflow</summary>

![Custom Audio Rendering Workflow](/images/video-sdk/custom-audio-render.svg)
</details>

To implement custom audio rendering, use the following methods:

1. Before calling `joinChannel`, use `setExternalAudioSink` to enable and configure custom audio rendering.

    ```java
    rtcEngine.setExternalAudioSink(
        true,      // Enable custom audio rendering
        44100,     // Sampling rate (Hz). Set this value to 16000, 32000, 441000, or 48000
        1          // Number of channels for the custom audio source. Set this value to 1 or 2
    );
    ```

2. After joining the channel, call `pullPlaybackAudioFrame` to get audio data sent by remote users. Use your own audio renderer to process the audio data and then play the rendered data.

    ```java
    private class FileThread implements Runnable {

        @Override
        public void run() {
            while (mPull) {
                int lengthInByte = 48000 / 1000 * 2 * 1 * 10;
                ByteBuffer frame = ByteBuffer.allocateDirect(lengthInByte);
                int ret = engine.pullPlaybackAudioFrame(frame, lengthInByte);
                byte[] data = new byte[frame.remaining()];
                frame.get(data, 0, data.length);
                // Write to a local file or render using a player
                FileIOUtils.writeFileFromBytesByChannel("/sdcard/agora/pull_48k.pcm", data, true, true);
                try {
                    Thread.sleep(10);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }
    ```

### Using raw audio data callback

This section explains how to implement custom audio rendering.

To retrieve audio data for playback, implement collection and processing of raw audio data. Refer to [Raw audio processing](./advanced-features/stream-raw-audio).

Follow these steps to call the raw audio data API in your project for custom audio rendering:

1. Retrieve audio data for playback using the `onRecordAudioFrame`, `onPlaybackAudioFrame`, `onMixedAudioFrame`, or `onPlaybackAudioFrameBeforeMixing` callback.

2. Independently render and play the audio data.

</PlatformWrapper>
