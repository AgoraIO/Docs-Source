import * as data from '@site/data/variables';

<PlatformWrapper platform="linux-java">

This page introduces how to use the <Vpd k="NAME" /> to send media streams to the client and receive media streams from the client.

## Prerequisites

Before you begin, make sure you have downloaded the latest <Vpd k="NAME" />. See [Integrate the Java SDK](../get-started/integrate-java-sdk).

## Preparation

Complete the following preparations before sending and receiving media streams.

### Step 1: Initialize the SDK

You need to call `AgoraService` and `initialize` to create and initialize an `AgoraService` object. The `AgoraService` object persists as long as the server app keeps running.

The SDK supports user IDs in both integer format and string format. This page only shows user IDs in int format (the character set can only be digitals). To learn more about user IDs in string format, see [Using User IDs in String Format](../develop/stringuid).

```java
// Import SDK, AgoraService, and AgoraServiceConfig classes for initialization
import io.agora.rtc.SDK;
import io.agora.rtc.AgoraService;
import io.agora.rtc.AgoraServiceConfig;


// Creates an AgoraService object
SDK.load(); // ensure JNI library load
AgoraService service = new AgoraService();
// Initializes the AgoraServiceConfig object
AgoraServiceConfig config = new AgoraServiceConfig();
// Enables the audio processing module
config.setEnableAudioProcessor(1);
// Disables the audio device module (Normally we do not directly connect audio capture or playback devices to a server)
config.setEnableAudioDevice(0);
// Enables video
config.setEnableVideo(1);
// Sets Agora App ID
config.setAppId(appid);
// Initializes the SDK
service.initialize(config);
```

### Step 2: Connect to the Agora <Vg k="VSDK" /> Channel

After initializing the SDK, you can refer to the following steps to connect to the Agora <Vg k="VSDK" /> channel.

1. Call `agoraRtcConnCreate` to create an `AgoraRtcConn` object to connect to the Agora <Vg k="VSDK" /> channel:

    ```java
    AgoraRtcConn conn = service.agoraRtcConnCreate(null);
    ```

2. Call `registerObserver` to listen to connection events:

    ```java
    conn.registerObserver(new ConnObserver());
    ```

3. Call `connect` to connect to an Agora <Vg k="VSDK" /> channel:

    ```java
    conn.connect(token, "test_channel", "1");
    ```

## Send media streams to the client

Refer to the following steps to send media streams to the client:

### Step 1: Create a media stream sender

You can use the `IMediaNodeFactory` object to create various types of media stream senders:

- `AgoraAudioPcmDataSender`：Sends audio data in PCM format.
- `AgoraVideoFrameSender`：Sends video data in YUV format.
- `AgoraAudioEncodedFrameSender`：Sends encoded audio data.
- `AgoraVideoEncodedImageSender`：Sends encoded video data.

1. Create an `IMediaNodeFactory` object:

    ```java
    AgoraMediaNodeFactory factory = service.createMediaNodeFactory();
    ```

2. Per your own requirements, create an `AgoraAudioPcmDataSender` object, an `AgoraVideoFrameSender` object, an `AgoraAudioEncodedFrameSender` object, or an `AgoraVideoEncodedImageSender` object for sending audio in PCM format, video in YUV format, encoded audio, and encoded video:

    ```java
    // Creates a sender for PCM audio
    AgoraAudioPcmDataSender audioFrameSender = factory.createAudioPcmDataSender();

    // Creates a sender for YUV video
    AgoraVideoFrameSender videoFrameSender = factory.createVideoFrameSender();

    // Creates a sender for encoded audio
    AgoraAudioEncodedFrameSender audioFrameSender = factory.createAudioEncodedFrameSender();
    
    // Creates a sender for encoded video
    AgoraVideoEncodedImageSender imageSender = factory.createVideoEncodedImageSender();
    ```

3. Create an `AgoraLocalAudioTrack` object and an `AgoraLocalVideoTrack` object, which respectively correspond to the local audio track and local video track to be published to the Agora <Vg k="VSDK" /> channel:

    ```java
    // Creates a custom audio track that uses a PCM audio stream sender
    customAudioTrack = service.createCustomAudioTrackPcm(audioFrameSender);

    // Creates a custom audio track that uses an encoded audio stream sender
    customAudioTrack = service.createCustomAudioTrackEncoded(audioFrameSender,0);

    // Creates a custom video track that uses a YUV video stream sender
    customVideoTrack = service.createCustomVideoTrackFrame(videoFrameSender);

    // Creates a custom video track that uses encoded video stream sender
    customVideoTrack = service.createCustomVideoTrackEncoded(videoFrameSender, option);
    ```

### Step 2: Send media streams

1. Use `publish` methods in the `AgoraLocalUser` object to publish local audio and video tracks created in the previous step to Agora <Vg k="VSDK" /> channel:

    ```java
    // Enables and publishes audio and video track
    customAudioTrack.setEnabled(1);
    customVideoTrack.setEnabled(1);
    conn.getLocalUser().publishAudio(customAudioTrack);
    conn.getLocalUser().publishVideo(customVideoTrack);
    ```

2. Start the sending thread, which calls the `send` methods of the audio/video sender:

    ```java
    pcmSender = new PcmSender(audioFile,audioFrameSender,numOfChannels,sampleRate);
    h264Sender = new H264Sender(videoFile,1000/fps,0,0,videoFrameSender);

    pcmSender.start();
    h264Sender.start();
    ```

    Taking PCM data as an example, the following code shows the implementation of `PcmSender`:

    ```java
    // audio thread
    // send audio data every 10 ms;
    class PcmSender extends FileSender {
        private AgoraAudioPcmDataSender audioFrameSender;
        private static final int INTERVAL = 10; //ms
        private int channels;
        private int samplerate;
        private int bufferSize = 0;
        private byte[] buffer;
        public PcmSender(String filepath, AgoraAudioPcmDataSender sender,int channels,int samplerate){
            super(filepath, INTERVAL);
            audioFrameSender = sender;
            this.channels = channels;
            this.samplerate = samplerate;
            this.bufferSize = channels * samplerate * 2 * INTERVAL /1000;
            this.buffer = new byte[this.bufferSize];
        }

        // sendOneFrame calls the send method of audioFrameSender to send PCM data
        @Override
        public void sendOneFrame(byte[] data) {
            if(data == null) return;
            audioFrameSender.send(data,(int)System.currentTimeMillis(),sampleRate/(1000/INTERVAL),2,channels,samplerate);
        }

        @Override
        public byte[] readOneFrame(FileInputStream fos) {
            if(fos != null ){
                try {
                    int size = fos.read(buffer,0,bufferSize);
                    if( size <= 0){
                        reset();
                        return null;
                    }
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
            return buffer;
        }
    }
    ```

    Taking H.264 video data as an example, the following code shows the implementation of `H264Sender`:

    ```java
    class H264Sender extends FileSender {
        private AgoraVideoEncodedImageSender imageSender;
        private H264Reader h264Reader;
        private int lastFrameType = 0;
        private int height;
        private int width;
        private int fps;
        public H264Sender(String path,int interval, int height,int width, AgoraVideoEncodedImageSender videoEncodedImageSender){
            super(path,interval,false);
            this.imageSender = videoEncodedImageSender;
            this.h264Reader = new H264Reader(path);
            this.height = height;
            this.width = width;
            this.fps = 1000/interval;
        }
        // sendOneH264Frame calls the send method of imageSender to send H.264 data.
        @Override
        public void sendOneFrame(byte[] data) {
            if(data == null) return;
            EncodedVideoFrameInfo info = new EncodedVideoFrameInfo();
            long currentTime = System.currentTimeMillis();
            info.setFrameType(lastFrameType);
            info.setWidth(width);
            info.setHeight(height);
            info.setCodecType(Constants.VIDEO_CODEC_H264);
            info.setCaptureTimeMs(currentTime);
            info.setRenderTimeMs(currentTime);
            info.setFramesPerSecond(fps);
            info.setRotation(0);
            imageSender.send(data,data.length,info);
        }

        @Override
        public byte[] readOneFrame(FileInputStream fos) {
            int retry = 0;
            H264Reader.H264Frame frame =  h264Reader.readNextFrame();
            while ( frame == null && retry < 4){
                h264Reader.reset();
                frame = h264Reader.readNextFrame();
                retry ++;
            }
            if( frame != null ) {
                lastFrameType = frame.frameType;
                return frame.data;
            } else {
                return null;
            }
        }

        @Override
        public void release() {
            super.release();
            h264Reader.close();
        }
    }  
    ```

    > You can set the format of the encoded video data by using the `info` parameter of the `send` method.


### Step 3: Disconnect and release resources

After finishing media sending tasks, you can refer to the following steps to disconnect from the channel and release resources.

1. Call `unpublish` methods to stop publishing audio and video:

    ```java
    if(conn != null) {
            conn.getLocalUser().unpublishAudio(customAudioTrack);
            conn.getLocalUser().unpublishVideo(customVideoTrack);
    }
    ```

2. Call `unregisterObserver` to unregister the connection observer:

    ```java
    conn.unregisterObserver();
    ```

3. Call `disconnect` to disconnect from Agora <Vg k="VSDK" /> channel:

    ```java
    int ret = conn.disconnect();
    ```

4. Release resources from create objects:

    ```java
    conn.destroy();
    ```

## Receive media stream from the client

Refer to the following steps to receive media stream from the client.

### Step 1: Use the `ILocalUserObserver` object to register video and audio frames

Instantiate the video and audio frame observer object, and register the observer by using the member methods of the `ILocalUserObserver` class. After registration is successful, the SDK triggers callbacks when audio or video frames are available. You can get audio and video frames from the callbacks.

The `SampleLocalUserObserver` class in the sample code not only includes observer objects from the `IVideoEncodedFrameObserver` class, the `IAudioFrameObserverBase` class, and the `IVideoFrameObserver2` class, and inherits the `ILocalUserObserver` class as well. The member methods of the `ILocalUserObserver` class can be used to register video and audio frame observer objects.

```java
// The SampleLocalUserObserver class inherits the ILocalUserObserver class
localUserObserver = new SampleLocalUserObserver(conn.getLocalUser());
conn.getLocalUser().registerObserver(localUserObserver);

// The PcmFrameObserver class inherits the IAudioFrameObserver class
int ret = conn.getLocalUser().setPlaybackAudioFrameBeforeMixingParameters(numOfChannels, sampleRate);
if (ret > 0) {
    System.out.printf("setPlaybackAudioFrameBeforeMixingParameters fail ret=%d\n", ret);
    return;
}

// The H264FrameReceiver class inherits the IVideoEncodedImageReceiver class
h264FrameReceiver = new H264FrameReceiver(videoFile);
conn.getLocalUser().registerVideoEncodedFrameObserver(new AgoraVideoEncodedFrameObserver(h264FrameReceiver));
```

`setAudioFrameObserver` and `registerVideoEncodedFrameObserver` are member methods of the `SampleLocalUserObserver` class and can be used to instantiate the `IAudioFrameObserver` class and the `AgoraVideoEncodedFrameObserver` class.

```java
localUserObserver.setAudioFrameObserver(pcmFrameObserver);

conn.getLocalUser().registerVideoEncodedFrameObserver(new AgoraVideoEncodedFrameObserver(h264FrameReceiver));
```

### Step 2: Use callbacks from the `ILocalUserObserver` class to receive media streams

The following code shows how to receive encoded video, video in YUV format, and audio in PCM format.

```java
// Receives encoded video by using the onEncodedVideoFrame callback and save the video data in a file 
class H264FrameReceiver extends FileWriter implements IVideoEncodedFrameObserver {

        public H264FrameReceiver(String path) {
            super(path);
        }

        @Override
        public int onEncodedVideoFrame(AgoraVideoEncodedFrameObserver agora_video_encoded_frame_observer, int uid, byte[] image_buffer, long length, EncodedVideoFrameInfo video_encoded_frame_info) {
            System.out.println("onEncodedVideoFrame success  " + video_encoded_frame_info.getFrameType());
            writeData(image_buffer, (int) length);
            return 1;
        }
    }

// Receives YUV video by using the onFrame callback and save the video data in a file 
 class YuvFrameObserver extends FileWriter implements IVideoFrameObserver2 {

        public YuvFrameObserver(String path) {
            super(path);
        }

        @Override
        public void onFrame(AgoraVideoFrameObserver2 agora_video_frame_observer2, String channel_id, String remote_uid, VideoFrame frame) {
            System.out.println("onFrame success  ");
            writeData(frame.getYBuffer(), frame.getYBuffer().remaining());
            writeData(frame.getUBuffer(), frame.getUBuffer().remaining());
            writeData(frame.getVBuffer(), frame.getVBuffer().remaining());
            return ;
        }
}

// Receives PCM audio by using the onPlaybackAudioFrameBeforeMixing callback and save the audio data in a file 
public static class PcmFrameObserver extends FileWriter implements IAudioFrameObserver {
        public PcmFrameObserver(String outputFilePath) {
            super(outputFilePath);
        }

        @Override
        public int onRecordAudioFrame(AgoraLocalUser agora_local_user, String channel_id, AudioFrame frame) {
            System.out.println("onRecordAudioFrame success");
            return 1;
        }

        @Override
        public int onPlaybackAudioFrame(AgoraLocalUser agora_local_user, String channel_id, AudioFrame frame) {
            System.out.println("onPlaybackAudioFrame success");
            return 1;
        }

        @Override
        public int onMixedAudioFrame(AgoraLocalUser agora_local_user, String channel_id, AudioFrame frame) {
            System.out.println("onMixedAudioFrame success");
            return 1;
        }

        @Override
        public int onPlaybackAudioFrameBeforeMixing(AgoraLocalUser agora_local_user, String channel_id, String uid, AudioFrame audioFrame) {
            // Write PCM samples
            int writeBytes = audioFrame.getSamplesPerChannel() * audioFrame.getChannels() * 2;
            writeData(audioFrame.getBuffer(), writeBytes);
            return 1;
        }
    }
```

### Step 3: Disconnect and release resources

When the media receiving task is complete, refer to the following steps to disconnect from the Agora <Vg k="VSDK" /> channel.

<div class="alert note">You must follow the sequence in the sample code to release resources.</div>

1. Call unset methods to release the video and audio observer.

    ```java
    // Release video and audio observer
    localUserObserver.unsetAudioFrameObserver();
    localUserObserver.unsetVideoFrameObserver();
    ```

2. Call `disconnect` to disconnect from the Agora <Vg k="VSDK" /> channel.

    ```java
    // Disconnect from the Agora channel
    int ret = conn.disconnect();
    if (ret != 0) {
    System.out.printf("conn.disconnect fail ret=%d\n", ret);
    }
    ```

3. Release the created objects.

    ```java
    // Releases the created objects.
    conn.destroy();
    ```

## Resource collection

When your server app stops running, refer to the following sample code to release the `AgoraService` object.

```java
// Destroy Agora Service
service.destroy();
```

## References

Here you can find a link to the API reference and developer considerations.

### API reference

Refer to <Link to= "{{global.CGATE_SDK_API_JAVA}}/index.html">Server Gateway API for Java</Link> to find detailed API and parameter descriptions.

### Considerations

- The previously mentioned methods are all asynchronous methods and do not block the main thread.
- When you use the [Agora <Vg k="VSDK" />](../reference/glossary#agora-video-sdk) to communicate with the <Vpd k="NAME" />, make sure to set the channel scenario of the <Vg k="VSDK" /> to `LIVE_BROADCASTING`.
- When you use the SDK to send audio data in AAC format, you cannot set the sampling rate to 44.1 Kbps.

</PlatformWrapper>