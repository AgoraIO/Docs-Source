---
title: 'Agent quickstart'
sidebar_position: 3
type: docs
platform_selector: false
description: >
  Build a backend server to manage Conversational AI agents.
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

This guide shows you how to build a backend server that manages <Vpd k="NAME" /> agents through RESTful APIs. You'll create a basic service that starts and stops AI agents, handles authentication, and integrates with your chosen AI models.

<details>
<summary>Backend server workflow</summary>

![](/images/conversational-ai/convo-ai-backend.svg)
</details>

## Prerequisites

<Admonition type="info" title="Important">
This guide assumes you understand the fundamentals of how <Vpd k="NAME" /> works. If you're new to <Vg k="COMPANY" /> or need a refresher on Agora channels, authentication tokens, and agent architecture, start with [Core concepts](core-concepts).
</Admonition>

Before you begin, make sure you have:

- **Development environment**: Node.js (16+), Python (3.8+), or Go (1.19+) installed
- **Configured <Vg k="COMPANY" /> project**:
    - [Enable <Vg k="COMPANY" /> conversational AI](../get-started/manage-agora-account#enable-conversational-ai) for your project. **This is critical**. Without it, your API calls will fail with cryptic errors.
    - [App ID](../get-started/manage-agora-account#get-the-app-id): Identifies your <Vg k="COMPANY" /> project
    - [App Certificate](/conversational-ai/get-started/manage-agora-account#get-the-app-certificate): Used to generate RTC tokens (found in <Vg k="CONSOLE" /> alongside your App ID). Keep this secret. Never expose it to clients.
    - [Customer ID and Customer Secret](/conversational-ai/rest-api/restful-authentication#generate-customer-id-and-customer-secret): Used for HTTP Basic Authentication when calling RESTful APIs. Keep these secret. Never expose them to clients.
- **AI provider API keys**: API keys from your chosen providers like OpenAI or Azure. Don't have these yet? See the [AI models](#ai-models) section for details on which keys you need and where to get them.


## AI models

Conversational AI agents require AI models to understand speech, generate responses, and speak naturally. <Vpd k="NAME" /> supports two workflow types, each optimized for different use cases:

![Side-by-side comparison diagram showing ASR-LLM-TTS pipeline workflow (left) with three separate components flowing linearly, and MLLM workflow (right) with a single multimodal model handling voice-to-voice directly](/images/conversational-ai/convo-ai-cascade.svg)

<Tabs groupId="workflow">
<TabItem value="pipeline" label="ASR-LLM-TTS Pipeline" default>

### ASR-LLM-TTS Pipeline

The pipeline workflow chains three specialized AI services to create a conversational agent. Each component excels at its specific task:

- **ASR (Automatic Speech Recognition)**: Converts user's spoken words into text
- **LLM (Large Language Model)**: Processes the text and generates intelligent responses
- **TTS (Text-to-Speech)**: Converts the LLM's text responses into natural-sounding speech

This approach gives you flexibility to mix and match providers to optimize for cost, speed, language support, or voice quality. For example, you might use <Vg k="COMPANY" />'s ARES for fast speech recognition, OpenAI's GPT-4o for smarter responses, and ElevenLabs for natural-sounding voices.

#### Recommended starter configuration

This configuration provides excellent quality with a simplified setup. The ASR component uses <Vg k="COMPANY" />'s built-in ARES engine, so you only need API keys for the LLM and TTS:

| Component | Recommended Model | Alternative Options |
|-----------|------------------|---------------------|
| **ASR** | [ARES](/conversational-ai/models/asr/ares) (Built-in) | [Microsoft Azure](/conversational-ai/models/asr/microsoft), [Deepgram](/conversational-ai/models/asr/deepgram), [AssemblyAI](/conversational-ai/models/asr/assembly-ai) |
| **LLM** | [OpenAI GPT-4o mini](/conversational-ai/models/llm/openai) | [Azure OpenAI](/conversational-ai/models/llm/azure-openai), [Google Gemini](/conversational-ai/models/llm/gemini), [Claude](/conversational-ai/models/llm/claude) |
| **TTS** | [Microsoft Azure](/conversational-ai/models/tts/microsoft) | [ElevenLabs](/conversational-ai/models/tts/elevenlabs), [Cartesia](/conversational-ai/models/tts/cartesia), [OpenAI](/conversational-ai/models/tts/openai) |

See the [ASR overview](/conversational-ai/models/asr/overview), [LLM overview](/conversational-ai/models/llm/overview), and [TTS overview](/conversational-ai/models/tts/overview) for complete provider catalogs and configuration details.

#### When to use the pipeline

Choose the ASR-LLM-TTS pipeline when you need:
- Full control over each AI component
- Ability to switch providers independently. For example, swap out TTS without touching your LLM
- Cost optimization by mixing free and paid services
- Support for specific languages or voices not available in MLLM models
- Integration with custom LLM endpoints or RAG systems with complete visibility into text transcripts

</TabItem>

<TabItem value="mllm" label="MLLM (Voice-to-Voice)">

### MLLM (Multimodal Large Language Model)

The MLLM workflow uses a single, powerful AI model that processes voice input directly and generates voice output without the need for separate ASR or TTS. This creates faster, more natural conversations with better context understanding.

MLLMs process voice input directly, picking up on tone and emotion that gets lost when you convert speech to text first. This means faster responses that sound more natural.

#### Supported MLLM providers

<Vpd k="NAME" /> currently supports:

| Provider | Model | Key advantages |
|----------|-------|----------------|
| **[OpenAI Realtime API](/conversational-ai/models/mllm/openai)** | GPT-4o Realtime | Excellent conversational abilities, low latency, multiple voices |
| **[Google Gemini Live](/conversational-ai/models/mllm/gemini)** | Gemini 2.5 Flash | Fast responses, strong multilingual support, cost-effective |

See [MLLM overview](/conversational-ai/models/mllm/overview) for complete provider catalog and configuration details.


#### Important notes

When you enable MLLM mode (`enable_mllm: true`), the system automatically disables separate ASR, LLM, and TTS configurations since the MLLM handles everything.

<Admonition type="info">
Keep in mind:
- Intelligent interruption handling (`enable_aivad`) isn't available with MLLM
- Turn detection works differently with MLLMs. See [`turn_detection`](/conversational-ai/rest-api/agent/join#turn-detection)
</Admonition>

#### When to use MLLM

Choose MLLM when you want:
- The fastest response times. Cuts latency by 30-50% compared to the pipeline
- More natural-sounding conversations that preserve emotional nuance
- Simpler setup (one model instead of three)
- Better understanding of tone and emotion from your users
- Access to cutting-edge AI capabilities as they emerge

See the [MLLM overview](/conversational-ai/models/mllm/overview) for detailed configuration instructions and capabilities.

</TabItem>
</Tabs>

<Admonition type="tip">
If you're just getting started, use the ASR-LLM-TTS pipeline. It's easier to debug and gives you more control. You can always switch to MLLM later when you want faster response times.
</Admonition>

## Implementation

This section shows you how to build a complete backend server with endpoints to start and stop conversational AI agents. Choose your preferred language. All three examples produce the same functionality.

### Initialize the project

Create a new project directory and initialize it for your chosen language.

<Tabs groupId="language">
<TabItem value="node" label="Node.js" default>

<CodeBlock language="bash">{`# Create project directory
mkdir agora-ai-backend
cd agora-ai-backend\n
\# Initialize Node.js project
npm init -y\n
\# Create source directory
mkdir src
touch src/server.js
touch .env`}</CodeBlock>

Your project structure:

<CodeBlock language="text">{`agora-ai-backend/
├── package.json
├── .env
└── src/
    └── server.js`}</CodeBlock>

</TabItem>
<TabItem value="python" label="Python">

<CodeBlock language="bash">{`# Create project directory
mkdir agora-ai-backend
cd agora-ai-backend\n
\# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n
\# Create source file
touch server.py`}</CodeBlock>

Your project structure:

<CodeBlock language="text">{`agora-ai-backend/
├── requirements.txt
├── .env
├── venv/
└── server.py`}</CodeBlock>

</TabItem>
<TabItem value="go" label="Go">

<CodeBlock language="bash">{`# Create project directory
mkdir agora-ai-backend
cd agora-ai-backend\n
\# Initialize Go module
go mod init agora-ai-backend\n
\# Create source file
touch server.go`}</CodeBlock>

Your project structure:

<CodeBlock language="text">{`agora-ai-backend/
├── go.mod
├── go.sum
├── .env
└── server.go`}</CodeBlock>

</TabItem>
</Tabs>

### Install packages

Install the packages you need to run an HTTP server, make API calls, and load environment variables.

<Tabs groupId="language">
<TabItem value="node" label="Node.js" default>

<CodeBlock language="bash">{`npm install express dotenv agora-token cors`}</CodeBlock>

What these packages do:
- `express`: Handles HTTP requests and API endpoints
- `dotenv`: Loads credentials from your `.env` file
- `agora-token`: Generates RTC tokens for agent authentication
- `cors`: Enables cross-origin requests from your client app

Node.js 18+ includes fetch built-in, so you don't need an extra package for API calls.

</TabItem>
<TabItem value="python" label="Python">

Create a `requirements.txt` file:

<CodeBlock language="text">{`fastapi==0.104.1
uvicorn==0.24.0
requests==2.31.0
python-dotenv==1.0.0
agora-token-builder`}</CodeBlock>

Install dependencies:

<CodeBlock language="bash">{`pip install -r requirements.txt`}</CodeBlock>

What these packages do:
- **fastapi**: Fast HTTP server framework with automatic API docs
- **uvicorn**: Server that runs your FastAPI app
- **requests**: Makes HTTP calls to <Vg k="COMPANY" />'s APIs
- **python-dotenv**: Loads credentials from your `.env` file
- **agora-token-builder**: Generates RTC tokens for agent authentication

</TabItem>
<TabItem value="go" label="Go">

<CodeBlock language="bash">{`go get github.com/gin-gonic/gin
go get github.com/joho/godotenv
go get github.com/AgoraIO-Community/go-tokenbuilder/rtctokenbuilder2`}</CodeBlock>

What these packages do:
- **gin**: Fast HTTP server framework
- **godotenv**: Loads credentials from your `.env` file
- **go-tokenbuilder**: Generates RTC tokens for agent authentication

Go's standard library already includes HTTP client functionality (`net/http`), so you don't need an extra package for API calls.

</TabItem>
</Tabs>

### Configure the environment

Update the `.env` file to store your credentials. 

<Admonition type="caution">
Keep your `.env` file secure. Add it to `.gitignore` immediately to prevent accidentally committing credentials to version control.
</Admonition>

<CodeBlock language="bash">{`# Agora Credentials
AGORA_APP_ID=your_app_id_here
AGORA_APP_CERTIFICATE=your_app_certificate_here
AGORA_CUSTOMER_ID=your_customer_id_here
AGORA_CUSTOMER_SECRET=your_customer_secret_here\n
\# AI Model API Keys
OPENAI_API_KEY=your_openai_api_key_here
MICROSOFT_TTS_KEY=your_microsoft_key_here
MICROSOFT_TTS_REGION=eastus\n
\# Server Configuration
PORT=3000`}</CodeBlock>

**What each variable does:**

- `AGORA_APP_ID`: Identifies your Agora project
- `AGORA_APP_CERTIFICATE`: Used to generate RTC tokens for agent authentication. Keep this secret—never expose it to clients
- `AGORA_CUSTOMER_ID` & `AGORA_CUSTOMER_SECRET`: Authenticate your server with Agora's APIs. Keep these secret—never expose them to clients
- `OPENAI_API_KEY`: Lets you call OpenAI's API for LLM or MLLM
- `MICROSOFT_TTS_KEY` & `MICROSOFT_TTS_REGION`: Lets you call Microsoft's text-to-speech API. Only needed for ASR-LLM-TTS pipeline
- `PORT`: The port your server runs on


### Generate authentication credentials

Your server authenticates with <Vg k="COMPANY" />'s APIs using HTTP Basic Authentication. It generates RTC tokens for both the client and agent to join channels securely:

- **Client token**: Generated for the client's UID. The client uses this token to authenticate when joining the channel.
- **Agent token**: Generated for the agent's UID (1001). The agent uses this token when calling Agora's `/join` API.

Both tokens are scoped to the same channel and expire after the specified time. 

<Tabs groupId="language">
<TabItem value="node" label="Node.js" default>

<CodeBlock language="javascript">{`const \{
  RtcTokenBuilder,
  RtcRole
\} = require('agora-token');\n
// Generate Base64 credentials for Agora API authentication
function generateBasicAuth(customerId, customerSecret) \{
  const credentials = \`\$\{customerId\}:\$\{customerSecret\}\`;
  return Buffer.from(credentials).toString('base64');
\}\n
// Generate RTC token for a specific UID
function generateRtcToken(channelName, uid) \{
  const currentTimestamp = Math.floor(Date.now() / 1000);
  const expireTimestamp = currentTimestamp + 3600; // Token expires in 1 hour
  return RtcTokenBuilder.buildTokenWithUid(
    AGORA_APP_ID,
    AGORA_APP_CERTIFICATE,
    channelName,
    uid,
    RtcRole.PUBLISHER,
    expireTimestamp
  );
\}`}</CodeBlock>

</TabItem>
<TabItem value="python" label="Python">

<CodeBlock language="python">{`from agora_token_builder import RtcTokenBuilder, RtcRole
import base64
from datetime import datetime\n
\# Generate Base64 credentials for Agora API authentication
def generate_basic_auth(customer_id: str, customer_secret: str) -> str:
    credentials = customer_id + ":" + customer_secret
    return base64.b64encode(credentials.encode()).decode()\n
\# Generate RTC token for a specific UID
def generate_rtc_token(channel_name: str, uid: int) -> str:
    current_timestamp = int(datetime.now().timestamp())
    expire_timestamp = current_timestamp + 3600  \# Token expires in 1 hour
    return RtcTokenBuilder.buildTokenWithUid(
        AGORA_APP_ID,
        AGORA_APP_CERTIFICATE,
        channel_name,
        uid,
        RtcRole.Publisher,
        expire_timestamp
    )`}</CodeBlock>

</TabItem>
<TabItem value="go" label="Go">

<CodeBlock language="go">{`import (
    "encoding/base64"
    "time"
    "github.com/AgoraIO-Community/go-tokenbuilder/rtctokenbuilder2"
)\n
\# Generate Base64 credentials for Agora API authentication
func generateBasicAuth(customerID, customerSecret string) string \{
    credentials := customerID + ":" + customerSecret
    return base64.StdEncoding.EncodeToString([]byte(credentials))
\}\n
\# Generate RTC token for a specific UID
func generateRtcToken(channelName string, uid uint32) (string, error) \{
    currentTimestamp := uint32(time.Now().Unix())
    expireTimestamp := currentTimestamp + 3600 \# Token expires in 1 hour
    token := rtctokenbuilder2.BuildTokenWithUid(
        config.AppID,
        config.AppCertificate,
        channelName,
        uid,
        rtctokenbuilder2.RolePublisher,
        expireTimestamp,
    )
    return token, nil
\}`}</CodeBlock>

</TabItem>
</Tabs>

For more details on authentication, see [RESTful authentication](/conversational-ai/rest-api/restful-authentication).

### Start an agent

When a client requests to start interaction with an agent:

1. Extract channel, agent name, and user UID from the request
2. Generate tokens for both client and agent
3. Configure the agent workflow 
4. Call the `/join` API to deploy the agent
5. Return connection details to the client

<Tabs groupId="language">
<TabItem value="node" label="Node.js" default>

<CodeBlock language="javascript">{`app.post('/agents/start', async (req, res) => \{
  const \{ channelName, agentName, userUid \} = req.body;\n
  // Client UID from request
  const clientUid = String(userUid).trim();
  const agentUid = 1001;\n
  // Generate TWO tokens: one for client, one for agent
  const clientToken = generateRtcToken(channelName, parseInt(clientUid));
  const agentToken = generateRtcToken(channelName, agentUid);\n
  // Configure agent with ASR-LLM-TTS pipeline
  const agentConfig = \{
    name: agentName,
    properties: \{
      channel: channelName,
      token: agentToken,  // Agent uses its own token
      agent_rtc_uid: String(agentUid),
      remote_rtc_uids: [clientUid],  // Agent listens to client's UID
      llm: \{
        url: "https://api.openai.com/v1/chat/completions",
        api_key: OPENAI_API_KEY,
        system_messages: [
          \{
            role: "system",
            content: "You are a helpful AI assistant powered by Agora's Conversational AI Engine."
          \}
        ],
        greeting_message: "Hello! How can I help you today?",
        params: \{ model: "gpt-4o-mini" \}
      \},
      asr: \{ language: "en-US" \},
      tts: \{
        vendor: "microsoft",
        params: \{
          key: MICROSOFT_TTS_KEY,
          region: MICROSOFT_TTS_REGION,
          voice_name: "en-US-AndrewMultilingualNeural"
        \}
      \}
    \}
  \};\n
  // Call Agora API to start the agent
  const response = await fetch(
    \`https://api.agora.io/api/conversational-ai-agent/v2/projects/\$\{AGORA_APP_ID\}/join\`,
    \{
      method: 'POST',
      headers: \{
        'Authorization': \`Basic \$\{basicAuth\}\`,
        'Content-Type': 'application/json'
      \},
      body: JSON.stringify(agentConfig)
    \}
  );\n
  const data = await response.json();\n
  // Return agent information to client
  res.json(\{
    success: true,
    agentId: data.agent_id,
    channelName: channelName,
    token: clientToken,          // Token for CLIENT to use
    clientUid: clientUid,        // Client's UID
    agentUid: String(agentUid),  // Agent's UID
    status: data.status,
    createTime: data.create_ts
  \});
\});`}</CodeBlock>

</TabItem>
<TabItem value="python" label="Python">

<CodeBlock language="python">{`@app.post("/agents/start")
async def start_agent(request: StartAgentRequest):
    \# Client UID from request, Agent UID hardcoded
    client_uid = str(request.userUid).strip()
    agent_uid = 1001\n
    \# Generate TWO tokens: one for client, one for agent
    client_token = generate_rtc_token(request.channelName, int(client_uid))
    agent_token = generate_rtc_token(request.channelName, agent_uid)\n
    \# Configure agent with ASR-LLM-TTS pipeline
    agent_config = \{
        "name": request.agentName,
        "properties": \{
            "channel": request.channelName,
            "token": agent_token,
            "agent_rtc_uid": str(agent_uid),
            "remote_rtc_uids": [client_uid],
            "llm": \{
                "url": "https://api.openai.com/v1/chat/completions",
                "api_key": OPENAI_API_KEY,
                "system_messages": [
                    \{
                        "role": "system",
                        "content": "You are a helpful AI assistant powered by Agora's Conversational AI Engine."
                    \}
                ],
                "greeting_message": "Hello! How can I help you today?",
                "params": \{"model": "gpt-4o-mini"\}
            \},
            "asr": \{"language": "en-US"\},
            "tts": \{
                "vendor": "microsoft",
                "params": \{
                    "key": MICROSOFT_TTS_KEY,
                    "region": MICROSOFT_TTS_REGION,
                    "voice_name": "en-US-AndrewMultilingualNeural"
                \}
            \}
        \}
    \}\n
    \# Call Agora API to start the agent
    response = requests.post(
        f"https://api.agora.io/api/conversational-ai-agent/v2/projects/\{AGORA_APP_ID\}/join",
        json=agent_config,
        headers=\{
            "Authorization": f"Basic \{basic_auth\}",
            "Content-Type": "application/json"
        \}
    )\n
    data = response.json()\n
    \# Return agent information to client
    return \{
        "success": True,
        "agentId": data["agent_id"],
        "channelName": request.channelName,
        "token": client_token,
        "clientUid": client_uid,
        "agentUid": str(agent_uid),
        "status": data["status"],
        "createTime": data["create_ts"]
    \}`}</CodeBlock>

</TabItem>
<TabItem value="go" label="Go">

<CodeBlock language="go">{`\# Start agent endpoint
func startAgent(c *gin.Context) \{
    var req StartAgentRequest
    if err := c.ShouldBindJSON(&req); err != nil \{
        c.JSON(http.StatusBadRequest, gin.H\{
            "error": "Missing required fields",
        \})
        return
    \}\n
    \# Client UID from request, Agent UID hardcoded
    clientUid := strings.TrimSpace(req.UserUid)
    agentUid := uint32(1001)\n
    \# Generate TWO tokens: one for client, one for agent
    clientToken, _ := generateRtcToken(req.ChannelName, uint32(1002))
    agentToken, _ := generateRtcToken(req.ChannelName, agentUid)\n
    \# Configure agent with ASR-LLM-TTS pipeline
    agentConfig := map[string]interface\{\}\{
        "name": req.AgentName,
        "properties": map[string]interface\{\}\{
            "channel":         req.ChannelName,
            "token":           agentToken,
            "agent_rtc_uid":   fmt.Sprintf("%d", agentUid),
            "remote_rtc_uids": []string\{clientUid\},
            "llm": map[string]interface\{\}\{
                "url":     "https://api.openai.com/v1/chat/completions",
                "api_key": config.OpenAIKey,
                "system_messages": []map[string]string\{
                    \{
                        "role":    "system",
                        "content": "You are a helpful AI assistant.",
                    \},
                \},
                "greeting_message": "Hello! How can I help you?",
                "params": map[string]string\{
                    "model": "gpt-4o-mini",
                \},
            \},
            "asr": map[string]string\{
                "language": "en-US",
            \},
            "tts": map[string]interface\{\}\{
                "vendor": "microsoft",
                "params": map[string]string\{
                    "key":        config.MicrosoftTTSKey,
                    "region":     config.MicrosoftTTSRegion,
                    "voice_name": "en-US-AndrewMultilingualNeural",
                \},
            \},
        \},
    \}\n
    \# Call Agora API to start the agent
    url := fmt.Sprintf("https://api.agora.io/api/conversational-ai-agent/v2/projects/%s/join", config.AppID)
    jsonData, _ := json.Marshal(agentConfig)
    httpReq, _ := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
    httpReq.Header.Set("Authorization", "Basic "+basicAuth)
    httpReq.Header.Set("Content-Type", "application/json")\n
    client := &http.Client\{Timeout: 10 * time.Second\}
    resp, _ := client.Do(httpReq)
    defer resp.Body.Close()\n
    body, _ := io.ReadAll(resp.Body)
    var agentResp AgentResponse
    json.Unmarshal(body, &agentResp)\n
    \# Return agent information to client
    c.JSON(http.StatusOK, gin.H\{
        "success":    true,
        "agentId":    agentResp.AgentID,
        "channelName": req.ChannelName,
        "token":       clientToken,
        "clientUid":   clientUid,
        "agentUid":    fmt.Sprintf("%d", agentUid),
        "status":      agentResp.Status,
        "createTime":  agentResp.CreateTS,
    \})
\}`}</CodeBlock>

</TabItem>
</Tabs>

### Complete server implementation

This backend server provides start and stop agent endpoints to manage agents through the <Vpd k="NAME" />.

<Tabs groupId="language">
<TabItem value="node" label="Node.js" default>

<CodeBlock language="javascript">{`require('dotenv').config();
const express = require('express');
const cors = require('cors');
const \{ RtcTokenBuilder, RtcRole \} = require('agora-token');\n
const app = express();\n
// Enable CORS for client requests
app.use(cors(\{
  origin: ['http://localhost:5173', 'http://localhost:3000'],
  credentials: true,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization']
\}));\n
app.use(express.json());\n
// Load environment variables
const \{
  AGORA_APP_ID,
  AGORA_APP_CERTIFICATE,
  AGORA_CUSTOMER_ID,
  AGORA_CUSTOMER_SECRET,
  OPENAI_API_KEY,
  MICROSOFT_TTS_KEY,
  MICROSOFT_TTS_REGION,
  PORT = 3000
\} = process.env;\n
// Generate Base64 credentials for Agora API authentication
function generateBasicAuth(customerId, customerSecret) \{
  const credentials = \`\$\{customerId\}:\$\{customerSecret\}\`;
  return Buffer.from(credentials).toString('base64');
\}\n
// Generate RTC token for a specific UID
function generateRtcToken(channelName, uid) \{
  const currentTimestamp = Math.floor(Date.now() / 1000);
  const expireTimestamp = currentTimestamp + 3600; // Token expires in 1 hour
  return RtcTokenBuilder.buildTokenWithUid(
    AGORA_APP_ID,
    AGORA_APP_CERTIFICATE,
    channelName,
    uid,
    RtcRole.PUBLISHER,
    expireTimestamp
  );
\}\n
const basicAuth = generateBasicAuth(AGORA_CUSTOMER_ID, AGORA_CUSTOMER_SECRET);\n
// Health check endpoint
app.get('/health', (req, res) => \{
  res.json(\{ status: 'ok', timestamp: new Date().toISOString() \});
\});\n
// Start agent endpoint
app.post('/agents/start', async (req, res) => \{
  try \{
    const \{ channelName, agentName, userUid \} = req.body;\n
    // Validate required fields
    if (!channelName || !agentName || !userUid) \{
      return res.status(400).json(\{
        error: 'Missing required fields',
        required: ['channelName', 'agentName', 'userUid']
      \});
    \}\n
    // Client UID from request, Agent UID hardcoded
    const clientUid = String(userUid).trim();
    const agentUid = 1001;\n
    // Generate TWO tokens: one for client, one for agent
    const clientToken = generateRtcToken(channelName, parseInt(clientUid));
    const agentToken = generateRtcToken(channelName, agentUid);\n
    console.log(\`Starting agent for client UID: \$\{clientUid\}, Agent UID: \$\{agentUid\}\`);
    console.log(\`Channel: \$\{channelName\}\`);\n
    // Configure agent with ASR-LLM-TTS pipeline
    const agentConfig = \{
      name: agentName,
      properties: \{
        channel: channelName,
        token: agentToken,  // Agent uses its own token
        agent_rtc_uid: String(agentUid),
        remote_rtc_uids: [clientUid],  // Agent listens to client's UID
        enable_string_uid: false,
        idle_timeout: 120,
        llm: \{
          url: "https://api.openai.com/v1/chat/completions",
          api_key: OPENAI_API_KEY,
          system_messages: [
            \{
              role: "system",
              content: "You are a helpful AI assistant powered by Agora's Conversational AI Engine."
            \}
          ],
          greeting_message: "Hello! How can I help you today?",
          failure_message: "I'm having trouble processing that. Could you try again?",
          max_history: 10,
          params: \{
            model: "gpt-4o-mini"
          \}
        \},
        asr: \{
          language: "en-US"
        \},
        tts: \{
          vendor: "microsoft",
          params: \{
            key: MICROSOFT_TTS_KEY,
            region: MICROSOFT_TTS_REGION,
            voice_name: "en-US-AndrewMultilingualNeural"
          \}
        \}
      \}
    \};\n
    // Call Agora API to start the agent
    // This is the critical step where the agent joins the channel
    const response = await fetch(
      \`https://api.agora.io/api/conversational-ai-agent/v2/projects/\$\{AGORA_APP_ID\}/join\`,
      \{
        method: 'POST',
        headers: \{
          'Authorization': \`Basic \$\{basicAuth\}\`,
          'Content-Type': 'application/json'
        \},
        body: JSON.stringify(agentConfig)
      \}
    );\n
    const data = await response.json();\n
    if (!response.ok) \{
      console.error('Agora API error:', data);
      return res.status(response.status).json(\{
        error: 'Failed to start agent',
        details: data
      \});
    \}\n
    console.log(\`Agent started successfully: \$\{data.agent_id\}\`);\n
    // Return agent information to client
    // Client uses token and channelName to join the same channel
    res.json(\{
      success: true,
      agentId: data.agent_id,
      channelName: channelName,
      token: clientToken,          // Token for CLIENT to use (generated for clientUid)
      clientUid: clientUid,        // Client's UID
      agentUid: String(agentUid),  // Agent's UID
      status: data.status,
      createTime: data.create_ts
    \});
  \} catch (error) \{
    console.error('Error starting agent:', error.message);
    res.status(500).json(\{
      error: 'Failed to start agent',
      details: error.message
    \});
  \}
\});\n
// Stop agent endpoint
app.post('/agents/:agentId/stop', async (req, res) => \{
  try \{
    const \{ agentId \} = req.params;\n
    console.log(\`Stopping agent: \$\{agentId\}\`);\n
    // Call Agora API to stop the agent
    const response = await fetch(
      \`https://api.agora.io/api/conversational-ai-agent/v2/projects/\$\{AGORA_APP_ID\}/agents/\$\{agentId\}/leave\`,
      \{
        method: 'POST',
        headers: \{
          'Authorization': \`Basic \$\{basicAuth\}\`,
          'Content-Type': 'application/json'
        \}
      \}
    );\n
    if (!response.ok) \{
      const data = await response.json();
      console.error('Agora API error:', data);
      return res.status(response.status).json(\{
        error: 'Failed to stop agent',
        details: data
      \});
    \}\n
    console.log(\`Agent stopped successfully: \$\{agentId\}\`);\n
    res.json(\{
      success: true,
      message: 'Agent stopped successfully'
    \});
  \} catch (error) \{
    console.error('Error stopping agent:', error.message);
    res.status(500).json(\{
      error: 'Failed to stop agent',
      details: error.message
    \});
  \}
\});\n
// Start server
app.listen(PORT, () => \{
  console.log(\`Agora AI backend server running on port \$\{PORT\}\`);
  console.log(\`Health check: http://localhost:\$\{PORT\}/health\`);
  console.log(\`Start agent: POST http://localhost:\$\{PORT\}/agents/start\`);
  console.log(\`Stop agent: POST http://localhost:\$\{PORT\}/agents/:agentId/stop\`);
\});`}</CodeBlock>

Run your server:

<CodeBlock language="bash">{`node src/server.js`}</CodeBlock>

</TabItem>
<TabItem value="python" label="Python">

<CodeBlock language="python">{`import os
import base64
from datetime import datetime, timedelta
from typing import Optional
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import requests
from dotenv import load_dotenv
from agora_token_builder import RtcTokenBuilder, RtcRole
import uvicorn\n
\# Load environment variables
load_dotenv()\n
app = FastAPI(title="Agora AI Backend")\n
\# Enable CORS for client requests
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["Content-Type", "Authorization"],
)\n
\# Configuration
AGORA_APP_ID = os.getenv("AGORA_APP_ID")
AGORA_APP_CERTIFICATE = os.getenv("AGORA_APP_CERTIFICATE")
AGORA_CUSTOMER_ID = os.getenv("AGORA_CUSTOMER_ID")
AGORA_CUSTOMER_SECRET = os.getenv("AGORA_CUSTOMER_SECRET")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MICROSOFT_TTS_KEY = os.getenv("MICROSOFT_TTS_KEY")
MICROSOFT_TTS_REGION = os.getenv("MICROSOFT_TTS_REGION")
PORT = int(os.getenv("PORT", 3000))\n
\# Generate Base64 credentials for Agora API authentication
def generate_basic_auth(customer_id: str, customer_secret: str) -> str:
    credentials = f"\{customer_id\}:\{customer_secret\}"
    return base64.b64encode(credentials.encode()).decode()\n
\# Generate RTC token for a specific UID
def generate_rtc_token(channel_name: str, uid: int) -> str:
    current_timestamp = int(datetime.now().timestamp())
    expire_timestamp = current_timestamp + 3600  \# Token expires in 1 hour
    return RtcTokenBuilder.buildTokenWithUid(
        AGORA_APP_ID,
        AGORA_APP_CERTIFICATE,
        channel_name,
        uid,
        RtcRole.Publisher,
        expire_timestamp
    )\n
basic_auth = generate_basic_auth(AGORA_CUSTOMER_ID, AGORA_CUSTOMER_SECRET)\n
\# Request models
class StartAgentRequest(BaseModel):
    channelName: str
    agentName: str
    userUid: str  \# Single UID\n
\# Health check endpoint
@app.get("/health")
async def health_check():
    return \{"status": "ok", "timestamp": datetime.now().isoformat()\}\n
\# Start agent endpoint
@app.post("/agents/start")
async def start_agent(request: StartAgentRequest):
    try:
        \# Validate required fields
        if not request.channelName or not request.agentName or not request.userUid:
            raise HTTPException(
                status_code=400,
                detail="Missing required fields: channelName, agentName, userUid"
            )\n
        \# Client UID from request, Agent UID hardcoded
        client_uid = str(request.userUid).strip()
        agent_uid = 1001\n
        \# Generate TWO tokens: one for client, one for agent
        client_token = generate_rtc_token(request.channelName, int(client_uid))
        agent_token = generate_rtc_token(request.channelName, agent_uid)\n
        print(f"Starting agent for client UID: \{client_uid\}, Agent UID: \{agent_uid\}")
        print(f"Channel: \{request.channelName\}")\n
        \# Configure agent with ASR-LLM-TTS pipeline
        agent_config = \{
            "name": request.agentName,
            "properties": \{
                "channel": request.channelName,
                "token": agent_token,  \# Agent uses its own token
                "agent_rtc_uid": str(agent_uid),
                "remote_rtc_uids": [client_uid],  \# Agent listens to client's UID
                "enable_string_uid": False,
                "idle_timeout": 120,
                "llm": \{
                    "url": "https://api.openai.com/v1/chat/completions",
                    "api_key": OPENAI_API_KEY,
                    "system_messages": [
                        \{
                            "role": "system",
                            "content": "You are a helpful AI assistant powered by Agora's Conversational AI Engine."
                        \}
                    ],
                    "greeting_message": "Hello! How can I help you today?",
                    "failure_message": "I'm having trouble processing that. Could you try again?",
                    "max_history": 10,
                    "params": \{
                        "model": "gpt-4o-mini"
                    \}
                \},
                "asr": \{
                    "language": "en-US"
                \},
                "tts": \{
                    "vendor": "microsoft",
                    "params": \{
                        "key": MICROSOFT_TTS_KEY,
                        "region": MICROSOFT_TTS_REGION,
                        "voice_name": "en-US-AndrewMultilingualNeural"
                    \}
                \}
            \}
        \}\n
        \# Call Agora API to start the agent
        \# This is the critical step where the agent joins the channel
        response = requests.post(
            f"https://api.agora.io/api/conversational-ai-agent/v2/projects/\{AGORA_APP_ID\}/join",
            json=agent_config,
            headers=\{
                "Authorization": f"Basic \{basic_auth\}",
                "Content-Type": "application/json"
            \}
        )\n
        if response.status_code != 200:
            print(f"Agora API error: \{response.json()\}")
            raise HTTPException(
                status_code=response.status_code,
                detail=response.json()
            )\n
        data = response.json()
        print(f"Agent started successfully: \{data['agent_id']\}")\n
        \# Return agent information to client
        \# Client uses token and channelName to join the same channel
        return \{
            "success": True,
            "agentId": data["agent_id"],
            "channelName": request.channelName,
            "token": client_token,  \# Token for CLIENT to use (generated for clientUid)
            "clientUid": client_uid,  \# Client's UID
            "agentUid": str(agent_uid),  \# Agent's UID
            "status": data["status"],
            "createTime": data["create_ts"]
        \}
    except requests.exceptions.RequestException as e:
        print(f"Error starting agent: \{str(e)\}")
        raise HTTPException(status_code=500, detail=str(e))\n
\# Stop agent endpoint
@app.post("/agents/\{agent_id\}/stop")
async def stop_agent(agent_id: str):
    try:
        print(f"Stopping agent: \{agent_id\}")\n
        \# Call Agora API to stop the agent
        response = requests.post(
            f"https://api.agora.io/api/conversational-ai-agent/v2/projects/\{AGORA_APP_ID\}/agents/\{agent_id\}/leave",
            headers=\{
                "Authorization": f"Basic \{basic_auth\}",
                "Content-Type": "application/json"
            \}
        )\n
        if response.status_code != 200:
            print(f"Agora API error: \{response.json()\}")
            raise HTTPException(
                status_code=response.status_code,
                detail=response.json()
            )\n
        print(f"Agent stopped successfully: \{agent_id\}")\n
        return \{
            "success": True,
            "message": "Agent stopped successfully"
        \}
    except requests.exceptions.RequestException as e:
        print(f"Error stopping agent: \{str(e)\}")
        raise HTTPException(status_code=500, detail=str(e))\n
if __name__ == "__main__":
    print(f"Agora AI backend server running on port \{PORT\}")
    print(f"Health check: http://localhost:\{PORT\}/health")
    print(f"Start agent: POST http://localhost:\{PORT\}/agents/start")
    print(f"Stop agent: POST http://localhost:\{PORT\}/agents/\{agent_id\}/stop")
    uvicorn.run(app, host="0.0.0.0", port=PORT)`}</CodeBlock>

Run your server:

<CodeBlock language="bash">{`python server.py`}</CodeBlock>

</TabItem>
<TabItem value="go" label="Go">

<CodeBlock language="go">{`package main\n
import (
    "bytes"
    "encoding/base64"
    "encoding/json"
    "fmt"
    "io"
    "log"
    "net/http"
    "os"
    "strconv"
    "strings"
    "time"\n
    "github.com/gin-gonic/gin"
    "github.com/joho/godotenv"
    "github.com/AgoraIO-Community/go-tokenbuilder/rtctokenbuilder2"
)\n
\# Config holds environment variables
type Config struct \{
    AppID              string
    AppCertificate     string
    CustomerID         string
    CustomerSecret     string
    OpenAIKey          string
    MicrosoftTTSKey    string
    MicrosoftTTSRegion string
    Port               string
\}\n
\# StartAgentRequest represents the request body for starting an agent
type StartAgentRequest struct \{
    ChannelName string \`json:"channelName"\`
    AgentName   string \`json:"agentName"\`
    UserUid     string \`json:"userUid"\` \# Single UID
\}\n
\# AgentResponse represents the response from Agora API
type AgentResponse struct \{
    AgentID   string \`json:"agent_id"\`
    CreateTS  int64  \`json:"create_ts"\`
    Status    string \`json:"status"\`
\}\n
var config Config
var basicAuth string\n
\# Generate RTC token for a specific UID
func generateRtcToken(channelName string, uid uint32) (string, error) \{
    currentTimestamp := uint32(time.Now().Unix())
    expireTimestamp := currentTimestamp + 3600 \# Token expires in 1 hour
    token := rtctokenbuilder2.BuildTokenWithUid(
        config.AppID,
        config.AppCertificate,
        channelName,
        uid,
        rtctokenbuilder2.RolePublisher,
        expireTimestamp,
    )
    return token, nil
\}\n
func main() \{
    \# Load environment variables
    if err := godotenv.Load(); err != nil \{
        log.Println("No .env file found")
    \}\n
    config = Config\{
        AppID:              os.Getenv("AGORA_APP_ID"),
        AppCertificate:     os.Getenv("AGORA_APP_CERTIFICATE"),
        CustomerID:         os.Getenv("AGORA_CUSTOMER_ID"),
        CustomerSecret:     os.Getenv("AGORA_CUSTOMER_SECRET"),
        OpenAIKey:          os.Getenv("OPENAI_API_KEY"),
        MicrosoftTTSKey:    os.Getenv("MICROSOFT_TTS_KEY"),
        MicrosoftTTSRegion: os.Getenv("MICROSOFT_TTS_REGION"),
        Port:               getEnv("PORT", "3000"),
    \}\n
    \# Generate Base64 credentials for Agora API authentication
    basicAuth = generateBasicAuth(config.CustomerID, config.CustomerSecret)\n
    \# Setup HTTP server
    gin.SetMode(gin.ReleaseMode)
    router := gin.Default()\n
    \# Routes
    router.GET("/health", healthCheck)
    router.POST("/agents/start", startAgent)
    router.POST("/agents/:agentId/stop", stopAgent)\n
    \# Start server
    log.Printf("Agora AI backend server running on port %s", config.Port)
    log.Printf("Health check: http://localhost:%s/health", config.Port)
    if err := router.Run(":" + config.Port); err != nil \{
        log.Fatal("Failed to start server:", err)
    \}
\}\n
\# Helper function to generate Base64 authentication string
func generateBasicAuth(customerID, customerSecret string) string \{
    credentials := customerID + ":" + customerSecret
    return base64.StdEncoding.EncodeToString([]byte(credentials))
\}\n
\# Helper function to get environment variable with default
func getEnv(key, defaultVal string) string \{
    if value := os.Getenv(key); value != "" \{
        return value
    \}
    return defaultVal
\}\n
\# Health check endpoint
func healthCheck(c *gin.Context) \{
    c.JSON(http.StatusOK, gin.H\{
        "status":    "ok",
        "timestamp": time.Now().Format(time.RFC3339),
    \})
\}\n
\# Start agent endpoint
func startAgent(c *gin.Context) \{
    var req StartAgentRequest
    if err := c.ShouldBindJSON(&req); err != nil \{
        c.JSON(http.StatusBadRequest, gin.H\{
            "error":    "Missing required fields",
            "required": []string\{"channelName", "agentName", "userUid"\},
        \})
        return
    \}\n
    \# Client UID from request, Agent UID hardcoded
    clientUid := strings.TrimSpace(req.UserUid)
    agentUid := uint32(1001)\n
    \# Generate TWO tokens: one for client, one for agent
    clientUidInt, _ := strconv.ParseUint(clientUid, 10, 32)
    clientToken, err := generateRtcToken(req.ChannelName, uint32(clientUidInt))
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to generate client token"\})
        return
    \}\n
    agentToken, err := generateRtcToken(req.ChannelName, agentUid)
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to generate agent token"\})
        return
    \}\n
    \# Configure agent with ASR-LLM-TTS pipeline
    agentConfig := map[string]interface\{\}\{
        "name": req.AgentName,
        "properties": map[string]interface\{\}\{
            "channel":           req.ChannelName,
            "token":             agentToken,
            "agent_rtc_uid":     fmt.Sprintf("%d", agentUid),
            "remote_rtc_uids":   []string\{clientUid\},
            "enable_string_uid": false,
            "idle_timeout":      120,
            "llm": map[string]interface\{\}\{
                "url":     "https://api.openai.com/v1/chat/completions",
                "api_key": config.OpenAIKey,
                "system_messages": []map[string]string\{
                    \{
                        "role":    "system",
                        "content": "You are a helpful AI assistant powered by Agora's Conversational AI Engine.",
                    \},
                \},
                "greeting_message": "Hello! How can I help you today?",
                "failure_message":  "I'm having trouble processing that. Could you try again?",
                "max_history":      10,
                "params": map[string]string\{
                    "model": "gpt-4o-mini",
                \},
            \},
            "asr": map[string]string\{
                "language": "en-US",
            \},
            "tts": map[string]interface\{\}\{
                "vendor": "microsoft",
                "params": map[string]string\{
                    "key":        config.MicrosoftTTSKey,
                    "region":     config.MicrosoftTTSRegion,
                    "voice_name": "en-US-AndrewMultilingualNeural",
                \},
            \},
        \},
    \}\n
    \# Marshal config to JSON
    jsonData, err := json.Marshal(agentConfig)
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to create request"\})
        return
    \}\n
    \# Call Agora API to start the agent
    url := fmt.Sprintf("https://api.agora.io/api/conversational-ai-agent/v2/projects/%s/join", config.AppID)
    httpReq, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to create request"\})
        return
    \}\n
    httpReq.Header.Set("Authorization", "Basic "+basicAuth)
    httpReq.Header.Set("Content-Type", "application/json")\n
    client := &http.Client\{Timeout: 10 * time.Second\}
    resp, err := client.Do(httpReq)
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to call Agora API"\})
        return
    \}
    defer resp.Body.Close()\n
    body, err := io.ReadAll(resp.Body)
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to read response"\})
        return
    \}\n
    if resp.StatusCode != http.StatusOK \{
        c.JSON(resp.StatusCode, gin.H\{
            "error":   "Failed to start agent",
            "details": string(body),
        \})
        return
    \}\n
    var agentResp AgentResponse
    if err := json.Unmarshal(body, &agentResp); err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to parse response"\})
        return
    \}\n
    \# Return agent information to client
    c.JSON(http.StatusOK, gin.H\{
        "success":    true,
        "agentId":    agentResp.AgentID,
        "channelName": req.ChannelName,
        "token":       clientToken,
        "clientUid":   clientUid,
        "agentUid":    fmt.Sprintf("%d", agentUid),
        "status":      agentResp.Status,
        "createTime":  agentResp.CreateTS,
    \})
\}\n
\# Stop agent endpoint
func stopAgent(c *gin.Context) \{
    agentID := c.Param("agentId")\n
    \# Call Agora API to stop the agent
    url := fmt.Sprintf("https://api.agora.io/api/conversational-ai-agent/v2/projects/%s/agents/%s/leave",
        config.AppID, agentID)
    httpReq, err := http.NewRequest("POST", url, nil)
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to create request"\})
        return
    \}\n
    httpReq.Header.Set("Authorization", "Basic "+basicAuth)
    httpReq.Header.Set("Content-Type", "application/json")\n
    client := &http.Client\{Timeout: 10 * time.Second\}
    resp, err := client.Do(httpReq)
    if err != nil \{
        c.JSON(http.StatusInternalServerError, gin.H\{"error": "Failed to call Agora API"\})
        return
    \}
    defer resp.Body.Close()\n
    if resp.StatusCode != http.StatusOK \{
        body, _ := io.ReadAll(resp.Body)
        c.JSON(resp.StatusCode, gin.H\{
            "error":   "Failed to stop agent",
            "details": string(body),
        \})
        return
    \}\n
    c.JSON(http.StatusOK, gin.H\{
        "success": true,
        "message": "Agent stopped successfully",
    \})
\}`}</CodeBlock>

Run your server:

<CodeBlock language="bash">{`go run server.go`}</CodeBlock>

</TabItem>
</Tabs>

## Test your server

Test your endpoints to ensure everything works correctly:

### Check server health

<CodeBlock language="bash">{`curl http://localhost:3000/health`}</CodeBlock>

Expected response:

<CodeBlock language="json">{`\{
  "status": "ok",
  "timestamp": "2026-02-02T10:30:00.000Z"
\}`}</CodeBlock>

### Start an agent

<CodeBlock language="bash">{`curl -X POST http://localhost:3000/agents/start \\
    -H "Content-Type: application/json" \\
    -d '\{
    "channelName": "test-channel",
    "agentName": "test-agent-1",
    "userUid": "1002"
    \}'`}</CodeBlock>

Expected response:

<CodeBlock language="json">{`\{
  "success": true,
  "agentId": "1NT29X10YHxxxxxWJOXLYHNYB",
  "channelName": "test-channel",
  "token": "007eAAA...",
  "clientUid": "1002",
  "agentUid": "1001",
  "status": "RUNNING",
  "createTime": 1737111452
\}`}</CodeBlock>

<Admonition type="info">
Store the `agentId` returned from the start endpoint. You'll need it to stop, query, or update the agent. In production, save this to a database associated with the user's session.
</Admonition>

### Stop the agent

<CodeBlock language="bash">{`curl -X POST http://localhost:3000/agents/1NT29X10YHxxxxxWJOXLYHNYB/stop`}</CodeBlock>

Expected response:

<CodeBlock language="json">{`\{
  "success": true,
  "message": "Agent stopped successfully"
\}`}</CodeBlock>


### Use MLLM instead of the pipeline

To use multimodal voice-to-voice models instead of the ASR-LLM-TTS pipeline, modify the agent configuration in the start endpoint:

<Tabs groupId="language">
<TabItem value="node" label="Node.js" default>

<CodeBlock language="javascript">{`// Replace the agent_config in the /agents/start endpoint with:
const agentConfig = \{
  name: agentName,
  properties: \{
    channel: channelName,
    token: agentToken,
    agent_rtc_uid: String(agentUid), // Use the defined agent UID
    remote_rtc_uids: [clientUid],
    enable_string_uid: false,
    idle_timeout: 120,
    advanced_features: \{
      enable_mllm: true  // Enable MLLM mode
    \},
    mllm: \{
      url: "wss://api.openai.com/v1/realtime",
      api_key: OPENAI_API_KEY,
      params: \{
        model: "gpt-realtime",
        voice: "coral",
        instructions: "You are a helpful AI assistant powered by Agora's Conversational AI Engine."
      \},
      greeting_message: "Hello! How can I help you today?",
      output_modalities: ["text", "audio"],
      vendor: "openai",
      style: "openai"
    \}
  \}
\};`}</CodeBlock>

</TabItem>
<TabItem value="python" label="Python">

<CodeBlock language="python">{`# Replace the agent_config in the /agents/start endpoint with:
\# Note: remote_rtc_uids should already be normalized to a list from the request
agent_config = \{
    "name": request.agentName,
    "properties": \{
        "channel": request.channelName,
        "token": agent_token,  \# Generated token
        "agent_rtc_uid": str(agent_uid),  \# Use the defined agent UID
        "remote_rtc_uids": [client_uid],  \# Already normalized to list
        "enable_string_uid": False,
        "idle_timeout": 120,
        "advanced_features": \{
            "enable_mllm": True  \# Enable MLLM mode
        \},
        "mllm": \{
            "url": "wss://api.openai.com/v1/realtime",
            "api_key": OPENAI_API_KEY,
            "params": \{
                "model": "gpt-realtime",
                "voice": "coral",
                "instructions": "You are a helpful AI assistant powered by Agora's Conversational AI Engine."
            \},
            "greeting_message": "Hello! How can I help you today?",
            "output_modalities": ["text", "audio"],
            "vendor": "openai",
            "style": "openai"
        \}
    \}
\}`}</CodeBlock>

</TabItem>
<TabItem value="go" label="Go">

<CodeBlock language="go">{`// Replace the agentConfig in the startAgent function with:
agentConfig := map[string]interface\{\}\{
    "name": req.AgentName,
    "properties": map[string]interface\{\}\{
        "channel":           req.ChannelName,
        "token":             agentToken,  // Generated token
        "agent_rtc_uid":     fmt.Sprintf("%d", agentUid),  
        "remote_rtc_uids":   []string{clientUid},
        "enable_string_uid": false,
        "idle_timeout":      120,
        "advanced_features": map[string]bool\{
            "enable_mllm": true,  // Enable MLLM mode
        \},
        "mllm": map[string]interface\{\}\{
            "url":     "wss://api.openai.com/v1/realtime",
            "api_key": config.OpenAIKey,
            "params": map[string]string\{
                "model":        "gpt-realtime",
                "voice":        "coral",
                "instructions": "You are a helpful AI assistant powered by Agora's Conversational AI Engine.",
            \},
            "greeting_message":   "Hello! How can I help you today?",
            "output_modalities":  []string\{"text", "audio"\},
            "vendor":             "openai",
            "style":              "openai",
        \},
    \},
\}`}</CodeBlock>

</TabItem>
</Tabs>

<Admonition type="caution">
When `enable_mllm` is `true`, do NOT include `asr`, `llm`, or `tts` configurations. The MLLM handles all voice processing internally.
</Admonition>

## Client application

Before implementing the client code, understand what your backend endpoint expects and returns.

* Client sends to `/agents/start` endpoint:

    ```json
    {
      "channelName": "support-room-123",
      "agentName": "SupportBot",
      "userUid": "1002"
    }
    ```

* Backend returns to client:

    ```json
    {
      "success": true,
      "agentId": "1NT29X10YHxxxxxWJOXLYHNYB",
      "channelName": "support-room-123",
      "token": "007eAAA...",
      "clientUid": "1002",
      "agentUid": "1001",
      "status": "RUNNING",
      "createTime": 1737111452
    }
    ```

    **Key parameters returned**:

    - `agentId`: The agent identifier. Use this ID to stop the agent when you are done.
    - `channelName`: Client uses this to join the same channel where the agent is waiting.
    - `token`: Client uses this to authenticate when joining the channel. Always, generate the token on the server-side, never expose your App Certificate to clients.
    - `clientUid`: The client's unique identifier in the channel; matches the `userUid` sent in the request.
    - `agentUid`: The agent's unique identifier in the channel. Client uses this to identify the agent's audio stream.

To implement a client that connects to the server and enables users to interact with AI agents, follow the [Voice AI client quickstart](client-quickstart) or explore the [Recipes](/conversational-ai/get-started/recipes) page.

<Admonition type="info">
For the best conversational experience, <Vg k="COMPANY" /> recommends using <Vpd k="NAME" /> with specific <Vg k="COMPANY" /> Video/Voice SDK versions. For details, [contact technical support](https://agoraio.zendesk.com/hc/en-us).
</Admonition>

## Reference

### Next steps

You now have a working backend server that manages Conversational AI agents. Here's what to explore next:

- Implement a [Voice AI client](client-quickstart) to work with your server
- Explore the [Recipes](/conversational-ai/get-started/recipes) page for more backend and client implementation examples
- Explore [Custom LLM integration](/conversational-ai/develop/custom-llm) for RAG and function calling
- Configure [agent interruption behavior](/conversational-ai/develop/interrupt-agent)
- Set up [webhooks](/conversational-ai/develop/webhooks) for agent event notifications
- Review the [API Reference](/conversational-ai/rest-api/agent/join) for advanced configuration options

<Admonition type="caution">
The number of Peak Concurrent Users (PCU) allowed to call the server API under a single App ID is limited to 20. If you need to increase this limit, [contact technical support](https://agoraio.zendesk.com/hc/en-us).
</Admonition>

### Why use a backend server

Your backend server is critical for security and scalability. Your Customer ID and Customer Secret must never be exposed to client applications. They grant full API access to your <Vg k="COMPANY" /> project. By centralizing agent management on your backend, you:

- Keep credentials secure on the server side
- Control who can start agents and when
- Implement business logic and access control
- Monitor agent usage and costs
- Handle errors and edge cases reliably

This architecture also lets you:
- Generate RTC tokens on-demand without exposing your App Certificate
- Add authentication and authorization for your users
- Log and audit all agent operations
- Implement rate limiting and cost controls
- Scale independently from your client applications


