<PlatformWrapper platform="android">
    In this example, your modify the captured video frame buffer to crop and scale the frame and play a zoomed-in version of the video.
    
    ```kotlin
    private fun modifyVideoBuffer(videoFrame: VideoFrame) {
        if (isZoomed) {
            // Read the videoFrame buffer
            var buffer = videoFrame.buffer

            val w = buffer.width
            val h = buffer.height
            val cropX = (w - 320) / 2
            val cropY = (h - 240) / 2
            val cropWidth = 320
            val cropHeight = 240
            val scaleWidth = 320
            val scaleHeight = 240

            // modify the buffer
            buffer = buffer.cropAndScale(
                cropX, cropY,
                cropWidth, cropHeight,
                scaleWidth, scaleHeight
            )

            // replace the videoFrame buffer with the modified buffer
            videoFrame.replaceBuffer(buffer, 270, videoFrame.timestampNs)
        }
    }
    ```
    - <Link to="{{global.API_REF_ANDROID_ROOT}}/class_videoframe.html">VideoFrame</Link>
    - <Link to="{{global.API_REF_ANDROID_ROOT}}/class_audioframe.html">AudioFrame</Link>
</PlatformWrapper>
<PlatformWrapper platform={["ios","macos"]}>

    To modify the video frame:

    ```swift
    public class ModifyVideoFrameDelegate: NSObject, AgoraVideoFrameDelegate {
        public func onCapture(
            _ videoFrame: AgoraOutputVideoFrame, sourceType: AgoraVideoSourceType
        ) -> Bool {
            // Change the video frame immediately after recording it
            true
        }

        // Indicate the video frame mode of the observer
        public func getVideoFrameProcessMode() -> AgoraVideoFrameProcessMode {
            // The process mode of the video frame: readOnly, readWrite
            // Default is `.readOnly` function is required to change the output.
            .readWrite
        }
    }
    ```

    <PlatformWrapper platform="ios">
    - <Link to="{{Global.API_REF_IOS_ROOT_RTC_KIT}}/agoravideoframedelegate/oncapture(_:sourcetype:)">onCapture(_:sourceType:)</Link>
    - <Link to="{{Global.API_REF_IOS_ROOT_RTC_KIT}}/agoraoutputvideoframe/pixelbuffer">pixelBuffer</Link>
    </PlatformWrapper>
    <PlatformWrapper platform="macos">
    - <Link to="{{Global.API_REF_MACOS_ROOT_RTC_KIT}}/agoravideoframedelegate/oncapture(_:sourcetype:)">onCapture(_:sourceType:)</Link>
    - <Link to="{{Global.API_REF_MACOS_ROOT_RTC_KIT}}/agoraoutputvideoframe/pixelbuffer">pixelBuffer</Link>
    </PlatformWrapper>

    To modify the audio frame:

    ```swift
    public class ModifyAudioFrameDelegate: NSObject, AgoraAudioFrameDelegate {
        public func onRecordAudioFrame(_ frame: AgoraAudioFrame, channelId: String) -> Bool {
            true
        }
    }
    ```

    <PlatformWrapper platform="ios">
    - <Link to="{{Global.API_REF_IOS_ROOT_RTC_KIT}}/agoraaudioframedelegate/onrecordaudioframe(_:channelid:)">onRecordAudioFrame(_:channelId:)</Link>
    - <Link to="{{Global.API_REF_IOS_ROOT_RTC_KIT}}/agoraaudioframe/buffer">buffer</Link>
    </PlatformWrapper>
    <PlatformWrapper platform="macos">
    - <Link to="{{Global.API_REF_MACOS_ROOT_RTC_KIT}}/agoraaudioframedelegate/onrecordaudioframe(_:channelid:)">onRecordAudioFrame(_:channelId:)</Link>
    - <Link to="{{Global.API_REF_MACOS_ROOT_RTC_KIT}}/agoraaudioframe/buffer">buffer</Link>
    </PlatformWrapper>
</PlatformWrapper>
<PlatformWrapper platform="unity">
1. Convert the raw audio data to a float array:
    ```csharp
    internal static float[] ConvertByteToFloat16(byte[] byteArray)
    {
        var floatArray = new float[byteArray.Length / 2];
        for (var i = 0; i < floatArray.Length; i++)
        {
            floatArray[i] = BitConverter.ToInt16(byteArray, i * 2) / 32768f; // -Int16.MinValue
        }

        return floatArray;
    }
    ```
1.  Set up an audio source to play the recorded audio frame:
    ```csharp
    void SetupAudio(AudioSource aud, string clipName)
    {
        _audioClip = AudioClip.Create(clipName,
            SAMPLE_RATE / PULL_FREQ_PER_SEC * CHANNEL,
            CHANNEL, SAMPLE_RATE, true,
            OnAudioRead);
        aud.clip = _audioClip;
        aud.loop = true;
        if (isPlaying)
        {
            aud.Play();
        }
    }
    ```
1.  Feed the raw audio frame data to the audio source:
    ```csharp
    private void OnAudioRead(float[] data)
    {
        lock (_audioBuffer)
        {
            for (var i = 0; i < data.Length; i++)
            {
                if (_audioBuffer.Count > 0)
                {
                    data[i] = _audioBuffer.Get();
                    _readCount += 1;
                }
            }
            Debug.Log(string.Format("{0},{1},{2},{3},{4},{5},{6},{7},{8}", data[0], data[1], data[2], data[3], data[4], data[5], data[6], data[7], data[8]));
        }

        //Debug.LogFormat("buffer length remains: {0}", _writeCount - _readCount);
    }
    ```
<ProductWrapper notAllowed="voice-calling">
4.  Resize the captured video frame:
    ```csharp
    public void ResizeVideoFrame()
    {
        if (!_isTextureAttach)
        {
            var rd = LocalView.GetComponent<RawImage>();
            rd.texture = _texture;
            _isTextureAttach = true;
        }
        else if (VideoBuffer != null && VideoBuffer.Length != 0 && !_needResize)
        {
            lock (VideoBuffer)
            {
                _texture.LoadRawTextureData(VideoBuffer);
                _texture.Apply();
            }
        }
        else if (_needResize)
        {
            Debug.Log("Resized frame ==> (Width: " + _videoFrameHeight + " Height: " + _videoFrameWidth + ")");
            // Adjust the texture width and height.
            _texture.Resize(_videoFrameHeight, _videoFrameHeight);
            _texture.Apply();
            _needResize = false;
        }
    }
    ```

1. Configure the video encoder according to the resized frame:
    ```csharp
    // Set video encoder configuration
    public void SetVideoEncoderConfiguration()
    {
        VideoEncoderConfiguration config = new VideoEncoderConfiguration();
        config.dimensions = new VideoDimensions(_videoFrameWidth, _videoFrameHeight);
        agoraEngine.SetVideoEncoderConfiguration(config);
    }
    ```
    - <Link to="{{Global.API_REF_UNITY_ROOT}}/class_videoencoderconfiguration.html">VideoEncoderConfiguration</Link>
    - <Link to="{{Global.API_REF_UNITY_ROOT}}/class_irtcengine.html#api_irtcengine_setvideoencoderconfiguration">SetVideoEncoderConfiguration</Link>
</ProductWrapper>
</PlatformWrapper>