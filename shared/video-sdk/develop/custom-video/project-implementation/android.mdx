<PlatformWrapper platform="android">

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

### Custom video capture

The following figure shows the workflow you implement to capture and stream a custom video source in your <Vpl k="CLIENT"/>.

<details>
<summary>Custom video capture</summary>

![API call sequence](https://agora-doc.s3.us-east-1.amazonaws.com/images/video-sdk/custom-video-capture.svg)
</details>

Take the following steps to implement this workflow:

1. Create a custom video track

   To create a custom video track and obtain the video track ID, call `createCustomVideoTrack` after initializing an instance of `RtcEngine`. To create multiple custom video tracks, call the method multiple times.

   <Tabs groupId="language">
   <TabItem value="java" label="Java">
   <CodeBlock language="java" showLineNumbers>
   {`int videoTrackId = RtcEngine.createCustomVideoTrack();`}
   </CodeBlock>
   </TabItem>

   <TabItem value="kotlin" label="Kotlin" default>
   <CodeBlock language="kotlin" showLineNumbers>
   {`val videoTrackId = RtcEngine.createCustomVideoTrack()`}
   </CodeBlock>
   </TabItem>
   </Tabs>

1. Join a channel and publish the custom video track

   <Tabs groupId="language">
   <TabItem value="java" label="Java">
   <CodeBlock language="java" showLineNumbers>
   {`// Create a ChannelMediaOptions instance
    ChannelMediaOptions option = new ChannelMediaOptions();
    // Set the client role to BROADCASTER
    option.clientRoleType = Constants.CLIENT_ROLE_BROADCASTER;
    // Enable auto subscription of audio and video
    option.autoSubscribeAudio = true;
    option.autoSubscribeVideo = true;
    // Publish self-captured video stream
    option.publishCustomVideoTrack = true;
    // Set custom video track ID
    option.customVideoTrackId = videoTrackId;
    // Join a channel with the specified options
    int res = engine.joinChannel(accessToken, channelId, 0, option);`}
   </CodeBlock>
   </TabItem>

   <TabItem value="kotlin" label="Kotlin" default>
   <CodeBlock language="kotlin" showLineNumbers>
   {`// Create a ChannelMediaOptions instance
   val option = ChannelMediaOptions().apply {
       // Set the client role to BROADCASTER
       clientRoleType = Constants.CLIENT_ROLE_BROADCASTER
       // Enable auto subscription of audio and video
       autoSubscribeAudio = true
       autoSubscribeVideo = true
       // Publish self-captured video stream
       publishCustomVideoTrack = true
       // Set custom video track ID
       customVideoTrackId = videoTrackId
   }

   // Join a channel with the specified options
   val res = engine.joinChannel(accessToken, channelId, 0, option)
   `}
   </CodeBlock>
   </TabItem>
   </Tabs>

1. Implement your self-capture module

    <Vg k= "COMPANY"/> provides the [VideoFileReader](https://github.com/AgoraIO/API-Examples/blob/main/Android/APIExample/app/src/main/java/io/agora/api/example/utils/VideoFileReader.java) demo project that shows you how to read `YUV` format video data from a local file. In a production environment, create a custom video module for your device using <Vg k= "VSDK"/> based on your business requirements.

1. Push video data to the SDK 

    Before sending captured video frames to <Vg k= "VSDK"/>, integrate your video module with the `VideoFrame`. To ensure audio-video synchronization, best practice is to obtain the current monotonic time from <Vg k= "VSDK"/> and pass it as the timestamp parameter in the `VideoFrame`.

    <Admonition type="info" title="Information">
    To ensure audio-video synchronization, set the timestamp parameter of `VideoFrame` to the system's Monotonic Time. Use `getCurrentMonotonicTimeInMs` to obtain the current monotonic Time.
    </Admonition>

    Call `pushExternalVideoFrameById` [2/2] to push the captured video frames through the video track to <Vg k= "VSDK"/>. Ensure that the `videoTrackId` matches the track ID you specified when joining the channel. Customize parameters like pixel format, data type, and timestamp in the `VideoFrame`.

    The following code samples demonstrate pushing `I420`, `NV21`, `NV12`, and `Texture` format video data:
    
   <details>
   <summary>I420</summary>
   <Tabs groupId="language">
   <TabItem value="java" label="Java">
   <CodeBlock language="java" showLineNumbers>
   {`private void pushVideoFrameByI420(int trackId, byte[] yuv, int width, int height) {
      // Create an i420Buffer object and store the original YUV data in the buffer
      JavaI420Buffer i420Buffer = JavaI420Buffer.allocate(width, height);
      i420Buffer.getDataY().put(yuv, 0, i420Buffer.getDataY().limit());
      i420Buffer.getDataU().put(yuv, i420Buffer.getDataY().limit(), i420Buffer.getDataU().limit());
      i420Buffer.getDataV().put(yuv, i420Buffer.getDataY().limit() + i420Buffer.getDataU().limit(), i420Buffer.getDataV().limit());
      // Get the current monotonic time from the SDK
      long currentMonotonicTimeInMs = engine.getCurrentMonotonicTimeInMs();
      // Create a VideoFrame object, passing the I420 video frame to be pushed and the monotonic time of the video frame (in nanoseconds)
      VideoFrame videoFrame = new VideoFrame(i420Buffer, 0, currentMonotonicTimeInMs * 1000000);

      // Push the video frame to the SDK through the video track
      int ret = engine.pushExternalVideoFrameById(videoFrame, trackId);
      // Release the memory resources occupied by the i420Buffer object
      i420Buffer.release();

      if (ret != Constants.ERR_OK) {
         Log.w(TAG, "pushExternalVideoFrame error");
      }
   }`}
   </CodeBlock>
   </TabItem>
      
   <TabItem value="kotlin" label="Kotlin" default>
   <CodeBlock language="kotlin" showLineNumbers>
   {`private fun pushVideoFrameByI420(trackId: Int, yuv: ByteArray, width: Int, height: Int) {
      // Create an i420Buffer object and store the original YUV data in the buffer
      val i420Buffer = JavaI420Buffer.allocate(width, height)
      i420Buffer.getDataY().put(yuv, 0, i420Buffer.getDataY().limit())
      i420Buffer.getDataU().put(yuv, i420Buffer.getDataY().limit(), i420Buffer.getDataU().limit())
      i420Buffer.getDataV().put(yuv, i420Buffer.getDataY().limit() + i420Buffer.getDataU().limit(), i420Buffer.getDataV().limit())
               
      // Get the current monotonic time from the SDK
      val currentMonotonicTimeInMs = engine.getCurrentMonotonicTimeInMs()
            
      // Create a VideoFrame object, passing the I420 video frame to be pushed and the monotonic time of the video frame (in nanoseconds)
      val videoFrame = VideoFrame(i420Buffer, 0, currentMonotonicTimeInMs * 1_000_000)
            
      // Push the video frame to the SDK through the video track
      val ret = engine.pushExternalVideoFrameById(videoFrame, trackId)
            
      // Release the memory resources occupied by the i420Buffer object
      i420Buffer.release()
            
      if (ret != Constants.ERR_OK) {
         Log.w(TAG, "pushExternalVideoFrame error")
      }
   }`}
   </CodeBlock>
   </TabItem>
   </Tabs>
   </details>
      
   <details>
   <summary>NV21</summary>
   <Tabs groupId="language">
   <TabItem value="java" label="Java">
   <CodeBlock language="java" showLineNumbers>
   {`private void pushVideoFrameByNV21(int trackId, byte[] nv21, int width, height) {
      // Create a frameBuffer object and store the original YUV data in the NV21 format buffer
      VideoFrame.Buffer frameBuffer = new NV21Buffer(nv21, width, height, null);

      // Get the current monotonic time from the SDK
      long currentMonotonicTimeInMs = engine.getCurrentMonotonicTimeInMs();
      // Create a VideoFrame object, pass the NV21 video frame to be pushed and the monotonic time of the video frame (in nanoseconds)
      VideoFrame videoFrame = new VideoFrame(frameBuffer, 0, currentMonotonicTimeInMs * 1000000);

      // Push the video frame to the SDK through the video track
      int ret = engine.pushExternalVideoFrameById(videoFrame, trackId);

      if (ret != Constants.ERR_OK) {
         Log.w(TAG, "pushExternalVideoFrame error");
      }
   }`}
   </CodeBlock>
   </TabItem>

   <TabItem value="kotlin" label="Kotlin" default>
   <CodeBlock language="kotlin" showLineNumbers>
   {`private fun pushVideoFrameByNV21(trackId: Int, nv21: ByteArray, width: Int, height: Int) {
      // Create a frameBuffer object and store the original YUV data in the NV21 format buffer
      val frameBuffer: VideoFrame.Buffer = NV21Buffer(nv21, width, height, null)
   
      // Get the current monotonic time from the SDK
      val currentMonotonicTimeInMs = engine.getCurrentMonotonicTimeInMs()
   
      // Create a VideoFrame object, pass the NV21 video frame to be pushed and the monotonic time of the video frame (in nanoseconds)
      val videoFrame = VideoFrame(frameBuffer, 0, currentMonotonicTimeInMs * 1_000_000)
   
      // Push the video frame to the SDK through the video track
      val ret = engine.pushExternalVideoFrameById(videoFrame, trackId)
            
      if (ret != Constants.ERR_OK) {
         Log.w(TAG, "pushExternalVideoFrame error")
      }
   }`}
   </CodeBlock>
   </TabItem>
   </Tabs> 
   </details>
   <details>
      <summary>NV12</summary>

   <Tabs groupId="language">
   <TabItem value="java" label="Java">
   <CodeBlock language="java" showLineNumbers>
   {`private void pushVideoFrameByNV12(int trackId, ByteBuffer nv12, int width, int height) {
      // Create a frameBuffer object and store the original YUV data in the NV12 format buffer
      VideoFrame.Buffer frameBuffer = new NV12Buffer(width, height, width, height, nv12, null);
      // Get the current monotonic time from the SDK
      long currentMonotonicTimeInMs = engine.getCurrentMonotonicTimeInMs();
      // Create a VideoFrame object, pass the NV12 video frame to be pushed and the monotonic time of the video frame (in nanoseconds)
      VideoFrame videoFrame = new VideoFrame(frameBuffer, 0, currentMonotonicTimeInMs * 1000000);
      
      // Push the video frame to the SDK through the video track
      int ret = engine.pushExternalVideoFrameById(videoFrame, trackId);
      if (ret != Constants.ERR_OK) {
            Log.w(TAG, "pushExternalVideoFrame error");
      }
   }`}
   </CodeBlock>
   </TabItem>

   <TabItem value="kotlin" label="Kotlin" default>
   <CodeBlock language="kotlin" showLineNumbers>
   {`private fun pushVideoFrameByNV12(trackId: Int, nv12: ByteBuffer, width: Int, height: Int) {
      // Create a frameBuffer object and store the original YUV data in the NV12 format buffer
      val frameBuffer: VideoFrame.Buffer = NV12Buffer(width, height, width, height, nv12, null)
      // Get the current monotonic time from the SDK
      val currentMonotonicTimeInMs = engine.getCurrentMonotonicTimeInMs()
      // Create a VideoFrame object, pass the NV12 video frame to be pushed and the monotonic time of the video frame (in nanoseconds)
      val videoFrame = VideoFrame(frameBuffer, 0, currentMonotonicTimeInMs * 1_000_000)
      // Push the video frame to the SDK through the video track
      val ret = engine.pushExternalVideoFrameById(videoFrame, trackId)
         
      if (ret != Constants.ERR_OK) {
         Log.w(TAG, "pushExternalVideoFrame error")
      }
   }`}
   </CodeBlock>
   </TabItem>
   </Tabs>
   </details>
   <details>
   <summary>Texture</summary>

   <Tabs groupId="language">
   <TabItem value="java" label="Java">
   <CodeBlock language="java" showLineNumbers>
   {`private void pushVideoFrameByTexture(int trackId, int textureId, VideoFrame.TextureBuffer.Type textureType, int width, int height) {
      // Create a frameBuffer object to store the texture format video frame
      VideoFrame.Buffer frameBuffer = new TextureBuffer(
         EglBaseProvider.getCurrentEglContext(),
         width,
         height,
         textureType,
         textureId,
         new Matrix(),
         null,
         null,
         null
      );
      // Get the current monotonic time from the SDK
      long currentMonotonicTimeInMs = engine.getCurrentMonotonicTimeInMs();
      // Create a VideoFrame object, passing the texture video frame to be pushed and the monotonic time of the video frame (in nanoseconds)
      VideoFrame videoFrame = new VideoFrame(frameBuffer, 0, currentMonotonicTimeInMs * 1000000);
      // Push the video frame to the SDK through the video track
      int ret = engine.pushExternalVideoFrameById(videoFrame, trackId);
      if (ret != Constants.ERR_OK) {
         Log.w(TAG, "pushExternalVideoFrame error");
      }
   }`}
   </CodeBlock>
   </TabItem>

   <TabItem value="kotlin" label="Kotlin" default>
   <CodeBlock language="kotlin" showLineNumbers>
   {`private fun pushVideoFrameByTexture(
         trackId: Int,
         textureId: Int,
         textureType: VideoFrame.TextureBuffer.Type,
         width: Int,
         height: Int
      ) {
      // Create a frameBuffer object to store the texture format video frame
      val frameBuffer: VideoFrame.Buffer = TextureBuffer(
         EglBaseProvider.getCurrentEglContext(),
         width,
         height,
         textureType,
         textureId,
         Matrix(),
         null,
         null,
         null
      )

      // Get the current monotonic time from the SDK
      val currentMonotonicTimeInMs = engine.getCurrentMonotonicTimeInMs()
      // Create a VideoFrame object, passing the texture video frame to be pushed and the monotonic time of the video frame (in nanoseconds)
      val videoFrame = VideoFrame(frameBuffer, 0, currentMonotonicTimeInMs * 1_000_000)
      // Push the video frame to the SDK through the video track
      val ret = engine.pushExternalVideoFrameById(videoFrame, trackId)

      if (ret != Constants.ERR_OK) {
         Log.w(TAG, "pushExternalVideoFrame error")
      }
   }`}
   </CodeBlock>
   </TabItem>
   </Tabs>

   <Admonition type="info" title="Information">
   If the captured custom video format is Texture and remote users experience flickering or distortion in the captured video, it is recommended to first duplicate the video data and then send both the original and duplicated video data back to the <Vg k="VSDK"/>. This helps eliminate anomalies during internal data encoding processes.
   </Admonition>
   </details>

    
5. Destroy custom video tracks

    To stop custom video capture and destroy the video track, call `destroyCustomVideoTrack`. 

   <Tabs groupId="language">
   <TabItem value="java" label="Java">
   <CodeBlock language="java" showLineNumbers>
   {`// Destroy custom video track
   engine.destroyCustomVideoTrack(videoTrack);
   // Leave the channel
   engine.leaveChannelEx(connection);`}
   </CodeBlock>
   </TabItem>

   <TabItem value="kotlin" label="Kotlin" default>
   <CodeBlock language="kotlin" showLineNumbers>
   {`// Destroy custom video track
   engine.destroyCustomVideoTrack(videoTrack)
   // Leave the channel
   engine.leaveChannelEx(connection)`}
   </CodeBlock>
   </TabItem>
   </Tabs>

### Custom video rendering

To implement custom video rendering in your <Vpl k="CLIENT" />, refer to the following steps:

1. Set up `onCaptureVideoFrame` or `onRenderVideoFrame` callback to obtain the video data to be played.
1. Implement video rendering and playback yourself.

</PlatformWrapper>