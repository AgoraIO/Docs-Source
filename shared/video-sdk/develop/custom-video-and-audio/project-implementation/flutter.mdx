<PlatformWrapper platform="flutter">

### Implement a custom video source

In the following code example, you push an image to the video track using the basic custom video framework. To create the basic framework, take the following steps:

1. **Update the user interface**

    To enable a user to start pushing video frames, add a button to the user interface.

    Open `/lib/main.dart` and add the following lines after `ListView(...children: [` in the `build` method:

    ```dart
    ElevatedButton(
        onPressed:_isJoined ? () => {_pushVideoFrame()} : null,
        child: const Text("Push Video Frame"),
    ),
    ```

1. **Import the required dart libraries**

    To import dart libraries required for converting an image to a video frame, add the following statements after the last `import` statement in `/lib/main.dart`.

    ```dart
    import 'dart:typed_data';
    import 'dart:ui';
    import 'package:flutter/services.dart';
    ```

1. **Define variables to load and push image data**

    In `/lib/main.dart`, add the following declarations to the `_MyAppState` class:

    ```dart
    late final Uint8List _imageByteData;
    late final int _imageWidth;
    late final int _imageHeight;
    ```

1. **Enable publishing the custom video track**

    To allow publishing of video from a custom source, you call the `setExternalVideoSource` method of the `MediaEngine`. To do this, in `setupVideoSDKEngine`, add the following lines after the call to `agoraEngine.initialize`:

    ```dart
    await agoraEngine
        .getMediaEngine()
        .setExternalVideoSource(enabled: true, useTexture: false);
    ```

1. **Load the image to push as a video frame**

    Take the following steps to read the image from the assets folder and convert it to byte data:

    1. Add the following method to the `_MyAppState` class:

        ```dart
        Future<void> _loadImageByteData() async {
            ByteData data = await rootBundle.load("assets/agora-logo.png");
            Uint8List bytes =
                data.buffer.asUint8List(data.offsetInBytes, data.lengthInBytes);

            final image = await decodeImageFromList(bytes);

            final byteData =
                await image.toByteData(format: ImageByteFormat.rawStraightRgba);
            _imageByteData = byteData!.buffer.asUint8List();
            _imageWidth = image.width;
            _imageHeight = image.height;
            image.dispose();
        }
        ```

    1. To load the image at startup, add the following line at the end of the `setupVideoSDK()` method:
    
        ```dart
        _loadImageByteData();
        ```

1. **Push the video frames**

    When the user presses the **Push Video Frame** button, you call `_pushVideoFrame` to create an `ExternalVideoFrame` from the loaded image data and publish it using the `pushVideoFrame` method of the `MediaEngine`: To do this, add the following method to the `_MyAppState` class:

    ```dart
    Future<void> _pushVideoFrame() async {

        ExternalVideoFrame agoraFrame = ExternalVideoFrame(
            type: VideoBufferType.videoBufferRawData,
            format: VideoPixelFormat.videoPixelRgba,
            buffer: _imageByteData,
            stride: _imageWidth,
            height: _imageHeight,
            timestamp: DateTime.now().millisecondsSinceEpoch);

        await agoraEngine.getMediaEngine().pushVideoFrame(
            frame: agoraFrame);
    }
    ```

### Implement a custom audio source

To push audio from a custom source to a channel, take the following steps:

1. **Import the required Android and Java libraries**

    You use an `InputStream` to read the contents of the custom audio source. The <Vpl k="CLIENT" /> starts a separate `Process` to read and push the audio data. To use these libraries in your <Vpl k="CLIENT" />, add the following statements after the last `import` statement in `/app/java/com.example.<projectname>/MainActivity`.

    ```dart
    import android.os.Process;
    import java.io.InputStream;
    import java.io.IOException;
    ```

1. **Define variables to manage and push the audio stream**

    In `/app/java/com.example.<projectname>/MainActivity`, add the following declarations to the `MainActivity` class:

    ```dart
    // Audio file parameters
    private static final String AUDIO_FILE = "applause.wav"; // raw audio file
    private static final Integer SAMPLE_RATE = 44100;
    private static final Integer SAMPLE_NUM_OF_CHANNEL = 2;
    private static final Integer BITS_PER_SAMPLE = 16;
    private static final Integer SAMPLES = 441;
    private static final Integer BUFFER_SIZE = SAMPLES * BITS_PER_SAMPLE / 8 * SAMPLE_NUM_OF_CHANNEL;
    private static final Integer PUSH_INTERVAL = SAMPLES * 1000 / SAMPLE_RATE;

    private InputStream inputStream;
    private Thread pushingTask = new Thread(new PushingTask());
    private boolean pushing = false;
    ```

1. **Add a raw audio file to the project**

    In this example, you use an audio file as the source of your custom audio data. To add the audio file to your Android project, create a folder `app\src\main\assets` and add a sample audio file in `*.wav` or `*.raw` format to this folder. Update the value of the `AUDIO_FILE` variable to show the audio file name. Also make sure that the values of the audio file parameters in your code match the audio file you placed in the assets folder.

1. **Enable publishing the custom video track**

    When a user presses **Join**, you set the `ChannelMediaOptions` to disable the microphone audio track and enable the custom audio track. You also enable custom audio local playback and set the external audio source. To do this, add the following lines to the `joinChannel(View view)` method in the `MainActivity` class after `options.clientRoleType = Constants.CLIENT_ROLE_BROADCASTER;`:

    ```dart
    options.publishMicrophoneTrack = false; // Disable publishing microphone audio
    options.publishCustomAudioTrack = true; // Enable publishing custom audio
    options.enableAudioRecordingOrPlayout = true;

    agoraEngine.enableCustomAudioLocalPlayback(0, true);
    agoraEngine.setExternalAudioSource(true, SAMPLE_RATE, SAMPLE_NUM_OF_CHANNEL, 2, false, true);
    ```

1. **Open the audio file**

    When the <Vpl k="CLIENT" /> starts, you open the audio file. To do this, add the following lines at the bottom of the `onCreate` method:

    ```dart
    try {
        inputStream = this.getResources().getAssets().open(AUDIO_FILE);
    } catch (IOException e) {
        e.printStackTrace();
    }
    ```

1. **Start the task to push audio frames**

    When a user successfully joins a channel, you start the task that pushes audio frames. To do this, add the following lines at the bottom of the `onJoinChannelSuccess` callback in the `MainActivity` class:

    ```dart
    pushing = true;
    pushingTask.start();
    ```

1. **Read the input stream into a buffer**

    You read data from the input stream into a buffer. To do this, add the following method to the `MainActivity` class:

    ```dart
    private byte[] readBuffer() {
        int byteSize = BUFFER_SIZE;
        byte[] buffer = new byte[byteSize];
        try {
            if (inputStream.read(buffer) < 0) {
                inputStream.reset();
                return readBuffer();
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
        return buffer;
    }
    ```

1. **Push the audio frames**

    You push the data in the buffer as an audio frame using a separate process. To do this, define the following `Runnable` class in the `MainActivity` class:

    ```dart
    class PushingTask implements Runnable {
        long number = 0;

        @Override
        public void run() {
            Process.setThreadPriority(Process.THREAD_PRIORITY_URGENT_AUDIO);
            while (pushing) {
                long before = System.currentTimeMillis();
                agoraEngine.pushExternalAudioFrame(readBuffer(), 0);
                long now = System.currentTimeMillis();
                long consuming = now - before;
                if(consuming < PUSH_INTERVAL){
                    try {
                        Thread.sleep(PUSH_INTERVAL - consuming);
                    } catch (InterruptedException e) {
                    }
                }
            }
        }
    }
    ```

1. **Close the audio file**

    When the <Vpl k="CLIENT" /> is closed, you close the audio file. To do this, add the following lines at the bottom of the `onDestroy` method:

    ```dart
    try {
        inputStream.close();
    } catch (IOException e) {
        e.printStackTrace();
    }
    ```

</PlatformWrapper>
